# 十一、使爬虫真正成为一种服务

在本章中，我们将介绍：

*   创建和配置弹性云试用帐户
*   使用 curl 访问弹性云簇
*   使用 Python 连接到弹性云集群
*   使用 Python API 执行 Elasticsearch 查询
*   使用 Elasticsearch 查询具有特定技能的工作
*   修改 API 以按技能搜索作业
*   在环境中存储配置
    为 ECS 创建 AWS IAM 用户和密钥对
*   配置 Docker 以使用 ECR 进行身份验证
*   将容器推入 ECR
*   创建 ECS 集群
*   创建任务以运行容器
*   在 AWS 中启动和访问容器

# 介绍

在本章中，我们将首先添加一个使用 Elasticsearch 搜索工作列表的功能，并扩展此功能的 API。然后将 Elasticsearch 功能移动到 Elastic Cloud，这是云实现我们基于云的刮板的第一步。然后，我们将我们的 Docker 容器移动到 Amazon**弹性容器存储库**（**ECR**），最后在 Amazon**弹性容器服务**中运行我们的容器（和刮板）**ECS**。

# 创建和配置弹性云试用帐户

在此配方中，我们将创建并配置一个 Elastic Cloud 试用帐户，以便我们可以将 Elasticsearch 用作托管服务。Elastic Cloud 是由 Elasticsearch 的创建者提供的云服务，并提供 Elasticsearch 的完全托管实现。

While we have examined putting Elasticsearch in a Docker container, actually running a container with Elasticsearch within AWS is very difficult due to a number of memory requirements and other system configurations that are complicated to get working within ECS.  Therefore, for a cloud solution, we will use Elastic Cloud.

# 怎么做

我们将按照以下方法继续制作配方：

1.  打开浏览器并导航至[https://www.elastic.co/cloud/as-a-service/signup](https://www.elastic.co/cloud/as-a-service/signup) 。您将看到类似于以下内容的页面：

![](img/db8027f8-ba93-421c-a026-fb2cedd5ddcb.png)

The Elastic Cloud signup page

2.  输入您的电子邮件，然后按“开始免费试用”按钮。当电子邮件到达时，请验证您自己。您将进入创建群集的页面：

![](img/c08434c1-5481-4c1f-8582-674152731121.png)

Cluster creation page

3.  在其他示例中，我将在俄勒冈州（us-west-2）地区使用 AWS（而不是 Google），因此我将在此集群中同时选择这两种。您可以选择适合您的云和地区。您可以保留其他选项，只需按 create。然后，您将看到您的用户名和密码。记下它们。下面的屏幕截图展示了如何显示用户名和密码：

![](img/c8d98099-d766-43d2-9825-62dc4ddd9b9c.png)

The credentials info for the Elastic Cloud account We won't use the Cloud ID in any recipes.

4.  接下来，您将看到您的端点。Elasticsearch URL 对我们很重要：

![](img/054dab3f-ed34-43a7-9cab-099198e4bc8a.png)

5.  就这样，你已经准备好出发了（至少 14 天）！

# 使用 curl 访问弹性云簇

Elasticsearch 基本上是通过 REST API 访问的。Elastic Cloud 与 REST API 没有什么不同，实际上是一个完全相同的 API。我们只需要知道如何正确构建 URL 以进行连接。让我们看看这个。

# 怎么做

我们按照以下方法进行配方：

1.  当您注册弹性云时，会为您提供各种端点和变量，例如用户名和密码。URL 类似于以下内容：

```py
https://<account-id>.us-west-2.aws.found.io:9243
```

Depending on the cloud and region, the rest of the domain name, as well as the port, may differ.

2.  我们将使用以下 URL 的一个轻微变体与弹性云通信和验证：

```py
https://<username>:<password>@<account-id>.us-west-2.aws.found.io:9243
```

3.  目前，我的是（在您阅读本文时将被禁用）：

```py
https://elastic:tduhdExunhEWPjSuH73O6yLS@d7c72d3327076cc4daf5528103c46a27.us-west-2.aws.found.io:9243
```

4.  可以使用 curl 检查基本身份验证和连接：

```py
$ curl https://elastic:tduhdExunhEWPjSuH73O6yLS@7dc72d3327076cc4daf5528103c46a27.us-west-2.aws.found.io:9243
{
  "name": "instance-0000000001",
  "cluster_name": "7dc72d3327076cc4daf5528103c46a27",
  "cluster_uuid": "g9UMPEo-QRaZdIlgmOA7hg",
  "version": {
    "number": "6.1.1",
    "build_hash": "bd92e7f",
    "build_date": "2017-12-17T20:23:25.338Z",
    "build_snapshot": false,
    "lucene_version": "7.1.0",
    "minimum_wire_compatibility_version": "5.6.0",
    "minimum_index_compatibility_version": "5.0.0"
  },
  "tagline": "You Know, for Search"
}
Michaels-iMac-2:pems michaelheydt$
```

我们站起来说话！

# 使用 Python 连接到弹性云集群

现在让我们看看如何使用 Elasticsearch Python 库连接到弹性云。

# 准备

此配方的代码在`11/01/elasticcloud_starwars.py`脚本中。此脚本将从 swapi.co API/网站上抓取星球大战角色数据，并将其放入弹性云中。

# 怎么做

我们按照以下方法进行配方：

1.  以 Python 脚本的形式执行该文件：

```py
$ python elasticcloud_starwars.py
```

2.  这将循环最多 20 个字符，并将它们放入文档类型为`people`的`sw`索引中。代码很简单（将 URL 替换为您的 URL）：

```py
from elasticsearch import Elasticsearch
import requests
import json

if __name__ == '__main__':
    es = Elasticsearch(
        [
            "https://elastic:tduhdExunhEWPjSuH73O6yLS@d7c72d3327076cc4daf5528103c46a27.us-west-2.aws.found.io:9243"
        ])

i = 1
while i<20:
    r = requests.get('http://swapi.co/api/people/' + str(i))
    if r.status_code is not 200:
        print("Got a " + str(r.status_code) + " so stopping")
        break
 j = json.loads(r.content)
 print(i, j)
 #es.index(index='sw', doc_type='people', id=i, body=json.loads(r.content))
 i = i + 1
```

3.  连接是使用添加了用户名和密码的 URL 进行的。使用 GET 请求从 swapi.co 提取数据，然后调用 Elasticsearch 对象上的`.index()`，您将看到类似于以下内容的输出：

```py
1 Luke Skywalker
2 C-3PO
3 R2-D2
4 Darth Vader
5 Leia Organa
6 Owen Lars
7 Beru Whitesun lars
8 R5-D4
9 Biggs Darklighter
10 Obi-Wan Kenobi
11 Anakin Skywalker
12 Wilhuff Tarkin
13 Chewbacca
14 Han Solo
15 Greedo
16 Jabba Desilijic Tiure
Got a 404 so stopping
```

# 还有更多。。。

当您注册 Elastic Cloud 时，您还获得了 Kibana 的 URL。Kibana 是 Elasticsearch 强大的图形前端：

1.  在浏览器中打开 URL。您将看到一个登录页面：

![](img/8cba8c2e-8870-4c2c-a721-4a1787387ad8.png)

The Kibana login page

2.  输入用户名和密码，您将被带到主仪表板：

![](img/6aff28f8-f90a-4018-a809-990fceae344a.png)

Creating an index pattern

我们被要求为我们的应用程序 sw 创建的索引创建索引模式。在索引模式文本框中，输入`sw*`，然后按下一步

3.  将要求我们选择时间筛选器字段名称。选择我不想使用时间筛选器，然后按“创建索引模式”按钮。几分钟后，您将看到对已创建索引的确认：

![](img/951c8ef3-95f8-454a-b76c-7315b6f68b47.png)

The index that was created

4.  现在单击“发现”菜单项，您将进入交互式数据资源管理器，您将看到我们刚才输入的数据：

![](img/3c49c59b-7f1d-4f48-b3bc-081f342a95b8.png)

The data added to our index

在这里，您可以浏览数据并查看 Elasticsearch 如何有效地存储和组织这些数据。

# 使用 Python API 执行 Elasticsearch 查询

现在让我们看看如何使用 Elasticsearch Python 库搜索 Elasticsearch。我们将对星球大战索引执行一个简单的搜索。

# 准备

确保将示例中的连接 URL 修改为您的 URL。

# 怎么做

搜索代码在`11/02/search_starwars_by_haircolor.py`脚本中，只需执行脚本即可运行。这是一个相当简单的搜索，可以找到发色为`blond`的角色：

1.  代码的主要部分是：

```py
es = Elasticsearch(
    [
        "https://elastic:tduhdExunhEWPjSuH73O6yLS@7dc72d3327076cc4daf5528103c46a27.us-west-2.aws.found.io:9243"
    ])

search_definition = {
    "query":{
        "match": {
            "hair_color": "blond"
        }
    }
}

result = es.search(index="sw", doc_type="people", body=search_definition)
print(json.dumps(result, indent=4))
```

2.  搜索是通过构造一个表示 Elasticsearch DSL 查询的字典来执行的。在这种情况下，我们的查询要求所有文档的`"hair_color"`属性为`"blond"`。然后将该对象作为`.search`方法的主体参数传递。该方法的结果是描述所发现内容（或未发现内容）的词汇.在这种情况下：

```py
{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 1.3112576,
    "hits": [
      {
        "_index": "sw",
        "_type": "people",
        "_id": "1",
        "_score": 1.3112576,
        "_source": {
          "name": "Luke Skywalker",
          "height": "172",
          "mass": "77",
          "hair_color": "blond",
          "skin_color": "fair",
          "eye_color": "blue",
          "birth_year": "19BBY",
          "gender": "male",
          "homeworld": "https://swapi.co/api/planets/1/",
          "films": [
            "https://swapi.co/api/films/2/",
            "https://swapi.co/api/films/6/",
            "https://swapi.co/api/films/3/",
            "https://swapi.co/api/films/1/",
            "https://swapi.co/api/films/7/"
          ],
          "species": [
            "https://swapi.co/api/species/1/"
          ],
          "vehicles": [
            "https://swapi.co/api/vehicles/14/",
            "https://swapi.co/api/vehicles/30/"
          ],
          "starships": [
            "https://swapi.co/api/starships/12/",
            "https://swapi.co/api/starships/22/"
          ],
          "created": "2014-12-09T13:50:51.644000Z",
          "edited": "2014-12-20T21:17:56.891000Z",
          "url": "https://swapi.co/api/people/1/"
        }
      },
      {
        "_index": "sw",
        "_type": "people",
        "_id": "11",
        "_score": 0.80259144,
        "_source": {
          "name": "Anakin Skywalker",
          "height": "188",
          "mass": "84",
          "hair_color": "blond",
          "skin_color": "fair",
          "eye_color": "blue",
          "birth_year": "41.9BBY",
          "gender": "male",
          "homeworld": "https://swapi.co/api/planets/1/",
          "films": [
            "https://swapi.co/api/films/5/",
            "https://swapi.co/api/films/4/",
            "https://swapi.co/api/films/6/"
          ],
          "species": [
            "https://swapi.co/api/species/1/"
          ],
          "vehicles": [
            "https://swapi.co/api/vehicles/44/",
            "https://swapi.co/api/vehicles/46/"
          ],
          "starships": [
            "https://swapi.co/api/starships/59/",
            "https://swapi.co/api/starships/65/",
            "https://swapi.co/api/starships/39/"
          ],
          "created": "2014-12-10T16:20:44.310000Z",
          "edited": "2014-12-20T21:17:50.327000Z",
          "url": "https://swapi.co/api/people/11/"
        }
      }
    ]
  }
}
```

结果为我们提供了一些有关搜索执行的元数据，然后在`hits`属性中显示结果。每次点击返回实际文档以及索引名、文档类型、文档 ID、，和分数。分数是文档与搜索查询相关性的 lucene 计算。虽然此查询使用属性与值的精确匹配，但您可以看到这两个文档仍然有不同的分数。我不确定为什么在这种情况下，但是搜索也可能不那么精确，并且基于各种内置的启发式方法来查找“像”某个句子的项目，也就是说，当你在谷歌搜索框中输入文本时。

# 还有更多。。。

Elasticsearch DSL 和搜索引擎本身都非常强大和富有表现力。我们将只看这个例子，在下一个配方中再看一个，所以我们不会详细介绍。要了解更多关于 DSL 的信息，您可以从官方文档开始，网址为 [https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html) 。

# 使用 Elasticsearch 查询具有特定技能的工作

在此配方中，我们回到使用我们创建的爬虫程序，在 Elasticsearch 中从 StackOverflow 中抓取和存储工作列表。然后，我们扩展此功能，查询 Elasticsearch 以查找包含一个或多个指定技能的工作列表。

# 准备

我们将使用的示例编码为使用本地 Elastic 云引擎，而不是本地 Elastic 搜索引擎。如果需要，您可以更改。现在，我们将在本地运行的单个 python 脚本中执行此过程，而不是在容器内或 API 后面。

# 怎么做

我们按照以下方法进行配方：

1.  配方代码在`11/03/search_jobs_by_skills.py`文件中：

```py
from sojobs.scraping import get_job_listing_info
from elasticsearch import Elasticsearch
import json

if __name__ == "__main__":

    es = Elasticsearch()

    job_ids = ["122517", "163854", "138222", "164641"]

    for job_id in job_ids:
        if not es.exists(index='joblistings', doc_type='job-listing', id=job_id):
            listing = get_job_listing_info(job_id)
            es.index(index='joblistings', doc_type='job-listing', id=job_id, body=listing)

    search_definition = {
        "query": {
            "match": {
                "JSON.skills": {
                    "query": "c#"
                }
            }
        }
    }

    result = es.search(index="joblistings", doc_type="job-listing", body=search_definition)
    print(json.dumps(result, indent=4))
```

此代码的第一部分定义了四个要放入 Elasticsearch 的工作列表（如果它们已经不可用）。它迭代此工作的 ID，如果还不可用，则检索它们并将它们放入 Elasticsearch。

本文的其余部分定义了针对 Elasticsearch 执行的查询，并遵循执行搜索的相同模式。唯一的区别在于搜索条件的定义。最终，我们希望将工作技能列表与工作列表中的技能匹配

此查询只是将单个技能与我们的工作列表文档中的技能字段中的技能进行匹配。该示例指定要与目标文档中的 JSON.skills 属性匹配。这些文档中的技巧就在文档的根下面，因此在这个语法中，我们用 JSON 作为它的序言。

Elasticsearch 中的此属性是一个数组，如果该属性数组中的任何值为`"c#"`，则我们拥有的查询值将与文档匹配。

2.  仅使用 Elasticsearch 中的这四个文档运行此搜索，结果如下（此处的输出仅显示结果，而不是返回的四个文档的完整内容）：

```py
{
  "took": 4,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 1.031828,
    "hits": [

```

Elasticsearch 中的每个工作都有 C#表示技能（我随机挑选了这些文档，所以这有点巧合）。

3.  这些搜索的结果将返回已识别的每个文档的全部内容。如果我们不希望每次点击都返回整个文档，我们可以更改查询以实现此目的。让我们修改查询以仅返回点击中的 ID。将`search_definition`变量更改为以下内容：

```py
search_definition = {
    "query": {
        "match": {
            "JSON.skills": {
                "query": "c# sql"
            }
        }
    },
    "_source": ["ID"]
}
```

4.  包含`"_source"`属性会告诉 Elasticsearch 在结果中返回指定的文档属性。执行此查询会导致以下输出：

```py
{
  "took": 4,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 1.031828,
    "hits": [
      {
        "_index": "joblistings",
        "_type": "job-listing",
        "_id": "164641",
        "_score": 1.031828,
        "_source": {
          "ID": "164641"
        }
      },
      {
        "_index": "joblistings",
        "_type": "job-listing",
        "_id": "122517",
        "_score": 0.9092852,
        "_source": {
          "ID": "122517"
        }
      }
    ]
  }
}
```

Each of the hits now only returns the ID property of the document. This will help control the size of the result if there are a lot of hits.

5.  让我们进入这个配方的最终目标，识别具有多种技能的文档。这实际上是对`search_defintion`的一个非常简单的更改：

```py
search_definition={
  "query": {
    "match": {
      "JSON.skills": {
        "query": "c# sql",
        "operator": "AND"
      }
    }
  },
  "_source": [
    "ID"
  ]
}
```

这说明我们只需要技能同时包含`"c#"`和`"sql"`的文档。运行脚本的结果如下：

```py
{
  "took": 4,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 1.031828,
    "hits": [
      {
        "_index": "joblistings",
        "_type": "job-listing",
        "_id": "164641",
        "_score": 1.031828,
        "_source": {
          "ID": "164641"
        }
      },
      {
        "_index": "joblistings",
        "_type": "job-listing",
        "_id": "122517",
        "_score": 0.9092852,
        "_source": {
          "ID": "122517"
        }
      }
    ]
  }
}
```

结果集现在减少到两次点击，如果您检查，这些是技能中仅有的两次具有这些值的点击。

# 修改 API 以按技能搜索作业

在这个配方中，我们将修改现有的 API，添加一个方法，以便能够使用一组技能搜索作业。

# 怎么做

我们将扩展 API 代码。我们将对 API 的实现进行两个基本更改。第一个是，我们将为搜索功能添加额外的 Flask RESTful API 实现，第二个是，我们将通过环境变量配置 Elasticsearch 和我们自己的微服务的地址。

API 实现在`11/04_scraper_api.py`中。默认情况下，实现会尝试连接到本地系统上的 Elasticsearch。如果您使用的是 Elastic Cloud，请确保更改 URL（并确保索引中有文档）：

1.  只需执行脚本即可启动 API：

```py
$ python scraper_api.py
Starting the job listing API ...
 * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)
 * Restarting with stat
Starting the job listing API ...
 * Debugger is active!
 * Debugger pin code: 449-370-213
```

2.  为了发出搜索请求，我们向`/joblistings/search`端点发送 POST，以`"skills=<skills separated with a space>"`的形式传递数据。下面使用 C#和 SQL 搜索作业：

```py
$ curl localhost:8080/joblistings/search -d "skills=c# sql"
{
  "took": 4,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 1.031828,
    "hits": [
      {
        "_index": "joblistings",
        "_type": "job-listing",
        "_id": "164641",
        "_score": 1.031828,
        "_source": {
          "ID": "164641"
        }
      },
      {
        "_index": "joblistings",
        "_type": "job-listing",
        "_id": "122517",
        "_score": 0.9092852,
        "_source": {
          "ID": "122517"
        }
      }
    ]
  }
}
```

我们得到了我们在上一个配方中看到的结果。现在，我们可以通过 REST 在互联网上访问我们的搜索功能！

# 工作原理

这通过添加另一个 Flask RESTful 类实现来实现：

```py
class JobSearch(Resource):
    def post(self):
        skills = request.form['skills']
        print("Request for jobs with the following skills: " + skills)

        host = 'localhost'
        if os.environ.get('ES_HOST'):
            host = os.environ.get('ES_HOST')
        print("ElasticSearch host: " + host)

        es = Elasticsearch(hosts=[host])
        search_definition = {
            "query": {
                "match": {
                    "JSON.skills": {
                        "query": skills,
                        "operator": "AND"
                    }
                }
            },
            "_source": ["ID"]
        }

        try:
            result = es.search(index="joblistings", doc_type="job-listing", body=search_definition)
            print(result)
            return result

        except:
            return sys.exc_info()[0]

api.add_resource(JobSearch, '/', '/joblistings/search')
```

此类实现了一个 post 方法作为映射到`/joblistings/search`的资源。post 操作的原因是我们正在传递一个由多个单词组成的字符串。虽然这可能是 GET 操作中的 URL 编码，但 post 允许我们将其作为键控值传递。虽然我们只有一个键，但是 skills，以后扩展到其他键以支持其他搜索参数，只需添加即可。

# 还有更多。。。

从 API 实现中执行搜索的决定应该被视为一个系统的发展。我的观点，也是我的观点（但我想其他人也会同意），就像 API 如何调用用于实际抓取的微服务一样，它也应该调用处理搜索的微服务（然后，该微服务将与 Elasticsearch 接口）。存储从刮片微服务返回的文档，以及访问 Elasticsearch 以检查缓存的文档也是如此。但出于我们的目的，我们将尽量保持简单。

# 在环境中存储配置

此配方指出了对上一配方中 API 代码的更改，以支持**12 因子**应用程序的*因子*之一。12 因子应用程序被定义为设计为作为软件即服务运行的应用程序。我们已经朝此方向移动了一段时间，将其分解为可以独立运行的组件，如脚本或容器，我们很快就会在云中看到。您可以在[了解所有关于 12 因素应用程序的信息 https://12factor.net/](https://12factor.net/) 。

Factor-3 指出，我们应该通过环境变量将配置传递给我们的应用程序。虽然我们绝对不希望将 URL 等硬编码到外部服务，但使用配置文件也不是最佳做法。当部署到各种环境（如容器或云）时，配置文件通常在映像中得到修复，并且由于应用程序被动态部署到不同的环境，因此无法按需更改

解决此问题的最佳方法是始终在环境变量中查找可根据应用程序运行方式更改的配置设置。大多数运行 12 因素应用程序的工具允许根据环境决定应用程序应运行的方式和位置设置环境变量。

# 怎么做

在我们的工作清单实现中，我们使用以下代码来确定 Elasticsearch 的主机：

```py
host = 'localhost'
if os.environ.get('ES_HOST'):
    host = os.environ.get('ES_HOST')
print("ElasticSearch host: " + host)

es = Elasticsearch(hosts=[host])
```

这是一件简单明了的事情，但对于让我们的应用程序难以置信地可移植到不同的环境非常重要。这默认使用 localhost，但允许我们使用`ES_HOST`环境变量定义不同的主机。

skills search 的实现还进行了类似的更改，允许我们更改我们的刮片微服务的默认本地主机：

```py
CONFIG = {'AMQP_URI': "amqp://guest:guest@localhost"}
if os.environ.get('JOBS_AMQP_URL'):
    CONFIG['AMQP_URI'] = os.environ.get('JOBS_AMQP_URL')
print("AMQP_URI: " + CONFIG["AMQP_URI"])

with ClusterRpcProxy(CONFIG) as rpc:
```

我们将在接下来的配方中看到 Factor-3 的使用，因为我们将此代码转移到 AWS 的弹性容器服务中。

# 为 ECS 创建 AWS IAM 用户和密钥对

在此配方中，我们将创建一个身份和访问管理（IAM）用户帐户，以允许我们访问 AWS 弹性容器服务（ECS）。我们需要这样做，因为我们将在 Docker 容器中打包刮片器和 API（我们已经这样做了），但现在我们要将这些容器移动到 AWS ECS 中并从中运行它们，使我们的刮板成为真正的云服务。

# 准备

这假设您已经创建了一个 AWS 帐户，我们在本书前面讨论 SQS 和 S3 时使用了该帐户。您不需要其他帐户，但我们需要创建一个具有使用 ECS 权限的非 root 用户。

# 怎么做

有关创建具有 ECS 权限和密钥对的 IAM 用户的说明，请参见[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html) 。

本页有很多说明，例如设置 VPC 和安全组。现在只需关注创建用户、分配权限和创建密钥对。

我想强调的一点是您创建的 IAM 帐户的权限。有关此操作的详细说明，请参见[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html) 。我发现这样做不正确。请确保在检查刚创建的用户的权限时，已分配以下权限：

![](img/f67ea806-ca40-49f7-a2f1-fd561116c372.png)

AWS IAM credentials

我将这些直接附加到我用于 ECS 的帐户上，而不是通过组。如果未分配这些，则在将容器推送到 ECR 时，您将获得神秘的身份验证错误。

还有一件事：我们需要访问密钥 ID 和关联的密钥。这将在创建用户时提供给您。如果您没有记录它，您可以在用户帐户页面的“安全凭据”选项卡中创建另一个：

![](img/9fa87343-5f4c-439a-abc8-f79339dfcd9b.png)

请注意，您无法获取已存在的访问密钥 ID 的机密。您必须进行另一个访问密钥 ID。

# 配置 Docker 以使用 ECR 进行身份验证

在此配方中，我们将配置 docker，使其能够将容器推送到弹性容器存储库（ECR）

# 准备

Docker 的一个关键元素是 Docker 容器存储库。我们以前使用 Docker Hub 拉取容器。但我们也可以将容器推送到 Docker Hub 或任何与 Docker 兼容的容器存储库，如 ECR。但这并非没有问题。docker CLI 自然不知道如何使用 ECR 进行身份验证，因此我们必须克服一些困难才能使其正常工作

确保安装了 AWS 命令行工具。这些工具需要通过 Docker 认证才能使用 ECR。在[中可以找到良好的说明 https://docs.aws.amazon.com/cli/latest/userguide/installing.html](https://docs.aws.amazon.com/cli/latest/userguide/installing.html) 。一旦验证安装，您需要将 CLI 配置为使用在上一个配方中创建的帐户。这可以使用`aws configure`命令完成，该命令将提示您输入四项：

```py
$ aws configure
AWS Access Key ID [None]: AKIA---------QKCVQAA
AWS Secret Access Key [None]: KEuSaLgn4dpyXe-------------VmEKdhV
Default region name [None]: us-west-2
Default output format [None]: json
```

将键交换为先前检索到的键，并设置默认区域和数据类型。

# 怎么做

我们按照以下方法进行配方：

1.  执行以下命令。这将返回一个命令，用 ECR 对 Docker 进行身份验证：

```py
$ aws ecr get-login --no-include-email --region us-west-2
docker login -u AWS -p eyJwYXlsb2FkIjoiN3BZVWY4Q2JoZkFwYUNKOUp6c1BkRy80VmRYN0Y2LzQ0Y2pVNFJKZTA5alBrUEdSMHlNUk9TMytsTFVURGtxb3Q5VTZqV0xxNmRCVHJnL1FIb2lGbEF0dVZhNFpEOUkxb1FxUTNwcUluaVhqS1FCZmU2WTRLNlQrbjE4VHdiOEpqbmtwWjJJek8xRlR2Y2Y5S3NGRlQrbDZhcktUNXZJbjNkb1czVGQ2TXZPUlg5cE5Ea2w4S29vamt6SE10Ym8rOW5mLzBvVkRRSDlaY3hqRG45d0FzNVA5Z1BPVUU5OVFrTEZGeENPUHJRZmlTeHFqaEVPcGo3ZVAxL3pCNnFTdjVXUEozaUNtV0I0b1lFNEcyVzA4M2hKQmpESUFTV1VMZ1B0MFI2YUlHSHJxTlRvTGZOR1R5clJ2VUZKcnFWZGptMkZlR0ppK3I5emFrdGFKeDJBNVRCUzBzZDZaOG1yeW1Nd0dBVi81NDZDeU1XYVliby9reWtaNUNuZE8zVXFHdHFKSnJmQVRKakhlVU1jTXQ1RjE0Tk83OWR0ckNnYmZmUHdtS1hXOVh6MklWUG5VUlJsekRaUjRMMVFKT2NjNlE0NWFaNkR2enlDRWw1SzVwOEcvK3lSMXFPYzdKUWpxaUErdDZyaCtDNXJCWHlJQndKRm5mcUJhaVhBMVhNMFNocmlNd0FUTXFjZ0NtZTEyUGhOMmM2c0pNTU5hZ0JMNEhXSkwyNXZpQzMyOVI2MytBUWhPNkVaajVMdG9iMVRreFFjbjNGamVNdThPM0ppZnM5WGxPSVJsOHlsUUh0LzFlQ2ZYelQ1cVFOU2g1NjFiVWZtOXNhNFRRWlhZUlNLVVFrd3JFK09EUXh3NUVnTXFTbS9FRm1PbHkxdEpncXNzVFljeUE4Y1VYczFnOFBHL2VwVGtVTG1ReFYwa0p5MzdxUmlIdHU1OWdjMDRmZWFSVGdSekhQcXl0WExzdFpXcTVCeVRZTnhMeVVpZW0yN3JkQWhmaStpUHpMTXV1NGZJa3JjdmlBZFF3dGwrdEVORTNZSVBhUnZJMFN0Q1djN2J2blI2Njg3OEhQZHJKdXlYaTN0czhDYlBXNExOamVCRm8waUt0SktCckJjN0tUZzJEY1d4NlN4b1Vkc2ErdnN4V0N5NWFzeWdMUlBHYVdoNzFwOVhFZWpPZTczNE80Z0l5RklBU0pHR3o1SVRzYVkwbFB6ajNEYW9QMVhOT3dhcDYwcC9Gb0pQMG1ITjNsb202eW1EaDA0WEoxWnZ0K0lkMFJ4bE9lVUt3bzRFZFVMaHJ2enBMOUR4SGI5WFFCMEdNWjFJRlI0MitSb3NMaDVQa0g1RHh1bDJZU0pQMXc0UnVoNUpzUm5rcmF3dHZzSG5PSGd2YVZTeWl5bFR0cFlQY1haVk51NE5iWnkxSzQwOG5XTVhiMFBNQzJ5OHJuNlpVTDA9IiwiZGF0YWtleSI6IkFRRUJBSGo2bGM0WElKdy83bG4wSGMwMERNZWs2R0V4SENiWTRSSXBUTUNJNThJblV3QUFBSDR3ZkFZSktvWklodmNOQVFjR29HOHdiUUlCQURCb0Jna3Foa2lHOXcwQkJ3RXdIZ1lKWUlaSUFXVURCQUV1TUJFRURQdTFQVXQwRDFkN3c3Rys3Z0lCRUlBN21Xay9EZnNOM3R5MS9iRFdRYlZtZjdOOURST2xhQWFFbTBFQVFndy9JYlBjTzhLc0RlNDBCLzhOVnR0YmlFK1FXSDBCaTZmemtCbzNxTkE9IiwidmVyc2lvbiI6IjIiLCJ0eXBlIjoiREFUQV9LRVkiLCJleHBpcmF0aW9uIjoxNTE1NjA2NzM0fQ== https://270157190882.dkr.ecr.us-west-2.amazonaws.com
```

此输出是您需要执行的命令，以使 docker CLI 通过 ECR 认证！这个秘密只在几个小时内有效（我相信是十二个小时）。你可以从它以`docker login`开头的地方复制到这个秘密末尾的 URL 的末尾。

2.  在 Mac（和 Linux）上，我通常将其缩短为以下内容：

```py
$(aws ecr get-login --no-include-email --region us-west-2)
WARNING! Using --password via the CLI is insecure. Use --password-stdin.
Login Succeeded
```

容易多了。此时，我们可以使用 docker 命令将容器推送到 ECR。

This is an area where I've seen a couple of problems.  I've found the URL at the end of the secret can still be the root user and not the user you created for ECR (this login HAS to be for that user).  If that is the case, later commands will get weird authentication issues.  The fix is to delete all the AWS CLI configuration files and reconfigure.  This fix doesn't always work. Sometimes, I've had to use a fresh system/VM, go through the AWS CLI install/ config, and then generate this secret to get it to work.

# 将容器推入 ECR

在此配方中，我们将重建 API 和微服务容器，并将它们推送到 ECR。我们还将把 RabbitMQ 容器推送到 ECR

# 准备

请忍耐，因为这可能会变得棘手。除了容器映像之外，我们还需要将 RabbitMQ 容器推送到 ECR。ECS 不与 Docker Hub 通信，也无法提取该图像。这将非常方便，但同时可能也是一个安全问题。

Pushing these containers to ECR from a home internet connection can take a long time. I create a Linux image in EC2 in the same region as my ECR, pulled down the code from github, build the containers on that EC2 system, and then push to ECR.  The push takes a matter of minutes, if not seconds.

首先，让我们在本地系统上重新构建 API 和微服务容器。我在`11/05`配方文件夹中包含了 Python 文件、两个 docker 文件和一个微服务配置文件。

让我们从 API 容器的构建开始：

```py
$ docker build ../.. -f Dockerfile-api -t scraper-rest-api:latest
```

此 docker 文件与之前的 API docker 文件类似，修改为从`11/05`文件夹复制文件。

```py
FROM python:3
WORKDIR /usr/src/app

RUN pip install Flask-RESTful Elasticsearch Nameko
COPY 11/11/scraper_api.py .

CMD ["python", "scraper_api.py"]
```

然后为 scraper microservice 构建容器：

```py
$ docker build ../.. -f Dockerfile-microservice -t scraper-microservice:latest
```

此 Dockerfile 与 microservice 的 Dockerfile 略有不同。其内容如下：

```py
FROM python:3
WORKDIR /usr/src/app

RUN pip install nameko BeautifulSoup4 nltk lxml
RUN python -m nltk.downloader punkt -d /usr/share/nltk_data all

COPY 11/05/scraper_microservice.py .
COPY modules/sojobs sojobs

CMD ["python", "-u", "scraper_microservice.py"]
```

现在，我们已经准备好配置 ECR 来存储容器以供 ECS 使用。

We now run the microservice using python and not with the "nameko run" command.  This is due to an issue with sequencing the launch of containers in ECS.  The "nameko run" command does not perform well if the RabbitMQ server is not already running, which is not guaranteed in ECS.  So, we start this with python.  Because of this, the implementation has a startup that essentially copies the code for "nameko run" and wraps it with a while loop and exception handlers as it retries connections until the container is stopped.

# 怎么做

我们按照以下方法进行配方：

1.  当登录到我们为 ECS 创建的帐户时，我们可以访问弹性容器存储库。此服务可以保存我们的容器供 ECS 使用。有许多 AWS CLI 命令可用于使用 ECR。让我们从以下列出现有存储库的命令开始：

```py
$ aws ecr describe-repositories
{
    "repositories": []
}
```

2.  现在我们没有任何存储库，所以让我们创建一些。我们将创建三个存储库，一个用于不同的容器：scraper rest api、scraper microservice，另一个用于 RabbitMQ 容器，我们将其称为`rabbitmq`。每个存储库根据其名称映射到一个容器，但可以有多个标记（每个版本最多 1000 个不同的版本/标签）。让我们创建三个存储库：

```py
$ aws ecr create-repository --repository-name scraper-rest-api
{
  "repository": {
    "repositoryArn": "arn:aws:ecr:us-west-2:414704166289:repository/scraper-rest-api",
    "repositoryUri": "414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-rest-api",
    "repositoryName": "scraper-rest-api",
    "registryId": "414704166289",
    "createdAt": 1515632756.0
  }
}

05 $ aws ecr create-repository --repository-name scraper-microservice
{
  "repository": {
    "repositoryArn": "arn:aws:ecr:us-west-2:414704166289:repository/scraper-microservice",
    "registryId": "414704166289",
    "repositoryName": "scraper-microservice",
    "repositoryUri": "414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-microservice",
    "createdAt": 1515632772.0
  }
}

05 $ aws ecr create-repository --repository-name rabbitmq
{
  "repository": {
    "repositoryArn": "arn:aws:ecr:us-west-2:414704166289:repository/rabbitmq",
    "repositoryName": "rabbitmq",
    "registryId": "414704166289",
    "createdAt": 1515632780.0,
    "repositoryUri": "414704166289.dkr.ecr.us-west-2.amazonaws.com/rabbitmq"
  }
}
```

Note the data returned.  We will need the repository URL for each in the following step(s).

3.  我们需要*标记*我们的本地容器图像，以便他们的 docker 知道当我们*推送*它们时，它们应该进入我们 ECR 中的特定存储库。此时，docker 中应该有以下图像：

```py
$ docker images
REPOSITORY           TAG          IMAGE ID     CREATED        SIZE
scraper-rest-api     latest       b82653e11635 29 seconds ago 717MB
scraper-microservice latest       efe19d7b5279 11 minutes ago 4.16GB
rabbitmq             3-management 6cb6e2f951a8 2 weeks ago    151MB
python               3            c1e459c00dc3 3 weeks ago    692MB
```

4.  使用`<image-id> <ECR-repository-uri>`docker 标记进行标记。让我们标记所有三个（我们不需要做 python 图像）：

```py
$ docker tag b8 414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-rest-api

$ docker tag ef 414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-microservice

$ docker tag 6c 414704166289.dkr.ecr.us-west-2.amazonaws.com/rabbitmq
```

5.  docker 图像列表现在显示标记图像以及原始图像：

```py
$ docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-rest-api latest b82653e11635 4 minutes ago 717MB
scraper-rest-api latest b82653e11635 4 minutes ago 717MB
414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-microservice latest efe19d7b5279 15 minutes ago 4.16GB
scraper-microservice latest efe19d7b5279 15 minutes ago 4.16GB
414704166289.dkr.ecr.us-west-2.amazonaws.com/rabbitmq latest 6cb6e2f951a8 2 weeks ago 151MB
rabbitmq 3-management 6cb6e2f951a8 2 weeks ago 151MB
python 3 c1e459c00dc3 3 weeks ago 692MB
```

6.  现在，我们最终将图像推入 ECR：

```py
$ docker push 414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-rest-api
The push refers to repository [414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-rest-api]
7117db0da9a9: Pushed
8eb1be67ed26: Pushed
5fcc76c4c6c0: Pushed
6dce5c484bde: Pushed
057c34df1f1a: Pushed
3d358bf2f209: Pushed
0870b36b7599: Pushed
8fe6d5dcea45: Pushed
06b8d020c11b: Pushed
b9914afd042f: Pushed
4bcdffd70da2: Pushed
latest: digest: sha256:2fa2ccc0f4141a1473386d3592b751527eaccb37f035aa08ed0c4b6d7abc9139 size: 2634

$ docker push 414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-microservice
The push refers to repository [414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-microservice]
3765fccaf6a6: Pushed
4bde7a8212e1: Pushed
d0aa245987b4: Pushed
5657283a8f79: Pushed
4f33694fe63a: Pushed
5fcc76c4c6c0: Pushed
6dce5c484bde: Pushed
057c34df1f1a: Pushed
3d358bf2f209: Pushed
0870b36b7599: Pushed
8fe6d5dcea45: Pushed
06b8d020c11b: Pushed
b9914afd042f: Pushed
4bcdffd70da2: Pushed
latest: digest: sha256:02c1089689fff7175603c86d6ef8dc21ff6aaffadf45735ef754f606f2cf6182 size: 3262

$ docker push 414704166289.dkr.ecr.us-west-2.amazonaws.com/rabbitmq
The push refers to repository [414704166289.dkr.ecr.us-west-2.amazonaws.com/rabbitmq]
e38187f05202: Pushed
ea37471972cd: Pushed
2f1d47e88a53: Pushed
e8c84964de08: Pushed
d0537ac3fb13: Pushed
9f345d60d035: Pushed
b45610229549: Pushed
773afacc96cc: Pushed
5eb8d21fccbb: Pushed
10699a5bd960: Pushed
27be686b9e1f: Pushed
96bfbdb03e1c: Pushed
1709335ba200: Pushed
2ec5c0a4cb57: Pushed
latest: digest: sha256:74308ef1dabc1a0b9615f756d80f5faf388f4fb038660ae42f437be45866b65e size: 3245
```

7.  现在检查图像是否已发送到存储库。以下显示了`scraper-rest-api`的情况：

```py
$ aws ecr list-images --repository-name scraper-rest-api
{
  "imageIds": [
    {
      "imageTag": "latest",
      "imageDigest": "sha256:2fa2ccc0f4141a1473386d3592b751527eaccb37f035aa08ed0c4b6d7abc9139"
    }
  ]
}
```

现在我们的容器存储在 ECR 中，我们可以继续创建一个集群来运行容器。

# 创建 ECS 集群

Elastic Container Service（ECS）是一个 AWS 服务，它在云中运行 Docker 容器在使用 ECS 时，我们将看到一个简单的部署，在单个 EC2 虚拟机上运行我们的容器。我们的目标是将我们的刮板放到云上。关于使用 ECS 扩展刮板的详细信息将在下一次发布（并预定）。

# 怎么做

我们首先使用 AWS CLI 创建一个 ECR 集群。我们将在集群中创建一个 EC2 虚拟机来运行我们的容器

I've included a shell file, in the `11/06` folder, names `create-cluster-complete.sh`, which runs through all of these commands in one run. 

配置此配置有许多步骤，但都相当简单。让我们来了解一下：

1.  下面创建一个名为 scraper cluster 的 ECR 集群：

```py
$ aws ecs create-cluster --cluster-name scraper-cluster
{
  "cluster": {
    "clusterName": "scraper-cluster",
    "registeredContainerInstancesCount": 0,
    "clusterArn": "arn:aws:ecs:us-west-2:414704166289:cluster/scraper-cluster",
    "status": "ACTIVE",
    "activeServicesCount": 0,
    "pendingTasksCount": 0,
    "runningTasksCount": 0
  }
}
```

哇，那很容易！嗯，还有一些细节需要处理。目前，我们还没有任何 EC2 实例来运行容器。我们还需要设置密钥对、安全组、IAM 策略等等！看起来很多，但我们会很快很容易地度过难关。

2.  创建密钥对。每个 EC2 实例都需要一个来启动，并且需要远程进入实例（如果您愿意的话）。下面创建一个密钥对，将其放入本地文件，然后向 AWS 确认该密钥对已创建：

```py
$ aws ec2 create-key-pair --key-name ScraperClusterKP --query 'KeyMaterial' --output text > ScraperClusterKP.pem

$ aws ec2 describe-key-pairs --key-name ScraperClusterKP
{
  "KeyPairs": [
    {
      "KeyFingerprint": "4a:8a:22:fa:53:a7:87:df:c5:17:d9:4f:b1:df:4e:22:48:90:27:2d",
      "KeyName": "ScraperClusterKP"
    }
  ]
}
```

3.  现在我们创建安全组。安全组允许我们从 Internet 打开群集实例的端口，从而允许我们访问容器中运行的应用程序。我们将创建一个安全组，其中包含端口 22（ssh）和 80（http），以及 RabbitMQ 的两个端口（5672 和 15672）opened。我们需要 80 open 与 REST API 对话（我们将在下一个配方中将 80 映射到 8080 容器）。我们不需要 15672 open，但它们允许您从 AWS 外部连接到 RabbitMQ，从而有助于调试流程。以下四个命令创建安全组和该组中的规则：

```py
$ aws ec2 create-security-group --group-name ScraperClusterSG --description "Scraper Cluster SG”
{
  "GroupId": "sg-5e724022"
}

$ aws ec2 authorize-security-group-ingress --group-name ScraperClusterSG --protocol tcp --port 22 --cidr 0.0.0.0/0

$ aws ec2 authorize-security-group-ingress --group-name ScraperClusterSG --protocol tcp --port 80 --cidr 0.0.0.0/0

$ aws ec2 authorize-security-group-ingress --group-name ScraperClusterSG --protocol tcp --port 5672 --cidr 0.0.0.0/0

$ aws ec2 authorize-security-group-ingress --group-name ScraperClusterSG --protocol tcp --port 15672 --cidr 0.0.0.0/0
```

You can confirm the contents of the security group using the aws ec2 describe-security-groups --group-names ScraperClusterSG command. This will output a JSON representation of the group.

4.  要将 EC2 实例启动到 ECS 集群中，它需要有一个 IAM 策略以允许其连接。它还需要具备 ECR 的各种能力，例如拉动容器。这些在配方目录中包含的两个文件`ecsPolicy.json`和`rolePolicy.json`中定义。以下命令将向 IAM 注册这些策略（忽略输出）：

```py
$ aws iam create-role --role-name ecsRole --assume-role-policy-document file://ecsPolicy.json

$ aws iam put-role-policy --role-name ecsRole --policy-name ecsRolePolicy --policy-document file://rolePolicy.json

$ aws iam create-instance-profile --instance-profile-name ecsRole

$ aws iam add-role-to-instance-profile --instance-profile-name ecsRole --role-name ecsRole
```

We need to do one more thing before we launch the instance.  We need to have a file to pass user data to the instance that tells the instance which cluster to connect to. If we don't do this, it will connect to a cluster named `default` instead of `scraper-cluster`.  This file is `userData.txt` in the recipe directory.  There is no real action here as I provided the file.

5.  新的，我们在集群中启动了一个实例。我们需要使用 ECS 优化的 AMI 或使用 ECS 容器代理创建 AMI。我们将使用预构建的 AMI 和此代理。下面启动该实例：

```py
$ aws ec2 run-instances --image-id ami-c9c87cb1 --count 1 --instance-type m4.large --key-name ScraperClusterKP --iam-instance-profile "Name= ecsRole" --security-groups ScraperClusterSG --user-data file://userdata.txt
```

这将抛出一点 JSON 来描述您的实例

6.  几分钟后，您可以检查此实例是否正在容器中运行：

```py
$ aws ecs list-container-instances --cluster scraper-cluster
{
  "containerInstanceArns": [
    "arn:aws:ecs:us-west-2:414704166289:container-instance/263d9416-305f-46ff-a344-9e7076ca352a"
  ]
}
```

令人惊叹的现在我们需要定义要在容器实例上运行的任务。

This is an m4.large instance.  It's a bit larger than the t2.micro that fits within the free-tier.  So, make sure you don't leave this running if you want to keep things cheap.

# 创建任务以运行容器

在此配方中，我们将创建一个 ECS 任务。一个任务告诉 ECR 集群管理器要运行哪些容器。任务是对 ECR 中要运行哪些容器以及每个容器所需参数的描述。任务描述与我们使用 Docker Compose 所做的非常相似。

# 准备

任务定义可以通过 GUI 构建，也可以通过提交任务定义 JSON 文件来启动。我们将使用后一种技术并检查文件`td.json`的结构，该文件描述了如何一起运行容器。该文件位于`11/07`配方文件夹中。

# 怎么做

以下命令将任务注册到 ECS：

```py
$ aws ecs register-task-definition --cli-input-json file://td.json
{
  "taskDefinition": {
    "volumes": [

    ],
    "family": "scraper",
    "memory": "4096",
    "placementConstraints": [

    ]
  ],
  "cpu": "1024",
  "containerDefinitions": [
    {
      "name": "rabbitmq",
      "cpu": 0,
      "volumesFrom": [

      ],
      "mountPoints": [

      ],
      "portMappings": [
        {
          "hostPort": 15672,
          "protocol": "tcp",
          "containerPort": 15672
        },
        {
          "hostPort": 5672,
          "protocol": "tcp",
          "containerPort": 5672
        }
      ],
      "environment": [

      ],
      "image": "414704166289.dkr.ecr.us-west-2.amazonaws.com/rabbitmq",
      "memory": 256,
      "essential": true
    },
    {
      "name": "scraper-microservice",
      "cpu": 0,
      "essential": true,
      "volumesFrom": [

      ],
      "mountPoints": [

      ],
      "portMappings": [

      ],
      "environment": [
        {
          "name": "AMQP_URI",
          "value": "pyamqp://guest:guest@rabbitmq"
        }
      ],
      "image": "414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-microservice",
      "memory": 256,
      "links": [
        "rabbitmq"
      ]
    },
    {
      "name": "api",
      "cpu": 0,
      "essential": true,
      "volumesFrom": [

      ],
      "mountPoints": [

      ],
      "portMappings": [
        {
          "hostPort": 80,
          "protocol": "tcp",
          "containerPort": 8080
        }
      ],
      "environment": [
        {
          "name": "AMQP_URI",
          "value": "pyamqp://guest:guest@rabbitmq"
        },
        {
          "name": "ES_HOST",
          "value": "https://elastic:tduhdExunhEWPjSuH73O6yLS@7dc72d3327076cc4daf5528103c46a27.us-west-2.aws.found.io:9243"
        }
      ],
      "image": "414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-rest-api",
      "memory": 128,
      "links": [
        "rabbitmq"
      ]
    }
  ],
  "requiresCompatibilities": [
    "EC2"
  ],
  "status": "ACTIVE",
  "taskDefinitionArn": "arn:aws:ecs:us-west-2:414704166289:task-definition/scraper:7",
  "requiresAttributes": [
    {
      "name": "com.amazonaws.ecs.capability.ecr-auth"
    }
  ],
  "revision": 7,
  "compatibilities": [
    "EC2"
  ]
}
```

输出是 ECS 填写的定义，并确认收到任务定义。

# 工作原理

任务定义由两个主要部分组成。第一个部分给出了关于整个任务的一般信息，例如容器作为一个整体允许多少内存和 CPU。然后它由一个部分组成，定义了我们将运行的三个容器。

该文件以定义总体设置的几行开始：

```py
{
    "family": "scraper-as-a-service",
    "requiresCompatibilities": [
        "EC2"
    ],
    "cpu": "1024",
    "memory": "4096",
    "volumes": [],

```

任务的实际名称由`"family"`属性定义。我们声明我们的容器需要 EC2（任务可以在没有 EC2 的情况下运行-我们需要它）。然后我们声明要将整个任务限制在指定的 CPU 和内存量内，并且不附加任何卷。

现在让我们看看定义容器的部分。它从以下内容开始：

```py
"containerDefinitions": [
```

现在让我们检查每个容器定义。以下是`rabbitmq`容器的定义：

```py
{
    "name": "rabbitmq",
    "image": "414704166289.dkr.ecr.us-west-2.amazonaws.com/rabbitmq",
    "cpu": 0,
    "memory": 256,
    "portMappings": [
        {
            "containerPort": 15672,
            "hostPort": 15672,
            "protocol": "tcp"
        },
        {
            "containerPort": 5672,
            "hostPort": 5672,
            "protocol": "tcp"
        }
    ],
    "essential": true
},
```

第一行定义容器的名称，此名称还参与 API 和 scraper 容器对此容器名称的 DNS 解析。image 标记定义要为容器提取的 ECR 存储库 URI

Make sure to change the image URL for this and the other two containers to that of your repositories.

接下来是此容器允许的最大 CPU（0 为无限）和内存的定义。端口映射定义容器主机（我们在群集中创建的 EC2 实例）和容器之间的映射。我们映射两个 RabbitMQ 端口

The essential tag states that this container must remain running.  If it fails, the entire task will be stopped.

定义的下一个容器是 scraper microservice：

```py
{
    "name": "scraper-microservice",
    "image": "414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-microservice",
    "cpu": 0,
    "memory": 256,
    "essential": true,
    "environment": [
        {
            "name": "AMQP_URI",
            "value": "pyamqp://guest:guest@rabbitmq"
        }
    ],
    "links": [
        "rabbitmq"
    ]
},
```

不同之处在于它定义了一个环境变量和链接。环境变量是`rabbitmq`容器的 URL。ECS 将确保在该容器内将环境变量设置为该值（实现因子-3）。虽然这与我们在 docker compose 上本地运行时的 URL 相同，如果`rabbitmq`容器的名称不同或在另一个集群上，则可能是不同的 URL。

链接设置需要一点说明。链接是 Docker 不推荐使用的功能，但在 ECS 中仍然使用。ECS 要求它们让容器解析同一集群网络中其他容器的 DNS 名称。这告诉 ECS，当此容器尝试解析`rabbitmq`主机名时（根据环境变量中的定义），它应该返回分配给该容器的 IP 地址。

文件的其余部分定义了 API 容器：

```py
{
  "name": "api",
  "image": "414704166289.dkr.ecr.us-west-2.amazonaws.com/scraper-rest-api",
  "cpu": 0,
  "memory": 128,
  "essential": true,
  "portMappings": [
    {
      "containerPort": 8080,
      "hostPort": 80,
      "protocol": "tcp"
    }
  ],
  "environment": [
    {
      "name": "AMQP_URI",
      "value": "pyamqp://guest:guest@rabbitmq"
    },
    {
      "name": "ES_HOST",
      "value": "https://elastic:tduhdExunhEWPjSuH73O6yLS@7dc72d3327076cc4daf5528103c46a27.us-west-2.aws.found.io:9243"
    }
  ],
  "links": [
    "rabbitmq"
  ]
}
    ]
}
```

在这个定义中，我们定义了允许 HTTP 进入容器的端口映射，并设置了 API 用于与弹性云和`rabbitmq`服务器（将请求传递给`scraper-microservice`容器）对话的环境变量。这还定义了到`rabbitmq`的链接，因为这也需要解决。

# 在 AWS 中启动和访问容器

在此配方中，我们将通过告诉 ECS 运行任务定义来启动 scraper 作为服务。然后，我们将通过发出 curl 来获取作业列表的内容来检查它是否正在运行。

# 准备

在运行任务之前，我们需要做一件快速的事情。ECS 中的任务经过修订。每次您使用相同的名称（“系列”）注册任务定义时，ECS 都会定义一个新的修订号。您可以运行任何修订

要运行最新的任务定义，我们需要列出该族的任务定义并查找最新的修订号。以下列出了群集中的所有任务定义。此时，我们只有一个任务定义：

```py
$ aws ecs list-task-definitions
{
  "taskDefinitionArns": [
    "arn:aws:ecs:us-west-2:414704166289:task-definition/scraper-as-a-service:17"
  ]
}
```

请注意，我的修订号是 17。虽然这是我当前唯一注册的任务版本，但我已经注册（并取消注册）了 16 个以前的修订。

# 怎么做

我们按照以下方法进行配方：

1.  现在我们可以运行我们的任务了。我们使用以下命令执行此操作：

```py
$ aws ecs run-task --cluster scraper-cluster --task-definition scraper-as-a-service:17 --count 1
{
  "tasks": [
    {
      "taskArn": "arn:aws:ecs:us-west-2:414704166289:task/00d7b868-1b99-4b54-9f2a-0d5d0ae75197",
      "version": 1,
      "group": "family:scraper-as-a-service",
      "containerInstanceArn": "arn:aws:ecs:us-west-2:414704166289:container-instance/5959fd63-7fd6-4f0e-92aa-ea136dabd762",
      "taskDefinitionArn": "arn:aws:ecs:us-west-2:414704166289:task-definition/scraper-as-a-service:17",
      "containers": [
        {
          "name": "rabbitmq",
          "containerArn": "arn:aws:ecs:us-west-2:414704166289:container/4b14d4d5-422c-4ffa-a64c-476a983ec43b",
          "lastStatus": "PENDING",
          "taskArn": "arn:aws:ecs:us-west-2:414704166289:task/00d7b868-1b99-4b54-9f2a-0d5d0ae75197",
          "networkInterfaces": [

          ]
        },
        {
          "name": "scraper-microservice",
          "containerArn": "arn:aws:ecs:us-west-2:414704166289:container/511b39d2-5104-4962-a859-86fdd46568a9",
          "lastStatus": "PENDING",
          "taskArn": "arn:aws:ecs:us-west-2:414704166289:task/00d7b868-1b99-4b54-9f2a-0d5d0ae75197",
          "networkInterfaces": [

          ]
        },
        {
          "name": "api",
          "containerArn": "arn:aws:ecs:us-west-2:414704166289:container/0e660af7-e2e8-4707-b04b-b8df18bc335b",
          "lastStatus": "PENDING",
          "taskArn": "arn:aws:ecs:us-west-2:414704166289:task/00d7b868-1b99-4b54-9f2a-0d5d0ae75197",
          "networkInterfaces": [

          ]
        }
      ],
      "launchType": "EC2",
      "overrides": {
        "containerOverrides": [
          {
            "name": "rabbitmq"
          },
          {
            "name": "scraper-microservice"
          },
          {
            "name": "api"
          }
        ]
      },
      "lastStatus": "PENDING",
      "createdAt": 1515739041.287,
      "clusterArn": "arn:aws:ecs:us-west-2:414704166289:cluster/scraper-cluster",
      "memory": "4096",
      "cpu": "1024",
      "desiredStatus": "RUNNING",
      "attachments": [

      ]
    }
  ],
  "failures": [

  ]
}

```

输出为我们提供了任务的当前状态。第一次运行时，需要一点时间才能开始，因为容器正在复制到 EC2 实例。延迟 u 的主要原因是包含所有 NLTK 数据的`scraper-microservice`容器。

2.  您可以使用以下命令检查任务的状态：

```py
$ aws ecs describe-tasks --cluster scraper-cluster --task 00d7b868-1b99-4b54-9f2a-0d5d0ae75197
```

您需要更改任务 GUID 以匹配运行任务时输出的`"taskArn"`属性中的 GUID。当所有容器都在运行时，我们就可以测试 API 了。

3.  要调用我们的服务，我们需要找到群集实例的 IP 地址或 DNS 名称。当我们创建集群时，您可以通过门户或使用以下命令从输出中获取此信息。首先，描述集群实例：

```py
$ aws ecs list-container-instances --cluster scraper-cluster
{
  "containerInstanceArns": [
    "arn:aws:ecs:us-west-2:414704166289:container-instance/5959fd63-7fd6-4f0e-92aa-ea136dabd762"
  ]
}
```

4.  使用 EC2 实例的 GUID，我们可以查询其信息并使用以下内容提取 EC2 实例 ID：

```py
$ aws ecs describe-container-instances --cluster scraper-cluster --container-instances 5959fd63-7fd6-4f0e-92aa-ea136dabd762 | grep "ec2InstanceId"
            "ec2InstanceId": "i-08614daf41a9ab8a2",
```

5.  使用该实例 ID，我们可以获得 DNS 名称：

```py
$ aws ec2 describe-instances --instance-ids i-08614daf41a9ab8a2 | grep "PublicDnsName"
                    "PublicDnsName": "ec2-52-27-26-220.us-west-2.compute.amazonaws.com",
                                        "PublicDnsName": "ec2-52-27-26-220.us-west-2.compute.amazonaws.com"
                                "PublicDnsName": "ec2-52-27-26-220.us-west-2.compute.amazonaws.com"
```

6.  使用该 DNS 名称，我们可以进行卷曲以获得作业列表：

```py
$ curl ec2-52-27-26-220.us-west-2.compute.amazonaws.com/joblisting/122517 | head -n 6
```

我们得到了如下熟悉的结果！

```py
{
  "ID": "122517",
  "JSON": {
    "@context": "http://schema.org",
    "@type": "JobPosting",
    "title": "SpaceX Enterprise Software Engineer, Full Stack",
```

我们的爬虫现在正在云端运行！

# 还有更多。。。

我们的 scraper 正在一个`m4.large`实例上运行，所以我们想关闭它，以不超过免费层的使用量。这是一个两步过程。首先，需要终止集群中的 EC2 实例，并删除集群。请注意，删除集群不会终止 EC2 实例。

我们可以使用以下命令终止 EC2 实例（以及我们刚刚通过询问集群获得的实例 ID）：

```py
$ aws ec2 terminate-instances --instance-ids i-08614daf41a9ab8a2
{
  "TerminatingInstances": [
    {
      "CurrentState": {
        "Name": "shutting-down",
        "Code": 32
      },
      "PreviousState": {
        "Name": "running",
        "Code": 16
      },
      "InstanceId": "i-08614daf41a9ab8a2"
    }
  ]
}
```

可以通过以下方式删除群集：

```py
$ aws ecs delete-cluster --cluster scraper-cluster
{
  "cluster": {
    "activeServicesCount": 0,
    "pendingTasksCount": 0,
    "clusterArn": "arn:aws:ecs:us-west-2:414704166289:cluster/scraper-cluster",
    "runningTasksCount": 0,
    "clusterName": "scraper-cluster",
    "registeredContainerInstancesCount": 0,
    "status": "INACTIVE"
  }
}
```