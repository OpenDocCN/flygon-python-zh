# 四、文件系统和目录

在本章中，我们将介绍以下配方：

*   遍历文件夹递归遍历文件系统中的路径并检查其内容
*   使用路径以独立于系统的方式构建路径
*   展开文件名查找与特定模式匹配的所有文件
*   获取文件信息检测文件或目录的属性
*   命名的临时文件使用您也需要从其他进程访问的临时文件
*   内存和磁盘缓冲区如果临时缓冲区大于阈值，则将其假脱机到磁盘
*   管理文件名编码使用文件名编码
*   复制目录复制整个目录的内容
*   安全地替换文件内容如何在出现故障时安全地替换文件内容

# 介绍

处理文件和目录对于大多数软件来说都是很自然的事情，我们作为用户每天都在做这些事情，但是作为一名开发人员，您很快就会发现它可能比预期的更复杂，特别是当需要支持多个平台或涉及编码时。

Python 标准库有许多强大的工具来处理文件和目录。起初，可能很难在`os`、`shutil`、`stat`和`glob`函数中找到这些函数，但一旦您了解了所有这些函数，很明显，标准库提供了一套处理文件和目录的强大工具。

# 遍历文件夹

在使用文件系统中的路径时，通常需要查找直接包含在子文件夹中的所有文件。考虑复制目录或计算其大小；在这两种情况下，您都需要获取包含在要复制的目录中或要计算其大小的文件的完整列表。

# 怎么做。。。

此配方的步骤如下所示：

1.  `os`模块中的`os.walk`函数用于递归遍历一个目录，它的使用不是立即的，但我们可以轻松地将其包装成一个方便的所有包含文件的生成器：

```py
import os

def traverse(path):
    for basepath, directories, files in os.walk(path):
        for f in files:
            yield os.path.join(basepath, f)
```

2.  然后，我们可以迭代`traverse`并在上面应用我们需要的任何操作：

```py
for f in traverse('.'):
    print(f)
```

# 它是如何工作的。。。

`os.walk`函数用于导航目录及其所有子文件夹。对于找到的每个目录，它返回三个值：目录本身、包含的子目录和包含的文件。然后，它将移动到它刚才提供的目录的子目录中，并为该子目录返回相同的三个值。

这意味着在我们的配方中，`basepath`始终是正在检查的当前目录，`directories`是它的子目录，`files`是它包含的文件。

通过迭代当前目录中包含的文件列表并将它们的名称与目录路径本身连接起来，我们可以获得目录中包含的所有文件的路径。由于`os.walk`随后将移动到所有子目录中，我们将能够返回直接或间接位于所需路径内的所有文件。

# 使用路径

Python 最初是作为一种系统管理语言创建的。它原本是为 Unix 系统编写脚本的，因此导航磁盘一直是该语言的核心部分之一，但在最新版本的 Python 中，这一点通过`pathlib`模块进一步扩展，这使得构建引用文件或目录的路径非常方便和容易，不必关心我们正在运行的系统。

由于编写多平台软件可能会很麻烦，因此具有抽象底层系统约定的中间层并允许我们编写在任何地方都能工作的代码是非常重要的。

尤其是在处理路径时，Unix 和 Windows 系统处理路径的方式之间的差异可能会产生问题。事实上，一个系统使用`/`和另一个`\`来分离路径的各个部分，这本身就很麻烦，但 Windows 也有驱动程序的概念，而 Unix 系统没有，因此我们需要一些东西，使我们能够抽象这些差异，并轻松管理路径。

# 怎么做。。。

为此配方执行以下步骤：

1.  `pathlib`库允许我们根据您所使用的系统正确地执行正确的操作，从构成它的部分构建路径：

```py
>>> import pathlib
>>> 
>>> path = pathlib.Path('somefile.txt')
>>> path.write_text('Hello World')  # Write some text into file.
11
>>> print(path.resolve())  # Print absolute path
/Users/amol/wrk/pythonstlcookbook/somefile.txt
>>> path.read_text()  # Check the file content
'Hello World'
>>> path.unlink()  # Destroy the file
```

2.  有趣的是，相同的操作会在 Windows 上产生相同的精确结果，即使`path.resolve()`会打印出稍微不同的结果：

```py
>>> print(path.resolve())  # Print absolute path
C:\\wrk\\pythonstlcookbook\\somefile.txt
```

3.  一旦有了`pathlib.Path`实例，我们甚至可以使用`/`操作符在文件系统中移动：

```py
>>> path = pathlib.Path('.')
>>> path = path.resolve()
>>> path
PosixPath('/Users/amol/wrk/pythonstlcookbook')
>>> path = path / '..'
>>> path.resolve()
PosixPath('/Users/amol/wrk')
```

前面的代码在 Windows 和 Linux/macOS 上都能工作，并产生了预期的结果，尽管我是在类似 Unix 的系统上编写的。

# 还有更多。。。

`pathlib.Path`实际上根据我们所处的系统构建不同的对象。在 POSIX 系统上，它将导致一个`pathlib.PosixPath`对象，而在 Windows 系统上，它将导致一个`pathlib.WindowsPath`对象。

不可能在 POSIX 系统上构建`pathlib.WindowsPath`，因为它是在 Windows 系统调用之上实现的，而 Windows 系统调用在 Unix 系统上不可用。如果您需要在 POSIX 系统上使用 Windows 路径（或在 Windows 系统上使用 POSIX 路径），您可以依赖`pathlib.PureWindowsPath`和`pathlib.PurePosixPath`。

这两个对象不会实现实际访问文件的功能（读、写、链接、解析绝对路径等），但它们允许您执行仅与操作路径本身相关的简单操作。

# 扩展文件名

在我们系统的日常使用中，我们习惯于提供路径，例如`*.py`，以识别所有 Python 文件，因此，当我们的用户向我们的软件提供一个或多个文件时，他们希望能够执行相同的操作，这并不奇怪。

通常，通配符由 shell 本身进行扩展，但是假设您正在从配置文件中读取通配符，或者您想编写一个工具来清除当前项目中的`.pyc`文件（已编译 Python 字节码的缓存），那么 Python 标准库就具备了您所需的功能。

# 怎么做。。。

此配方的步骤如下：

1.  `pathlib`能够在您提供的路径上执行许多操作。其中之一是解析通配符：

```py
>>> list(pathlib.Path('.').glob('*.py'))
[PosixPath('conf.py')]
```

2.  它还支持递归解析通配符：

```py
>>> list(pathlib.Path('.').glob('**/*.py'))
[PosixPath('conf.py'), PosixPath('venv/bin/cmark.py'), 
 PosixPath('venv/bin/rst2html.py'), ...]
```

# 获取文件信息

当用户提供一条路径时，您真的不知道该路径指的是什么。是档案吗？它是目录吗？它真的存在吗？

通过检索文件信息，我们可以获取有关所提供路径的详细信息，例如它是否指向文件以及该文件有多大。

# 怎么做。。。

为此配方执行以下步骤：

1.  在任何`pathlib.Path`上使用`.stat()`将提供有关路径的大多数详细信息：

```py
>>> pathlib.Path('conf.py').stat()
os.stat_result(st_mode=33188, 
               st_ino=116956459, 
               st_dev=16777220, 
               st_nlink=1, 
               st_uid=501, 
               st_gid=20, 
               st_size=9306, 
               st_atime=1519162544, 
               st_mtime=1510786258, 
               st_ctime=1510786258)
```

返回的详细信息涉及：

2.  如果我们想查看其他详细信息，例如路径是否存在或是否为目录，我们可以依赖以下特定方法：

```py
>>> pathlib.Path('conf.py').exists()
True
>>> pathlib.Path('conf.py').is_dir()
False
>>> pathlib.Path('_build').is_dir()
True
```

# 命名临时文件

通常在处理临时文件时，我们不关心它们存储在哪里。我们需要创建它们，在那里存储一些内容，并在完成后将其丢弃。大多数情况下，当我们想要存储太大而无法放入内存的内容时，我们会使用临时文件，但有时您需要能够将文件提供给其他工具或软件，而临时文件是避免需要知道在何处存储此类文件的一种很好的方法。

在这种情况下，我们需要知道指向临时文件的路径，以便能够将其提供给其他工具。

这就是`tempfile.NamedTemporaryFile`可以提供帮助的地方。与所有其他`tempfile`形式的临时文件一样，它将为我们创建，并在我们使用完它后自动删除，但与其他类型的临时文件不同，它将有一个已知的路径，我们可以提供给能够从该文件读写的其他程序。

# 怎么做。。。

`tempfile.NamedTemporaryFile`将创建临时文件：

```py
>>> from tempfile import NamedTemporaryFile
>>>
>>> with tempfile.NamedTemporaryFile() as f:
...   print(f.name)
... 
/var/folders/js/ykgc_8hj10n1fmh3pzdkw2w40000gn/T/tmponbsaf34
```

`.name`属性导致磁盘上的完整文件路径，这一事实允许我们将其提供给其他外部程序：

```py
>>> with tempfile.NamedTemporaryFile() as f:
...   os.system('echo "Hello World" > %s' % f.name)
...   f.seek(0)
...   print(f.read())
... 
0
0
b'Hello World\n'
```

# 内存和磁盘缓冲区

有时，我们需要将某些数据保存在缓冲区中，例如从 internet 下载的文件或正在动态生成的某些数据。

由于这些数据的大小并不总是可预测的，因此将其全部保存在内存中通常不是一个好主意。

如果您正在从 internet 下载一个需要处理（如解压缩或解析）的 32 GB 大文件，如果您在处理之前尝试将其存储到字符串中，可能会耗尽所有内存。

这就是为什么依赖`tempfile.SpooledTemporaryFile`通常是一个好主意，它会将内容保留在内存中，直到达到其最大大小，然后将其移动到一个临时文件中，如果它大于允许的最大大小。

这样，我们就可以在内存中保留数据缓冲区，而不会耗尽所有内存，因为一旦内容太大，它就会被移动到磁盘上。

# 怎么做。。。

与另一个`tempfile`对象一样，创建`SpooledTemporaryFile`就足以使临时文件可用。唯一的附加部分是提供允许的最大大小`max_size=`，之后内容将移动到磁盘：

```py
>>> with tempfile.SpooledTemporaryFile(max_size=30) as temp:
...     for i in range(3):
...         temp.write(b'Line of text\n')
...     
...     temp.seek(0)
...     print(temp.read())
... 
b'Line of text\nLine of text\nLine of text\n'
```

# 它是如何工作的。。。

`tempfile.SpooledTemporaryFile`有一个`internal _file`属性，该属性将实际数据存储在`BytesIO`存储中，直到它可以放入内存，然后在其大于`max_size`时将其移动到实际文件中。

通过在写入数据时打印`_file`的值，可以很容易地看到这种行为：

```py
>>> with tempfile.SpooledTemporaryFile(max_size=30) as temp:
...     for i in range(3):
...         temp.write(b'Line of text\n')
...         print(temp._file)
... 
<_io.BytesIO object at 0x10d539ca8>
<_io.BytesIO object at 0x10d539ca8>
<_io.BufferedRandom name=4>
```

# 管理文件名编码

以可靠的方式使用文件系统并不像看上去那么容易。我们的系统必须有一个特定的编码来表示文本，这通常意味着我们创建的所有内容都是用该编码处理的，包括文件名。

问题是没有强有力的文件名编码保证。假设您连接了一个外部硬盘，该硬盘上的文件名编码是什么？嗯，这将取决于文件创建时系统的编码。

通常，为了解决这个问题，软件会尝试系统编码，如果失败，它会打印一些占位符（您是否曾经看到过一个文件名充满了`?`，仅仅因为您的系统无法理解文件名？），这通常允许我们看到有一个文件，在许多情况下甚至打开它，尽管我们可能不知道它的名字。

为了使一切变得更复杂，Windows 和 Unix 系统在处理文件名方面有很大的不同。在 Unix 系统上，路径基本上只是字节；您并不真正关心它们的编码，因为您只是读取和写入一堆字节。在 Windows 上，文件名实际上是文本。

在 Python 中，文件名通常存储为`str`。它们是需要以某种方式编码/解码的文本。

# 怎么做。。。

无论何时处理文件名，都应该根据预期的文件系统编码对其进行解码。如果我们失败了（因为它没有存储在预期的编码中），我们必须仍然能够在不损坏它的情况下将其放入`str`，这样即使我们无法读取其名称，我们也可以打开该文件：

```py
def decode_filename(fname):
    fse = sys.getfilesystemencoding()
    return fname.decode(fse, "surrogateescape")
```

# 它是如何工作的。。。

`decode_filename`尝试做两件事：首先，它询问 Python 根据操作系统预期的文件系统编码是什么。一旦知道，它尝试使用该编码解码提供的文件名。如果失败，则使用`surrogateescape`进行解码。

这实际上意味着*如果你不能解码它，就把它解码成假字符，我们将使用它来表示文本*。

这真的很方便，因为这样我们可以将文件名作为文本管理，即使我们不知道它的编码，并且当它用`surrogateescape`编码回字节时，它将返回其原始字节序列。

当文件名采用与我们系统相同的编码方式进行编码时，很容易看到我们如何将其解码为`str`并将其打印以读取其内容：

```py
>>> utf8_filename_bytes = 'ùtf8.txt'.encode('utf8')
>>> utf8_filename = decode_filename(utf8_filename_bytes)
>>> type(utf8_filename)
<class 'str'>
>>> print(utf8_filename)
ùtf8.txt
```

如果编码不是我们的系统编码（也就是说，文件来自一个非常旧的外部驱动器），我们无法真正读取内部写入的内容，但我们仍然能够将其解码为字符串，这样我们就可以将其保存在变量中，并将其提供给可能需要使用该文件的任何函数：

```py
>>> latin1_filename_bytes = 'làtìn1.txt'.encode('latin1')
>>> latin1_filename = decode_filename(latin1_filename_bytes)
>>> type(latin1_filename)
<class 'str'>
>>> latin1_filename
'l\udce0t\udcecn1.txt'
```

`surrogateescape`意味着能够告诉 Python*我不在乎数据是否是垃圾，只需像*一样传递未知字节即可。

# 复制目录

复制目录的内容是我们可以轻松做到的事情，但是如果我告诉你像`cp`（在 GNU 系统上复制文件的命令）这样的工具大约有 1200 行代码呢？

显然，`cp`实现并不是基于 Python 的，它已经发展了几十年，而且它处理的事情远远超出了您可能需要的，但是仍然滚动您自己的代码以递归方式复制目录所花费的时间远远超出您的预期。

幸运的是，Python 标准库提供了实用程序来执行最常见的开箱即用操作，这就是其中之一。

# 怎么做。。。

此配方的步骤如下所示：

1.  `copydir`功能可以依赖`shutil.copytree`完成大部分工作：

```py
import shutil

def copydir(source, dest, ignore=None):
    """Copy source to dest and ignore any file matching ignore 
       pattern."""
    shutil.copytree(source, dest, ignore_dangling_symlinks=True,
                    ignore=shutil.ignore_patterns(*ignore) if 
                    ignore else None)
```

2.  然后，我们可以很容易地使用它复制任何目录的内容，甚至将其限制为仅相关部分。我们将复制一个包含三个文件的目录，我们只想从中复制`.pdf`文件：

```py
>>> import glob
>>> print(glob.glob('_build/pdf/*'))
['_build/pdf/PySTLCookbook.pdf', '_build/pdf/PySTLCookbook.rtc', '_build/pdf/PySTLCookbook.stylelog']
```

3.  我们的目的地当前不存在，因此它不包含任何内容：

```py
>>> print(glob.glob('/tmp/buildcopy/*'))
[]
```

4.  一旦我们完成`copydir`，它将被创建并包含我们期望的内容：

```py
>>> copydir('_build/pdf', '/tmp/buildcopy', ignore=('*.rtc', '*.stylelog'))
```

5.  现在，目标目录已存在并包含我们期望的内容：

```py
>>> print(glob.glob('/tmp/buildcopy/*'))
['/tmp/buildcopy/PySTLCookbook.pdf']
```

# 它是如何工作的。。。

`shutil.copytree`将通过`os.listdir`检索所提供目录的内容。对于`listdir`返回的每个条目，它将检查它是文件还是目录。

如果它是一个文件，它将通过`shutil.copy2`函数复制它（实际上可以通过提供`copy_function`参数替换使用过的函数），如果它是一个目录，`copytree`本身被递归调用。

`ignore`参数随后用于构建一个函数，该函数一旦调用，将返回给定模式下需要忽略的所有文件：

```py
>>> f = shutil.ignore_patterns('*.rtc', '*.stylelog')
>>> f('_build', ['_build/pdf/PySTLCookbook.pdf', 
                 '_build/pdf/PySTLCookbook.rtc', 
                 '_build/pdf/PySTLCookbook.stylelog'])
{'_build/pdf/PySTLCookbook.stylelog', '_build/pdf/PySTLCookbook.rtc'}
```

因此，`shutil.copytree`将复制除`ignore_patterns`之外的所有文件，这将使其跳过。

最后一个`ignore_dangling_symlinks=True`参数确保在`symlinks`中断的情况下，我们只是跳过文件而不是崩溃。

# 安全地替换文件的内容

替换文件内容是一个非常缓慢的操作。与替换变量的内容相比，它通常要慢几倍；当我们将某些内容写入磁盘时，它需要一段时间才能真正刷新，内容也需要一段时间才能真正写入磁盘。这不是一个原子操作，因此，如果我们的软件在保存文件时遇到任何问题，那么很有可能文件会被写入一半，而我们的用户无法恢复其数据的一致状态。

有一种模式通常用于解决这类问题，它基于这样一个事实：写入文件是一种缓慢、昂贵、容易出错的操作，但重命名文件是一种原子级、快速且廉价的操作。

# 怎么做。。。

您需要执行以下配方：

1.  就像`open`可以用作上下文管理器一样，我们可以轻松推出`safe_open`功能，允许我们以安全的方式打开文件进行写入：

```py
import tempfile, os

class safe_open:
    def __init__(self, path, mode='w+b'):
        self._target = path
        self._mode = mode

    def __enter__(self):
        self._file = tempfile.NamedTemporaryFile(self._mode, delete=False)
        return self._file

    def __exit__(self, exc_type, exc_value, traceback):
        self._file.close()
        if exc_type is None:
            os.rename(self._file.name, self._target)
        else:
            os.unlink(self._file.name)
```

2.  使用`safe_open`作为上下文管理器，我们可以像平常一样写入文件：

```py
with safe_open('/tmp/myfile') as f:
    f.write(b'Hello World')
```

3.  一旦我们退出上下文，内容将被正确保存：

```py
>>> print(open('/tmp/myfile').read())
Hello World
```

4.  主要的区别是，如果在我们编写时软件崩溃或系统故障，我们不会得到一个写了一半的文件，但我们会保留该文件以前的任何状态。在本例中，我们在尝试写入`Replace the hello world, expect to write some more`时中途崩溃：

```py
with open('/tmp/myfile', 'wb+') as f:
    f.write(b'Replace the hello world, ')
    raise Exception('but crash meanwhile!')
    f.write(b'expect to write some more')
```

5.  使用正常的`open`，结果将仅为`"Replace the hello world, "`：

```py
>>> print(open('/tmp/myfile').read())
Replace the hello world,
```

6.  当使用`safe_open`时，只有在整个写入过程成功时，文件才会包含新数据：

```py
with safe_open('/tmp/myfile') as f:
    f.write(b'Replace the hello world, ')
    raise Exception('but crash meanwhile!')
    f.write(b'expect to write some more')
```

7.  在所有其他情况下，文件仍将保持其以前的状态：

```py
>>> print(open('/tmp/myfile').read())
Hello World
```

# 它是如何工作的。。。

`safe_open`依赖`tempfile`创建一个新文件，其中实际发生写入操作。在我们的上下文中，任何时候我们向`f`写入内容，实际上都是在向临时文件写入内容。

然后，只有当上下文存在时（`exc_type`在`safe_open.__exit__`中没有），我们才使用`os.rename`将旧文件与我们刚刚编写的新文件交换。

如果一切正常，我们应该更新新文件及其所有内容。

如果任何一个步骤失败，我们只需将部分数据或没有数据写入临时文件，并通过`os.unlink`将其清除。

在本例中，我们以前的文件从未接触过，因此仍保留其以前的状态。