# 二、文本管理

在本章中，我们将介绍以下配方：

*   模式匹配正则表达式不是解析模式的唯一方法；Python 提供了更简单、同样强大的工具来解析模式
*   文本相似性很难检测两个相似字符串的执行方式，但 Python 有一些易于使用的内置工具
*   文本建议 Python 寻找最相似的文本建议，向用户建议正确的拼写
*   模板生成文本时，模板是定义规则的最简单方法
*   拆分字符串保留空格在空空格上拆分可能很容易，但如果要保留某些空格，则会变得更难
*   清除文本从文本中删除任何标点符号或奇数字符
*   规范化文本在处理国际文本时，通常可以方便地避免处理特殊字符和拼写错误
*   对齐文本输出文本时，正确对齐文本可大大提高可读性

# 介绍

Python 是为系统工程而诞生的，在使用 shell 脚本和基于 shell 的软件时，经常需要创建和解析文本。这就是为什么 Python 有非常强大的工具来处理文本。

# 模式匹配

在文本中查找模式时，正则表达式通常是附加此类问题的最常见方式。它们非常灵活和强大，尽管它们不能表达所有类型的语法，但它们通常可以处理最常见的情况。

正则表达式的威力来自于它们可以生成的一系列符号和表达式。问题是，对于不习惯正则表达式的开发人员来说，它们可能看起来像纯噪音，即使是有过正则表达式使用经验的人，在理解以下表达式之前也常常需要思考一下：

```py
"^(*d{3})*( |-)*d{3}( |-)*d{4}$"
```

这个表达式实际上试图检测电话号码。

对于大多数常见的情况，开发人员需要寻找非常简单的模式：例如，文件扩展名（是否以`.txt`结尾？），分隔文本，等等。

# 怎么做。。。

`fnmatch`模块为大多数开发人员提供了一种简化的模式匹配语言，该语言具有非常快速且易于理解的语法。

很少有字符具有特殊含义：

*   `*`指任何文本
*   `?`表示任何字符
*   `[...]`指方括号内包含的字符
*   `[!...]`指除方括号内的字符以外的所有内容

您可能会从系统 shell 中识别出这种语法，因此很容易看出`*.txt`是如何表示*每个具有.txt 扩展名*的名称的：

```py
>>> fnmatch.fnmatch('hello.txt', '*.txt')
True
>>> fnmatch.fnmatch('hello.zip', '*.txt')
False
```

# 还有更多。。。

实际上，`fnmatch`可以用于识别由某种常量值分隔的文本片段。

例如，如果我有一个模式定义了一个变量的`type`、`name`和`value`，该变量由`:`分隔，那么我们可以通过`fnmatch`识别它，然后声明所描述的变量：

```py
>>> def declare(decl):
...   if not fnmatch.fnmatch(decl, '*:*:*'):
...     return False
...   t, n, v = decl.split(':', 2)
...   globals()[n] = getattr(__builtins__, t)(v)
...   return True
... 
>>> declare('int:somenum:3')
True
>>> somenum
3
>>> declare('bool:somebool:True')
True
>>> somebool
True
>>> declare('int:a')
False
```

`fnmatch`明显的亮点是文件名。如果您有一个文件列表，则很容易只提取与特定模式匹配的文件：

```py
>>> os.listdir()
['.git', '.gitignore', '.vscode', 'algorithms.rst', 'concurrency.rst', 
 'conf.py', 'crypto.rst', 'datastructures.rst', 'datetimes.rst', 
 'devtools.rst', 'filesdirs.rst', 'gui.rst', 'index.rst', 'io.rst', 
 'make.bat', 'Makefile', 'multimedia.rst', 'networking.rst', 
 'requirements.txt', 'terminal.rst', 'text.rst', 'venv', 'web.rst']
>>> fnmatch.filter(os.listdir(), '*.git*')
['.git', '.gitignore']
```

虽然非常方便，`fnmatch`肯定是有限的，但当一个工具达到极限时，它能做的最好的事情之一就是提供与另一个可以克服它们的工具的兼容性。

例如，如果我想查找包含单词`git`或`vs`的所有文件，我无法在单个`fnmatch`模式中查找。我必须声明两种不同的模式，然后合并结果。但是，如果我能使用正则表达式，那是绝对可能的。

`fnmatch.translate`在`fnmatch`模式和正则表达式之间架起桥梁，提供描述`fnmatch`模式的正则表达式，以便可以按照您的意愿对其进行扩展。

例如，我们可以创建一个匹配这两种模式的正则表达式：

```py
>>> reg = '({})|({})'.format(fnmatch.translate('*.git*'), 
                             fnmatch.translate('*vs*'))
>>> reg
'(.*\.git.*\Z(?ms))|(.*vs.*\Z(?ms))'
>>> import re
>>> [s for s in os.listdir() if re.match(reg, s)]
['.git', '.gitignore', '.vscode']
```

`fnmatch`的真正优势在于，它是一种简单、安全的语言，可以向用户公开。假设您正在编写一个电子邮件客户端，并且希望提供搜索功能，那么如果您有来自 Jane Smith 和 Smith Lincoln 的电子邮件，您如何允许您的用户以姓名或姓氏搜索 Smith？

对于`fnmatch`来说，这很容易，因为你可以将它公开给你的用户，让他们写`*Smith`或`Smith*`，这取决于他们是在寻找一个叫史密斯还是以史密斯为姓氏的人：

```py
>>> senders = ['Jane Smith', 'Smith Lincoln']
>>> fnmatch.filter(senders, 'Smith*')
['Smith Lincoln']
>>> fnmatch.filter(senders, '*Smith')
['Jane Smith']
```

# 文本相似性

在许多情况下，在处理文本时，我们可能必须识别与其他文本相似的文本，即使两者不相等。在记录链接、查找重复条目或纠正键入错误时，这是一种非常常见的情况。

寻找文本间的相似性不是一项简单的任务。如果你试着走自己的路，你会很快意识到它很快变得复杂和缓慢。

Python 库提供了检测`difflib`模块中两个序列之间差异的工具。由于文本本身是一个序列（字符序列），我们可以应用提供的函数来检测字符串中的相似性。

# 怎么做。。。

为此配方执行以下步骤：

1.  给定一个字符串，我们要比较：

```py
>>> s = 'Today the weather is nice'
```

2.  此外，我们希望将一组字符串与第一个字符串进行比较：

```py
>>> s2 = 'Today the weater is nice'
>>> s3 = 'Yesterday the weather was nice'
>>> s4 = 'Today my dog ate steak'
```

3.  我们可以使用`difflib.SequenceMatcher`计算字符串之间的相似性（从 0 到 1）：

```py
>>> import difflib
>>> difflib.SequenceMatcher(None, s, s2, False).ratio()
0.9795918367346939
>>> difflib.SequenceMatcher(None, s, s3, False).ratio()
0.8
>>> difflib.SequenceMatcher(None, s, s4, False).ratio()
0.46808510638297873
```

所以`SequenceMatcher`能够检测到`s`和`s2`非常相似（98%），除了`weather`*中的一个拼写错误外，*实际上是相同的短语。然后说明`Today the weather is nice`与`Yesterday the weather was nice`有 80%的相似性，最后说明`Today the weather is nice`与`Today my dog ate steak`几乎没有共同之处。

# 还有更多。。。

`SequenceMatcher`支持将某些值标记为*垃圾。*你可能认为这意味着这些值被忽略了，但事实并非如此。

在大多数情况下，计算包含和不包含垃圾的比率将返回相同的值：

```py
>>> a = 'aaaaaaaaaaaaaXaaaaaaaaaa'
>>> b = 'X'
>>> difflib.SequenceMatcher(lambda c: c=='a', a, b, False).ratio()
0.08
>>> difflib.SequenceMatcher(None, a, b, False).ratio()
0.08    
```

尽管我们提供了一个将所有`a`结果报告为垃圾的`isjunk`函数（指向`SequenceMatcher`的第一个参数），但`a`结果并未被忽略。

通过使用`.get_matching_blocks()`可以看出，在这两种情况下，字符串中唯一匹配的部分是`a`和`b`的`X`位置`13`和`0`：

```py
>>> difflib.SequenceMatcher(None, a, b, False).get_matching_blocks()
[Match(a=13, b=0, size=1), Match(a=24, b=1, size=0)]
>>> difflib.SequenceMatcher(lambda c: c=='a', a, b, False).get_matching_blocks()
[Match(a=13, b=0, size=1), Match(a=24, b=1, size=0)]
```

如果您想在计算差异时忽略某些字符，则必须在运行`SequenceMatcher`之前去除它们，可能需要使用一个将它们全部丢弃的翻译映射：

```py
>>> discardmap = str.maketrans({"a": None})
>>> difflib.SequenceMatcher(None, a.translate(discardmap), b.translate(discardmap), False).ratio()
1.0
```

# 文本建议

在我们之前的配方中，我们看到了`difflib`如何计算两个字符串之间的相似性。这意味着我们可以计算两个单词之间的相似性，并向用户建议更正。

如果已知一组*正确的*单词（通常适用于任何语言），我们可以首先检查该单词是否在该集合中，如果不在，我们可以寻找最相似的单词，向用户建议正确的拼写。

# 怎么做。。。

遵循此配方的步骤如下：

1.  首先，我们需要一组有效词。为了避免带入整本英语词典，我们将只抽取一些单词：

```py
dictionary = {'ability', 'able', 'about', 'above', 'accept',    
              'according', 
              'account', 'across', 'act', 'action', 'activity', 
              'actually', 
              'add', 'address', 'administration', 'admit', 'adult', 
              'affect', 
              'after', 'again', 'against', 'age', 'agency', 
              'agent', 'ago', 
              'agree', 'agreement', 'ahead', 'air', 'all', 'allow',  
              'almost', 
              'alone', 'along', 'already', 'also', 'although', 
              'always', 
              'American', 'among', 'amount', 'analysis', 'and', 
              'animal', 
              'another', 'answer', 'any', 'anyone', 'anything', 
              'appear', 
              'apply', 'approach', 'area', 'argue', 
              'arm', 'around', 'arrive', 
              'art', 'article', 'artist', 'as', 'ask', 'assume', 
              'at', 'attack', 
              'attention', 'attorney', 'audience', 'author',  
              'authority', 
              'available', 'avoid', 'away', 'baby', 'back', 'bad', 
              'bag', 
              'ball', 'bank', 'bar', 'base', 'be', 'beat', 
              'beautiful', 
              'because', 'become'}
```

2.  然后，我们可以为任何提供的短语创建一个函数，用于查找词典中的单词，如果没有，则通过`difflib`提供最相似的候选词：

```py
import difflib

def suggest(phrase):
    changes = 0
    words = phrase.split()
    for idx, w in enumerate(words):
        if w not in dictionary:
            changes += 1
            matches = difflib.get_close_matches(w, dictionary)
            if matches:
                words[idx] = matches[0]
    return changes, ' '.join(words)
```

3.  我们的`suggest`功能将能够检测拼写错误并建议更正短语：

```py
>>> suggest('assume ani answer')
(1, 'assume any answer')
>>> suggest('anoter agrement ahead')
(2, 'another agreement ahead')
```

返回的第一个参数是检测到的错误单词数，第二个参数是具有最合理更正的字符串。

4.  如果我们的短语没有错误，我们将返回原短语`0`：

```py
>>> suggest('beautiful art')
(0, 'beautiful art')
```

# 模板

向用户显示文本时，经常需要根据软件的状态动态生成文本。

通常，这会导致以下代码：

```py
name = 'Alessandro'
messages = ['Message 1', 'Message 2']

txt = 'Hello %s, You have %s message' % (name, len(messages))
if len(messages) > 1:
    txt += 's'
txt += ':n'
for msg in messages:
    txt += msg + 'n'
print(txt)
```

这使得我们很难预测即将到来的信息结构，也很难长期维持。要生成文本，通常更方便的方法是反转方法，而不是将文本放在代码中，我们应该将代码放在文本中。这正是模板引擎所做的，虽然标准库有非常完整的格式化解决方案，但它缺少现成的模板引擎，但可以很容易地进行扩展以生成一个模板引擎。

# 怎么做。。。

此配方的步骤如下：

1.  `string.Formatter`对象允许您扩展其语法，因此我们可以对其进行专门化，以支持将代码注入到它将接受的表达式中：

```py
import string

class TemplateFormatter(string.Formatter):
    def get_field(self, field_name, args, kwargs):
        if field_name.startswith("$"):
            code = field_name[1:]
            val = eval(code, {}, dict(kwargs))
            return val, field_name
        else:
            return super(TemplateFormatter, self).get_field(field_name, args, kwargs)
```

2.  然后，我们的`TemplateFormatter`可以更清晰地生成类似于我们示例的文本：

```py
messages = ['Message 1', 'Message 2']

tmpl = TemplateFormatter()
txt = tmpl.format("Hello {name}, "
                  "You have {$len(messages)} message{$len(messages) and 's'}:n{$'\n'.join(messages)}", 
                  name='Alessandro', messages=messages)
print(txt)
```

结果应该是：

```py
Hello Alessandro, You have 2 messages:
Message 1
Message 2
```

# 它是如何工作的。。。

`string.Formatter`支持与`str.format`方法支持的语言相同的语言。实际上，它根据 Python 所称的*格式字符串语法*解析包含`{}`的表达式。`{}`之外的所有内容都按原样保存，而`{}`之内的任何内容都会被解析为`field_name!conversion:format_spec`规范。因此，由于我们的`field_name`不包含`!`或`:`，所以它可以是其他任何内容。

然后将提取的`field_name`提供给`Formatter.get_field`，以便在`format`方法提供的参数中查找该字段的值。

例如，采用如下表达式：

```py
string.Formatter().format("Hello {name}", name='Alessandro')
```

这导致：

```py
Hello Alessandro
```

因为`{name}`被标识为要解析的块，所以在`.format`参数中查找名称，其余的按原样保留。

这非常方便，可以解决大多数字符串格式化需求，但它缺乏像循环和条件一样的真正模板引擎的功能。

我们所做的扩展`Formatter`不仅用于解析`field_name`中指定的变量，还用于计算 Python 表达式。

正如我们所知，所有的`field_name`解析都通过`Formatter.get_field`，在我们自己的自定义类中重写该方法将允许我们在对`field_name`类`{name}`进行求值时更改所发生的情况：

```py
class TemplateFormatter(string.Formatter):
    def get_field(self, field_name, args, kwargs):
```

为了区分普通变量和表达式，我们使用了`$`符号。由于 Python 变量永远不能以`$`开头，因此我们不会与提供给 format 的参数发生冲突（因为`str.format($something=5`在 Python 中实际上是一个语法错误）。因此，类似于`{$something}`的`field_name`并不意味着查找`''$something`的值，而是评估`something`表达式：

```py
if field_name.startswith("$"):
    code = field_name[1:]
    val = eval(code, {}, dict(kwargs))
```

`eval`函数运行任何用字符串编写的代码，并将执行限制在表达式上（Python 中的表达式总是会产生一个值，与不产生值的语句不同），因此我们还进行了语法检查，以防止模板用户编写`if something: x='hi'`，它不会提供任何值以显示在呈现模板所产生的文本中。

然后，由于我们希望用户能够查找他们提供的表达式（如`{$len(messages)}`引用的任何变量，我们将`kwargs`作为`locals`变量提供给`eval`，以便引用变量的任何表达式都能正确解析。我们还提供了一个空的全局上下文`{}`，这样我们就不会无意中触及软件的任何全局变量。

剩下的最后一部分只是返回`eval`提供的表达式执行结果作为`field_name`解析的结果：

```py
return val, field_name
```

真正有趣的是，由于所有的处理都发生在`get_field`阶段。转换和格式规范仍受支持，因为它们应用于`get_field`返回的值。

这使我们可以编写类似以下内容：

```py
{$3/2.0:.2f}
```

我们返回`1.50`作为输出，而不是`1.5`。这是因为我们在专门的`TemplateFormatter.get_field`方法中首先评估`3/2.0`，然后解析器继续对结果值应用格式化程序规范（`.2f`。

# 还有更多。。。

我们的简单模板引擎很方便，但仅限于将生成文本的代码表示为一组表达式和静态文本的情况。

问题是，更高级的模板并不总是能够表示。我们仅限于简单的表达式，因此实际上任何不能在`lambda`中表示的内容都不能由我们的模板引擎执行。

虽然有些人会争辩说，非常复杂的软件可以通过组合多个`lambda`来编写，但大多数人会认识到，语句会导致更可读的代码。

因此，如果您需要处理非常复杂的文本，那么您应该使用功能齐全的模板引擎，寻找诸如 Jinja、Kajiki 或 Mako 之类的内容来解决您的问题。特别是对于生成 HTML，像 Kajiki 这样的解决方案也能够验证您的 HTML，非常方便，并且可以比我们的`TemplateFormatter`更进一步。

# 分裂字符串和保留空间

通常，当在空格上拆分字符串时，开发人员会倾向于依赖`str.split`，它能够很好地实现这一目的。但是当需要*分割一些空间并保留其他*时，事情很快就会变得更加困难，实现自定义解决方案可能需要花费时间进行适当的转义。

# 怎么做。。。

只需依赖`shlex.split`而不是`str.split`：

```py
>>> import shlex
>>>
>>> text = 'I was sleeping at the "Windsdale Hotel"'
>>> print(shlex.split(text))
['I', 'was', 'sleeping', 'at', 'the', 'Windsdale Hotel']
```

# 它是如何工作的。。。

`shlex`是最初创建用于解析 Unix shell 代码的模块。因此，它支持通过引号保存短语。通常，在 Unix 命令行中，由空格分隔的单词作为被调用命令的参数提供，但是如果要将多个单词作为单个参数提供，可以使用引号将它们分组。

这正是`shlex`所复制的，为我们提供了一种可靠的方法来推动分裂。我们只需要用双引号或单引号将要保留的所有内容都封装起来。

# 清除文本

在分析用户提供的文本时，我们通常只对有意义的词感兴趣；标点符号、空格和连词可能很容易妨碍我们。假设你想在一本书中计算单词的频率，你不想最后把“世界”和“世界”算作两个不同的单词。

# 怎么做。。。

您必须执行以下步骤：

1.  提供要清理的文本：

```py
txt = """And he looked over at the alarm clock,
ticking on the chest of drawers. "God in Heaven!" he thought.
It was half past six and the hands were quietly moving forwards,
it was even later than half past, more like quarter to seven.
Had the alarm clock not rung? He could see from the bed that it
had been set for four o'clock as it should have been; it certainly must have rung.
Yes, but was it possible to quietly sleep through that furniture-rattling noise?
True, he had not slept peacefully, but probably all the more deeply because of that."""
```

2.  我们可以依靠`string.punctuation`来知道要丢弃哪些字符，并制作一个翻译表来丢弃所有字符：

```py
>>> import string
>>> trans = str.maketrans('', '', string.punctuation)
>>> txt = txt.lower().translate(trans)
```

结果将是我们的文本的清理版本：

```py
"""and he looked over at the alarm clock
ticking on the chest of drawers god in heaven he thought
it was half past six and the hands were quietly moving forwards
it was even later than half past more like quarter to seven
had the alarm clock not rung he could see from the bed that it
had been set for four oclock as it should have been it certainly must have rung
yes but was it possible to quietly sleep through that furniturerattling noise
true he had not slept peacefully but probably all the more deeply because of that"""
```

# 它是如何工作的。。。

这个方法的核心是使用翻译表。转换表是将字符链接到替换字符的映射。类似于`{'c': 'A'}`的翻译表意味着任何`'c'`都必须替换为`'A'`。

`str.maketrans`是用于建立翻译表的函数。第一个参数中的每个字符都将映射到第二个参数中相同位置的字符。那么最后一个参数中的所有字符都将映射到`None`：

```py
>>> str.maketrans('a', 'b', 'c')
{97: 98, 99: None}
```

`97`、`98`和`99`是`'a'`、`'b'`和`'c'`的 Unicode 值：

```py
>>> print(ord('a'), ord('b'), ord('c'))
97 98 99
```

然后可以将我们的映射传递到`str.translate`以将其应用于目标字符串。有趣的是，映射到`None`的任何字符都将被删除：

```py
>>> 'ciao'.translate(str.maketrans('a', 'b', 'c'))
'ibo'
```

在前面的示例中，我们将第三个参数`string.punctuation`作为`str.maketrans`提供。

`string.punctuation`是包含最常见标点符号的字符串：

```py
>>> string.punctuation
'!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~'
```

通过这样做，我们构建了一个事务映射，将每个标点符号映射到`None`，并且没有指定任何其他映射：

```py
>>> str.maketrans('', '', string.punctuation)
{64: None, 124: None, 125: None, 91: None, 92: None, 93: None,
 94: None, 95: None, 96: None, 33: None, 34: None, 35: None,
 36: None, 37: None, 38: None, 39: None, 40: None, 41: None,
 42: None, 43: None, 44: None, 45: None, 46: None, 47: None,
 123: None, 126: None, 58: None, 59: None, 60: None, 61: None,
 62: None, 63: None}
```

这一点一旦与`str.translate`一起应用，就使得标点符号都被丢弃，其他所有字符保持原样：

```py
>>> 'This, is. A test!'.translate(str.maketrans('', '', string.punctuation))
'This is A test'
```

# 规范化文本

在许多情况下，一个单词可以用多种方式书写。例如，写“Über”和“Uber”的用户可能是同一个词的意思。如果你正在为一个博客实现一个像标签这样的功能，你肯定不希望最后为这两个词使用两个不同的标签。

因此，在保存标记之前，您可能希望将它们规范化为纯 ASCII 字符，以便它们最终都被视为同一个标记。

# 怎么做。。。

我们需要的是一个翻译映射，它可以将所有重音字符转换为它们的普通表示：

```py
import unicodedata, sys

class unaccented_map(dict):
    def __missing__(self, key):
        ch = self.get(key)
        if ch is not None:
            return ch
        de = unicodedata.decomposition(chr(key))
        if de:
            try:
                ch = int(de.split(None, 1)[0], 16)
            except (IndexError, ValueError):
                ch = key
        else:
            ch = key
        self[key] = ch
        return ch

unaccented_map = unaccented_map()
```

然后我们可以将其应用于任何单词以使其正常化：

```py
>>> 'Über'.translate(unaccented_map) Uber >>> 'garçon'.translate(unaccented_map) garcon
```

# 它是如何工作的。。。

正如*清理文本*配方中所解释的，我们已经知道`str.translate`的工作原理：在翻译表中查找每个字符，并用表中指定的替换字符替换。

所以，我们需要的是一个将`"Ü"`映射到`"U"`和`"ç"`映射到`"c"`的转换表，以此类推。

但是我们怎么知道所有这些映射呢？这些字符的一个有趣特性是，它们可以被视为带有附加符号的普通字符。很像`à`可以被认为是带有口音的`a`。

Unicode 等价性知道这一点，并提供多种方法来编写被认为是同一个字符的内容。我们真正感兴趣的是分解形式，这意味着将一个字符写成定义它的多个分离符号。例如，`é`将分解为`0065`和`0301`，这是`e`和重音的代码点。

Python 提供了一种通过`unicodedata.decompostion`函数了解字符分解版本的方法：

```py
>>> import unicodedata
>>> unicodedata.decomposition('é')
'0065 0301'
```

第一个代码点是基本字符之一，而第二个是添加的符号。因此，为了规范化我们的`è`，我们将选择第一个代码点`0065`并丢弃符号：

```py
>>> unicodedata.decomposition('é').split()[0]
'0065'
```

现在我们不能单独使用代码点，但我们需要它所表示的字符。幸运的是，`chr`函数提供了一种从其代码点的整数表示中获取字符的方法。

`unicodedata.decomposition`函数将代码点提供为表示十六进制数的字符串，因此首先我们需要将它们转换为整数：

```py
>>> int('0065', 16)
101
```

然后我们可以应用`chr`来了解实际字符：

```py
>>> chr(101)
'e'
```

现在我们知道了如何分解这些字符并获得我们想要将它们全部规范化的基本字符，但是我们如何为它们构建一个翻译映射呢？

答案是我们没有。事先为所有字符构建翻译映射不是很方便，因此我们可以使用字典提供的功能在需要时动态地为字符构建翻译。

翻译映射是字典，当字典需要查找它不知道的键时，它可以依赖`__missing__`方法为该键生成值。所以我们的`__missing__`方法必须像我们刚才做的那样，在`str.translate`试图在翻译图中查找字符时，使用`unicodedata.decomposition`获取字符的规范化版本。

一旦我们计算了所请求字符的翻译，我们就将其存储在字典本身中，这样下次请求它时，我们就不必再计算它了。

因此，我们配方的`unaccented_map`只是一个提供`__missing__`方法的字典，该方法依赖`unicodedata.decompostion`检索每个提供字符的规范化版本。

如果找不到字符的非规范化版本，它将只返回原始版本一次，这样字符串就不会损坏。

# 对齐文本

在打印表格数据时，确保文本正确对齐到固定长度通常非常重要，该长度不得超过或小于我们为表格单元格保留的空间。

如果文本太短，下一列可能开始得太早；如果时间太长，可能开始得太晚。这将导致如下结果：

```py
col1 | col2-1
col1-2 | col2-2
```

或者这个：

```py
col1-000001 | col2-1
col1-2 | col2-2
```

这两种方法都很难阅读，而且远远没有给出一个合适的表格。

给定一个固定的列宽（20 个字符），我们希望我们的文本始终是精确的长度，这样就不会导致表不对齐。

# 怎么做。。。

以下是此配方的步骤：

1.  `textwrap`模块一旦与`str`对象的特性结合，可以帮助我们达到预期的效果。首先，我们需要要打印的列的内容：

```py
cols = ['hello world', 
        'this is a long text, maybe longer than expected, surely long enough', 
        'one more column']
```

2.  然后我们需要确定列的大小：

```py
COLSIZE = 20
```

3.  一旦这些准备就绪，我们就可以实际实现缩进功能：

```py
import textwrap, itertools

def maketable(cols):
    return 'n'.join(map(' | '.join, itertools.zip_longest(*[
        [s.ljust(COLSIZE) for s in textwrap.wrap(col, COLSIZE)] for col in cols
    ], fillvalue=' '*COLSIZE)))
```

4.  然后，我们可以正确打印任何表格：

```py
>>> print(maketable(cols))
hello world          | this is a long text, | one more column     
                     | maybe longer than    |                     
                     | expected, surely     |                     
                     | long enough          |                     
```

# 它是如何工作的。。。

实现`maketable`功能需要解决三个问题：

*   将文本长度延长到 20 个字符以下
*   多行拆分长度超过 20 个字符的文本
*   用较少的行填充列中缺少的行

如果我们分解`maketable`函数，它做的第一件事就是将长度超过 20 个字符的文本拆分为多行：

```py
[textwrap.wrap(col, COLSIZE) for col in cols]
```

应用于每一列的结果导致我们有一个列列表，每个列包含一个行列表：

```py
[['hello world'], 
 ['this is a long text,', 'maybe longer than', 'expected, surely', 'long enough'],
 ['one more column']]
```

然后，我们需要确保每行少于 20 个字符的长度扩展到正好 20 个字符，以便我们的表保持形状，这是通过对每行应用`ljust`方法实现的：

```py
[[s.ljust(COLSIZE) for s in textwrap.wrap(col, COLSIZE)] for col in cols]
```

将`ljust`与`textwrap`相结合，可以得到我们想要的结果：一个列列表，每个列包含 20 个字符的行：

```py
[['hello world         '], 
 ['this is a long text,', 'maybe longer than   ', 'expected, surely    ', 'long enough         '],
 ['one more column     ']]
```

现在我们需要找到一种方法来翻转行和列，因为当打印时，我们需要逐行打印，因为`print`函数一次打印一行。此外，我们需要确保每列的行数相同，因为我们需要在逐行打印时打印所有行。

这两个需求都可以通过`itertools.zip_longest`函数来解决，该函数将通过交错提供的每个列表中包含的值来生成一个新列表，直到最长的列表用尽为止。当`zip_longest`一直持续到最长的 iterable 用尽时，它支持一个`fillvalue`参数，该参数可用于指定用于填充较短列表值的值：

```py
list(itertools.zip_longest(*[
    [s.ljust(COLSIZE) for s in textwrap.wrap(col, COLSIZE)] for col in cols
], fillvalue=' '*COLSIZE))
```

结果将是一个行列表，每个行包含一列，对于没有值的行，列为空：

```py
[('hello world         ', 'this is a long text,', 'one more column     '), 
 ('                    ', 'maybe longer than   ', '                    '), 
 ('                    ', 'expected, surely    ', '                    '), 
 ('                    ', 'long enough         ', '                    ')]
```

文本的表格形式现在清晰可见。函数的最后两个步骤包括在列之间添加一个`|`分隔符，并通过`' | '.join`将列合并为一个字符串：

```py
map(' | '.join, itertools.zip_longest(*[
    [s.ljust(COLSIZE) for s in textwrap.wrap(col, COLSIZE)] for col in cols
], fillvalue=' '*COLSIZE))
```

这将产生一个字符串列表，其中包含所有三列的文本：

```py
['hello world          | this is a long text, | one more column     ', 
 '                     | maybe longer than    |                     ', 
 '                     | expected, surely     |                     ', 
 '                     | long enough          |                     ']
```

最后，可以打印行。为了返回单个字符串，我们的函数应用最后一个步骤，通过应用最后一个`'n'.join()`，将所有行连接到一个由换行符分隔的字符串中，从而返回一个包含准备打印的整个文本的单个字符串：

```py
'''hello world          | this is a long text, | one more column     
                        | maybe longer than    |                     
                        | expected, surely     |                     
                        | long enough          |                     '''
```