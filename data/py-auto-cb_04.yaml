- en: Searching and Reading Local Files
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索和阅读本地文件
- en: 'In this chapter, we''ll cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下食谱：
- en: Crawling and searching directories
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬取和搜索目录
- en: Reading text files
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读文本文件
- en: Dealing with encodings
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理编码
- en: Reading CSV files
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读CSV文件
- en: Reading log files
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读日志文件
- en: Reading file metadata
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读文件元数据
- en: Reading images
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读图像
- en: Reading PDF files
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读PDF文件
- en: Reading Word documents
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读Word文档
- en: Scanning documents for a keyword
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扫描文档以查找关键字
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In this chapter, we will deal with the basic operations to read files, starting
    with searching and opening files in directories and subdirectories. Then, we'll
    describe some of the most common file types and how to read them, including formats
    such as raw text files, PDFs, and Word documents.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将处理读取文件的基本操作，从搜索和打开目录和子目录中的文件开始。然后，我们将描述一些最常见的文件类型以及如何读取它们，包括原始文本文件、PDF和Word文档等格式。
- en: The last recipe will combine them all, showing how to search recursively in
    a directory for a word in different kinds of files.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个食谱将把它们全部结合起来，展示如何在目录中递归搜索不同类型的文件中的单词。
- en: Crawling and searching directories
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 爬取和搜索目录
- en: In this recipe, we'll learn how to recursively scan a directory to get all the
    files contained there. The files can be of a particular kind, or just all of them.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将学习如何*递归*扫描目录以获取其中包含的所有文件。文件可以是特定类型的，也可以是所有类型的。
- en: Getting ready
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Let''s start by creating a test directory with some file information:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个带有一些文件信息的测试目录开始：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: All the files will be empty; we will use them in this recipe only to discover
    them. Notice there are four files that have a `.txt` extension, and two that have
    a `.pdf` extension.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所有文件都将是空的；我们只会在本食谱中使用它们来发现它们。请注意，有四个文件的扩展名是`.txt`，另外两个文件的扩展名是`.pdf`。
- en: The files are also available in the GitHub repository here: [https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/documents/dir](https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/documents/dir).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文件也可以在GitHub存储库中找到：[https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/documents/dir](https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/documents/dir)。
- en: 'Enter the created `dir` directory:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 进入创建的`dir`目录：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How to do it...
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'Print all the filenames in the `dir` directory and subdirectories:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`dir`目录和子目录中的所有文件名：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Print the full path of the files, joining with the `root`:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印文件的完整路径，与`root`连接：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Print only the `.pdf` files:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅打印`.pdf`文件：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Print only files that contain an even number:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅打印包含偶数的文件：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How it works...
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: '`os.walk()` goes through the whole directory and all subdirectories, returning
    all the files. It returns a tuple with the specific directory, the subdirectories
    that depends directly, and all the files:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`os.walk()`遍历整个目录和所有子目录，返回所有文件。它返回一个元组，其中包含特定目录、直接依赖的子目录和所有文件：'
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `os.path.join()` function allows us to cleanly join two paths, such as the
    base path and the file.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`os.path.join()`函数允许我们清晰地连接两个路径，比如基本路径和文件。'
- en: As files are returned as pure strings, any kind of filtering can be done, as
    in step 3\. In step 4, the full power of regular expressions can be used to filter.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文件以纯字符串形式返回，因此可以进行任何类型的过滤，就像第3步那样。在第4步中，可以使用正则表达式的全部功能进行过滤。
- en: In the next recipe, we'll deal with the content of the files, and not just the
    filename.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个食谱中，我们将处理文件的内容，而不仅仅是文件名。
- en: There's more...
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The returned files are not opened or modified in anyway. This operation is read-only.
    Files can be opened as usual, and described as in the following recipes.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的文件不会以任何方式打开或修改。此操作是只读的。文件可以像平常一样打开，并且可以像下面的食谱中描述的那样进行操作。
- en: Be aware that changing the structure of the directory while walking it may affect
    the results. If you need to store any file while working, for example, when copying
    or moving a file, it's usually a good idea to store it in a different directory.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在遍历目录时更改目录的结构可能会影响结果。如果需要在工作时存储任何文件，例如复制或移动文件时，通常最好将其存储在不同的目录中。
- en: 'The  `os.path` module has other interesting functions. The most useful, other
    than `join()`, are probably:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`os.path`模块还有其他有趣的函数。除了`join()`之外，最有用的可能是：'
- en: '`os.path.abspath()`, which returns the absolute path of a file'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os.path.abspath()`，返回文件的绝对路径'
- en: '`os.path.split()`, which splits the path between directory and file:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os.path.split()`，用于在目录和文件之间拆分路径：'
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`os.path.exists()`, to return whether a file exists or not on the filesystem'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os.path.exists()`，用于返回文件在文件系统上是否存在'
- en: The full documentation about `os.path` can be found here: [https://docs.python.org/3/library/os.path.html](https://docs.python.org/3/library/os.path.html).
    Another module, `pathlib`, can be used for higher-level access, in an object-oriented
    way: [https://docs.python.org/3/library/pathlib.html](https://docs.python.org/3/library/pathlib.html).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`os.path`的完整文档可以在这里找到：[https://docs.python.org/3/library/os.path.html](https://docs.python.org/3/library/os.path.html)。另一个模块`pathlib`可以用于以面向对象的方式进行更高级别的访问：[https://docs.python.org/3/library/pathlib.html](https://docs.python.org/3/library/pathlib.html)。
- en: As demonstrated in step 4, multiple ways of filtering can be used. All of the
    string manipulations shown in [Chapter 1](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml), *Let
    Us Begin Our Automation Journey* can be used.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如第4步所示，可以使用多种过滤方式。在[第1章](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml)中展示的所有字符串操作，*让我们开始自动化之旅*都可以使用。
- en: See also
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Introducing regular expressions* recipe in [Chapter 1](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml), *Let
    Us Begin Our Automation Journey *
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第1章](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml)中的*介绍正则表达式*食谱，*让我们开始自动化之旅*'
- en: The *Reading text files* recipe
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*阅读文本文件*食谱'
- en: Reading text files
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读文本文件
- en: After searching for a particular file, we'll probably follow up by opening it
    and reading it. Text files are very simple yet very powerful files. They store
    data in plain text, without complicated binary formats.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在搜索特定文件之后，我们可能会打开并阅读它。文本文件非常简单，但非常强大。它们以纯文本形式存储数据，而不是复杂的二进制格式。
- en: Text file support is provided natively in Python, and it's easy to consider
    it a collection of lines.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Python本身提供了对文本文件的支持，并且很容易将其视为一系列行。
- en: Getting ready
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll read the `zen_of_python.txt` file, containing the *Zen of Python* by
    Tim Peters, which is a collection of aphorisms that very well describe the design
    principles behind Python. It is available in the GitHub repository here: [https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将阅读包含Tim Peters的*Python之禅*的`zen_of_python.txt`文件，这是一系列很好地描述了Python设计原则的格言。它在GitHub存储库中可用：[https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt)：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The *Zen of Python* is described in PEP-20 here: [https://www.python.org/dev/peps/pep-0020/](https://www.python.org/dev/peps/pep-0020/).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python之禅*在PEP-20中描述：[https://www.python.org/dev/peps/pep-0020/](https://www.python.org/dev/peps/pep-0020/)。'
- en: The *Zen of Python* can be displayed in any Python interpreter by calling `import
    this`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python之禅*可以通过调用`import this`在任何Python解释器中显示。'
- en: How to do it...
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Open and print the whole file, line by line (the result is not displayed):'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开并打印整个文件，逐行（结果不显示）：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Open the file and print any line containing the string `should`:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开文件并打印包含字符串`should`的任何行：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Open the file and print the first line containing the word `better`:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开文件并打印包含单词`better`的第一行：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How it works...
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: To open a file in text mode, use the `open()` function. This returns a `file`
    object that then can be iterated over to return it line by line, as shown in step
    1 of the *How to do it…* section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要以文本模式打开文件，请使用`open()`函数。这将返回一个`file`对象，然后可以迭代返回每一行，如*如何做...*部分的步骤1所示。
- en: The `with` context manager is a very convenient way of dealing with files, as
    it will close them after finishing its use (leaving the block). It will do so
    even if there's an exception raised.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`with`上下文管理器是处理文件的非常方便的方式，因为它在完成使用后会关闭它们（离开块）。即使出现异常，它也会这样做。'
- en: Step 2 shows how to iterate and filter the lines based in what lines are applicable
    for our tasks. The lines are returned as strings that can be filtered in multiple
    ways, as described before.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤2显示了如何迭代和过滤基于哪些行适用于我们的任务。这些行作为字符串返回，可以以多种方式进行过滤，如前面所述。
- en: Reading the whole file may not be required, as shown in step 3\. Because iterating
    through the file line by line will be reading the file as you go, you can stop
    at any time, avoiding reading the rest of the file. For a small file such as our
    example, that's not very relevant, but for long files, this can reduce memory
    use and time.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 可能不需要读取整个文件，如步骤3所示。因为逐行迭代文件将在读取文件时进行，您可以随时停止，避免读取文件的其余部分。对于像我们的示例这样的小文件来说，这并不是很重要，但对于长文件来说，这可以减少内存使用和时间。
- en: There's more...
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The `with` context manager is the preferred way of dealing with files, but
    it''s not the only one. You may also open and close them manually, like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`with`上下文管理器是处理文件的首选方式，但不是唯一的方式。您也可以像这样手动打开和关闭它们：'
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note the `.close() ` method, to ensure that the file is closed and to free resources
    related to opening a file. The `.read()` method reads the whole file in one go,
    instead of line by line.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`.close()`方法，以确保文件已关闭并释放与打开文件相关的资源。`.read()`方法一次读取整个文件，而不是逐行读取。
- en: The `.read()` method also accepts a size parameter in bytes that limits the
    size of the data read. For example, `file.read(1024)` will return up to 1 KB of
    information. The next call to `.read()` will continue from that point.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`.read()`方法还接受以字节为单位的大小参数，限制读取的数据大小。例如，`file.read(1024)`将返回最多1KB的信息。下一次调用`.read()`将从那一点继续。'
- en: Files are opened in a particular mode. Modes define a combination of read/write
    as well as text or binary data. By default, files are opened in read-only and
    text mode, which are described as `'r'` (step 2) or `'rt'` (step 3).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 文件以特定模式打开。模式定义了读/写以及文本或二进制数据的组合。默认情况下，文件以只读和文本模式打开，描述为`'r'`（步骤2）或`'rt'`（步骤3）。
- en: More modes will be explored in other recipes.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其他配方将探讨更多模式。
- en: See also
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Crawling and searching directories* recipe
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*爬取和搜索目录*配方'
- en: The *Dealing with encodings* recipe
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*处理编码*配方'
- en: Dealing with encodings
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理编码
- en: Text files can be present in different encodings. In recent years, the situation
    has greatly improved, but there are still compatibility problems when working
    with different systems.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 文本文件可以以不同的编码形式存在。近年来，情况有了很大改善，但在处理不同系统时仍然存在兼容性问题。
- en: There's a difference between raw data in a file and a string object in Python.
    The string object has been transformed from whatever encoding the file contains
    into a native string. Once it is in this format, it may need to be stored in different
    encodings. By default, Python works with the defined by the OS, which in modern
    operating systems is UTF-8.  This is a highly compatible encoding, but you may
    need to save files in a different one.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 文件中的原始数据和Python中的字符串对象之间存在差异。字符串对象已从文件包含的任何编码转换为本机字符串。一旦以这种格式存在，可能需要以不同的编码进行存储。默认情况下，Python使用操作系统定义的编码，在现代操作系统中为UTF-8。这是一种高度兼容的编码，但您可能需要以不同的编码保存文件。
- en: Getting ready
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We prepared two files in the GitHub repository that store the string `20£`
    in two different encodings. One in usual UTF8 and another in ISO 8859-1, another
    common encoding. The files are available in GitHub under the `Chapter04/documents` directory,
    with the names `example_iso.txt` and `example_utf8.txt`:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在GitHub存储库中准备了两个文件，这两个文件以两种不同的编码存储字符串`20£`。一个是通常的UTF8，另一个是ISO 8859-1，另一种常见的编码。这些文件可以在GitHub的`Chapter04/documents`目录下找到，文件名分别是`example_iso.txt`和`example_utf8.txt`：
- en: '[https://github.com/PacktPublishing/Python-Automation-Cookbook](https://github.com/PacktPublishing/Python-Automation-Cookbook)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Python-Automation-Cookbook](https://github.com/PacktPublishing/Python-Automation-Cookbook)'
- en: We'll use the Beautiful Soup module, presented in the *Parsing HTML* recipe
    in [Chapter 3](d640524b-3aa3-406e-a6d4-842bc61c4658.xhtml), *Building Your First
    Web Scraping Application*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Beautiful Soup模块，该模块在[第3章](d640524b-3aa3-406e-a6d4-842bc61c4658.xhtml)中的*解析HTML*食谱中介绍，*构建您的第一个网络爬虫应用程序*。
- en: How to do it...
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'Open the `example_utf8.txt` file and display its content:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`example_utf8.txt`文件并显示其内容：
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Try to open the `example_iso.txt` file, which will raise an exception:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试打开`example_iso.txt`文件，这将引发异常：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Open the `example_iso.txt` file with the proper encoding:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以正确的编码打开`example_iso.txt`文件：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Open the `utf8` file and save its content in an `iso-8859-1` file:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`utf8`文件并将其内容保存在`iso-8859-1`文件中：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, read from the new file in the proper format to ensure it is correctly
    saved:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，从新文件中以正确的格式读取，以确保它已正确保存：
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How it works...
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Steps 1 and 2 in the *How to do it…* section are very straightforward. In step
    3, we add an extra parameter, `encoding`, to specify that the file needs to be
    opened in something different to UTF-8.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*操作步骤...*部分的步骤1和2非常简单。在第3步中，我们添加了一个额外的参数`encoding`，以指定文件需要以与UTF-8不同的方式打开。'
- en: Python accepts a lot of standard encodings right out of the box. Check here
    for all of them and their aliases: [https://docs.python.org/3/library/codecs.html#standard-encodings](https://docs.python.org/3/library/codecs.html#standard-encodings).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Python可以直接接受很多标准编码。在这里检查所有标准编码及其别名：[https://docs.python.org/3/library/codecs.html#standard-encodings](https://docs.python.org/3/library/codecs.html#standard-encodings)。
- en: In step 4, we create a new file in ISO-8859-1 and write to it as usual. Notice
    the `'w'` parameter, which specifies to open it for writing and in text mode.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4步中，我们创建一个新的ISO-8859-1文件，并像往常一样写入。注意`'w'`参数，它指定以文本模式打开文件进行写入。
- en: Step 5 is a confirmation that the file is properly saved.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤5是确认文件已正确保存。
- en: There's more...
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This recipe assumes that we know the encoding a file is in. But sometimes we're
    not sure about that. Beautiful Soup, a module to parse HTML, can try to detect
    what encoding a particular file has.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱假设我们知道文件的编码。但有时我们不确定。Beautiful Soup，一个用于解析HTML的模块，可以尝试检测特定文件的编码。
- en: Automatically detecting what encoding a file has may be, well, impossible, as
    there are potentially an infinte number of encodings. But we'll check the usual
    encodings that should cover 90% of the real world cases. Just remember that the
    easiest way of knowing for sure is to ask whomever created the file in the first
    place.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 自动检测文件的编码可能是不可能的，因为潜在的编码可能有无限多种。但我们将检查通常的编码，应该可以覆盖90%的真实情况。只需记住，确切知道的最简单方法是询问创建文件的人。
- en: 'To do so, we''ll need to open the file to read in binary format with the `''rb''`
    parameter, to then pass the binary content to the `UnicodeDammit` module of Beautiful
    Soup, like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要以`'rb'`参数以二进制格式打开文件进行读取，然后将二进制内容传递给Beautiful Soup的`UnicodeDammit`模块，如下所示：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The encoding can then be inferred. Though `.unicode_markup` returns the decoded
    string, it's better to use this suggestion only once, to then open the file in
    our automated task with the proper encoding.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以推断出编码。虽然`.unicode_markup`返回解码后的字符串，但最好只使用这个建议一次，然后以正确的编码打开文件进行自动化任务。
- en: See also
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Manipulating strings* recipe in [Chapter 1](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml), *Let
    Us Begin Our Automation Journey*
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第1章](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml)中的*操作字符串*食谱，*让我们开始我们的自动化之旅*'
- en: The *Parsing HTML* recipe in [Chapter 3](d640524b-3aa3-406e-a6d4-842bc61c4658.xhtml), *Building
    Your First Web Scraping Application*
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第3章](d640524b-3aa3-406e-a6d4-842bc61c4658.xhtml)中的*解析HTML*食谱，*构建您的第一个网络爬虫应用程序*'
- en: Reading CSV files
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取CSV文件
- en: Some text files contain tabular data separated by commas. This is a convenient
    way of creating structured data, instead of using proprietary, more complex formats
    such as Excel or others. These files are called **Comma Separated Values**, or
    **CSV**, files and most spreadsheet packages also export to it.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一些文本文件包含用逗号分隔的表格数据。这是一种方便的创建结构化数据的方式，而不是使用专有的、更复杂的格式，如Excel或其他格式。这些文件称为**逗号分隔值**，或**CSV**文件，大多数电子表格软件也可以导出到它。
- en: Getting ready
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We've prepared a CSV file using the data for the 10 top movies by theatre attendance,
    as described by this page: [http://www.mrob.com/pub/film-video/topadj.html](http://www.mrob.com/pub/film-video/topadj.html).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了这个页面描述的10部票房电影的数据制作了一个CSV文件：[http://www.mrob.com/pub/film-video/topadj.html](http://www.mrob.com/pub/film-video/topadj.html)。
- en: 'We copied the first ten elements of the table into a spreadsheet program (Numbers)
    and exported the file as a CSV. The file is available in the GitHub repository
    in the `Chapter04/documents` directory as `top_films.csv`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将表格的前十个元素复制到电子表格程序（Numbers）中，并将文件导出为CSV。该文件可以在GitHub存储库的`Chapter04/documents`目录中找到，文件名为`top_films.csv`：
- en: '![](assets/167bb0f1-03c9-4a8f-80af-8faa051e79c5.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/167bb0f1-03c9-4a8f-80af-8faa051e79c5.png)'
- en: How to do it...
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'Import the `csv` module:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`csv`模块：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Open the file, create a reader, and iterate through it to show the tabular
    data of all rows (only three rows are shown):'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开文件，创建读取器，并迭代显示所有行的表格数据（仅显示了三行）：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Open the file and use `DictReader` to structure the data, including the header:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开文件并使用`DictReader`来构造数据，包括标题：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Each of the items in `structured_data` is a full dictionary that contains each
    of the values:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`structured_data`中的每个项目都是一个包含所有值的完整字典：'
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Notice that the file needs to be read, and we use a `with` context manager.
    This ensures that the file is closed at the end of the block.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，需要读取文件，并且我们使用`with`上下文管理器。这确保了文件在块结束时关闭。
- en: As shown in step 2 from the *How to do it…* section, the `csv.reader` class
    allows us to structure the returning lines of code by subdividing them as lists,
    following the format of the table data. Notice how all the values are described
    as strings. `csv.reader` does not understand whether the first line is a header
    or not.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如*如何做*部分的第2步所示，`csv.reader`类允许我们通过将它们细分为列表来结构化返回的代码行，遵循表格数据的格式。请注意，所有值都被描述为字符串。`csv.reader`无法理解第一行是否是标题。
- en: For a more structured read of the file, in step 3 we use `csv.DictReader`, which
    by default reads the first row as a header defining the fields described later,
    and then converts each of the rows into dictionaries with those fields.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更结构化地读取文件，在第3步中我们使用`csv.DictReader`，它默认将第一行读取为一个标题，定义后面描述的字段，然后将每一行转换为包含这些字段的字典。
- en: Sometimes, like in this case, the names of the fields as described in the file
    can be a little verbose. Don't be afraid to translate the dictionary on an extra
    step into more manageable field names.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，就像在这种情况下一样，文件中描述的字段名称可能有点冗长。不要害怕将字典翻译成更易管理的字段名称。
- en: There's more...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: As CSV is a very loosely defined interpretation, there are several ways that
    the data can be stored. This is represented in the `csv` module as **dialects**.
    For example, the values can be delimited by commas, semicolons, or tabs. The list
    of default accepted dialects can be displayed by calling `csv.list_dialect`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CSV是一个非常宽泛的解释，数据可以以几种方式存储。这在`csv`模块中表示为**方言**。例如，值可以由逗号、分号或制表符分隔。可以通过调用`csv.list_dialect`来显示默认接受的方言列表。
- en: By default, the dialect will be Excel, which is the most common one. Even other
    spreadsheets will commonly use it.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，方言将是Excel，这是最常见的方言。即使其他电子表格也通常会使用它。
- en: But dialects can also be inferred from the file itself through the `Sniffer`
    class. The `Sniffer` class analyzes a sample of the file (or the whole file) and
    returns a `dialect` object to allow reading in the proper way.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，方言也可以通过`Sniffer`类从文件本身推断出来。`Sniffer`类分析文件的样本（或整个文件）并返回一个`dialect`对象，以允许以正确的方式进行读取。
- en: 'Notice that the file is open with no new lines, to not make any assumptions
    about it:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，文件是没有换行符打开的，因此不要对其进行任何假设：
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The dialect can then be used when opening the reader. Note the `newline` again,
    as the dialect will split the lines correctly:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以在打开读取器时使用方言。再次注意`newline`，因为方言将正确地拆分行：
- en: '[PRE24]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The full `csv` module documentation can be found here: [https://docs.python.org/3.6/library/csv.html](https://docs.python.org/3.6/library/csv.html).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的`csv`模块文档可以在这里找到：[https://docs.python.org/3.6/library/csv.html](https://docs.python.org/3.6/library/csv.html)。
- en: See also
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Dealing with encodings* recipe
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*处理编码*配方'
- en: The *Reading text files* recipe
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*读取文本文件*配方'
- en: Reading log files
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取日志文件
- en: Another common structured text file format is **log files**. Log files consist
    of rows of logs, which are a line of text with a particular format. Typically,
    each one will have a time when it happened, so the file is an ordered collection
    of events.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的结构化文本文件格式是**日志文件**。日志文件由一行行的日志组成，每行都有特定格式的文本。通常，每个日志都会有发生时间，因此文件是事件的有序集合。
- en: Getting ready
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The `example_log.log` file with five sales logs can be obtained from the GitHub
    repository here: [https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/example_logs.log](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/example_logs.log).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从GitHub存储库获取包含五个销售日志的`example_log.log`文件：[https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/example_logs.log](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/example_logs.log)。
- en: 'The format is the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 格式如下：
- en: '[PRE25]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We'll use the `Chapter01/price_log.py` file to process each log into an object.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`Chapter01/price_log.py`文件来将每个日志处理为一个对象。
- en: How to do it...
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import `PriceLog`:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`PriceLog`：
- en: '[PRE26]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Open the log file and parse all logs:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开日志文件并解析所有日志：
- en: '[PRE27]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Determine the total income by all sales:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定所有销售的总收入：
- en: '[PRE28]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Determine how many units have been sold of each `product_id`:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定每个`product_id`已售出多少个单位：
- en: '[PRE29]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Filter the logs to find all occurrences of selling product ID `1489`:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤日志，找到所有销售产品ID为`1489`的事件：
- en: '[PRE30]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How it works...
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: As each of the logs is a single line, we open the file and go one by one, parsing
    each of them. The parsing code is available on `price_log.py`. Check it for more
    details.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个日志都是单独的一行，我们逐个打开文件并解析每个日志。解析代码在`price_log.py`中可用。查看它以获取更多细节。
- en: In Step 2 in the *How to do it…* section, we open the file and process each
    of the lines to create a log list with all our processed logs. Then, we can produce
    aggregation operations, as in the next steps.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在*如何做*部分的第2步中，我们打开文件并处理每一行，以创建包含所有已处理日志的日志列表。然后，我们可以进行聚合操作，就像下一步一样。
- en: Step 3 shows how to aggregate all values, in this case summing the price of
    all items sold over the log file, to get the total revenue.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 第3步显示了如何聚合所有值，例如对文件日志中出售的所有商品的价格进行求和，以获得总收入。
- en: Step 4 uses the Counter to determine the amount of each item in the file log.
    This returns a dictionary-like object with the values to count and the number
    of times they appear.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 第4步使用Counter来确定文件日志中每个项目的数量。这将返回一个类似字典的对象，其中包含要计数的值以及它们出现的次数。
- en: Filtering can also be done in a line-by-line approach, as shown in step 5\.
    This is similar to the other filtering in the recipes of this chapter.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤也可以逐行进行，就像第5步中所示的那样。这类似于本章中其他配方中的过滤。
- en: There's more...
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Remember that you can stop processing a file as soon as you have all the data
    you need. This may be a good strategy if the file is very big, as is usually the
    case with log files.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，一旦获得所需的所有数据，就可以立即停止处理文件。如果文件非常大，通常情况下是日志文件的情况，这可能是一个很好的策略。
- en: 'Counter is a great tool to quickly count a list. See the Python documentation
    here for more details: [https://docs.python.org/2/library/collections.html#counter-objects](https://docs.python.org/2/library/collections.html#counter-objects).
    You can get the ordered items by calling the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Counter是一个快速计算列表的好工具。有关更多详细信息，请参阅Python文档：[https://docs.python.org/2/library/collections.html#counter-objects](https://docs.python.org/2/library/collections.html#counter-objects)。您可以通过调用以下方式获取有序项目：
- en: '[PRE31]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: See also
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Using a third party tool—parse* recipe in [Chapter 1](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml), *Let
    Us Begin Our Automation Journey*
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第1章](e139aa50-5631-4b75-9257-d4eb2e12ef90.xhtml)中的*使用第三方工具—parse*食谱，*让我们开始自动化之旅*'
- en: The *Reading text files* recipe
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*读取文本文件*食谱'
- en: Reading file metadata
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取文件元数据
- en: File metadata is everything associated with a particular file that is not the
    data itself. That means parameters such as the size of the file, the creation
    date, or its permissions.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 文件元数据是与特定文件相关的除数据本身之外的所有内容。这意味着参数，如文件的大小、创建日期或其权限。
- en: Browsing through that data is important, for example, to filter files older
    than a date, or find all files bigger than a value in KBs. In this recipe, we'll
    see how to access the file metadata in Python.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览这些数据很重要，例如，要筛选早于某个日期的文件，或查找所有大于某个KB值的文件。在本食谱中，我们将看到如何在Python中访问文件元数据。
- en: Getting ready
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll use the `zen_of_python.txt` file, available in the GitHub repository
    ([https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt)).
    As you can see by using the `ls` command, the file has `856` bytes, and, in this
    example, it was created on June 14:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用GitHub存储库中的`zen_of_python.txt`文件（[https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/documents/zen_of_python.txt)）。通过使用`ls`命令，您可以看到该文件有`856`字节，并且在此示例中，它是在6月14日创建的：
- en: '[PRE32]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: On your computer the dates may vary, based on when you downloaded the code.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的计算机上，日期可能会有所不同，这取决于您下载代码的时间。
- en: How to do it...
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Import `os` and `datetime`:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`os`和`datetime`：
- en: '[PRE33]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Retrieve the stats of the `zen_of_python.txt` file:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索`zen_of_python.txt`文件的统计信息：
- en: '[PRE34]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Get the size of the file, in bytes:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取文件的大小，以字节为单位：
- en: '[PRE35]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Obtain when the file was last modified:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取文件上次修改的时间：
- en: '[PRE36]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Obtain when the file was last accessed:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取文件上次访问的时间：
- en: '[PRE37]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How it works...
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: '`os.stats` returns a stats object that represents the metadata stored in the
    filesystem. The metadata includes:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`os.stats`返回一个表示文件系统中存储的元数据的stats对象。元数据包括：'
- en: The size of the file, in bytes, as shown in step 3 in the *How to do it…* section,
    using `st_size`
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件的大小，以字节为单位，如*如何做…*部分中的步骤3所示，使用`st_size`
- en: When the file content was last modified, as shown in step 4, using `st_mtime`
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件内容上次修改的时间，如步骤4所示，使用`st_mtime`
- en: When the file was last read (accessed), as shown in step 5, using `st_atime`
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件上次读取（访问）的时间，如步骤5所示，使用`st_atime`
- en: The times are returned as timestamps, so in steps 4 and 5 we create a `datetime` object
    from the timestamps to better access the data.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 时间以时间戳形式返回，因此在步骤4和5中，我们从时间戳创建一个`datetime`对象，以更好地访问数据。
- en: All these values can be used to filter the files.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些值都可以用来过滤文件。
- en: Notice you don't need to open the file with `open()` to read its metadata. Detecting
    whether a file has been changed after a known value will be quicker than comparing
    its content, so you can take advantage of that for comparison.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您无需使用`open()`打开文件以读取其元数据。检测文件是否在已知值之后已更改将比比较其内容更快，因此您可以利用这一点进行比较。
- en: There's more...
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'To obtain the stats one by one, there are also convenience functions available
    in `os.path`, which follow the pattern `get<value>`:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要逐个获取统计信息，还有`os.path`中可用的便利函数，其遵循模式`get<value>`：
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The value is specified in the UNIX timestamp format (seconds since  January 1, 1970).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 该值以UNIX时间戳格式指定（自1970年1月1日以来的秒数）。
- en: Notice calling these three functions will be slower than calling `os.stats` and
    processing the results. Also, returned `stats` can be inspected to detect the
    available values.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，调用这三个函数的速度将比调用`os.stats`和处理结果要慢。此外，返回的`stats`可以被检查以检测可用的值。
- en: The values described in the recipe are available for all filesystems, but there
    are more that can be used.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 该食谱中描述的数值适用于所有文件系统，但还有更多可以使用的数值。
- en: For example, to obtain the creation date of a file, you can use the `st_birthtime`
    parameter for MacOS or `st_mtime` in Windows.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要获取文件的创建日期，可以在MacOS中使用`st_birthtime`参数，或在Windows中使用`st_mtime`。
- en: '`st_mtime` is always available, but its meaning changes between systems. In
    Unix systems, it will change when the content is modified, so it''s not a reliable
    time of creation.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`st_mtime`始终可用，但其含义在不同系统之间会有所不同。在Unix系统中，当内容被修改时，它会发生变化，因此它不是一个可靠的创建时间。'
- en: '`os.stat` will follow symbolic links. If you want to get the stats of a symbolic
    link, use `os.lstat()`.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`os.stat`将遵循符号链接。如果要获取符号链接的统计信息，请使用`os.lstat()`。'
- en: Check the full documentation about all available stats here: [https://docs.python.org/3.6/library/os.html#os.stat_result](https://docs.python.org/3.6/library/os.html#os.stat_result).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 查看所有可用统计信息的完整文档：[https://docs.python.org/3.6/library/os.html#os.stat_result](https://docs.python.org/3.6/library/os.html#os.stat_result)。
- en: See also
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Reading text files* recipe
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*读取文本文件*食谱'
- en: The *Reading images* recipe
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*读取图像*食谱'
- en: Reading images
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取图像
- en: Probably the most common data that is not text is image data. Images had their
    own set of specific metadata that can be read to filter values or perform other
    operations.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 可能最常见的非文本数据是图像数据。图像有自己一套特定的元数据，可以读取以筛选值或执行其他操作。
- en: A main challenge is dealing with multiple formats and different metadata definitions.
    We'll show in this recipe how to get information from both a JPEG and PNG, and
    how the same information can be encoded differently.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 主要挑战是处理多种格式和不同的元数据定义。在本示例中，我们将展示如何从JPEG和PNG中获取信息，以及相同的信息如何以不同的方式编码。
- en: Getting ready
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The best general toolkit for dealing with images in Python is, arguably, Pillow.
    This module allows you to easily read files in the most common formats, as well
    as perform operations on them. Pillow started as a fork of **PIL** (**Python Imaging
    Library**), a previous module that became stagnant some years ago.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 处理Python中图像的最佳通用工具可能是Pillow。该模块允许您轻松读取最常见格式的文件，并对其进行操作。Pillow最初是**PIL**（**Python
    Imaging Library**）的一个分支，几年前成为停滞不前的模块。
- en: 'We will also use the `xmltodict` module to transform some data in XML to a
    more convenient dictionary. Add both modules to `requirements.txt` and reinstall
    into the virtual environment:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用`xmltodict`模块将一些XML数据转换为更方便的字典。将这两个模块添加到`requirements.txt`中，并重新安装到虚拟环境中：
- en: '[PRE39]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The metadata information in photo files is defined in the **EXIF** (**Exchangeable
    Image File**) format. EXIF is a standard to store information about pictures,
    including things like what camera took the picture, when it was taken, GPS on
    where, exposure, focal length, color info, and so on.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 照片文件中的元数据信息是以**EXIF**（**Exchangeable Image File**）格式定义的。EXIF是一种存储有关照片信息的标准，包括拍摄照片的相机、拍摄时间、GPS位置、曝光、焦距、颜色信息等。
- en: You can get a good summary here: [https://www.slrphotographyguide.com/what-is-exif-metadata/](https://www.slrphotographyguide.com/what-is-exif-metadata/).
    All the information is optional, but virtually all digital cameras and processing
    software will store some data. Because of the privacy concerns, parts of it, like
    the exact location, can be disabled.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处获取更多信息：[https://www.slrphotographyguide.com/what-is-exif-metadata/](https://www.slrphotographyguide.com/what-is-exif-metadata/)。所有信息都是可选的，但几乎所有数字相机和处理软件都会存储一些数据。由于隐私问题，其中的部分信息，如确切位置，可以被禁用。
- en: 'The following images will be used for this recipe, and are available to download
    in the GiHub repository ([https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/images](https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/images)):'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像将用于此示例，并可在GiHub存储库中下载（[https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/images](https://github.com/PacktPublishing/Python-Automation-Cookbook/tree/master/Chapter04/images)）：
- en: '`photo-dublin-a1.jpg`'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`photo-dublin-a1.jpg`'
- en: '`photo-dublin-a2.png`'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`photo-dublin-a2.png`'
- en: '`photo-dublin-b.png`'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`photo-dublin-b.png`'
- en: Two of them, `photo-dublin-a1.jpg` and `photo-dublin-a2.png`, are the same photo,
    but while the first is the raw picture the second one has been retouched to slightly
    change the colors and crop it. Notice one is in JPEG format and the other in PNG.
    The other one, `photo-dublin-b.png `, is a different picture. Both pictures were
    taken in Dublin, with the same phone camera, on two different days.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 其中两张照片，`photo-dublin-a1.jpg`和`photo-dublin-a2.png`，是同一张照片，但第一张是原始照片，而第二张经过了轻微的颜色变化和裁剪。请注意，一张是JPEG格式，另一张是PNG格式。另一张照片，`photo-dublin-b.png`，是一张不同的照片。这两张照片是在都柏林用同一部手机相机拍摄的，分别在两天拍摄。
- en: While Pillow understands how JPG files store the EXIF info directly, PNG files
    store XMP info, a more generic standard that can contain EXIF info.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Pillow可以直接理解JPG文件存储的EXIF信息，但PNG文件存储XMP信息，这是一种更通用的标准，可以包含EXIF信息。
- en: More info about XMP can be obtained here: [https://www.adobe.com/devnet/xmp.html](https://www.adobe.com/devnet/xmp.html).
    For the most part, it defines an XML tree structure that's relatively readable
    in raw.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在此处获取有关XMP的更多信息：[https://www.adobe.com/devnet/xmp.html](https://www.adobe.com/devnet/xmp.html)。在很大程度上，它定义了一个相对易于阅读的XML树结构。
- en: To further complicate it, XMP is a subset of RDF, which is a standard describing
    the way of encoding the information.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 更进一步复杂化的是，XMP是RDF的一个子集，RDF是一种描述信息编码方式的标准。
- en: If EFIX, XMP, and RDF sounds confusing, well, it's because they are. Ultimately,
    they are just names to store the values we are interested in. We can inspect the
    specifics of the names using Python introspection tools and check exactly how
    the data is structured and what the name of the parameter we are looking for is.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果EFIX、XMP和RDF听起来令人困惑，那是因为它们确实如此。最终，它们只是用来存储我们感兴趣的值的名称。我们可以使用Python内省工具检查名称的具体信息，确切地查看数据的结构以及我们要查找的参数名称。
- en: 'As the GPS information is stored in different formats, we''ve included in the
    GitHub repository a file called `gps_conversion.py`, here: [https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/gps_conversion.py](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/gps_conversion.py). This
    includes the functions `exif_to_decimal` and `rdf_to_decimal`, which will transform
    both formats into decimals to compare them.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GPS信息以不同的格式存储，我们在GitHub存储库中包含了一个名为`gps_conversion.py`的文件，位于此处：[https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/gps_conversion.py](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/gps_conversion.py)。其中包括`exif_to_decimal`和`rdf_to_decimal`函数，它们将两种格式转换为十进制以进行比较。
- en: How to do it...
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the modules and functions to use in this recipe:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入要在此示例中使用的模块和函数：
- en: '[PRE40]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Open the first photo:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开第一张照片：
- en: '[PRE41]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Get the width, height, and format of the file:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取文件的宽度、高度和格式：
- en: '[PRE42]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Retrieve the EXIF information of the image, and process it for a convenient
    dictionary. Show the camera, the lens used, and when it was taken:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检索图像的EXIF信息，并处理为方便的字典。显示相机、使用的镜头以及拍摄时间：
- en: '[PRE43]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Open the second image and obtain the XMP info:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开第二张图像并获取XMP信息：
- en: '[PRE44]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Obtain the RDF description field, which contains all the values we are looking
    for. Retrieve the model (a TIFF value), the lens model (an EXIF value), and the
    creation date (an XMP value). Check the values are the same as in step 4, even
    if the file is different:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取包含我们正在寻找的所有值的RDF描述字段。检索模型（TIFF值）、镜头模型（EXIF值）和创建日期（XMP值）。检查这些值是否与第4步中的相同，即使文件不同：
- en: '[PRE45]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Obtain the GPS information in both pictures, transform into an equivalent format,
    and check that they are the same. Notice that the resolution is not the same,
    but they match up to the fourth decimal point:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取两张图片中的GPS信息，转换为等效格式，并检查它们是否相同。请注意，分辨率不同，但它们匹配到第四位小数：
- en: '[PRE46]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Open the third image and obtain the creation date and GPS info, and check it
    doesn''t match the other photo, although it is close (the second and third decimals
    are not the same):'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开第三张图片，获取创建日期和GPS信息，并检查它与另一张照片不匹配，尽管它很接近（第二和第三位小数不相同）：
- en: '[PRE47]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: How it works...
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Pillow is able to interpret files in most common languages, and open them as
    images in JPG format, as shown in step 2 in the *How to do it…* section.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Pillow能够解释大多数常见语言的文件，并将它们以JPG格式的图像打开，就像在*如何做…*部分的第2步中所示。
- en: The `Image` object contains the basic information about the size and format
    of the file, and is displayed in step 3\. The `info` property contains information
    that is dependent on the format.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: “Image”对象包含有关文件大小和格式的基本信息，并在第3步中显示。 “info”属性包含取决于格式的信息。
- en: The EXIF metadata for JPG files can be parsed with the `._getexif()` method,
    but then it needs to be translated properly, as it uses the raw binary definition.
    For example, the number 42,036 corresponds to the `LensModel` property. Fortunately,
    there's a definition of all tags in the `PIL.ExifTags` module. We translate the
    dictionary to readable tags in the step 4 to obtain a more readable dictionary.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: JPG文件的EXIF元数据可以使用“._getexif()”方法进行解析，但随后需要正确翻译，因为它使用原始二进制定义。例如，数字42,036对应于“LensModel”属性。幸运的是，“PIL.ExifTags”模块中有所有标签的定义。我们在第4步中将字典翻译为可读标签，以获得更可读的字典。
- en: Step 5 opens a PNG format, which has the same properties related to size, but
    the metadata is stored in XML/RDF format and needs to be parsed with the help
    of `xmltodict.` Step 6 shows how to navigate this metadata to extract the same
    information as in the JPG format. The data is the same, as both files come from
    the same original picture, even if the images are different.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 第5步打开了PNG格式，其与大小相关的属性相同，但元数据存储在XML/RDF格式中，并且需要借助“xmltodict”进行解析。第6步展示了如何导航此元数据以提取与JPG格式中相同的信息。数据是相同的，因为这两个文件来自同一原始图片，即使图片不同。
- en: '`xmltodict` has some issues when trying to parse data that''s not in XML format.
    Check that the input is valid XML.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: “xmltodict”在尝试解析非XML格式的数据时会出现一些问题。请检查输入是否为有效的XML。
- en: Step 7 extracted the GPS information for both images, which is stored in different
    ways, and shows they are the same (although the precision is different because
    of the way it is encoded).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 第7步提取了两张图片的GPS信息，这些信息以不同的方式存储，并显示它们是相同的（尽管由于编码方式不同，精度也不同）。
- en: Step 8 shows the information on a different photo.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 第8步显示了不同照片的信息。
- en: There's more...
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Pillow also has a lot of functionality around modifying pictures. It is very
    easy to resize or make simple modifications to a file, such as rotating it. You
    can find the complete Pillow documentation here: [https://pillow.readthedocs.io](https://pillow.readthedocs.io).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Pillow还具有许多围绕修改图片的功能。很容易调整大小或对文件进行简单修改，例如旋转。您可以在这里找到完整的Pillow文档：[https://pillow.readthedocs.io](https://pillow.readthedocs.io)。
- en: Pillow allow a lot of operations with images. Not only simple operations such
    as resizing or transforming one format into another, but also things like cropping
    the image, applying color filters, or generating animated GIFs. If you're interested
    in image processing using Python, it is definitely something to take a look at.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: Pillow允许对图像进行许多操作。不仅可以进行简单的操作，如调整大小或将一个格式转换为另一个格式，还可以进行诸如裁剪图像、应用颜色滤镜或生成动画GIF等操作。如果您对使用Python进行图像处理感兴趣，那么Pillow绝对值得一看。
- en: The GPS coordinates in the recipe are stated in **DMS** (**Degrees**, **Minutes**,
    **Seconds**), **DDM** (**Degrees**, **Decimal Minutes**), and transformed into
    **DD** (**Decimal Degrees**). You can find more about the different GPS formats
    here: [http://www.ubergizmo.com/how-to/read-gps-coordinates/](http://www.ubergizmo.com/how-to/read-gps-coordinates/).
    You'll also find how to search the exact locations of the pictures there, in case
    you're curious.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 食谱中的GPS坐标以DMS（度，分，秒），DDM（度，十进制分钟）表示，并转换为DD（十进制度）。您可以在这里找到有关不同GPS格式的更多信息：[http://www.ubergizmo.com/how-to/read-gps-coordinates/](http://www.ubergizmo.com/how-to/read-gps-coordinates/)。如果您感兴趣，还可以在那里找到如何搜索图片的确切位置。
- en: A more advanced use of reading image files is to try to process them for **OCR**
    (**Optical Character Recognition**). This means automatically detecting text in
    an image and extracting and processing it. The open source module `tesseract`
    allows you to do this, and it can be used with Python and Pillow.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读图像文件的更高级用法是尝试对其进行OCR（光学字符识别）处理。这意味着自动检测图像中的文本并提取和处理它。开源模块“tesseract”允许您执行此操作，并且可以与Python和Pillow一起使用。
- en: You need to install `tesseract` in your system ([https://github.com/tesseract-ocr/tesseract/wiki](https://github.com/tesseract-ocr/tesseract/wiki)),
    and the `pytesseract` Python module (using `pip install pytesseract`). You can
    download a file with clear text, called `photo-text.jpg`, from the GitHub repository
    at [https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-text.jpg](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-text.jpg)[:](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-text.jpg)
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在系统中安装`tesseract`（[https://github.com/tesseract-ocr/tesseract/wiki](https://github.com/tesseract-ocr/tesseract/wiki)），以及`pytesseract`
    Python模块（使用`pip install pytesseract`）。您可以从GitHub存储库中下载一个带有清晰文本的文件，称为`photo-text.jpg`，网址为[https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-text.jpg](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-text.jpg)。
- en: '[PRE48]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'OCR can be difficult if the text is not very clear in the image, or it is mixed
    with images, or it uses a distinctive font. There''s an example of that in the `photo-dublin-a-text.jpg` file,
    (available in the GitHub repository at [https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-dublin-a-text.jpg](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-dublin-a-text.jpg)),
    which includes text over the picture:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图像中的文本不太清晰，或者与图像混合在一起，或者使用了独特的字体，OCR可能会很困难。在GitHub存储库中提供了`photo-dublin-a-text.jpg`文件的示例（可在[https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-dublin-a-text.jpg](https://github.com/PacktPublishing/Python-Automation-Cookbook/blob/master/Chapter04/images/photo-dublin-a-text.jpg)找到），其中包含图片上的文本：
- en: '[PRE49]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'More information about Tesseract is available at the following links: [https://github.com/tesseract-ocr/tesseract](https://github.com/tesseract-ocr/tesseract)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Tesseract的更多信息，请访问以下链接：[https://github.com/tesseract-ocr/tesseract](https://github.com/tesseract-ocr/tesseract)
- en: '[https://github.com/madmaze/pytesseract](https://github.com/madmaze/pytesseract)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/madmaze/pytesseract](https://github.com/madmaze/pytesseract)'
- en: Properly importing files to OCR may require initial image processing for better
    results. Image processing is out of scope for the objectives of this book, but
    you may use OpenCV, which more powerful than Pillow. You can process a file and
    then open it with Pillow: [http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 将文件正确导入OCR可能需要进行初始图像处理以获得更好的结果。图像处理超出了本书的目标范围，但您可以使用比Pillow更强大的OpenCV。您可以处理一个文件，然后使用Pillow打开它：[http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html)。
- en: See also
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Reading text files* recipe
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读文本文件食谱
- en: The *Reading file metadata* recipe
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读文件元数据食谱
- en: The *Crawling and searching directories* recipe
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬行和搜索目录食谱
- en: Reading PDF files
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读PDF文件
- en: A common format for documents is **PDF** (**Portable Document Format**). It
    started as a format to describe a document for any printer, so PDF is a format
    that ensures that the document will be printed exactly as it shows, and therefore
    is a great way of guaranteeing consistency. It has become a powerful standard for
    sharing documents, especially documents that are read-only.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 文档的常见格式是PDF（便携式文档格式）。它起初是一种描述任何打印机文档的格式，因此PDF是一种确保文档将被打印为其显示的格式的格式，因此是保证一致性的绝佳方式。它已成为共享文档的强大标准，特别是只读文档。
- en: Getting ready
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: 'For this recipe, we are going to use the `PyPDF2` module. We need to add it
    to our virtual environment:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，我们将使用`PyPDF2`模块。我们需要将其添加到我们的虚拟环境中：
- en: '[PRE50]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: In the GitHub directory `Chapter03/documents`, we have prepared two documents,
    `document-1.pdf` and `document-2.pdf`, to use in this recipe. Note they contain
    mostly Lorem Ipsum text, which is just placeholder text.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub目录`Chapter03/documents`中，我们准备了两个文档，`document-1.pdf`和`document-2.pdf`，供本食谱使用。请注意，它们主要包含Lorem
    Ipsum文本，这只是占位文本。
- en: Lorem Ipsum text is commonly used in design to show text without needing to
    create the content before the design. Learn more about it here: [https://loremipsum.io/](https://loremipsum.io/).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: Lorem Ipsum文本通常用于设计，以显示文本而无需在设计之前创建内容。在这里了解更多：[https://loremipsum.io/](https://loremipsum.io/)。
- en: They are both the same test document, but the second one can only be opened
    with a password. The password is `automate`.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都是相同的测试文档，但第二个只能使用密码打开。密码是`automate`。
- en: How to do it...
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the module:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入模块：
- en: '[PRE51]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Open the `document-1.pdf` file and create a PDF document object. Notice the
    file needs to be open for the whole reading:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`document-1.pdf`文件并创建一个PDF文档对象。请注意，文件需要一直处于打开状态以进行阅读：
- en: '[PRE52]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Get the number of pages of the document, and check it is not encrypted:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取文档的页数，并检查它是否已加密：
- en: '[PRE53]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Get the creation date from the document info (`2018-Jun-24 11:15:18`), and
    discover that it has been created with a Mac `Quartz PDFContext`:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文档信息中获取创建日期（2018年6月24日11:15:18），并发现它是使用Mac的`Quartz PDFContext`创建的：
- en: '[PRE54]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Get the first page, and read the text on it:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取第一页，并阅读其上的文本：
- en: '[PRE55]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Do the same operation for the second page (redacted here):'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对第二页执行相同的操作（此处已编辑）：
- en: '[PRE56]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Close the file and open `document-2.pdf`:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭文件并打开`document-2.pdf`：
- en: '[PRE57]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Check the document is encrypted (it requires a password) and raises an error
    if trying to access its content:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查文档是否已加密（需要密码），并在尝试访问其内容时引发错误：
- en: '[PRE58]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Decrypt the file and access its content:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解密文件并访问其内容：
- en: '[PRE59]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Close the file to clean up:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭文件以进行清理：
- en: '[PRE60]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: How it works...
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Once the document is open, as shown on steps 1 and 2 in the *How to do it…*
    section, the `document` object provides access to the document.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文档打开，如*如何做...*部分的步骤1和2所示，`document`对象将提供对文档的访问。
- en: The most interesting properties are the number of pages, available in `.numPages`,
    and each of the pages, available in `.pages`, which can be accessed like a list.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 最有趣的属性是页面数量，可在 `.numPages` 中找到，以及每个页面，可在 `.pages` 中找到，可以像列表一样访问。
- en: Other data accessible is stored in `.documentInfo`, which stores metadata on
    the creator and when it was created.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 其他可访问的数据存储在 `.documentInfo` 中，其中存储了有关创建者和创建时间的元数据。
- en: The information in `.documentInfo` is optional and sometimes not up-to-date.
    It depends greatly on the tool used to generate the PDF.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '`.documentInfo` 中的信息是可选的，有时不是最新的。这在很大程度上取决于用于生成 PDF 的工具。'
- en: Each of the `page` objects can get its text by calling `.extractText()`, which
    will return all the text contained in the page, as done in steps 5 and 6\. This
    method tries to extract all text, but it has some limitations. For well-structured
    texts, such as our example, it works quite well and the resulting text can be
    processed cleanly. Dealing with text in multiple columns or located in strange
    positions, it may complicate working with it.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 `page` 对象都可以通过调用 `.extractText()` 来获取其文本，这将返回页面中包含的所有文本，就像步骤 5 和 6 中所做的那样。这种方法尝试提取所有文本，但它也有一些限制。对于结构良好的文本，例如我们的示例，它运行得相当好，生成的文本可以被干净地处理。处理多列文本或位于奇怪位置的文本可能会使处理变得复杂。
- en: Notice that the PDF file needs to be open for the whole operation, instead of
    using a `with` context operator. After leaving the `with` block, the file is closed.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，PDF 文件需要在整个操作期间保持打开状态，而不是使用 `with` 上下文运算符。离开 `with` 块后，文件将被关闭。
- en: Steps 8 and 9 shows how to deal with encrypted files. You can detect whether
    a file is encrypted or not with `.isEncrypted`, and then decrypt it with the `.decrypt`
    method, giving the password.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 8 和 9 展示了如何处理加密文件。您可以使用 `.isEncrypted` 检测文件是否已加密，然后使用 `.decrypt` 方法解密文件，提供密码。
- en: There's more...
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: PDF is such a flexible format that it is very standard, but that also means
    that it can be difficult to parse and process.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: PDF 是一种非常灵活的格式，因此它非常标准，但这也意味着它可能很难解析和处理。
- en: While most PDF files contain text information, it is not uncommon that they
    contain images. This, for example, happens very often with scanned documents.
    This means that the information is stored as a collection of images, instead of
    in text. This makes it difficult to extract the data; we end up having to resolve
    to methods such as OCR to parse the images into text.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数 PDF 文件包含文本信息，但并不罕见它们包含图像。例如，扫描文档经常会出现这种情况。这意味着信息被存储为图像的集合，而不是文本。这使得提取数据变得困难；我们最终不得不采用诸如
    OCR 这样的方法来将图像解析为文本。
- en: PyPDF2 does not provide a good interface to deal with images. You may need to
    transform the PDF into a collection of images and then process them. Most PDF
    readers can do it, or you can use a command-line tool such as `pdftooppm` ([https://linux.die.net/man/1/pdftoppm](https://linux.die.net/man/1/pdftoppm))
    or QPDF (see the following). See the *Reading images* recipe  for ideas about
    OCR.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: PyPDF2 没有提供处理图像的良好接口。您可能需要将 PDF 转换为一组图像，然后对其进行处理。大多数 PDF 阅读器都可以做到这一点，或者您可以使用命令行工具，如
    `pdftooppm`（[https://linux.die.net/man/1/pdftoppm](https://linux.die.net/man/1/pdftoppm)）或
    QPDF（参见下文）。有关 OCR 的想法，请参阅 *读取图像* 配方。
- en: 'Some ways of encrypting files may not be understood by PyPDF2\. It will generate
    `NotImplementedError: only algorithm code 1 and 2 are supported`. If that happens,
    you need to decrypt the PDF externally and open it once it is decrypted. You can
    use QPDF to create a copy without the password, as follows:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '某些加密文件的加密方式可能无法被 PyPDF2 理解。它会生成 `NotImplementedError: only algorithm code 1
    and 2 are supported`。如果发生这种情况，您需要在外部解密 PDF 并在解密后打开它。您可以使用 QPDF 创建一个无需密码的副本，方法如下：'
- en: '[PRE61]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The full QPDF is available here: [http://qpdf.sourceforge.net/files/qpdf-manual.html](http://qpdf.sourceforge.net/files/qpdf-manual.html).
    QPDF is available in most package managers as well.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 QPDF 可在此处找到：[http://qpdf.sourceforge.net/files/qpdf-manual.html](http://qpdf.sourceforge.net/files/qpdf-manual.html)。QPDF
    也可以在大多数软件包管理器中找到。
- en: QPDF is capable of doing a lot of transformations and analyzing PDFs in-depth.
    There are also bindings into Python on a module called `pikepdf` ([https://pikepdf.readthedocs.io/en/stable/](https://pikepdf.readthedocs.io/en/stable/)).
    This module is more difficult to use than PyPDF2 and it's not as straightforward
    for text extraction, but it can be useful if other operations such as extracting
    images from a PDF are required.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: QPDF 能够进行大量的转换和深入分析 PDF。还有一个名为 `pikepdf` 的 Python 模块的绑定（[https://pikepdf.readthedocs.io/en/stable/](https://pikepdf.readthedocs.io/en/stable/)）。这个模块比
    PyPDF2 更难使用，对于文本提取来说也不那么直接，但如果需要其他操作，比如从 PDF 中提取图像，它可能会很有用。
- en: See also
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Reading text files* recipe
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*读取文本文件* 配方'
- en: The *Crawling and searching directories* recipe
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*爬取和搜索目录* 配方'
- en: Reading Word documents
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读 Word 文档
- en: Word documents (`.docx`) are another common kind of document that stores text.
    They are typically generated with Microsoft Office, but other tools also produce
    compatible files. They are probably the most common format to share files that
    need to be editable, but they are also common for distributing documents.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: Word 文档（`.docx`）是另一种常见的存储文本的文档类型。它们通常是使用 Microsoft Office 生成的，但其他工具也会生成兼容的文件。它们可能是最常见的用于共享需要可编辑的文件的格式，但也常用于分发文档。
- en: We'll see in this recipe how to extract text information from a Word document.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将看到如何从 Word 文档中提取文本信息。
- en: Getting ready
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We''ll use the `python-docx` module to read and process Word documents:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `python-docx` 模块来读取和处理 Word 文档：
- en: '[PRE62]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: We have prepared a test file, available in the GitHub `Chapter04/documents`
    directory, called `document-1.docx`, which we'll use with this recipe. Note that
    this document follows the same Lorem Ipsun pattern that was described in the test
    document for the recipe *Reading PDF files* recipe .
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备了一个测试文件，位于 GitHub 的 `Chapter04/documents` 目录中，名为 `document-1.docx`，我们将在本配方中使用它。请注意，该文档遵循了与配方
    *读取 PDF 文件* 配方中的测试文档中描述的 Lorem Ipsun 模式相同。
- en: How to do it...
  id: totrans-331
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import `python-docx`:'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `python-docx`：
- en: '[PRE63]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Open the `document-1.docx` file:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `document-1.docx` 文件：
- en: '[PRE64]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Check some of the metadata properties stored in `core_properties`:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查存储在`core_properties`中的一些元数据属性：
- en: '[PRE65]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Check the number of paragraphs:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查段落的数量：
- en: '[PRE66]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Walk through the paragraphs to detect the ones that contain text. Notice not
    all text is displayed here:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历段落以检测包含文本的段落。请注意，并非所有文本都在此处显示：
- en: '[PRE67]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Obtain the text for paragraphs `30` and `31`, which correspond to the title
    and subtitle on the first page:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取段落`30`和`31`的文本，这对应于第一页的标题和副标题：
- en: '[PRE68]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Each of the paragraphs has `runs`, which are sections of the text with different
    properties. Check that the first text paragraph and `run` is in bold and the second
    is in italics:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个段落都有`runs`，这些是具有不同属性的文本部分。检查第一个文本段落和`run`是否为粗体，第二个是否为斜体：
- en: '[PRE69]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'In this document, most of the paragraphs have only one `run`, but we have a
    good example of different runs in paragraph `48`. Display its text and the different
    styles. For example, the word `Word` is in bold, and `ipsum` is in italics:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个文档中，大多数段落只有一个`run`，但我们在第`48`段有一个不错的例子，其中包含不同的运行。显示其文本和不同的样式。例如，单词`Word`是粗体，`ipsum`是斜体：
- en: '[PRE70]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: How it works...
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The most important peculiarity of Word documents is that the data is structured
    in paragraphs, instead of in pages. The size of the font, line size and other
    considerations may make the number of pages change.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: Word文档最重要的特点是数据是以段落而不是页面结构化的。字体大小、行大小和其他考虑因素可能导致页面数量发生变化。
- en: Most of the paragraphs are also typically empty, or include only new lines,
    tabs, or other whitespace characters. It is a good idea to check when a paragraph
    is empty and skip it.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数段落通常也是空的，或者只包含换行符、制表符或其他空白字符。检查段落是否为空并跳过它是一个好主意。
- en: In the *How to do it…* section, step 2 opens the file and step 3 shows how to
    access the core properties. These are properties that are defined in Word as document
    metadata, such as the author or creation date.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在*如何做…*部分，第2步打开文件，第3步显示如何访问核心属性。这些属性在Word中被定义为文档元数据，例如作者或创建日期。
- en: This information needs to be taken with a grain of salt, as a lot of tools that
    produce Word documents (but not Microsoft Office) won't necessarily fill it. Double-check
    before using that information.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这些信息需要谨慎对待，因为许多生成Word文档的工具（但不包括Microsoft Office）不一定会填充它。在使用该信息之前，请再次检查。
- en: The paragraphs of the document can be iterated and have their text extracted
    in raw format, as shown in step 6\. This is information that doesn't include styling
    information and it's typically the most useful one for processing the data automatically.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 文档的段落可以被迭代，并以原始格式提取其文本，如第6步所示。这是不包括样式信息的信息，通常对于自动处理数据来说是最有用的。
- en: If the styling information is required, the runs can be used, as in steps 7
    and 8\. Each paragraph can contain one or more runs, which are smaller units that
    share the same styling. For example, if a sentence is *Word1* word2 **word3**,
    there will be three runs, one with italic text (Word1), another with underline
    (word2), and another with bold (word3). Even more so, there can be intermediate
    runs with regular text that contains just the whitespaces, making a total of 5
    runs.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要样式信息，可以使用运行，如第7和第8步。每个段落可以包含一个或多个运行，这些运行是共享相同样式的较小单位。例如，如果一个句子是*Word1* word2
    **word3**，将有三个运行，一个是斜体文本（Word1），另一个是下划线（word2），另一个是粗体（word3）。更甚者，可能会有包含空格的常规文本的中间运行，总共有5个运行。
- en: The styling can be detected individually on properties such as bold, italic,
    or underline.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 样式可以通过属性进行单独检测，例如粗体、斜体或下划线。
- en: The division in runs can quite complicated. Due to the way editors work it,
    is not uncommon to have *half-words,* a split word in two runs, sometimes with
    the same properties. Do not rely on the number of runs and analyse the content.
    In particular, double-check if trying to ensure if a part with a particular style
    is divided in two or more runs. A good example is the words `lore` `m` (it should
    be `lorem`) in Step 8.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 运行的划分可能相当复杂。由于编辑器的工作方式，*半词*是很常见的，一个单词分成两个运行，有时具有相同的属性。不要依赖于运行的数量并分析内容。特别是在试图确保具有特定样式的部分是否分成两个或更多个运行时，请再次检查。一个很好的例子是第8步中的单词`lore`
    `m`（应该是`lorem`）。
- en: Be aware that, because Word documents are produced by so many sources, a lot
    of properties may not be set up, leaving it to the tool on what specifics to use.
    For example, is very common to keep the default font, which may mean that the
    font information is left empty.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于Word文档由许多来源生成，许多属性可能未设置，因此需要工具决定使用哪些具体属性。例如，保留默认字体非常常见，这可能意味着字体信息为空。
- en: There's more...
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Further style information can be found under the font attribute, such as `small_caps`
    or size:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在字体属性下找到更多样式信息，例如`small_caps`或大小：
- en: '[PRE71]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Normally focusing on the raw text, without paying attention to the style information
    is the correct parsing. But sometimes a bold word in a paragraph, will have special
    significance. It may be the header or the result you're looking for. Because it's
    highlighted, it likely is what you're looking for! Keep that in mind when analysing
    documents.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 通常专注于原始文本，而不关注样式信息是正确的解析。但有时段落中的粗体单词会有特殊意义。它可能是标题或您正在寻找的结果。因为它被突出显示，很可能就是您要找的！在分析文档时请记住这一点。
- en: You can find the whole `python-docx` documentation here: [https://python-docx.readthedocs.io/en/latest/](https://python-docx.readthedocs.io/en/latest/).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到整个`python-docx`文档：[https://python-docx.readthedocs.io/en/latest/](https://python-docx.readthedocs.io/en/latest/)。
- en: See also
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Reading text files* recipe
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*阅读文本文件*配方'
- en: The *Reading PDF files* recipe
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*阅读PDF文件*配方'
- en: Scanning documents for a keyword
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扫描文档以查找关键字
- en: In this recipe, we will join all the lessons of the previous recipes and will
    search the files in the directory for a particular keyword. This is a recap of
    the rest of the recipes in this chapter and includes a script that searches different
    kinds of files.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将汇总前几个配方的所有课程，并在目录中搜索特定关键字的文件。这是本章其余配方的总结，包括一个搜索不同类型文件的脚本。
- en: Getting ready
  id: totrans-368
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'Be sure to include all the following modules in the `requirements.txt` file
    and install them into your virtual environment:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在`requirements.txt`文件中包含以下所有模块，并将它们安装到您的虚拟环境中：
- en: '[PRE72]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Check that the directory to search has the following files (all are available
    in GitHub in the `Chapter04/documents` directory). Note that `file5.pdf` and `file6.pdf`
    are copies of `document-1.pdf`, for simplicity. `file1.txt` to `file4.txt` are
    empty files:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 检查要搜索的目录是否有以下文件（所有文件都在GitHub的`Chapter04/documents`目录中可用）。请注意，`file5.pdf`和`file6.pdf`是`document-1.pdf`的副本，以简化。`file1.txt`到`file4.txt`是空文件：
- en: '[PRE73]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: We've prepared a script, `scan.py`, that will search for a word in all the `.txt`,
    `.csv`, `.pdf`, and `.docx` files. The script is available in the `Chapter04`
    directory of the GitHub repository.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我们准备了一个名为`scan.py`的脚本，它将在所有`.txt`、`.csv`、`.pdf`和`.docx`文件中搜索一个单词。该脚本可在GitHub存储库的`Chapter04`目录中找到。
- en: How to do it...
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Refer to help `-h` for how to use the `scan.py` script:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有关如何使用`scan.py`脚本，请参考帮助`-h`：
- en: '[PRE74]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Search for the word `the`, which is present in most of the files:'
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索单词`the`，它出现在大多数文件中：
- en: '[PRE75]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Search for the word `lorem`, only present in the PDF and docx files:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索单词`lorem`，只出现在PDF和docx文件中：
- en: '[PRE76]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Search for the word `20£`, only present in the two ISO files, with different
    encodings:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索单词`20£`，只出现在两个ISO文件中，使用不同的编码：
- en: '[PRE77]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The search is case insensitive. Search for the word `BETTER`, only present
    in the `zen_of_python.txt` file:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索是不区分大小写的。搜索单词`BETTER`，只出现在`zen_of_python.txt`文件中：
- en: '[PRE78]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: How it works...
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The file `scan.py` has the following elements:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 文件`scan.py`包含以下元素：
- en: An entry point that parses the input parameters and creates the help for the
    command line.
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析输入参数并为命令行创建帮助的入口点。
- en: A main function that walks through the directory and analyses each of the files found.
    Based on their extension, it decides whether there's an available function to
    process and search it.
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个主要函数遍历目录并分析找到的每个文件。根据它们的扩展名，它决定是否有可用的函数来处理和搜索它。
- en: An `EXTENSION` dictionary, which pairs the extensions with the function to search
    them.
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个`EXTENSION`字典，将扩展名与搜索它们的函数配对。
- en: The `search_txt`, `search_csv`, `search_pdf`, and `search_docx` functions, which
    process and search for the required word for each kind of file.
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`search_txt`，`search_csv`，`search_pdf`和`search_docx`函数，用于处理和搜索每种文件所需的单词。'
- en: The comparison is case-insensitive, so the search word is transformed in lower
    case and, in all comparisons, the text is transformed into lowercase.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 比较不区分大小写，因此搜索词转换为小写，在所有比较中，文本都转换为小写。
- en: 'Each of the search functions have their own peculiarities:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 每个搜索函数都有自己的特点：
- en: '`search_txt` first opens the file to determine its encoding, using `UnicodeDammit`,
    then it opens the file and reads it line by line. If the word is found, it stops
    immediately and returns success.'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`search_txt`首先打开文件以确定其编码，使用`UnicodeDammit`，然后逐行打开文件并读取。如果找到该单词，它会立即停止并返回成功。'
- en: '`search_csv` opens the file in CSV, and iterates not only line by line, but
    also column by column. As soon as the word is found, it returns.'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`search_csv`以CSV格式打开文件，并不仅逐行迭代，还逐列迭代。一旦找到该单词，它就会返回。'
- en: '`search_pdf` opens the file and exits if it is encrypted. It not, it goes page
    by page, extracting the text and comparing it with the word. It returns as soon
    as it finds a match.'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`search_pdf`打开文件，如果文件被加密，则退出。如果没有加密，它会逐页提取文本并与单词进行比较。一旦找到匹配项，它就会立即返回。'
- en: '`search_docx` opens the file and iterates through all its paragraphs for a
    match. As soon as a match is found, the function returns.'
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`search_docx`打开文件并遍历其所有段落以进行匹配。一旦找到匹配项，函数就会返回。'
- en: There's more...
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'There are some extra ideas that could be implemented:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些额外的想法可以实现：
- en: More search functions could be added. In this chapter, we went through log files
    and images.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以添加更多的搜索函数。在本章中，我们浏览了日志文件和图像。
- en: A similar structure could work for searching for files and returning only the
    last 10.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似的结构也可以用于搜索文件并仅返回最后10个。
- en: '`search_csv` is not sniffing to detect the dialect. This could be added as
    well.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`search_csv`没有嗅探以检测方言。这也可以添加。'
- en: Reading is quite sequential. It should be possible to read the files in parallel,
    analyzing them for faster returns, but be aware that reading files in parallel
    can lead to sorting issues, as the files won't always be processed in the same
    order.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读是相当顺序的。应该可以并行读取文件，分析它们以获得更快的返回，但要注意，并行读取文件可能会导致排序问题，因为文件不总是以相同的顺序处理。
- en: See also
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Crawling and searching directories* recipe
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬行和搜索目录的配方
- en: The *Reading text files* recipe
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读文本文件的配方
- en: The *Dealing with encodings* recipe
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理编码的配方
- en: The *Reading CSV files* recipe
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读CSV文件的配方
- en: The *Reading PDF files* recipe
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读PDF文件的配方
- en: The *Reading Word documents* recipe
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读Word文档的配方
