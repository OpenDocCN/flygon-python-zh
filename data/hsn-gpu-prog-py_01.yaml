- en: Why GPU Programming?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要进行GPU编程？
- en: It turns out that besides being able to render graphics for video games, **graphics
    processing units** (**GPUs**) also provide a readily accessible means for the
    general consumer to do *massively parallel* *computing*—an average person can
    now buy a $2,000 modern GPU card from a local electronics store, plug it into
    their PC at home, and then use it almost immediately for computational power that
    would only have been available in the supercomputing labs of top corporations
    and universities only 5 or 10 years ago. This open accessibility of GPUs has become
    apparent in many ways in recent years, which can be revealed by a brief observation
    of the news—cryptocurrency miners use GPUs to generate digital money such as Bitcoins,
    geneticists and biologists use GPUs for DNA analysis and research, physicists
    and mathematicians use GPUs for large-scale simulations, AI researchers can now
    program GPUs to write plays and compose music, while major internet companies,
    such as Google and Facebook, use *farms* of servers with GPUs for large-scale
    machine learning tasks… the list goes on and on.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，除了能够为视频游戏渲染图形外，**图形处理单元**（**GPU**）还为普通消费者提供了一种便捷的方式进行*大规模并行* *计算*——现在普通人可以在当地的电子商店购买一张价值2000美元的现代GPU卡，将其插入家中的个人电脑，几乎立即就可以用于计算能力，而这种计算能力在5年或10年前只能在顶级公司和大学的超级计算实验室中获得。近年来，GPU的开放可访问性在许多方面已经显而易见，这可以通过简要观察新闻来揭示——加密货币挖矿者使用GPU生成比特币等数字货币，遗传学家和生物学家使用GPU进行DNA分析和研究，物理学家和数学家使用GPU进行大规模模拟，人工智能研究人员现在可以编程GPU来撰写剧本和作曲，而主要的互联网公司，如谷歌和Facebook，使用带有GPU的服务器*农场*进行大规模机器学习任务……等等。
- en: This book is primarily aimed at bringing you up to speed with GPU programming,
    so that you too may begin using their power as soon as possible, no matter what
    your end goal is. We aim to cover the core essentials of how to program a GPU,
    rather than provide intricate technical details and schematics of how a GPU works.
    Toward the end of the book, we will provide further resources so that you may
    specialize further, and apply your new knowledge of GPUs. (Further details as
    to particular required technical knowledge and hardware follow this section.)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书主要旨在让您迅速掌握GPU编程，以便您也可以尽快开始使用它们的强大功能，无论您的最终目标是什么。我们旨在涵盖如何编程GPU的核心要点，而不是提供GPU工作的复杂技术细节和原理图。在本书的末尾，我们将提供更多资源，以便您可以进一步专门化，并应用您对GPU的新知识。（有关特定所需的技术知识和硬件的进一步细节，请参阅本节后面的内容。）
- en: In this book, we will be working with **CUDA**, a framework for **general-purpose
    GPU** (**GPGPU**) programming from NVIDIA, which was first released back in 2007\.
    While CUDA is proprietary for NVIDIA GPUs, it is a mature and stable platform
    that is relatively easy to use, provides an unmatched set of first-party accelerated
    mathematical and AI-related libraries, and comes with the minimal hassle when
    it comes to installation and integration. Moreover, there are readily available
    and standardized Python libraries, such as PyCUDA and Scikit-CUDA, which make
    GPGPU programming all the more readily accessible to aspiring GPU programmers.
    For these reasons, we are opting to go with CUDA for this book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将使用**CUDA**，这是NVIDIA推出的**通用GPU**（**GPGPU**）编程框架，最早发布于2007年。虽然CUDA专为NVIDIA
    GPU而设计，但它是一个成熟稳定的平台，相对容易使用，提供了一套无与伦比的第一方加速数学和人工智能相关库，并且在安装和集成方面几乎没有麻烦。此外，还有现成的标准化Python库，如PyCUDA和Scikit-CUDA，使得渴望成为GPU程序员的人更容易接触GPGPU编程。出于这些原因，我们选择在本书中使用CUDA。
- en: CUDA is *always* pronounced *coo-duh*, and never as the acronym *C-U-D-A*! CUDA
    originally stood for *Compute Unified Device Architecture*, but Nvidia has dropped
    the acronym and now uses CUDA as a proper name written in all-caps.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA始终发音为coo-duh，而不是缩写C-U-D-A！CUDA最初代表“计算统一设备架构”，但Nvidia已经放弃了这个缩写，现在将CUDA作为一个大写的专有名词。
- en: We will now start our journey into GPU programming with an overview of **Amdahl's
    Law**. Amdahl's Law is a simple but effective method to estimate potential speed
    gains we can get by offloading a program or algorithm onto a GPU; this will help
    us determine whether it's worth our effort to rewrite our code to make use of
    the GPU. We will then go over a brief review of how to profile our Python code
    with the *cProfile *module, to help us find the bottlenecks in our code.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将开始介绍GPU编程的旅程，并概述**阿姆达尔定律**。阿姆达尔定律是一种简单但有效的方法，用于估计将程序或算法转移到GPU上可以获得的潜在速度增益；这将帮助我们确定是否值得重新编写我们的代码以利用GPU。然后，我们将简要回顾如何使用*cProfile*模块对我们的Python代码进行分析，以帮助我们找到代码中的瓶颈。
- en: 'The learning outcomes for this chapter are as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的学习成果如下：
- en: Understand Amdahl's Law
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解阿姆达尔定律
- en: Apply Amdahl's Law in the context of your code
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在代码的上下文中应用阿姆达尔定律
- en: Using the *cProfile* module for basic profiling of Python code
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*cProfile*模块对Python代码进行基本分析
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'An installation of Anaconda Python 2.7 is suggested for this chapter:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章建议安装Anaconda Python 2.7：
- en: '[https://www.anaconda.com/download/](https://www.anaconda.com/download/)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.anaconda.com/download/](https://www.anaconda.com/download/)'
- en: 'This chapter''s code is also available on GitHub:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码也可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)'
- en: For more information about the pre-requisites, check the preface of this book;
    for the software and hardware requirements, check the README section in [https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有关先决条件的更多信息，请查看本书的前言；有关软件和硬件要求，请查看[https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA](https://github.com/PacktPublishing/Hands-On-GPU-Programming-with-Python-and-CUDA)中的README部分。
- en: Parallelization and Amdahl's Law
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行化和阿姆达尔定律
- en: Before we can dive in and unlock the potential of GPUs, we first have to realize
    where their computational power lies in comparison to a modern Intel/AMD central
    processing unit (CPU)—the power does not lie in the fact that it has a higher
    clock speed than a CPU, nor in the complexity or particular design of the individual
    cores. An individual GPU core is actually quite simplistic, and at a disadvantage
    when compared to a modern individual CPU core, which use many fancy engineering
    tricks, such as branch prediction to reduce the **latency** of computations. **Latency** refers
    to the beginning-to-end duration of performing a single computation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解并发解锁GPU的潜力之前，我们首先要意识到它们的计算能力相对于现代英特尔/AMD中央处理单元（CPU）的优势并不在于它的时钟速度比CPU更高，也不在于单个核心的复杂性或特定设计。一个单独的GPU核心实际上相当简单，并且与现代单个CPU核心相比处于劣势，后者使用了许多花哨的工程技巧，比如分支预测来减少计算的**延迟**。**延迟**指的是执行单个计算的开始到结束的持续时间。
- en: The power of the GPU derives from the fact that there are many, many more cores
    than in a CPU, which means a huge step forward in **throughput**. **Throughput** here
    refers to the number of computations that can be performed simultaneously. Let's
    use an analogy to get a better understanding of what this means. A GPU is like
    a very wide city road that is designed to handle many slower-moving cars at once
    (high throughput, high latency), whereas a CPU is like a narrow highway that can
    only admit a few cars at once, but can get each individual car to its destination
    much quicker (low throughput, low latency).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GPU的强大之处在于它的核心比CPU多得多，这意味着**吞吐量**有了巨大的提升。这里的**吞吐量**指的是可以同时执行的计算数量。让我们使用一个类比来更好地理解这意思。GPU就像一条非常宽的城市道路，设计成可以同时处理许多行驶缓慢的汽车（高吞吐量，高延迟），而CPU就像一条狭窄的高速公路，一次只能容纳几辆车，但可以更快地将每辆车送到目的地（低吞吐量，低延迟）。
- en: We can get an idea of the increase in throughput by seeing how many cores these
    new GPUs have. To give you an idea, the average Intel or AMD CPU has only two
    to eight cores—while an entry-level, consumer-grade NVIDIA GTX 1050 GPU has *640
    cores*, and a new top-of-the-line NVIDIA RTX 2080 Ti has *4,352 cores*! We can
    exploit this massive throughput, provided we know how properly to **parallelize**
    any program or algorithm we wish to speed up. By **parallelize**, we mean to rewrite
    a program or algorithm so that we can split up our workload to run in parallel
    on multiple processors simultaneously. Let's think about an analogy from real-life.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查看这些新GPU有多少核心来了解吞吐量的增加。举个例子，普通的英特尔或AMD CPU只有2到8个核心，而入门级的消费级NVIDIA GTX
    1050 GPU有640个核心，而新的顶级NVIDIA RTX 2080 Ti有4,352个核心！我们可以利用这种大规模的吞吐量，只要我们知道如何正确地**并行化**任何我们希望加速的程序或算法。通过**并行化**，我们的意思是重写程序或算法，以便我们可以将工作负载并行地在多个处理器上同时运行。让我们从现实生活中想一个类比。
- en: Suppose that you are building a house and that you already have all of the designs
    and materials in place. You hire a single laborer, and you estimate it will take
    100 hours to construct the house. Let's suppose that this particular house can
    be built in such a way that the work can be perfectly divided between every additional
    laborer you hire—that is to say, it will take 50 hours for two laborers, 25 hours
    for four laborers, and 10 hours for ten laborers to construct the house—the number
    of hours to construct your house will be 100 divided by the number of laborers
    you hire. This is an example of a **parallelizable task**.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在建造一座房子，你已经准备好了所有的设计和材料。你雇了一个劳工，你估计需要100个小时来建造这座房子。假设这个特定的房子可以以这样的方式建造，即每增加一个劳工，工作就可以完美地分配给他们，也就是说，两个劳工需要50个小时，四个劳工需要25个小时，十个劳工需要10个小时来建造这座房子——建造你的房子所需的时间将是100除以你雇佣的劳工数量。这是一个**可并行化的任务**的例子。
- en: We notice that this task is twice as fast to complete for two laborers, and
    ten times as fast for ten laborers to complete together (that is, in *parallel)*
    as opposed to one laborer building the house alone (that is, in *serial)*—that
    is, if *N* is the number of laborers, then it will be *N* times as fast. In this
    case, *N* is known as the **speedup** of parallelizing our task over the serial
    version of our task.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，这个任务对于两个劳工来说完成的速度是原来的两倍，对于十个劳工来说完成的速度是原来的十倍（也就是说，**并行**完成），而不是一个劳工独自建造房子（也就是说，**串行**完成）——也就是说，如果*N*是劳工的数量，那么速度将是*N*倍。在这种情况下，*N*被称为我们的任务并行化速度的**加速比**。
- en: Before we begin to program a parallel version of a given algorithm, we often
    start by coming up with an estimate of the *potential* *speedup* that parallelization
    would bring to our task. This can help us determine whether it is worth expending
    resources and time writing a parallelization of our program or not. Because real
    life is more complicated than the example we gave here, it's pretty obvious that
    we won't be able to parallelize every program perfectly, all of the time—most
    of the time, only a part of our program will be nicely parallelizable, while the
    rest will have to run in serial.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始编写给定算法的并行版本之前，我们经常首先估计一下并行化对我们任务可能带来的*潜在* *加速*。这可以帮助我们确定是否值得花费资源和时间来编写我们程序的并行版本。因为现实生活比我们在这里给出的例子更复杂，很明显我们不可能始终完美地并行化每个程序——大多数情况下，我们的程序只有一部分可以很好地并行化，而其余部分将不得不串行运行。
- en: Using Amdahl's Law
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用阿姆达尔定律
- en: We will now derive **Amdahl's Law**, which is a simple arithmetic formula that
    is used to estimate potential speed gain that may arise from parallelizing some
    portion of code from a serial program onto multiple processors. We will do this
    by continuing with our prior analogy of building a house.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将推导**阿姆达尔定律**，这是一个简单的算术公式，用于估计将一部分串行程序代码并行化到多个处理器上可能带来的潜在速度增益。我们将继续使用我们之前建造房子的类比来做这件事。
- en: Last time, we only considered the actual physical construction of the house
    as the entire time duration, but now, we will also consider the time it takes
    to design the house into the time duration for building the house. Suppose that
    only one person in the world has the ability to design your house—you—and it takes
    you 100 hours to design the plans for your house. There is no possibility that
    any other person on the planet can compare to your architectural brilliance, so
    there is no possibility that this part of the task can be split up at all between
    other architects—that is, so it will take 100 hours to design your house, regardless
    of what resources you have or how many people you can hire. So, if you have only
    one laborer to build your house, the entire time it will take to build your home
    will be 200 hours—100 hours for you to design it, and 100 hours for a single laborer
    to build it. If we hire two laborers, this will take 150 hours—the time to design
    the house will remain at 100 hours, while the construction will take 50 hours.
    It's clear that the total number of hours to construct the house will be 100 +
    100 / *N*, where *N* is the number of laborers we hire.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上次，我们只考虑了房子的实际物理建造作为整个时间持续时间，但现在，我们还将把设计房子所需的时间考虑在内。假设世界上只有一个人有能力设计你的房子——也就是你——并且你需要100小时来设计你的房子的计划。世界上没有其他人能够与你的建筑才华相比，因此这部分任务无法在其他建筑师之间分配，因此无论你拥有什么资源或可以雇佣多少人，设计你的房子都需要100小时。因此，如果你只有一名劳工来建造你的房子，建造你的房子所需的整个时间将是200小时——你设计它需要100小时，一名劳工建造它需要100小时。如果我们雇佣两名劳工，这将需要150小时——设计房子的时间仍然是100小时，而建造将需要50小时。很明显，建造房子所需的总时间将是100
    + 100 / *N*，其中*N*是我们雇佣的劳工数量。
- en: Now, let's step back and think about how much time building the house takes
    if we hire one laborer—we ultimately use this to determine speedup as we hire
    additional laborers; that is, how many times faster the process becomes. If we
    hire a single laborer, we see that it takes the same amount of time to both design
    and construct the house—100 hours. So, we can say that that the portion of time
    spent on the design is .5 (50%), and the portion of the time it takes to construct
    the house is .5 (50%)—of course, both of these portions add up to 1, that is 100%.
    We want to make comparisons to this as we add laborers—if we have two laborers,
    the portion of time for the construction is halved, so in comparison to the original
    serial version of our task, this will take .5 + .5/2 = .75 (75%) of the time of
    the original task, and .75 x 200 hours is 150 hours, so we can see that this works.
    Moreover, we can see that if we have *N* laborers, we can calculate the percentage
    of time our *parallelized* construction with *N* laborers will take which the
    formula .5 + .5 / N.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们退一步思考一下，如果我们只雇用一名劳工来建造房子需要多少时间——我们最终使用这个来确定我们雇用额外劳工时的加速度；也就是说，这个过程变得快了多少倍。如果我们只雇用一名劳工，我们会发现设计和建造房子需要相同的时间——100小时。因此，我们可以说，设计所花费的时间是.5（50%），建造房子所花费的时间也是.5（50%）——当然，这两部分加起来是1，也就是100%。当我们增加劳工时，我们想要与这个进行比较——如果我们有两名劳工，建造的时间减半，因此与我们任务的原始串行版本相比，这将花费.5
    + .5/2 = .75（75%）的时间，原始任务的.75 x 200小时是150小时，因此我们可以看到这是有效的。此外，我们可以看到，如果我们有*N*名劳工，我们可以使用公式.5
    + .5 / N来计算我们*并行化*的建造所需的时间百分比。
- en: Now, let's determine the *speedup* we are gaining by adding additional laborers.
    Since it takes 75% of the time to build a house if we have two laborers, we can
    take the reciprocal of .75 to determine the speedup of our parallelization—that
    is, the speedup will be 1 / .75, which is around 1.33 times faster than if we
    only have one laborer. In this case, we see that the speedup will be 1 / (.5 +
    .5 / *N*) if we have *N* laborers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们确定通过增加额外的劳工我们获得的*加速度*。如果有两名劳工，建造一座房子只需要75%的时间，我们可以取.75的倒数来确定我们并行化的加速度——也就是说，加速度将是1
    / .75，比我们只有一名劳工时快大约1.33倍。在这种情况下，我们可以看到，如果有*N*名劳工，加速度将是1 / (.5 + .5 / *N*)。
- en: We know that .5 / N will shrink very close to 0 as we add more and more laborers,
    so we can see there is always an upper bound on the speedup you can get when you
    parallelize this task—that is, 1 / (.5 + 0) = 2\. We can divide the original serial
    time with the estimated maximum speedup to determine an absolute minimum amount
    of time this task will take—200 / 2 = 100 hours.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，随着我们增加越来越多的劳工，.5 / N会缩小到接近0，因此我们可以看到在并行化这个任务时，你可以获得的加速度总是有一个上限，即1 / (.5
    + 0) = 2。我们可以将原始串行时间除以估计的最大加速度，以确定此任务将花费的绝对最短时间——200 / 2 = 100小时。
- en: The principle we have just applied to determine speedups in parallel programming is
    known as **Amdahl's Law**. It only requires knowledge of the parallelizable proportion
    of execution time for code in our original serial program, which is referred to
    as *p*, and the number of processor cores *N* that we have available.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚应用的用于确定并行编程中加速度的原则被称为**阿姆达尔定律**。它只需要知道原始串行程序中可并行执行时间的比例，即*p*，以及我们可用的处理器核心数*N*。
- en: The proportion of execution time for code that is not parallelizable in this
    case is always *1 – p*, so we only need to know *p.*
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，不可并行化代码的执行时间比例始终为*1-p*，因此我们只需要知道*p*。
- en: 'We can now calculate speedup with **Amdahl''s Law** as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用**阿姆达尔定律**来计算加速度，如下所示：
- en: '![](assets/6cadaf5b-8271-4a68-97f5-c0ef0c7ce418.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6cadaf5b-8271-4a68-97f5-c0ef0c7ce418.png)'
- en: To sum it up, Amdahl's Law is a simple formula that allows us to roughly (*very
    roughly)* estimate potential speedup for a program that can be at least partially
    parallelized. This can provide a general idea as to whether it will be worthwhile
    to write a parallel version of a particular serial program, provided we know what
    proportion of the code we can parallelize (*p*), and how many cores we can run
    our parallelized code on (*N*).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，Amdahl's Law是一个简单的公式，允许我们粗略（非常粗略）地估计一个可以至少部分并行化的程序的潜在加速。这可以提供一个大致的想法，即是否值得编写特定串行程序的并行版本，前提是我们知道我们可以并行化代码的比例（*p*），以及我们可以在其上运行并行化代码的核心数（*N*）。
- en: The Mandelbrot set
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Mandelbrot集
- en: We are now prepared to see a very standard example for parallel computing that
    we will revisit later in this text—an algorithm to generate an image of the *Mandelbrot
    set*. Let's first define exactly what we mean.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备看一个非常标准的并行计算示例，我们将在本文中稍后重新讨论——一个生成*Mandelbrot集*图像的算法。让我们首先确切地定义我们的意思。
- en: For a given complex number, *c*, we define a recursive sequence for ![](assets/dd84683c-b705-45c0-9e1c-38a047267cc3.png),
    with ![](assets/c18dfdf9-11a0-4f03-bc42-fe6b3eb9bd04.png) and![](assets/28ea6645-7e3f-4dfe-abd3-218ad0efc60d.png) for
    ![](assets/432f297f-deb2-4c14-a670-d20f5651a213.png). If |*z[n]*| remains bounded
    by 2 as *n* increases to infinity, then we will say that *c* is a member of the
    Mandelbrot set.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于给定的复数*c*，我们为![](assets/dd84683c-b705-45c0-9e1c-38a047267cc3.png)定义一个递归序列，其中![](assets/c18dfdf9-11a0-4f03-bc42-fe6b3eb9bd04.png)和![](assets/28ea6645-7e3f-4dfe-abd3-218ad0efc60d.png)对于![](assets/432f297f-deb2-4c14-a670-d20f5651a213.png)。如果|*z[n]*|随着*n*增加到无穷大仍然受到2的限制，那么我们将说*c*是Mandelbrot集的成员。
- en: 'Recall that we can visualize the complex numbers as residing on a two-dimensional
    Cartesian plane, with the *x*-axis representing the real components and the y-axis
    representing the imaginary components. We can therefore easily visualize the Mandelbrot
    set with a very appealing (and well-known) graph. Here, we will represent members
    of the Mandelbrot set with a lighter shade, and nonmembers with a darker shade
    on the complex Cartesian plane as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，我们可以将复数可视化为驻留在二维笛卡尔平面上，其中*x*轴代表实部分量，y轴代表虚部分量。因此，我们可以很容易地用一个非常吸引人（并且众所周知）的图形来可视化Mandelbrot集。在这里，我们将在复数笛卡尔平面上用浅色表示Mandelbrot集的成员，用深色表示非成员，如下所示：
- en: '![](assets/9808a92f-5a3b-42e2-bf31-ee4297cd94ea.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9808a92f-5a3b-42e2-bf31-ee4297cd94ea.png)'
- en: Now, let's think about how we would go about generating this set in Python.
    We have to consider a few things first—since we obviously can't check whether
    every single complex number is in the Mandelbrot set, we have to choose a certain
    range to check over; we have to determine how many points in each range we will
    consider (*width, height*); and the maximum value of *n* that we will check |*z[n]*|
    for (`max_iters`). We can now prepare to implement a function to generate a graph
    of the Mandelbrot set—here, we do this by iterating over every single point in
    the graph in *serial*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑如何在Python中生成这个集合。首先，我们必须考虑一些事情——因为显然我们无法检查每一个复数是否在Mandelbrot集中，我们必须选择一个特定的范围进行检查；我们必须确定我们将考虑每个范围内的多少点（*宽度，高度*）；以及我们将检查的|*z[n]*|的最大值（`max_iters`）。我们现在可以准备实现一个生成Mandelbrot集图形的函数——在这里，我们通过在*串行*中迭代图中的每一个点来实现这一点。
- en: 'We will start by importing the NumPy library, which is a numerical library
    that we will be making ample use of throughout this text. Our implementation here
    is in the `simple_mandelbrot` function. We start by using NumPy''s `linspace`
    function to generate a lattice that will act as a discrete complex plane (the
    rest of the code that follows should be fairly straightforward):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先导入NumPy库，这是一个我们在本文中将大量使用的数值库。我们在`simple_mandelbrot`函数中实现这里。我们首先使用NumPy的`linspace`函数生成一个将充当离散复平面的格点（接下来的代码应该相当简单）：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now, we want to add some code to dump the image of the Mandelbrot set to a
    PNG format file, so let''s add the appropriate headers at the beginning:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要添加一些代码来将Mandelbrot集的图像转储到PNG格式文件中，所以让我们在开头添加适当的标头：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s add some code to generate the Mandelbrot set and dump it to a file,
    and use the time function to time both operations:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加一些代码来生成Mandelbrot集并将其转储到文件中，并使用时间函数来计算这两个操作的时间：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now let''s run this program (this is also available as the `mandelbrot0.py` file,
    in folder `1`, within the GitHub repository):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们运行这个程序（这也可以在GitHub存储库的文件夹`1`中的`mandelbrot0.py`文件中找到）：
- en: '![](assets/c06de047-84d9-45c7-b526-fa42221273bf.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c06de047-84d9-45c7-b526-fa42221273bf.png)'
- en: It took about 14.62 seconds to generate the Mandelbrot set, and about 0.11 seconds
    to dump the image. As we have seen, we generate the Mandelbrot set point by point;
    there is no interdependence between the values of different points, and it is,
    therefore, an intrinsically parallelizable function. In contrast, the code to
    dump the image cannot be parallelized.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 生成Mandelbrot集大约需要14.62秒，转储图像大约需要0.11秒。正如我们所看到的，我们逐点生成Mandelbrot集；不同点的值之间没有相互依赖，因此，这是一个固有的可并行化函数。相比之下，转储图像的代码无法并行化。
- en: Now, let's analyze this in terms of Amdahl's Law. What sort of speedups can
    we get if we parallelize our code here? In total, both pieces of the program took
    about 14.73 seconds to run; since we can parallelize the Mandelbrot set generation,
    we can say that the portion of execution time for parallelizable code is *p* =
    14.62 / 14.73 = .99\. This program is 99% parallelizable!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从Amdahl's Law的角度来分析这个问题。如果我们在这里并行化我们的代码，我们可以得到什么样的加速？总的来说，程序的两部分共计大约需要14.73秒才能运行；因为我们可以并行化Mandelbrot集的生成，我们可以说可并行化代码的执行时间部分是 *p*
    = 14.62 / 14.73 = .99。这个程序有99%的可并行性！
- en: 'What sort of speedup can we potentially get? Well, I''m currently working on
    a laptop with an entry-level GTX 1050 GPU with 640 cores; our *N* will thus be
    640 when we use the formula. We calculate the speedup as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会得到什么样的加速？嗯，我目前正在使用一台配有640个核心的入门级GTX 1050 GPU的笔记本电脑；因此，当我们使用这个公式时，我们的*N*将是640。我们计算速度提升如下：
- en: '![](assets/28a9b78a-7113-4023-bfeb-6538e158f111.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/28a9b78a-7113-4023-bfeb-6538e158f111.png)'
- en: That is definitely very good and would indicate to us that it is worth our effort
    to program our algorithm to use the GPU. Keep in mind that Amdahl's Law only gives
    a very rough estimate! There will be additional considerations that will come
    into play when we offload computations onto the GPU, such as the additional time
    it takes for the CPU to send and receive data to and from the GPU; or the fact
    that algorithms that are offloaded to the GPU are only partially parallelizable.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这绝对非常好，这表明我们值得努力编程使我们的算法使用GPU。请记住，阿姆达尔定律只是一个非常粗略的估计！当我们将计算卸载到GPU时，将会有其他考虑因素，比如CPU发送和接收数据到GPU的额外时间；或者卸载到GPU的算法只能部分并行化。
- en: Profiling your code
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对代码进行性能分析
- en: 'We saw in the previous example that we can individually time different functions
    and components with the standard `time` function in Python. While this approach
    works fine for our small example program, this won''t always be feasible for larger
    programs that call on many different functions, some of which may or may not be
    worth our effort to parallelize, or even optimize on the CPU. Our goal here is
    to find the bottlenecks and hotspots of a program—even if we were feeling energetic
    and used `time` around every function call we make, we might miss something, or
    there might be some system or library calls that we don''t even consider that
    happen to be slowing things down. We should find candidate portions of the code
    to offload onto the GPU before we even think about rewriting the code to run on
    the GPU; we must always follow the wise words of the famous American computer
    scientist Donald Knuth: Premature optimization is the root of all evil.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们看到我们可以使用Python中的标准`time`函数来分别计时不同的函数和组件。虽然这种方法对我们的小例子程序效果很好，但对于调用许多不同函数的大型程序来说，这种方法并不总是可行，其中一些函数可能值得我们投入精力并行化，或者甚至在CPU上进行优化。我们的目标是找到程序的瓶颈和热点，即使我们在每个函数调用周围使用`time`，我们可能会错过一些东西，或者可能有一些系统或库调用我们甚至没有考虑到，这些调用可能会拖慢速度。在我们考虑重写代码在GPU上运行之前，我们必须始终遵循著名的美国计算机科学家唐纳德·克努斯的智慧话语：过早优化是万恶之源。
- en: We use what is known as a **profiler** to find these hot spots and bottlenecks
    in our code. A **profiler** will conveniently allow us to see where our program
    is taking the most time, and allow us to optimize accordingly.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用所谓的**分析器**来找到代码中的热点和瓶颈。**分析器**将方便地让我们看到程序花费最多时间的地方，并让我们相应地进行优化。
- en: Using the cProfile module
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用cProfile模块
- en: We will primarily be using the *cProfile* module to check our code. This module
    is a standard library function that is contained in every modern Python installation.
    We can run the profiler from the command line with `-m cProfile`, and specify
    that we want to organize the results by the cumulative time spent on each function
    with `-s cumtime`, and then redirect the output into a text file with the `>` operator.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将主要使用*cProfile*模块来检查我们的代码。这个模块是一个标准库函数，包含在每个现代Python安装中。我们可以从命令行运行分析器，使用`-m
    cProfile`，并指定我们要按每个函数花费的累积时间来组织结果，然后用`>`操作符将输出重定向到文本文件中。
- en: This will work on both the Linux Bash or Windows PowerShell command line.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在Linux Bash或Windows PowerShell命令行上都可以使用。
- en: 'Let''s try this now:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们试一试：
- en: '![](assets/9c107054-44a8-4242-804f-a40a43808776.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9c107054-44a8-4242-804f-a40a43808776.png)'
- en: 'We can now look at the contents of the text file with our favorite text editor.
    Let''s keep in mind that the output of the program will be included at the beginning
    of the file:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以用我们喜欢的文本编辑器查看文本文件的内容。让我们记住，程序的输出将包含在文件的开头：
- en: '![](assets/374abc78-403e-4068-b78f-3e019bd0638c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/374abc78-403e-4068-b78f-3e019bd0638c.png)'
- en: Now, since we didn't remove the references to `time` in the original example,
    we see their output in the first two lines at the beginning. We can then see the
    total number of function calls made in this program, and the cumulative amount
    of time to run it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于我们没有删除原始示例中对`time`的引用，我们在开头的前两行看到了它们的输出。然后我们可以看到在程序中进行的函数调用总数，以及运行它所花费的累积时间。
- en: Subsequently, we have a list of functions that are called in the program, ordered
    from the cumulatively most time-consuming functions to the least; the first line
    is the program itself, while the second line is, as expected, the `simple_mandelbrot`
    function from our program. (Notice that the time here aligns with what we measured
    with the `time` command). After this, we can see many libraries and system calls
    that relate to dumping the Mandelbrot graph to a file, all of which take comparatively
    less time. We use such output from *cProfile* to infer where our bottlenecks are
    within a given program.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们有一个程序中调用的函数列表，按照累积耗时最长的函数到最短的顺序排列；第一行是程序本身，而第二行是我们程序中的`simple_mandelbrot`函数。（请注意，这里的时间与我们用`time`命令测量的时间一致）。之后，我们可以看到许多与将Mandelbrot图形转储到文件相关的库和系统调用，所有这些调用所花费的时间相对较少。我们使用*cProfile*的输出来推断给定程序中的瓶颈在哪里。
- en: Summary
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The main advantage of using a GPU over a CPU is its increased throughput, which
    means that we can execute more *parallel* code simultaneously on GPU than on a
    CPU; a GPU cannot make recursive algorithms or nonparallelizable algorithms somewhat
    faster. We see that some tasks, such as the example of building a house, are only
    partially parallelizable—in this example, we couldn't speed up the process of
    *designing* the house (which is intrinsically *serial* in this case), but we could
    speed up the process of the *construction,* by hiring more laborers (which is
    parallelizable in this case).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPU而不是CPU的主要优势是其增加的吞吐量，这意味着我们可以在GPU上同时执行更多*并行*代码，而不是在CPU上；GPU无法使递归算法或非并行化算法变得更快。我们看到一些任务，比如建房子的例子，只能部分并行化——在这个例子中，我们无法加快*设计*房子的过程（在这种情况下本质上是*串行*的），但我们可以通过雇佣更多的工人来加快*施工*的过程（在这种情况下是可并行化的）。
- en: We used this analogy to derive Amdahl's Law, which is a formula that can give
    us a rough estimate of potential speedup for a program if we know the percentage
    of execution time for code that is parallelizable, and how many processors we
    will have to run this code. We then applied Amdahl's Law to analyze a small program
    that generates the Mandelbrot set and dumps it to an image file, and we determined
    that this would be a good candidate for parallelization onto a GPU. Finally, we
    ended with a brief overview of profiling code with the *cPython* module; this
    allows us to see where the bottlenecks in a program are, without explicitly timing
    function calls.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个类比来推导阿姆达尔定律，这是一个公式，可以在我们知道可并行代码执行时间百分比以及我们将运行此代码所需的处理器数量时，给出程序潜在加速的粗略估计。然后，我们应用了阿姆达尔定律来分析一个生成曼德勃罗集并将其转储到图像文件的小程序，并且我们确定这将是一个很好的候选者，可以并行化到GPU上。最后，我们以简要概述使用*cPython*模块对代码进行性能分析结束；这使我们能够看到程序中的瓶颈在哪里，而无需显式计时函数调用。
- en: Now that we have a few of the fundamental concepts in place, and have a motivator
    to learn GPU programming, we will spend the next chapter setting up a Linux- or
    Windows 10-based GPU programming environment. We will then immediately dive into
    the world of GPU programming in the following chapter, where we will actually
    write a GPU-based version of the Mandelbrot program that we saw in this chapter.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一些基本概念，并且有了学习GPU编程的动力，我们将在下一章中设置基于Linux或Windows 10的GPU编程环境。然后我们将立即进入GPU编程的世界，在接下来的章节中，我们将实际编写一个基于GPU的曼德勃罗程序的版本，这是我们在本章中看到的。
- en: Questions
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: There are three `for` statements in this chapter's Mandelbrot example; however,
    we can only parallelize over the first two. Why can't we parallelize over all
    of the `for` loops here?
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章的曼德勃罗示例中有三个`for`语句；然而，我们只能并行化前两个。为什么我们不能在所有的`for`循环上并行化呢？
- en: What is something that Amdahl's Law doesn't account for when we apply it to
    offloading a serial CPU algorithm to a GPU?
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们将阿姆达尔定律应用于将串行CPU算法卸载到GPU时，有什么是阿姆达尔定律没有考虑到的吗？
- en: Suppose that you gain exclusive access to three new top-secret GPUs that are
    the same in all respects, except for core counts—the first has 131,072 cores,
    the second has 262,144 cores, and the third has 524,288 cores. If you parallelize
    and offload the Mandelbrot example onto these GPUs (which generates a 512 x 512
    pixel image), will there be a difference in computation time between the first
    and second GPU? How about between the second and third GPU?
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设您独家获得了三个全新的绝密GPU，它们在所有方面都相同，只是核心数量不同——第一个有131,072个核心，第二个有262,144个核心，第三个有524,288个核心。如果您将曼德勃罗示例并行化并卸载到这些GPU上（生成一个512
    x 512像素的图像），第一个GPU和第二个GPU之间的计算时间会有区别吗？第二个GPU和第三个GPU之间呢？
- en: Can you think of any problems with designating certain algorithms or blocks
    of code as *parallelizable* in the context of Amdahl's Law?
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在阿姆达尔定律的背景下，您能想到指定某些算法或代码块为*可并行化*存在什么问题吗？
- en: Why should we use profilers instead of just using Python's `time` function?
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们应该使用性能分析器而不只是使用Python的`time`函数？
