- en: Chapter 9. Input/Output, Physical Format, and Logical Layout
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章。输入/输出、物理格式和逻辑布局
- en: 'In this chapter, we''ll look at the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看以下配方：
- en: Using pathlib to work with filenames
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用pathlib处理文件名
- en: Reading and writing files with context managers
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用上下文管理器读写文件
- en: Replacing a file while preserving the previous version
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 替换文件并保留先前版本
- en: Reading delimited files with the CSV module
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CSV模块读取分隔文件
- en: Reading complex formats using regular expressions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则表达式读取复杂格式
- en: Reading JSON documents
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取JSON文档
- en: Reading XML documents
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取XML文档
- en: Reading HTML documents
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 读取HTML文档
- en: Upgrading CSV from DictReader to namedtuple reader
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从DictReader升级CSV到命名元组读取器
- en: Upgrading CSV from DictReader to namespace reader
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从DictReader升级CSV到命名空间读取器
- en: Using multiple contexts for reading and writing files
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多个上下文读写文件
- en: Introduction
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'The term **file** is overloaded with many meanings:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 术语**文件**有许多含义：
- en: The **operating system** ( **OS** ) uses a file as a way to organize bytes of
    data. The bytes might represent an image, some sound samples, words, or even an
    executable program. All of the wildly different kinds of content are reduced to
    a collection of bytes. Application software makes sense of the bytes.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作系统**（**OS**）使用文件来组织数据的字节。字节可以表示图像、一些声音样本、单词，甚至可执行程序。所有这些截然不同的内容都被简化为一组字节。应用软件理解这些字节。'
- en: 'There are two common kinds of OS files:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种常见的操作系统文件：
- en: Block files exist on devices such as disks or **solid state drives** ( **SSD**
    ). These files can be read in blocks of bytes. The OS can seek any specific byte
    within the file at any time.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 块文件存在于诸如磁盘或**固态驱动器**（**SSD**）等设备上。这些文件可以按字节块读取。操作系统可以随时在文件中寻找任何特定的字节。
- en: Character files are a way to manage a device like a network connection, or a
    keyboard attached to a computer. The file is viewed as a stream of individual
    bytes, which arrive at seemingly random points of time. There's no way to seek
    forward or backwards in the stream of bytes.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符文件是管理设备的一种方式，比如连接到计算机的网络连接或键盘。文件被视为一系列单独的字节流，这些字节在看似随机的时间点到达。在字节流中没有办法向前或向后寻找。
- en: The word *file* also defines a data structure used by the Python runtime. The
    Python file abstraction wraps the various OS file implementations. When we open
    a file, there is a binding between a Python abstraction, an OS implementation,
    and the underlying collection of bytes on a disk or other device.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文件*一词还定义了Python运行时使用的数据结构。Python文件抽象包装了各种操作系统文件实现。当我们打开一个文件时，Python抽象、操作系统实现和磁盘或其他设备上的字节集之间存在绑定。'
- en: A file can also be interpreted as a collection of Python objects. From this
    viewpoint, the bytes of the file represent Python objects such as strings or numbers.
    Files of text strings are very common and easy to work with. The Unicode characters
    are often encoded to bytes using the UTF-8 encoding scheme, but there are are
    many alternatives. Python provides modules such as `shelve` and `pickle` to encode
    more complex Python objects as bytes.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件也可以被解释为Python对象的集合。从这个角度来看，文件的字节表示Python对象，如字符串或数字。文本字符串文件非常常见且易于处理。Unicode字符通常使用UTF-8编码方案编码为字节，但还有许多其他选择。Python提供了诸如`shelve`和`pickle`等模块，以将更复杂的Python对象编码为字节。
- en: Often, we'll talk about how an object is serialized. When an object is written
    to a file, the Python object state information is transformed to a series of bytes.
    Deserialization is the reverse process of recovering a Python object from the
    bytes. We can also call this idea the representation of state because we generally
    serialize the state of each individual object separate from the class definition.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们会谈论对象是如何序列化的。当对象被写入文件时，Python对象状态信息被转换为一系列字节。反序列化是从字节中恢复Python对象的反向过程。我们也可以称之为状态的表示，因为我们通常将每个单独对象的状态与类定义分开序列化。
- en: 'When we process data from files, we''ll often need to make two distinctions:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理文件中的数据时，我们经常需要做两个区分：
- en: '**The physical format of the data** : This answers the fundamental question
    of what Python data structure is encoded by the bytes in a file. The bytes might
    be Unicode text. The text could represent **comma-separated values** ( **CSV**
    ) or JSON documents. The physical format is commonly handled by Python libraries.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的物理格式**：这回答了文件中的字节编码的Python数据结构是什么。字节可以是Unicode文本。文本可以表示**逗号分隔值**（**CSV**）或JSON文档。物理格式通常由Python库处理。'
- en: '**The logical layout of the data** : The layout looks at the details of the
    various CSV columns, or JSON fields within the data. In some cases, the columns
    may be labeled, or there may be data that must be interpreted by position. This
    is something that is often the responsibility of our application.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据的逻辑布局**：布局查看数据中的各种CSV列或JSON字段的细节。在某些情况下，列可能带有标签，或者可能有必须按位置解释的数据。这通常是我们应用程序的责任。'
- en: Both the physical format and logical layout are essential to interpreting the
    data on a file. We'll look at a number of recipes for working with different physical
    formats. We'll also look at ways to divorce our program from some aspects of logical
    layout.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 物理格式和逻辑布局对解释文件中的数据至关重要。我们将看一些处理不同物理格式的方法。我们还将研究如何使我们的程序与逻辑布局的某些方面分离。
- en: Using pathlib to work with filenames
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pathlib处理文件名
- en: 'Most operating systems use a hierarchical path to identify a file. Here''s
    an example filename:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数操作系统使用分层路径来标识文件。以下是一个示例文件名：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This full pathname has the following elements:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这个完整的路径名有以下元素：
- en: The leading `/` means the name is absolute. It starts from the root of the filesystem.
    In Windows, there can be an extra letter in front of the name, such as `C:` ,
    to distinguish the filesystems on each individual storage device. Linux and Mac
    OS X treat all of the devices as a single, large filesystem.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前导`/`表示名称是绝对的。它从文件系统的根目录开始。在Windows中，名称前面可以有一个额外的字母，比如`C:`，以区分每个存储设备上的文件系统。Linux和Mac
    OS X将所有设备视为单个大文件系统。
- en: The names such as `Users` , `slott` , `Documents` , `Writing` , `Python Cookbook`
    , and `code` represent the directories (or folders) of the filesystem. There must
    be a top-level `Users` directory. It must contain the `slott` subdirectory. This
    is true for each name in the path.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Users`，`slott`，`Documents`，`Writing`，`Python Cookbook`和`code`等名称代表文件系统的目录（或文件夹）。必须有一个顶层的`Users`目录。它必须包含`slott`子目录。对于路径中的每个名称都是如此。'
- en: In Windows, the OS uses `\` to separate items on the path. Python uses `/` .
    Python's standard `/` is converted to the Windows path separator character gracefully;
    we can generally ignore the Windows `\` .
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Windows中，操作系统使用`\`来分隔路径上的项目。Python使用`/`。Python的标准`/`会被优雅地转换为Windows路径分隔符字符；我们通常可以忽略Windows的`\`。
- en: There is no way to tell what kind of object the name `code` represents. There
    are many kinds of filesystem objects. The name `code` might be a directory that
    names other files. It could be an ordinary data file, or a link to a stream-oriented
    device. There is additional directory information that shows what kind of filesystem
    object this is.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 无法确定名称`code`代表什么类型的对象。有许多种文件系统对象。名称`code`可能是一个命名其他文件的目录。它可能是一个普通的数据文件，或者是一个指向面向流的设备的链接。还有额外的目录信息显示这是什么类型的文件系统对象。
- en: A path without the leading `/` is relative to the current working directory.
    In Mac OS X and Linux, the `cd` command sets the current working directory. In
    Windows, the `chdir` command does this job. The current working directory is a
    feature of the login session with the OS. It's made visible by the shell.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 没有前导`/`的路径是相对于当前工作目录的。在Mac OS X和Linux中，`cd`命令设置当前工作目录。在Windows中，`chdir`命令执行此操作。当前工作目录是与操作系统的登录会话相关的特性。它由shell可见。
- en: How can we work with pathnames in a way that's independent of the specific operating
    system? How can we simplify common operations to make them as uniform as possible?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何以与特定操作系统无关的方式处理路径名？我们如何简化常见操作，使它们尽可能统一？
- en: Getting ready
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'It''s important to separate two concepts:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要区分两个概念：
- en: The path that identifies a file
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标识文件的路径
- en: The contents of the file
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件的内容
- en: The path provides an optional sequence of directory names and the final filename.
    It may provide some information about the file contents via the filename extension.
    The directory includes the files name, information about when the file was created,
    who owns it, what the permissions are, how big it is, and other details. The contents
    of the file are separate from the directory information and the name.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 路径提供了一个可选的目录名称序列和最终的文件名。它可能通过文件扩展名提供有关文件内容的一些信息。目录包括文件名，有关文件创建时间、所有者、权限、大小以及其他详细信息。文件的内容与目录信息和名称是分开的。
- en: Often, a filename has a suffix that can provide a hint as to what the physical
    format is. A file ending in `.csv` is likely a text file that can be interpreted
    as rows and columns of data. This binding between name and physical format is
    not absolute. File suffixes are only a hint, and can be wrong.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，文件名具有后缀，可以提供有关物理格式的提示。以`.csv`结尾的文件可能是可以解释为数据行和列的文本文件。名称和物理格式之间的绑定并不是绝对的。文件后缀只是一个提示，可能是错误的。
- en: It's possible for the contents of a file to have more than one name. Multiple
    paths can link to a single file. The directory entries that provide additional
    names for the file's content are created with the link (`ln` ) command. Windows
    uses `mklink` . This is called a **hard link** because it's a low-level connection
    between names and content.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的内容可能有多个名称。多个路径可以链接到单个文件。提供文件内容的目录条目是使用链接（`ln`）命令创建的。Windows使用`mklink`。这被称为**硬链接**，因为它是名称和内容之间的低级连接。
- en: In addition to hard links, we can also have **soft links** or **symbolic links**
    (or junction points). A soft link is a different kind of file, the link is easily
    seen as a reference to another file. The GUI presentation of the OS may show these
    as a different icon and call it an alias or shortcut to make it clear.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 除了硬链接，我们还可以有**软链接**或**符号链接**（或连接点）。软链接是一种不同类型的文件，链接很容易被看作是对另一个文件的引用。操作系统的GUI呈现可能会将这些显示为不同的图标，并称其为别名或快捷方式以使其清晰可见。
- en: 'In Python, the `pathlib` module handles all of the path-related processing.
    The module makes several distinctions among paths:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，`pathlib`模块处理所有与路径相关的处理。该模块在路径之间进行了几个区分：
- en: Pure paths that may or may not refer to an actual file
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能或可能不引用实际文件的纯路径
- en: Concrete paths that are resolved and refer to an actual file
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析并引用实际文件的具体路径
- en: This distinction allows us to create pure paths for files that our application
    will likely create or refer to. We can also create concrete paths for those files
    that actually exist on the OS. An application can resolve a pure path to create
    a concrete path.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区别使我们能够为我们的应用程序可能创建或引用的文件创建纯路径。我们还可以为实际存在于操作系统上的文件创建具体路径。应用程序可以解析纯路径以创建具体路径。
- en: The `pathlib` module also makes a distinction between Linux path objects and
    Windows path objects. This distinction is rarely needed; most of the time, we
    don't want to care about the OS-level details of the path. An important reason
    for using `pathlib` is because we want processing that is identical irrespective
    of the underlying OS. The cases where we might want to work with a `PureLinuxPath`
    object are rare.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`pathlib`模块还区分Linux路径对象和Windows路径对象。这种区分很少需要；大多数情况下，我们不想关心路径的操作系统级细节。使用`pathlib`的一个重要原因是，我们希望处理的方式与底层操作系统无关。我们可能想要使用`PureLinuxPath`对象的情况很少。'
- en: 'All of the mini recipes in this section will leverage the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的所有迷你配方都将利用以下内容：
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We rarely need any of the other class definitions from `pathlib` .
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很少需要`pathlib`中的其他类定义。
- en: We'll presume that `argparse` is used to gather the file or directory names.
    For more information on `argparse` , see the *Using argparse to get command line
    input* recipe in [Chapter 5](text00063.html#page "Chapter 5. User Inputs and Outputs")
    , *User Inputs and Outputs* . We'll use the `options` variable, which has the
    `input` filename or directory name that the recipe works with.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设使用`argparse`来收集文件或目录名称。有关`argparse`的更多信息，请参见[第5章](text00063.html#page "第5章.
    用户输入和输出")中的*使用argparse获取命令行输入*配方，*用户输入和输出*。我们将使用`options`变量，该变量具有配方处理的`input`文件名或目录名。
- en: 'For demonstration purposes, a mock argument parsing is shown by providing the
    following `Namespace` object:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示目的，通过提供以下`Namespace`对象显示了模拟参数解析：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This `options` object has three mock argument values. The `input` value is
    a pure path: it doesn''t necessarily reflect an actual file. The `file1` and `file2`
    values reflect concrete paths that exist on the author''s computer. This object
    behaves the same as the options created by the `argparse` module.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`options`对象有三个模拟参数值。`input`值是一个纯路径：它不一定反映实际文件。`file1`和`file2`值反映了作者计算机上存在的具体路径。这个对象的行为与`argparse`模块创建的选项相同。
- en: How to do it...
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We''ll show a number of common pathname manipulations as separate mini recipes.
    This will include the following manipulations:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示一些常见的路径名操作作为单独的迷你配方。这将包括以下操作：
- en: Making the output filename from the input filename
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从输入文件名制作输出文件名
- en: Making a number of sibling output files
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制作多个兄弟输出文件
- en: Creating a directory and a number of files
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个目录和一些文件
- en: Comparing file dates to see which is newer
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较文件日期以查看哪个更新
- en: Removing a file
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除一个文件
- en: Finding all files that match a given pattern
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找所有与给定模式匹配的文件
- en: Making the output filename by changing the input suffix
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过更改输入后缀来制作输出文件名
- en: 'Perform the following steps to make the output filename by changing the input
    suffix:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤，通过更改输入后缀来生成输出文件名：
- en: 'Create the `Path` object from the input filename string. The `Path` class will
    properly parse the string to determine the elements of the path:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入文件名字符串创建`Path`对象。`Path`类将正确解析字符串以确定路径的元素：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this example, the `PosixPath` class is displayed because the author is using
    Mac OS X. On a Windows machine, the class would be `WindowsPath` .
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，显示了`PosixPath`类，因为作者使用Mac OS X。在Windows机器上，该类将是`WindowsPath`。
- en: 'Create the output `Path` object using the `with_suffix()` method:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`with_suffix()`方法创建输出`Path`对象：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: All of the filename parsing is handled seamlessly by the `Path` class. The `with_suffix()`
    method saves us from manually parsing the text of the filename.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的文件名解析都由`Path`类无缝处理。`with_suffix()`方法使我们不必手动解析文件名的文本。
- en: Making a number of sibling output files with distinct names
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制作具有不同名称的多个兄弟输出文件
- en: 'Perform the following steps for making a number of sibling output files with
    distinct names:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤，制作具有不同名称的多个兄弟输出文件：
- en: 'Create a `Path` object from the input filename string. The `Path` class will
    properly parse the string to determine the elements of the path:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入文件名字符串创建`Path`对象。`Path`类将正确解析字符串以确定路径的元素：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this example, the `PosixPath` class is displayed because the author uses
    Linux. On a Windows machine, the class would be `WindowsPath` .
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，显示了`PosixPath`类，因为作者使用Linux。在Windows机器上，该类将是`WindowsPath`。
- en: 'Extract the parent directory and the stem from the filename. The stem is the
    name without the suffix:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文件名中提取父目录和干部。干部是没有后缀的名称：
- en: '[PRE6]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Build the desired output name. For this example, we''ll append `_pass` to the
    filename. An input file of `file.csv` will produce an output of `file_pass.csv`
    :'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建所需的输出名称。在这个例子中，我们将在文件名后附加`_pass`。输入文件`file.csv`将产生输出`file_pass.csv`：
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Build the complete `Path` object:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建完整的`Path`对象：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `/` operator assembles a new path from `path` components. We need to put
    this in parentheses to be sure that it's performed first and creates a new `Path`
    object. The `input_directory` variable has the parent `Path` object, and the `output_stem_pass`
    is a simple string. After assembling a new path with the `/` operator, the `with_suffix()`
    method is used to assure a specific suffix is used.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`/`运算符从`path`组件组装一个新路径。我们需要将其放在括号中，以确保它首先执行并创建一个新的`Path`对象。`input_directory`变量具有父`Path`对象，`output_stem_pass`是一个简单的字符串。使用`/`运算符组装新路径后，使用`with_suffix()`方法来确保使用特定的后缀。'
- en: Creating a directory and a number of files
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建一个目录和一些文件
- en: 'The following steps are for creating a directory and a number of files:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤是为了创建一个目录和一些文件：
- en: 'Create the `Path` object from the input filename string. The `Path` class will
    properly parse the string to determine the elements of the path:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入文件名字符串创建`Path`对象。`Path`类将正确解析字符串以确定路径的元素：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this example, the `PosixPath` class is displayed because the author uses
    Linux. On a Windows machine, the class would be `WindowsPath` .
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，显示了`PosixPath`类，因为作者使用Linux。在Windows机器上，该类将是`WindowsPath`。
- en: 'Create the `Path` object for the output directory. In this case, we''ll create
    an `output` directory as a subdirectory with the same parent directory as the
    source file:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为输出目录创建`Path`对象。在这种情况下，我们将创建一个`output`目录作为与源文件相同父目录的子目录：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Create the output filename using the output `Path` object. In this example,
    the output directory will contain a file that has the same name as the input with
    a different suffix:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用输出`Path`对象创建输出文件名。在这个例子中，输出目录将包含一个与输入文件同名但具有不同后缀的文件：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We've used the `/` operator to assemble a new `Path` object from the parent
    `Path` and a string based on the stem of a filename. Once a `Path` object has
    been created, we can use the `with_suffix()` method to set the desired suffix
    for the file.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`/`运算符从父`Path`和基于文件名的干部的字符串组装一个新的`Path`对象。创建了`Path`对象后，我们可以使用`with_suffix()`方法为文件设置所需的后缀。
- en: Comparing file dates to see which is newer
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 比较文件日期以查看哪个更新
- en: 'The following are the steps to see newer file dates by comparing them:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过比较来查看更新文件日期的步骤：
- en: 'Create the `Path` objects from the input filename strings. The `Path` class
    will properly parse the string to determine the elements of the path:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入文件名字符串创建`Path`对象。`Path`类将正确解析字符串以确定路径的元素：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Use the `stat()` method of each `Path` object to get timestamps for the file.
    This method returns a `stat` object, within that `stat` object, the `st_mtime`
    attribute of that object provides the most recent modification time for the file:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用每个`Path`对象的`stat()`方法获取文件的时间戳。这个方法返回一个`stat`对象，在`stat`对象中，该对象的`st_mtime`属性提供了文件的最近修改时间：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The values are timestamps measured in seconds. We can easily compare the two
    values to see which is newer.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值是以秒为单位测量的时间戳。我们可以轻松比较这两个值，看哪个更新。
- en: 'If we want a timestamp that''s sensible to people, we can use the `datetime`
    module to create a proper `datetime` object from this:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要一个对人们有意义的时间戳，我们可以使用`datetime`模块从中创建一个合适的`datetime`对象：
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can use the `strftime()` method to format the `datetime` object or we can
    use the `isoformat()` method to provide a standardized display. Note that the
    time will have the local time zone offset implicitly applied to the OS timestamp;
    depending on the OS configuration(s) a laptop may not show the same time as the
    server that created it because they're in different time zones.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`strftime()`方法格式化`datetime`对象，或者我们可以使用`isoformat()`方法提供一个标准化的显示。请注意，时间将隐含地应用于操作系统时间戳的本地时区偏移；根据操作系统的配置，笔记本电脑可能不会显示与创建它的服务器相同的时间，因为它们处于不同的时区。
- en: Removing a file
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除文件
- en: 'The Linux term for removing a file is **unlinking** . Since a file may have
    many links, the actual data isn''t removed until all links are removed:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 删除文件的Linux术语是**unlinking**。由于文件可能有许多链接，直到所有链接都被删除，实际数据才会被删除：
- en: 'Create the `Path` object from the input filename string. The `Path` class will
    properly parse the string to determine the elements of the path:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入文件名字符串创建`Path`对象。`Path`类将正确解析字符串以确定路径的元素：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Use the `unlink()` method of this `Path` object to remove the directory entry.
    If this was the last directory entry for the data, then the space can be reclaimed
    by the OS:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用这个`Path`对象的`unlink()`方法来删除目录条目。如果这是数据的最后一个目录条目，那么空间可以被操作系统回收：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: If the file does not exist, a `FileNotFoundError` is raised. In some cases,
    this exception needs to be silenced with the `pass` statement. In other cases,
    a warning message might be important. It's also possible that a missing file represents
    a serious error.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果文件不存在，将引发`FileNotFoundError`。在某些情况下，这个异常需要用`pass`语句来消除。在其他情况下，警告消息可能很重要。也有可能缺少文件代表严重错误。
- en: Additionally, we can rename a file using the `rename()` method of a `Path` object.
    We can create new soft links using the `symlink_to()` method. To create OS-level
    hard links, we need to use the `os.link()` function.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以使用`Path`对象的`rename()`方法重命名文件。我们可以使用`symlink_to()`方法创建新的软链接。要创建操作系统级别的硬链接，我们需要使用`os.link()`函数。
- en: Finding all files that match a given pattern
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查找所有与给定模式匹配的文件
- en: 'The following are steps to find all files that match a given pattern:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是查找所有与给定模式匹配的文件的步骤：
- en: 'Create the `Path` object from the input directory name. The `Path` class will
    properly parse the string to determine the elements of the path:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入目录名称创建`Path`对象。`Path`类将正确解析字符串以确定路径的元素：
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Use the `glob()` method of the `Path` object to locate all files that match
    a given pattern. By default, this will not recursively walk the entire directory
    tree:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Path`对象的`glob()`方法来定位所有与给定模式匹配的文件。默认情况下，这不会递归遍历整个目录树：
- en: '[PRE18]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Inside the OS, a path is a sequence of directories (a folder is a depiction
    of a directory). In a name such as `/Users/slott/Documents/writing` , the root
    directory, `/` , contains a directory named `Users` . This contains a subdirectory
    `slott` , which contains `Documents` , which contains `writing` .
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在操作系统内部，路径是一系列目录（文件夹是目录的一种表示）。在诸如`/Users/slott/Documents/writing`的名称中，根目录`/`包含一个名为`Users`的目录。这个目录包含一个子目录`slott`，其中包含`Documents`，其中包含`writing`。
- en: In some cases, a simple string representation is used to summarize the navigation
    from root to directory through to the final target directory. The string representation;
    however, makes many kinds of path operations into complex string parsing problems.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，简单的字符串表示用于总结从根目录到目标目录的导航。然而，字符串表示使许多种路径操作变成复杂的字符串解析问题。
- en: 'The `Path` class definition simplifies many operations on pure paths. A pure
    `Path` may or may not reflect actual filesystem resources. Operations on `Path`
    include the following examples:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`Path`类定义简化了许多纯路径上的操作。纯`Path`可能反映实际的文件系统资源，也可能不反映。`Path`上的操作包括以下示例：'
- en: Extract the parent directory, as well as a sequence of all enclosing directory
    names.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取父目录，以及所有封闭目录名称的序列。
- en: Extract the final name, the stem of the final name, and the suffix of the final
    name.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取最终名称、最终名称的干部和最终名称的后缀。
- en: Replace the suffix with a new suffix or replace the entire name with a new name.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用新后缀替换后缀或用新名称替换整个名称。
- en: Convert a string to a `Path` . And also convert a `Path` to a string. Many OS
    functions and parts of Python prefer to use filename strings.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将字符串转换为`Path`。还可以将`Path`转换为字符串。许多操作系统函数和Python的部分偏好使用文件名字符串。
- en: Build a new `Path` object from an existing `Path` joined with a string using
    the `/` operator.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`/`运算符从现有`Path`连接的字符串构建一个新的`Path`对象。
- en: 'A concrete `Path` represents an actual filesystem resource. For concrete `Paths`
    , we can do a number of additional manipulations of the directory information:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 具体的`Path`表示实际的文件系统资源。对于具体的`Path`，我们可以对目录信息进行许多额外的操作：
- en: 'Determine what kind of directory entry this is: an ordinary file, a directory,
    a link, a socket, a named pipe (or fifo), a block device, or a character device.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定这是什么类型的目录项：普通文件、目录、链接、套接字、命名管道（或fifo）、块设备或字符设备。
- en: Get the directory details, this includes information such as timestamps, permissions,
    ownership, size, and so on. We can also modify these things.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取目录详细信息，包括时间戳、权限、所有权、大小等。我们也可以修改这些内容。
- en: We can unlink (or remove) the directory entry.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以取消链接（或删除）目录项。
- en: Just about anything we might want to do with directory entries for files can
    be done with the `pathlib` module. The few exceptions are part of the `os` or
    `os.path` module.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎可以使用`pathlib`模块对文件的目录项执行任何想要的操作。少数例外情况属于`os`或`os.path`模块的一部分。
- en: There's more...
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: When we look at other file-related recipes in the rest of this chapter, we'll
    use `Path` objects to name the files. The objective is to avoid trying to use
    strings to represent paths.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章的其余部分查看其他与文件相关的示例时，我们将使用`Path`对象来命名文件。目标是避免尝试使用字符串来表示路径。
- en: The `pathlib` module makes a small distinction between Linux pure `Path` objects,
    and Windows pure `Path` objects. Most of the time, we don't care about the OS-level
    details of the path.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`pathlib`模块在Linux纯`Path`对象和Windows纯`Path`对象之间做了一个小区别。大多数情况下，我们不关心路径的操作系统级细节。'
- en: 'There are two cases where it can help to produce pure paths for a specific
    operating system:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种情况可以帮助为特定操作系统生成纯路径：
- en: If we do development on a Windows laptop, but deploy web services on a Linux
    server, it may be necessary to use `PureLinuxPath` . This allows us to write test
    cases on the Windows development machine that reflects actual intended use on
    a Linux server.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们在Windows笔记本电脑上进行开发，但在Linux服务器上部署Web服务，可能需要使用`PureLinuxPath`。这使我们能够在Windows开发机器上编写测试用例，反映出在Linux服务器上的实际使用意图。
- en: If we do development on a Mac OS X (or Linux) laptop, but deploy exclusively
    to Windows servers, it may be necessary to use `PureWindowsPath` .
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们在Mac OS X（或Linux）笔记本电脑上进行开发，但专门部署到Windows服务器，可能需要使用`PureWindowsPath`。
- en: 'We might have something like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会有类似这样的东西：
- en: '[PRE19]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note that the `/` characters are normalized from Windows to Python notation
    when displaying the `WindowsPath` object. Using the `str()` function retrieves
    a path string appropriate for the Windows OS.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当显示`WindowsPath`对象时，`/`字符会从Windows标准化为Python表示法。使用`str()`函数检索适合Windows操作系统的路径字符串。
- en: If we try this using the generic `Path` class, we'll get an implementation appropriate
    to the user's environment, which may not be Windows. By using `PureWindowsPath`
    , we've bypassed the mapping to the user's actual OS.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试使用通用的`Path`类，我们将得到一个适合用户环境的实现，这可能不是Windows。通过使用`PureWindowsPath`，我们已经绕过了映射到用户实际操作系统的过程。
- en: See also
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In the  *Replacing a file while preserving the previous version* recipe, we'll
    look at how to leverage the features of a `Path` to create a temporary file and
    then rename the temporary file to replace the original file
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*替换文件并保留上一个版本*示例中，我们将看到如何利用`Path`的特性创建临时文件，然后将临时文件重命名以替换原始文件
- en: In the *Using argparse to get command-line input* recipe in [Chapter 5](text00063.html#page
    "Chapter 5. User Inputs and Outputs") , *User Inputs and Outputs* , we'll look
    at one very common way to get the initial string that will be used to create a
    `Path` object
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第5章](text00063.html#page "第5章。用户输入和输出")的*使用argparse获取命令行输入*示例中，我们将看到获取用于创建`Path`对象的初始字符串的一种非常常见的方法
- en: Reading and writing files with context managers
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用上下文管理器读写文件
- en: Many programs will access external resources such as database connections, network
    connections, and OS files. It's important for a reliable, well-behaved program
    to release all external entanglements reliably and cleanly.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 许多程序将访问外部资源，如数据库连接、网络连接和操作系统文件。对于一个可靠、行为良好的程序来说，可靠而干净地释放所有外部纠缠是很重要的。
- en: A program that raises an exception and eventually crashes can still properly
    release resources. This includes closing a file and being sure that any buffered
    data is properly written to the file.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 引发异常并最终崩溃的程序仍然可以正确释放资源。这包括关闭文件并确保任何缓冲数据被正确写入文件。
- en: This is particularly important for long-running servers. A web server may open
    and close many files. If the server did not close each file properly, then data
    objects might be left in memory, reducing the amount of room that can be used
    for ongoing web services. The loss of working memory appears like a slow leak.
    Eventually the server needs to be restarted, reducing availability.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于长时间运行的服务器尤为重要。Web服务器可能会打开和关闭许多文件。如果服务器没有正确关闭每个文件，那么数据对象可能会留在内存中，减少可用于进行网络服务的空间。工作内存的丢失看起来像是一个缓慢的泄漏。最终服务器需要重新启动，降低可用性。
- en: How can we be sure that resources are acquired and released properly? How can
    we avoid resource leaks?
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何确保资源被正确获取和释放？我们如何避免资源泄漏？
- en: Getting ready
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: One common example of expensive and important resources is an external file.
    A file that has been opened for writing is also a precious resource; after all,
    we run programs to create useful output in the form of files. It's essential that
    the OS-level resources associated with a file be cleanly released by the Python
    application. We want to be sure that buffers are flushed and the file is properly
    closed no matter what happens inside the application.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 昂贵和重要资源的一个常见例子是外部文件。已经打开进行写入的文件也是宝贵的资源；毕竟，我们运行程序来创建文件形式的有用输出。Python应用程序必须清楚地释放与文件相关的操作系统级资源。我们希望确保无论应用程序内部发生什么，缓冲区都会被刷新，文件都会被正确关闭。
- en: When we use a context manager, we can be sure that the files being used by our
    application are handled properly. Specifically, the file will always be closed
    even when exceptions are raised during processing.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用上下文管理器时，我们可以确保我们的应用程序使用的文件得到正确处理。特别是，即使在处理过程中引发异常，文件也始终会被关闭。
- en: As an example, we'll use a script to collect some basic information about files
    in a directory. This can be used to detect file changes, the technique is often
    used to trigger processing when a file has been replaced.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们将使用一个脚本来收集关于目录中文件的一些基本信息。这可以用于检测文件更改，这种技术通常用于在文件被替换时触发处理。
- en: 'We''ll write a summary file that has the filename, modification date, size,
    and a checksum computed from the bytes in the file. We can then examine the directory
    and compare it with the previous state from the summary file. The description
    of a single file''s details can be prepared by this function:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将编写一个摘要文件，其中包含文件名、修改日期、大小以及从文件中的字节计算出的校验和。然后我们可以检查目录并将其与摘要文件中的先前状态进行比较。这个函数可以准备单个文件的详细描述：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This function gets a relative filename from the given `Path` object in the `path`
    parameter. We could also use the `resolve()` method to get the absolute pathname.
    The `stat()` method of a `Path` object returns a number of OS status values. The
    `st_mtime` value of the status is the last modified time. The expression `path.stat().st_mtime`
    gets the modification time for the file. This is used to create a complete `datetime`
    object. The `isoformat()` method then provides a standardized display of the modification
    time.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数从`path`参数中的给定`Path`对象获取相对文件名。我们还可以使用`resolve()`方法获取绝对路径名。`Path`对象的`stat()`方法返回一些操作系统状态值。状态的`st_mtime`值是最后修改时间。表达式`path.stat().st_mtime`获取文件的修改时间。这用于创建完整的`datetime`对象。然后，`isoformat()`方法提供了修改时间的标准化显示。
- en: The value of `path.stat().st_size` is the file's current size. The value of
    `path.read_bytes()` is all of the bytes in the file, these are passed to the `md5`
    class to create a checksum using the MD5 algorithm. The `hexdigest()` function
    of the resulting `md5` object gives us a value that is sensitive enough to detect
    any single-byte change in the file.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`path.stat().st_size`的值是文件的当前大小。`path.read_bytes()`的值是文件中的所有字节，这些字节被传递给`md5`类，使用MD5算法创建校验和。结果`md5`对象的`hexdigest()`函数给出了一个足够敏感的值，可以检测到文件中的任何单字节更改。'
- en: We want to apply this to a number of files in a directory. If the directory
    is being used for example, files are being written frequently then it's possible
    that our analysis program might crash with an I/O exception while trying to read
    a file that's being written by a separate process.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想将这个应用到目录中的多个文件。如果目录正在被使用，例如，文件经常被写入，那么我们的分析程序在尝试读取被另一个进程写入的文件时可能会崩溃并出现I/O异常。
- en: We'll use a context manager to make sure the program provides good output even
    in the rare case that it crashes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用上下文管理器来确保程序即使在罕见的崩溃情况下也能提供良好的输出。
- en: How to do it...
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We''ll be working with file paths, so it''s important to import the `Path`
    class:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用文件路径，因此重要的是导入`Path`类：
- en: '[PRE21]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Create a `Path` that identifies the output file:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个标识输出文件的`Path`：
- en: '[PRE22]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `with` statement creates the `file` object, and assigns it to a variable,
    `summary_file` . It also uses this `file` object as the context manager:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`with`语句创建`file`对象，并将其分配给变量`summary_file`。它还将这个`file`对象用作上下文管理器：'
- en: '[PRE23]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can now use the `summary_file` variable as an output file. No matter what
    exceptions are raised inside the `with` statement, the file will be properly closed,
    and all OS resources released.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`summary_file`变量作为输出文件。无论`with`语句内部引发什么异常，文件都将被正确关闭，所有操作系统资源都将被释放。
- en: 'The following statements will write information about files in the current
    working directory to the open summary file. These are indented inside the `with`
    statement:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下语句将把当前工作目录中文件的信息写入打开的摘要文件。这些语句缩进在`with`语句内部：
- en: '[PRE24]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This creates a `Path` for the current working directory and saves the object
    in the `base` variable. The `glob()` method of a `Path` object will generate all
    filenames that match the given pattern. The `file_facts()` function shown previously
    produces a namespace object that has useful information. We can print each summary
    to the `summary_file` .
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为当前工作目录创建一个`Path`，并将对象保存在`base`变量中。`Path`对象的`glob()`方法将生成与给定模式匹配的所有文件名。之前显示的`file_facts()`函数将生成一个具有有用信息的命名空间对象。我们可以将每个摘要打印到`summary_file`。
- en: We've omitted converting the facts to a more useful notation. It can slightly
    simplify subsequent processing if the data is serialized in JSON notation.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们省略了将事实转换为更有用的表示。如果数据以JSON表示法序列化，可以稍微简化后续处理。
- en: When the `with` statement finishes, the file will be closed. This will happen
    irrespective of any exception that might have been raised.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 当`with`语句结束时，文件将被关闭。这将发生无论是否引发了任何异常。
- en: How it works...
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The context manager object and the `with` statement work together to manage
    valuable resources. In this case, the file connection is a relatively expensive
    resource because it binds OS resources with our application. It's also precious
    because it's the useful output from the script.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文管理器对象和`with`语句一起工作，以管理宝贵的资源。在这种情况下，文件连接是一个相对昂贵的资源，因为它将操作系统资源与我们的应用程序绑定在一起。它也很珍贵，因为它是脚本的有用输出。
- en: 'When we write `with x:` , the object `x` is the context manager. A context
    manager object responds to two methods. These two methods are invoked by the `with`
    statement on the object provided. The significant events are as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们写`with x:`时，对象`x`是上下文管理器。上下文管理器对象响应两种方法。这两种方法是由提供的对象上的`with`语句调用的。重要事件如下：
- en: '`x.__enter__()` is evaluated at the beginning of the context.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在上下文的开始时评估`x.__enter__()`。
- en: '`x.__exit__(*details)` is evaluated at the end of the context. The `__exit__()`
    is guaranteed irrespective of any exceptions that might have been raised within
    the context. The exception details are provided to the `__exit__()` method. The
    context manager might want to behave differently if there was an exception.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在上下文结束时评估`x.__exit__(*details)`。`__exit__()`是无论上下文中是否引发了任何异常都会被保证执行的。异常细节会提供给`__exit__()`方法。如果有异常，上下文管理器可能会有不同的行为。
- en: File objects and several other kinds of objects are designed to work with this
    object manager protocol.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 文件对象和其他几种对象都设计为与此对象管理器协议一起使用。
- en: 'Here''s the sequence of events that describe how the context manager is used:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是描述上下文管理器如何使用的事件序列：
- en: Evaluate `summary_path.open('w')` to create a file object. This is saved to
    `summary_file` .
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估`summary_path.open('w')`以创建一个文件对象。这保存在`summary_file`中。
- en: Evaluate `summary_file.__enter__()` as the with context starts.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在上下文开始时评估`summary_file.__enter__()`。
- en: Do the processing inside the `with` statement context. This will write several
    lines to the given file.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`with`语句上下文中进行处理。这将向给定文件写入几行。
- en: At the end of the `with` statement, evaluate `summary_file.__exit__()` . This
    will close the output file, and release all OS resources.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`with`语句结束时，评估`summary_file.__exit__()`。这将关闭输出文件，并释放所有操作系统资源。
- en: If an exception was raised inside the `with` statement and not handled, then
    reraise that exception now that the file is properly closed.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在`with`语句内引发了异常并且未处理，则现在重新引发该异常，因为文件已正确关闭。
- en: The file close operations are handled automatically by the `with` statement.
    They're always performed, even if there's an exception raised. This guarantee
    is essential to preventing resource leaks.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 文件关闭操作由`with`语句自动处理。它们总是执行，即使有异常被引发。这个保证对于防止资源泄漏至关重要。
- en: Some people like to quibble about the word  *always* : they like to search for
    the very few situations where the context manager will not work properly. For
    example, there is a remote possibility that the entire Python runtime environment
    crashes; this will invalidate all of the language guarantees. If the Python context
    manager doesn't close the file properly, the OS will close the file, but the final
    buffer of data may be lost. There's an even more remote possibility that the entire
    OS crashes, or the hardware stops, or the computer is destroyed during a zombie
    apocalypse; the context manager won't close the files in these situations, either.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人喜欢争论关于“总是”这个词：他们喜欢寻找上下文管理器无法正常工作的极少数情况。例如，有可能整个Python运行时环境崩溃；这将使所有语言保证失效。如果Python上下文管理器没有正确关闭文件，操作系统将关闭文件，但最终的数据缓冲区可能会丢失。甚至有可能整个操作系统崩溃，或者硬件停止，或者在僵尸启示录期间计算机被摧毁；上下文管理器在这些情况下也不会关闭文件。
- en: There's more...
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Many database connections and network connections also work as context managers.
    The context manager guarantees that the connection is closed properly and the
    resources released.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据库连接和网络连接也可以作为上下文管理器。上下文管理器保证连接被正确关闭并释放资源。
- en: We can use context managers for input files, also. The best practice is to use
    a context manager for all file operations. Most of the recipes in this chapter
    will use files and context managers.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以为输入文件使用上下文管理器。最佳实践是对所有文件操作使用上下文管理器。本章中的大多数配方都将使用文件和上下文管理器。
- en: In rare cases, we'll need to add context management capabilities to an object.
    The `contextlib` includes a function, `closing()` , which will call an object's
    `close()` method.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在罕见的情况下，我们需要为一个对象添加上下文管理能力。`contextlib`包括一个名为`closing()`的函数，它将调用对象的`close()`方法。
- en: 'We can use this to wrap a database connection that lacks appropriate context
    manager capabilities:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个来包装一个缺乏适当上下文管理器功能的数据库连接：
- en: '[PRE25]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This assumes that the `some_database()` function creates a connection to a database.
    This connection can't be directly used as a context manager. By wrapping the connection
    in the `closing()` function, we've added the necessary features to make this into
    a proper connection manager object so that we can be assured that the database
    is properly closed.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这假设`some_database()`函数创建了与数据库的连接。这种连接不能直接用作上下文管理器。通过将连接包装在`closing()`函数中，我们添加了必要的功能，使其成为一个适当的连接管理器对象，以确保数据库被正确关闭。
- en: See also
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: For more information on multiple contexts, see the *Using multiple contexts
    for reading and writing files* recipe
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关多个上下文的更多信息，请参阅*使用多个上下文读写文件*配方
- en: Replacing a file while preserving the previous version
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 替换文件同时保留先前的版本
- en: We can leverage the power of `pathlib` to support a variety of filename manipulations.
    In the *Using pathlib to work with filenames* recipe, we looked at a few of the
    most common techniques of managing directories, filenames, and file suffixes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用`pathlib`的强大功能来支持各种文件名操作。在*使用pathlib处理文件名*配方中，我们看了一些管理目录、文件名和文件后缀的最常见技术。
- en: One common file processing requirement is to create output files in a fail-safe
    manner. That is, the application should preserve any previous output file no matter
    how or where the application fails.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的文件处理要求是以安全失败的方式创建输出文件。也就是说，应用程序应该保留任何先前的输出文件，无论应用程序如何失败或者在何处失败。
- en: 'Consider the following scenario:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下情景：
- en: At time *t* [0] there's a valid `output.csv` file from yesterday's use of the
    `long_complex.py` application.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在时间*t*[0]，有一个有效的`output.csv`文件，是昨天使用`long_complex.py`应用程序的结果。
- en: At time  *t* [1] we start running the `long_complex.py` application. It begins
    overwriting the `output.csv` file. It is expected to finish normally at time *t*
    [3] .
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在时间*t*[1]，我们开始运行`long_complex.py`应用程序。它开始覆盖`output.csv`文件。预计在时间*t*[3]正常完成。
- en: At time *t* [2] , the application crashes. The partial `output.csv` file is
    useless. Worse, the valid file from time  *t* [0] is not available either, since
    it was overwritten.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在时间*t*[2]，应用程序崩溃。部分`output.csv`文件是无用的。更糟糕的是，从时间*t*[0]开始的有效文件也不可用，因为它已经被覆盖。
- en: Clearly, we can make backup copies of files. This introduces an extra processing
    step. We can do better. What's a good approach to creating files that are fail-safe?
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们可以备份文件。这引入了一个额外的处理步骤。我们可以做得更好。创建一个安全失败的文件的好方法是什么？
- en: Getting ready
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Fail-safe file output generally means that we don't overwrite the previous file.
    Instead, the application will create a new file using a temporary name. If the
    file was created successfully, then the old file can be replaced using a rename
    operation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 安全失败的文件输出通常意味着我们不覆盖先前的文件。相反，应用程序将使用临时名称创建一个新文件。如果文件成功创建，那么可以使用重命名操作替换旧文件。
- en: The goal is to create files in such a way that at any time prior to the rename,
    a crash will leave the original file in place. At any time subsequent to the rename,
    the new file is in place and is valid.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是以这样的方式创建文件，以便在重命名之前的任何时间点，崩溃都会保留原始文件。在重命名之后的任何时间点，新文件都已经就位并且有效。
- en: 'There are several ways to approach this. We''ll show a variation that uses
    three separate files:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以解决这个问题。我们将展示一种使用三个单独文件的变体：
- en: 'The output file that will be overwritten eventually: `output.csv` .'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出文件最终将被覆盖：`output.csv`。
- en: 'A temporary version of the file: `output.csv.tmp` . There are a variety of
    conventions for naming this file. Sometimes extra characters such as `~` or `#`
    are placed on the filename to indicate that it''s a temporary, working file. Sometimes
    it will be in the `/tmp` filesystem.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件的临时版本：`output.csv.tmp`。有各种命名这个文件的约定。有时会在文件名上加上`~`或`#`等额外字符，以表示它是一个临时工作文件。有时它会在`/tmp`文件系统中。
- en: 'The previous version of the file: `name.out.old` . Any previous `.old` file
    will be removed as part of finalizing the output.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件的先前版本：`name.out.old`。任何先前的`.old`文件都将在最终输出时被删除。
- en: How to do it...
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Import the `Path` class:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`Path`类：
- en: '[PRE26]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'For demonstration purposes, we''ll mock the argument parsing by providing the
    following `Namespace` object:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了演示目的，我们将通过提供以下`Namespace`对象来模拟参数解析：
- en: '[PRE27]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We've provided a mock value for the `target` command-line argument. This `options`
    object behaves like the options created by the `argparse` module.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为`target`命令行参数提供了一个模拟值。这个`options`对象的行为类似于`argparse`模块创建的选项。
- en: 'Create the pure `Path` for the desired output file. This file doesn''t exist
    yet, which is why this is a pure path:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为所需的输出文件创建纯`Path`。这个文件还不存在，这就是为什么这是一个纯路径：
- en: '[PRE28]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Create the pure `Path` for a temporary output file. This will be used to create
    output:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个临时输出文件的纯`Path`。这将用于创建输出：
- en: '[PRE29]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Write content to the temporary file. This is of course the heart of the application.
    It''s often quite complex. For this example, we''ve shortened it to writing just
    one literal string:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将内容写入临时文件。当然，这是应用程序的核心。通常相当复杂。对于这个例子，我们将它缩短为只写一个字面字符串：
- en: '[PRE30]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Any failure here has no impact on the original output file; the original file
    hasn't been touched.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的任何失败都不会影响原始输出文件；原始文件没有被触及。
- en: 'Remove any prior `.old file` :'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除任何先前的`.old文件`：
- en: '[PRE31]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Any failure at this point has no impact on the original output file.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 此时的任何失败都不会影响原始输出文件。
- en: 'If there''s an existing file, rename it to become the `.old file` :'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果存在文件，将其重命名为`.old文件`：
- en: '[PRE32]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Any failure after this will leave the `.old` file in place. This extra file
    can be renamed as part of a recovery process.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后的任何失败都会保留`.old`文件。这个额外的文件可以作为恢复过程的一部分重命名。
- en: 'Rename the temporary file to be the new output file:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将临时文件重命名为新的输出文件：
- en: '[PRE33]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: At this point, the file has been overwritten by renaming the temporary file.
    An `.old` file will be left around in case there's a need to roll back the processing
    to the previous state.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此时，文件已经被重命名临时文件覆盖。一个`.old`文件将保留下来，以防需要将处理回滚到先前的状态。
- en: How it works...
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This process involves three separate OS operations, an unlink, and two renames.
    This leads to a situation in which the `.old` file needs to be used to recover
    the previously good state.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程涉及三个单独的操作系统操作，一个unlink和两个重命名。这导致了一个情况，即`.old`文件需要用来恢复先前的良好状态。
- en: 'Here''s a timeline that shows the state of the various files. We''ve labeled
    the content as version 1 (the previous contents) and version 2 (the revised contents):'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个显示各种文件状态的时间表。我们已经将内容标记为版本 1（先前的内容）和版本 2（修订后的内容）：
- en: '| **Time** | **Operation** | **.csv.old** | **.csv** | **.csv.tmp** |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| **时间** | **操作** | **.csv.old** | **.csv** | **.csv.tmp** |'
- en: '| *t* [0] |  | version 0 | version 1 |  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| *t* [0] |  | 版本 0 | 版本 1 |  |'
- en: '| *t* [1] | writing | version 0 | version 1 | in-process |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| *t*[1] | 写入 | 版本 0 | 版本 1 | 进行中 |'
- en: '| *t* [2] | close | version 0 | version 1 | version 2 |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| *t* [2] | 关闭 | 版本 0 | 版本 1 | 版本 2 |'
- en: '| *t* [3] | unlink `.csv.old` |  | version 1 | version 2 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| *t* [3] | unlink `.csv.old` |  | 版本 1 | 版本 2 |'
- en: '| *t* [4] | rename `.csv` to `.csv.old` | version 1 |  | version 2 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| *t*[4] | 将`.csv`重命名为`.csv.old` | 版本 1 |  | 版本 2 |'
- en: '| *t* [5] | rename `.csv.tmp` to `.csv` | version 1 | version 2 |  |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| *t* [5] | 将`.csv.tmp`重命名为`.csv` | 版本 1 | 版本 2 |  |'
- en: 'While there are several opportunities for failure, there''s no ambiguity about
    which file is valid:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然存在几种失败的机会，但是关于哪个文件有效没有任何歧义：
- en: If there's a `.csv` file, it's the current, valid file
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有`.csv`文件，则它是当前的有效文件
- en: If there's no `.csv` file, then the `.csv.old`  file is a backup copy, which
    can be used for recovery
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有`.csv`文件，则`.csv.old`文件是备份副本，可用于恢复
- en: Since none of these operations involved actually copying the files, they're
    all extremely fast and very reliable.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些操作都不涉及实际复制文件，因此它们都非常快速且非常可靠。
- en: There's more...
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In many cases, the output files involve optionally creating a directory based
    on timestamps. This can be handled gracefully by the `pathlib` module, also. We
    might, for example, have an archive directory that we''ll put old files in:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，输出文件涉及根据时间戳可选地创建目录。 这也可以通过`pathlib`模块优雅地处理。 例如，我们可能有一个存档目录，我们将在其中放入旧文件：
- en: '[PRE34]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We may want to create date-stamped subdirectories for keeping temporary or
    working files:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能希望创建日期戳子目录以保存临时或工作文件：
- en: '[PRE35]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can then do the following to define a working directory:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以执行以下操作来定义工作目录：
- en: '[PRE36]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The `mkdir()` method will create the expected directory. Including the `parents=True`
    argument that assures that all parent directories will also be created. This can
    be handy the very first time an application is executed. The `exists_ok=True`
    is handy so that the existing directory can be reused without raising an exception.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '`mkdir()`方法将创建预期的目录。 包括`parents=True`参数，以确保还将创建所有父目录。 这在首次执行应用程序时非常方便。 `exists_ok=True`很方便，因此可以在不引发异常的情况下重用现有目录。'
- en: The `parents=True` is not the default. With the default of `parents=False` ,
    when a parent directory doesn't exist, the application will crash because the
    required file doesn't exist.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '`parents=True`不是默认值。 使用`parents=False`的默认值时，当父目录不存在时，应用程序将崩溃，因为所需的文件不存在。'
- en: Similarly, the `exists_ok=True` is not the default. By default, if the directory
    exists, a `FileExistsError` exception is raised. Including options that make the
    operation silent when the directory exists.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，`exists_ok=True`不是默认值。 默认情况下，如果目录存在，则会引发`FileExistsError`异常。 包括使操作在目录存在时保持安静的选项。
- en: Also, it's sometimes appropriate to use the `tempfile` module to create temporary
    files. This module can create filenames that are guaranteed to be unique. This
    allows a complex server process to create temporary files without regard to filename
    conflicts.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，有时适合使用`tempfile`模块创建临时文件。 该模块可以创建保证唯一的文件名。 这允许复杂的服务器进程创建临时文件，而不考虑文件名冲突。
- en: See also
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In the *Using pathlib to work with filenames* recipe, we looked at the fundamentals
    of the `Path` class
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*使用pathlib处理文件名*配方中，我们研究了`Path`类的基本原理。
- en: In [Chapter 11](text00120.html#page "Chapter 11. Testing") , *Testing* , we'll
    look at some techniques for writing unit tests that can assure that parts of this
    will behave properly
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第11章](text00120.html#page "第11章。测试")中，*测试*，我们将研究一些编写单元测试的技术，以确保其中的部分行为正常
- en: Reading delimited files with the CSV module
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CSV模块读取分隔文件
- en: One commonly used data format is CSV. We can easily generalize this to think
    of the comma as simply one of many candidate separator characters. We might have
    a CSV file that uses the `|` character as the separator between columns of data.
    This generalization makes CSV files particularly powerful.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的数据格式之一是CSV。 我们可以很容易地将逗号视为许多候选分隔符字符之一。 我们可能有一个使用`|`字符作为数据列之间分隔符的CSV文件。 这种泛化使CSV文件特别强大。
- en: How can we process data in one of the wide varieties of CSV formatting?
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何处理各种各样的CSV格式之一的数据？
- en: Getting ready
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'A summary of a file''s content is called a schema. It''s essential to distinguish
    between two aspects of the schema:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 文件内容的摘要称为模式。 必须区分模式的两个方面：
- en: '**The Physical Format of the file** : For CSV, this means the file contains
    text. The text is organized into rows and columns. There will be a row separator
    character (or characters); there will also be a column separator character. Many
    spreadsheet products will use `,` as the column separator and the `\r\n` sequence
    of characters as the row separator. Other formats are possible, though, and it''s
    easy to change the punctuation that separates columns and rows. The specific combination
    of punctuation is called the CSV dialect.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件的物理格式**：对于CSV，这意味着文件包含文本。 文本被组织成行和列。 将有一个行分隔符字符（或字符）； 也将有一个列分隔符字符。 许多电子表格产品将使用`,`作为列分隔符和`\r\n`字符序列作为行分隔符。
    其他格式也是可能的，而且很容易更改分隔列和行的标点符号。 特定的标点符号组合称为CSV方言。'
- en: '**The Logical Layout of the data in the file** : This is the sequence of data
    columns that are present. There are several common cases for handling the logical
    layout in CSV files:'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件中数据的逻辑布局**：这是存在的数据列的顺序。 处理CSV文件中的逻辑布局有几种常见情况：'
- en: The file has one line of headings. This is ideal, and fits nicely with the way
    the CSV module works. The best headings are proper Python variable names.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该文件有一行标题。 这是理想的，并且与CSV模块的工作方式非常匹配。 最好的标题是适当的Python变量名。
- en: The file has no headings, but the column positions are fixed. In this case,
    we can impose headings on the file when we open it.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件没有标题，但列位置是固定的。 在这种情况下，我们可以在打开文件时对文件施加标题。
- en: If the file has no headings and the column positions aren't fixed, this is generally
    a serious problem. It can't easily be solved. Additional schema information is
    required; a separate list of column definitions, for example, can make the file
    useable.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果文件没有标题并且列位置不固定，则通常会出现严重问题。 这很难解决。 需要额外的模式信息； 例如，列定义的单独列表可以使文件可用。
- en: The file has multiple lines of headings. In this case, we have to write special
    processing to skip past these lines. We will also have to replace complex headings
    with something more useful in Python.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件有多行标题。在这种情况下，我们必须编写特殊处理来跳过这些行。我们还必须用Python替换复杂的标题为更有用的内容。
- en: An even more difficult case is where the file is not in proper **First Normal
    Form** ( **1NF** ). In 1NF, each row is independent of all other rows. When a
    file is not in this normal form, we'll need to add a generator function to rearrange
    the data into 1NF. See the *Slicing and dicing a list* recipe in [Chapter 4](text00048.html#page
    "Chapter 4. Built-in Data Structures – list, set, dict") , *Built-in Data Structures
    – list, set, dict* , and *Using stacked generator expressions* recipe in [Chapter
    8](text00088.html#page "Chapter 8. Functional and Reactive Programming Features")
    , *Functional And Reactive Programming Features* for other recipes that work on
    normalizing data structures.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更困难的情况是文件不符合**第一范式**（**1NF**）。在1NF中，每行都独立于所有其他行。当文件不符合这个正常形式时，我们需要添加一个生成器函数来将数据重新排列为1NF。参见[第4章](text00048.html#page
    "第4章.内置数据结构-列表、集合、字典")中的*切片和切块列表*配方，*内置数据结构-列表、集合、字典*，以及[第8章](text00088.html#page
    "第8章.功能和响应式编程特性")中的*使用堆叠的生成器表达式*配方，*功能和响应式编程特性*，了解其他规范化数据结构的配方。
- en: 'We''ll look at a relatively simple CSV file that has some real-time data recorded
    from the log of a sailboat. This is the `waypoints.csv` file. The data looks as
    follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看一个相对简单的CSV文件，其中包含从帆船日志记录的实时数据。这是`waypoints.csv`文件。数据如下所示：
- en: '[PRE37]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This data has four columns that need to be reformatted to create more useful
    information.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据有四列，需要重新格式化以创建更有用的信息。
- en: How to do it...
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the `csv` module and the `Path` class:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`csv`模块和`Path`类：
- en: '[PRE38]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'From `pathlib` import `PathExamine` from the data to confirm the following
    features:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`pathlib`导入`Path`检查数据以确认以下特性：
- en: 'The column separator characters: `'',''` are the default.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列分隔符字符：`','`是默认值。
- en: 'The row separator characters: `''\r\n''` are widely used in both Windows and
    Linux. This may be a feature of Excel, but it''s quite common. Python''s universal
    newlines feature means that the Linux standard `''\n''` will work just as well
    as a row separator.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行分隔符字符：`'\r\n'`在Windows和Linux中广泛使用。这可能是Excel的一个特性，但非常普遍。Python的通用换行符功能意味着Linux标准的`'\n'`将与行分隔符一样有效。
- en: The presence of a single-row heading. If not present, this information can be
    provided separately.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单行标题的存在。如果不存在，可以单独提供此信息。
- en: 'Create a `Path` object that identifies the file:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建标识文件的`Path`对象：
- en: '[PRE39]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Use the `Path` object to open the file in a `with` statement:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Path`对象在`with`语句中打开文件：
- en: '[PRE40]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: For more information on the with statement, see the *Reading and writing files
    with context managers* recipe.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 有关with语句的更多信息，请参阅*使用上下文管理器读写文件*配方。
- en: 'Create the CSV reader from the open file object. This is indented inside the
    `with` statement:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从打开文件对象创建CSV读取器。这在`with`语句内缩进：
- en: '[PRE41]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Read (and process) the various rows of data. This is properly indented inside
    the `with` statement. For this example, we''ll just print them:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取（和处理）各行数据。这在`with`语句内正确缩进。对于此示例，我们将只打印它们：
- en: '[PRE42]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The output is a series of dictionaries that looks as follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一系列如下的字典：
- en: '[PRE43]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Since the row was transformed into a dictionary, the column keys are not in
    the original order. If we use `pprint()` from the `pprint` module the keys tend
    to get sorted into alphabetical order. We can now process the data by referring
    to `row[''date'']` . Using the column names is more descriptive than referring
    to the column by position: `row[0]` is hard to understand.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 由于行已转换为字典，列键不是按原始顺序排列的。如果我们使用`pprint()`来自`pprint`模块，键往往会按字母顺序排序。现在我们可以通过引用`row['date']`来处理数据。使用列名称比按位置引用列更具描述性：`row[0]`难以理解。
- en: How it works...
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The `csv` module handles physical format work of separating the rows from each
    other, and separating the columns within each row. The default rules assure that
    each input line is treated as a separate row, and the columns are separated by
    `","` .
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '`csv`模块处理物理格式工作，将行与行分开，并将每行内的列分开。默认规则确保每个输入行都被视为单独的行，并且列由`","`分隔。'
- en: 'What happens when we need to use the column separator character as part of
    data? We might have data like this:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要使用列分隔符字符作为数据的一部分时会发生什么？我们可能会有这样的数据：
- en: '[PRE44]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The `notes` column has data in the first row which includes the `","` column
    separator character. The rules for CSV allow a column's value to be surrounded
    by quotes. By default, the quoting characters are `"` . Within these quoting characters,
    the column and row separator characters are ignored.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '`notes`列在第一行中包含了`","`列分隔符字符的数据。CSV的规则允许列的值被引号括起来。默认情况下，引号字符是`"`。在这些引号字符内，列和行分隔符字符被忽略。'
- en: In order to embed the quote character within a quoted string, it is doubled.
    The second example row shows how the value `"blowing "like stink""` is encoded
    by doubling the quote characters when they are used inside a quoted column. These
    quoting rules mean that a CSV file can represent any combination of characters,
    including the row and column separator characters.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在带引号的字符串中嵌入引号字符，需要加倍。第二个示例行显示了当在带引号的列内使用引号字符时，值`"blowing "like stink""`是如何通过加倍引号字符来编码的。这些引用规则意味着CSV文件可以表示任何组合的字符，包括行和列分隔符字符。
- en: The values in a CSV file are always strings. A string value like `7331` may
    look like a number to us, but it's merely text when processed by the `csv` module.
    This makes the processing simple and uniform, but it can be awkward for a human
    user.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件中的值始终为字符串。像`7331`这样的字符串值对我们来说可能看起来像一个数字，但在`csv`模块处理时，它只是文本。这使处理简单而统一，但对于人类用户来说可能有些尴尬。
- en: Some CSV data is exported from software such as databases or web servers. This
    data tends to be the easiest to work with because the various rows tend to be
    organized consistently.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 一些CSV数据是从数据库或Web服务器等软件导出的。这些数据往往是最容易处理的，因为各行往往是一致地组织的。
- en: When data is saved from a manually prepared spreadsheet, the data may reveal
    quirks of the desktop software's internal rules for data display. It's surprisingly
    common, for example, to have a column of data that is displayed as a date on the
    desktop software, but shows up as a simple floating-point number in the CSV file.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据从手动准备的电子表格保存时，数据可能会显示桌面软件内部数据显示规则的怪癖。例如，通常会出现一个在桌面软件上显示为日期的数据列，在CSV文件中却显示为简单的浮点数。
- en: There are two solutions to the date-as-number problem. One is to add a column
    in the source spreadsheet to properly format the date as a string. Ideally, this
    is done using ISO rules so that the date is represented in YYYY-MM-DD format.
    The other solution is to recognize the spreadsheet date as a number of seconds
    past some epochal date. The epochal dates vary slightly, but they're generally
    either Jan 1, 1900 or Jan 1, 1904.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 日期作为数字的问题有两种解决方案。一种是在源电子表格中添加一列，以正确格式化日期为字符串。理想情况下，这是使用ISO规则完成的，以便日期以YYYY-MM-DD格式表示。另一种解决方案是将电子表格日期识别为某个纪元日期之后的秒数。纪元日期略有不同，但通常是1900年1月1日或1904年1月1日。
- en: There's more...
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: As we saw in the *Combining map and reduce transformations* recipe, there's
    often a pipeline of processing that includes cleansing and transformation of the
    source data. In this specific example, there are no extra rows that need to be
    eliminated. However, each column needs to be converted into something more useful.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*组合映射和减少转换*配方中所看到的，通常有一个包括源数据清洗和转换的处理流水线。在这个特定的例子中，没有额外需要消除的行。然而，每一列都需要转换成更有用的东西。
- en: 'To transform the data into a more useful form, we''ll use a two-part design.
    First, we''ll define a row-level cleansing function. In this case, we''ll update
    the row-level dictionary object by adding additional column-like values:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将数据转换为更有用的形式，我们将使用两部分设计。首先，我们将定义一个行级清洗函数。在这种情况下，我们将通过添加额外的类似列的值来更新行级字典对象：
- en: '[PRE45]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: We've created new column values, `lat_n` and `lon_n` , which have proper floating-point
    values instead of strings. We've also parsed the date and time values to create
    `datetime.date` and `datetime.time` objects. We've also combined the date and
    time into a single, useful value, which is the value of the `timestamp` column.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了新的列值`lat_n`和`lon_n`，它们具有适当的浮点值而不是字符串。我们还解析了日期和时间值，创建了`datetime.date`和`datetime.time`对象。我们还将日期和时间合并成一个单一的有用值，即`timestamp`列的值。
- en: 'Once we have a row-level function for cleaning and enriching our data, we can
    map this function to each row in the source of data. We can use `map(clean_row,
    reader)` or we can write a function that embodies this processing loop:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了一个用于清理和丰富数据的行级函数，我们就可以将这个函数映射到数据源中的每一行。我们可以使用`map(clean_row, reader)`，或者我们可以编写一个体现这个处理循环的函数：
- en: '[PRE46]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This can be used to provide more useful data from each row:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以用来从每一行提供更有用的数据：
- en: '[PRE47]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: We've injected the `cleanse()` function to create a very small stack of transformation
    rules. The stack starts with the `data_reader` , and only has one other item in
    it. This is a good beginning. As the application software is expanded to do more
    computations, the stack will expand.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注入了`cleanse()`函数来创建一个非常小的转换规则堆栈。堆栈以`data_reader`开始，只有另一个项目。这是一个很好的开始。随着应用软件扩展到更多的计算，堆栈将扩展。
- en: 'These cleansed and enriched rows look as follows:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这些清洁和丰富的行如下：
- en: '[PRE48]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We've added columns such as `lat_n` and `lon_n` , which have proper numeric
    values instead of strings. We've also added `timestamp` , which has a full date-time
    value that can be used for simple computations of elapsed time between waypoints.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了诸如`lat_n`和`lon_n`这样的列，它们具有适当的数值而不是字符串。我们还添加了`timestamp`，它具有完整的日期时间值，可以用于简单计算航点之间的经过时间。
- en: See also
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: See the *Combining map and reduce transformations* recipe for more information
    on the idea of a processing pipeline or stack
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关处理管道或堆栈概念的更多信息，请参阅*组合映射和减少转换*配方
- en: See the *Slicing and dicing a list* recipe in [Chapter 4](text00048.html#page
    "Chapter 4. Built-in Data Structures – list, set, dict") , *Built-in Data Structures
    – list, set, dict* and *Using stacked generator expressions* recipe in [Chapter
    8](text00088.html#page "Chapter 8. Functional and Reactive Programming Features")
    , *Functional And Reactive Programming Features* for more information on processing
    a CSV file that isn't in a proper 1NF
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关处理不符合1NF的CSV文件的更多信息，请参阅[第4章](text00048.html#page "第4章.内置数据结构-列表、集合、字典")的*切片和切块列表*配方，以及[第8章](text00088.html#page
    "第8章.功能和反应式编程特性")的*使用堆叠的生成器表达式*配方。
- en: Reading complex formats using regular expressions
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正则表达式阅读复杂格式
- en: There are many file formats that lack the elegant regularity of a CSV file.
    One common file format that's rather difficult to parse is a web server log file.
    These files tend to have complex data without a single separator character or
    consistent quoting rules.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 许多文件格式缺乏CSV文件的优雅规律。一个常见的文件格式，而且相当难以解析的是Web服务器日志文件。这些文件往往具有复杂的数据，没有单一的分隔符字符或一致的引用规则。
- en: 'When we looked at a simplified log file in the *Writing generator functions
    with the yield statement* recipe in  [Chapter 8](text00088.html#page "Chapter 8. Functional
    and Reactive Programming Features") , *Functional And Reactive Programming Features*
    , we saw that the rows look as follows:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在[第8章](text00088.html#page "第8章.功能和反应式编程特性")的*使用yield语句编写生成器函数*配方中查看简化的日志文件时，我们看到行如下：
- en: '[PRE49]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: There are a variety of punctuation marks used in this file. The `csv` module
    can't handle this complexity.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件中使用了各种标点符号。`csv`模块无法处理这种复杂性。
- en: How can we process this kind of data with the elegant simplicity of a CSV file?
    Can we transform these irregular rows to a more regular data structure?
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何以CSV文件的简洁简单方式处理这种类型的数据？我们能把这些不规则的行转换成更规则的数据结构吗？
- en: Getting ready
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备好
- en: Parsing a file with a complex structure generally involves writing a function
    that behaves somewhat like the `reader()` function in the `csv` module. In some
    cases, it's slightly easier to create a small class that behaves like the `DictReader`
    class.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 解析具有复杂结构的文件通常涉及编写一个行为有点像`csv`模块中的`reader()`函数的函数。在某些情况下，创建一个行为像`DictReader`类的小类可能会稍微容易一些。
- en: The core feature of the reader is a function that will transform one line of
    text into a dict or tuple of individual field values. This job can often be done
    by the `re` package.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 读取器的核心特性是一个函数，它将把一行文本转换成一个字典或一组单独的字段值。这项工作通常可以通过`re`包来完成。
- en: Before we can start, we'll need to develop (and debug) the regular expression
    that properly parses each line of the input file. For more information on this,
    see the *String parsing with regular expressions* recipe in [Chapter 1](text00014.html#page
    "Chapter 1. Numbers, Strings, and Tuples") , *Numbers, Strings, and Tuples* .
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，我们需要开发（和调试）适当解析输入文件的每一行的正则表达式。有关更多信息，请参阅[第1章](text00014.html#page "第1章。数字、字符串和元组")中的*使用正则表达式解析字符串*配方，*数字、字符串和元组*。
- en: 'For this example, we''ll use the following code. We''ll define a pattern string
    with a series of regular expressions for the various elements of the line:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们将使用以下代码。我们将定义一个模式字符串，其中包含一系列用于行的各个元素的正则表达式：
- en: '[PRE50]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The date-time stamp is various kinds of digits, hyphens, colons, and a comma;
    it's surrounded by `[` and `]` . We've had to use `\[` and `\]` to escape the
    normal meaning of `[` and `]` in a regular expression. The date stamp is followed
    by a severity level, which is a single run of characters. The characters `in`
    can be ignored; there are no `()` 's to capture the matching data. The module
    name is a sequence of letter characters, summarized by the character class `\w`
    , and also including `_` and `.` . There's an extra `:` character after the module
    name that can also be ignored. Finally, there's a message that extends to the
    end of the line. We've wrapped the interesting data strings in `()` to capture
    each of these as part of the regular expression processing.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 日期时间戳是各种数字、连字符、冒号和逗号；它被`[`和`]`包围。我们不得不使用`\[`和`\]`来转义正则表达式中`[`和`]`的正常含义。日期戳后面是一个严重级别，它是一系列字符的单次运行。字符`in`可以被忽略；没有`()`来捕获匹配的数据。模块名称是一系列字母字符，由字符类`\w`总结，还包括`_`和`.`。模块名称后面还有一个额外的`:`字符，也可以被忽略。最后，有一条消息延伸到行的末尾。我们用`()`包装了有趣的数据字符串，以便在正则表达式处理中捕获每个字符串。
- en: Note that we've also included the `\s+` sequence to quietly skip any number
    of space-like characters. It appears that the sample data all use a single space
    as the separator. However, when absorbing whitespace, using `\s+` seems to be
    a slightly more general approach because it permits extra spaces.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们还包括了`\s+`序列，以静默地跳过任意数量的类似空格的字符。看起来样本数据都使用单个空格作为分隔符。然而，当吸收空白时，使用`\s+`似乎是一个稍微更一般化的方法，因为它允许额外的空格。
- en: 'Here''s how this pattern works:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这种模式的工作方式：
- en: '[PRE51]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We've provided a line of sample data. The match object, `match` , has a `groups()`
    method that returns each of the interesting fields. We can make this into a dictionary
    with named fields by using `(?P<name>...)` for each capture instead of simply
    `(...)` .
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一行样本数据。匹配对象`match`有一个`groups()`方法，返回每个有趣的字段。我们可以使用`(?P<name>...)`来为每个捕获命名字段，而不仅仅是`(...)`，将其转换为字典。
- en: How to do it...
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: This recipe has two parts-defining a parse function for a single line, and using
    the parse function for each line of input.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方有两个部分-为单行定义一个解析函数，并使用解析函数处理每行输入。
- en: Defining the parse function
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义解析函数
- en: 'Perform the following steps for defining the parse function:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 为定义解析函数执行以下步骤：
- en: 'Define the compiled regular expression object:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义编译的正则表达式对象：
- en: '[PRE52]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: We've used the `(?P<name>...)` regular expression construct to provide names
    for each group that's captured. The resulting dictionary will be identical with
    the results of `csv.DictReader` .
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`(?P<name>...)`正则表达式构造来为每个捕获的组提供名称。生成的字典将与`csv.DictReader`的结果相同。
- en: 'Define a function that accepts a line of text as an argument:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个接受文本行作为参数的函数：
- en: '[PRE53]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Apply the regular expression to create a match object. We''ve assigned it to
    the `match` variable:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用正则表达式创建匹配对象。我们将其分配给`match`变量：
- en: '[PRE54]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'If the match object is `None` , the line did not match the pattern. This line
    may be skipped silently. In some applications, it should be logged in some way
    to provide information useful for debugging or enhancing the application. It may
    also make sense to raise an exception for an input line that cannot be parsed:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果匹配对象是`None`，则该行与模式不匹配。这行可能会被静默地跳过。在某些应用中，应该以某种方式记录它，以提供有用于调试或增强应用的信息。对于无法解析的输入行，提出异常也可能是有意义的：
- en: '[PRE55]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Return a useful data structure with the various pieces of data from this input
    line:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回一个有用的数据结构，其中包含来自此输入行的各个数据片段：
- en: '[PRE56]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: This function can be used to parse each line of input. The text is transformed
    into a dictionary with field names and values.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数可以用来解析每一行输入。文本被转换成一个带有字段名和值的字典。
- en: Using the parse function
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用解析函数
- en: 'Import the `csv` module and the `Path` class:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`csv`模块和`Path`类：
- en: '[PRE57]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'From `pathlib` import `PathCreate` , the `Path` object that identifies the
    file:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`pathlib`导入`PathCreate`，标识文件的`Path`对象：
- en: '[PRE58]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Use the `Path` object to open the file in a `with` statement:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Path`对象在`with`语句中打开文件：
- en: '[PRE59]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Note
  id: totrans-363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on the `with` statement, see the *Reading and writing files
    with context managers* recipe.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`with`语句的更多信息，请参阅*使用上下文管理器读写文件*配方。
- en: 'Create the log file parser from the open file object, `data_file` . In this
    case, we''ll use `map()` to apply the parser to each line from the source file:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从打开的文件对象`data_file`创建日志文件解析器。在这种情况下，我们将使用`map()`将解析器应用于源文件的每一行：
- en: '[PRE60]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Read (and process) the various rows of data. For this example, we''ll just
    print them:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取（和处理）各行数据。在这个例子中，我们将只是打印它们：
- en: '[PRE61]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output is a series of dictionaries that looks as follows:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一系列如下所示的字典：
- en: '[PRE62]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: We can do more meaningful processing on these dictionaries than we can on a
    line of raw text. These allow us to filter the data by severity level, or create
    a `Counter` based on the module providing the message.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对这些字典进行比对原始文本行更有意义的处理。这使我们能够按严重程度级别过滤数据，或者基于提供消息的模块创建`Counter`。
- en: How it works...
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This log file is typical of files that are in First Normal Form. The data is
    organized into lines that represent independent entities or events. Each row has
    a consistent number of attributes or columns, and each column has data that is
    atomic or can't be meaningfully decomposed further. Unlike CSV files, the format
    requires a complex regular expression to parse.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这个日志文件是典型的第一正规形式文件。数据组织成代表独立实体或事件的行。每行具有一致数量的属性或列，每列的数据是原子的或不能进一步有意义地分解。与CSV文件不同，该格式需要复杂的正则表达式来解析。
- en: In our log file example, the timestamp has a number of individual elements—year,
    month, day, hour, minute, second, and millisecond, but there's little value in
    further decomposing the timestamp. It's more helpful to use it as a single `datetime`
    object, and derive details (like hour of the day) from this object rather than
    assembling individual fields into a new piece of composite data.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的日志文件示例中，时间戳具有许多单独的元素——年、月、日、小时、分钟、秒和毫秒，但进一步分解时间戳没有太大价值。更有帮助的是将其用作单个`datetime`对象，并从该对象中派生详细信息（如一天中的小时），而不是将各个字段组装成新的复合数据。
- en: In a complex log processing application, there may be several varieties of message
    fields. It may be necessary to parse these message types using separate patterns.
    When we need to do this, it reveals that the various lines in the log aren't consistent
    in the format and number of attributes, breaking one of the First Normal Form
    assumptions.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在复杂的日志处理应用程序中，可能会有几种消息字段的变体。可能需要使用单独的模式解析这些消息类型。当我们需要这样做时，它揭示了日志中的各行在格式和属性数量上不一致，打破了第一正规形式的假设之一。
- en: In the case of inconsistent data, we'll have to create more sophisticated parsers.
    This may include complex filtering rules to separate out the various kinds of
    information that may appear in a web server log file. It may involve parsing part
    of the line to determine which regular expression must be used to parse the rest
    of the line.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据不一致的情况下，我们将不得不创建更复杂的解析器。这可能包括复杂的过滤规则，以分离出可能出现在Web服务器日志文件中的各种信息。这可能涉及解析行的一部分，以确定必须使用哪个正则表达式来解析行的其余部分。
- en: We've relied on using the `map()` higher-order function. This applies the `log_parse()`
    function to each line of the source file. The direct simplicity of this provides
    some assurance that the number of data objects created will precisely match the
    number of lines in the log file.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直依赖使用`map()`高阶函数。这将`log_parse()`函数应用于源文件的每一行。这种直接的简单性提供了一些保证，即创建的数据对象数量将精确匹配日志文件中的行数。
- en: 'We''ve generally followed the design pattern from the *Reading delimited files
    with the cvs module* recipe, so that reading a complex log is nearly identical
    with reading a simple CSV file. Indeed, we can see that the primary difference
    lies in one line of code:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常遵循*使用cvs模块读取分隔文件*配方中的设计模式，因此读取复杂日志几乎与读取简单CSV文件相同。事实上，我们可以看到主要区别在于一行代码：
- en: '[PRE63]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'As compared to:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相比：
- en: '[PRE64]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This parallel construct allows us to reuse analysis functions across many input
    file formats. This allows us to create a library of tools that can be used on
    a number of data sources.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这种并行结构允许我们在许多输入文件格式上重用分析函数。这使我们能够创建一个可以用于许多数据源的工具库。
- en: There's more...
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: One of the most common operations when reading very complex files is to rewrite
    them into an easier-to-process format. We'll often want to save the data in CSV
    format for later processing.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在读取非常复杂的文件时，最常见的操作之一是将其重写为更易处理的格式。我们经常希望以CSV格式保存数据以供以后处理。
- en: Some of this is similar to the *Using multiple contexts for reading and writing
    files* recipe, which also shows multiple open contexts. We'll read from one file
    and write to another file.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些与*使用cvs模块读取和写入多个上下文*配方类似，该配方还显示了多个打开上下文。我们将从一个文件中读取并写入另一个文件。
- en: 'The file writing process looks as follows:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 文件写入过程如下所示：
- en: '[PRE65]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The first portion of this script defines a CSV writer for a given file. The
    path for the output file, `target_path` , is based on the input name, `data_path`
    . The suffix changed from the original filename's suffix to `.csv` .
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本的第一部分定义了给定文件的CSV写入器。输出文件的路径`target_path`基于输入名称`data_path`。后缀从原始文件名的后缀更改为`.csv`。
- en: This file is opened with the newline character turned off by the `newline=''`
    option. This allows the `csv.DictWriter` class to insert newline characters appropriate
    for the desired CSV dialect.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件使用`newline=''`选项关闭换行符打开。这允许`csv.DictWriter`类插入适合所需CSV方言的换行符。
- en: A `DictWriter` object is created to write to the given file. A sequence of column
    headings is provided. These must match the keys used to write each row to the
    file. We can see that these headings match the `(?P<name>...)` parts of the regular
    expression that produces the data.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了一个`DictWriter`对象来写入给定文件。提供了一系列列标题。这些标题必须与用于将每行写入文件的键匹配。我们可以看到这些标题与产生数据的正则表达式的`(?P<name>...)`部分匹配。
- en: The `writeheader()` method writes the column names as the first line of output.
    This makes reading the file slightly easier because the column names are provided.
    The first row of a CSV file can be a kind of explicit schema definition that shows
    what data is present.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '`writeheader()`方法将列名写为输出的第一行。这使得读取文件稍微容易，因为提供了列名。CSV文件的第一行可以是一种显式模式定义，显示了存在哪些数据。'
- en: The source file is opened as shown in the preceding recipe. Because of the way
    the `csv` module writers work, we can provide the `reader()` generator function
    to the `writerows()` method of the writer. The `writerows()` method will consume
    all of the data produced by the `reader()` function. This will, in turn, consume
    all of the rows produced by the open file.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 源文件如前面的配方所示打开。由于`csv`模块的写入器的工作方式，我们可以将`reader()`生成器函数提供给写入器的`writerows()`方法。`writerows()`方法将消耗`reader()`函数生成的所有数据。这将反过来消耗打开文件生成的所有行。
- en: We don't need to write any explicit `for` statements to assure that all of the
    input rows are processed. The `writerows()` function makes this guarantee.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要编写任何显式的`for`语句来确保处理所有输入行。`writerows()`函数保证了这一点。
- en: 'The output file looks as follows:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 输出文件如下：
- en: '[PRE66]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The file has been transformed from the rather complex input format to a simpler
    CSV format.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件已从相当复杂的输入格式转换为更简单的CSV格式。
- en: See also
  id: totrans-397
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Writing generator functions with the yield statement* recipe in [Chapter
    8](text00088.html#page "Chapter 8. Functional and Reactive Programming Features")
    , *Functional And Reactive Programming Features* shows other processing of this
    log format
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第8章](text00088.html#page "第8章。功能和响应式编程特性")的*使用yield语句编写生成器函数*配方中，*功能和响应式编程特性*显示了此日志格式的其他处理
- en: In the *Reading delimited files with the CSV module* recipe, we look at other
    applications of this general design pattern
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*使用CSV模块读取分隔文件*配方中，我们将研究此通用设计模式的其他应用
- en: In the *Upgrading CSV from Dictreader to namedtuple reader* and *Upgrading CSV
    from Dictreader to namespace reader* recipes we'll look at even more sophisticated
    processing techniques
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*从Dictreader升级CSV到命名元组读取器*和*从Dictreader升级CSV到命名空间读取器*的配方中，我们将研究更复杂的处理技术
- en: Reading JSON documents
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读JSON文档
- en: The JSON notation for serializing data is very popular. For details, see [http://json.org](http://json.org)
    . Python includes the `json` module to serialize and deserialize data in this
    notation.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 用于序列化数据的JSON表示法非常受欢迎。有关详细信息，请参阅[http://json.org](http://json.org)。Python包括`json`模块，用于在此表示法中序列化和反序列化数据。
- en: JSON documents are used widely by JavaScript applications. It's common to exchange
    data between Python-based servers and JavaScript-based clients using documents
    in JSON notation. These two tiers of the application stack communicate via JSON
    documents sent via the HTTP protocol. Interestingly, a data persistence layer
    may also use HTTP protocol and JSON notation.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: JSON文档被JavaScript应用广泛使用。使用JSON表示法在基于Python的服务器和基于JavaScript的客户端之间交换数据是很常见的。应用程序堆栈的这两个层通过HTTP协议发送的JSON文档进行通信。有趣的是，数据持久化层也可以使用HTTP协议和JSON表示法。
- en: How do we use the `json` module to parse JSON data in Python?
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何在Python中使用`json`模块解析JSON数据？
- en: Getting ready
  id: totrans-405
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We've gathered some sailboat racing results in `race_result.json` . This file
    has information on teams, legs, and the orders in which the various teams finish
    the legs of the race.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经收集了一些帆船比赛结果，保存在`race_result.json`中。该文件包含有关团队、航段以及各个团队完成比赛航段的顺序的信息。
- en: In many cases, there are null values when a boat did not start, did not finish,
    or was disqualified from the race. In those cases, the finish position is assigned
    a score of one more than the last position. If there are seven boats, then the
    team is given eight points. This is a hefty penalty.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，当船只没有启动，没有完成，或者被取消比赛资格时，会出现空值。在这些情况下，完成位置被分配一个比最后位置多一个的分数。如果有七艘船，那么团队将得到八分。这是一个相当大的惩罚。
- en: 'The data has the following schema. There are two fields within the overall
    document:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 数据具有以下模式。整个文档内有两个字段：
- en: '`legs` : Array of strings that show starting port and ending port.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`legs`：显示起始港口和目的港口的字符串数组。'
- en: '`teams` : Array of objects with details about each team. Within each team object,
    there are several fields of data:'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`teams`：包含有关每个团队的详细信息的对象数组。在每个团队对象内部，有几个数据字段：'
- en: '`name` : String team name.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：团队名称字符串。'
- en: '`position` : Array of integers and nulls with position. The order of items
    in this array matches the order of items in the legs array.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`position`：包含位置的整数和空值的数组。此数组中项目的顺序与legs数组中项目的顺序相匹配。'
- en: 'The data looks as follows:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 数据如下：
- en: '[PRE67]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: We've only shown the first team. There were a total of seven teams in this particular
    race.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只显示了第一个团队。在这场比赛中总共有七个团队。
- en: 'The JSON-formatted data looks like a Python dictionary that contains lists
    within it. This overlap between Python syntax and JSON syntax can be thought of
    as a happy coincidence: it makes it easier to visualize the Python data structure
    that will be built from the JSON source document.'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: JSON格式的数据看起来像一个包含列表的Python字典。Python语法和JSON语法之间的重叠可以被认为是一个幸运的巧合：它使得更容易可视化从JSON源文档构建的Python数据结构。
- en: Not all JSON structures are simply Python objects. Interestingly, the JSON document
    has a null item, which maps to Python's `None` object. The meaning is similar,
    but the syntax is different.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的JSON结构都只是Python对象。有趣的是，JSON文档中有一个空项，它映射到Python的`None`对象。含义是相似的，但语法不同。
- en: Also, one of the strings contains a Unicode escape sequence, `\u00cd` , instead
    of the actual Unicode character, Í. This is a common technique used to encode
    characters beyond the 128 ASCII characters.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，其中一个字符串包含一个Unicode转义序列`\u00cd`，而不是实际的Unicode字符Í。这是一种常用的技术，用于编码超出128个ASCII字符的字符。
- en: How to do it...
  id: totrans-419
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the `json` module:'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`json`模块：
- en: '[PRE68]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Define a `Path` object that identifies the file to be processed:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个标识要处理的文件的`Path`对象：
- en: '[PRE69]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: The `json` module doesn't currently work directly with `Path` objects. Consequently,
    we'll read the content as a big block of text and process that text object.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '`json`模块目前不能直接处理`Path`对象。因此，我们将把内容读取为一个大文本块，并处理该文本对象。'
- en: 'Create a Python object by parsing the JSON document:'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过解析JSON文档创建Python对象：
- en: '[PRE70]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: We've used `source_path.read_text()` to read the file named by the `Path` .
    We provided this string to the `json.loads()` function for parsing.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`source_path.read_text()`来读取由`Path`命名的文件。我们将这个字符串提供给`json.loads()`函数进行解析。
- en: Once we've parsed the document to create a Python dictionary, we can see the
    various pieces. For example, the field `teams` has all of the results for each
    team. It's an array, and item 0 in that array is the first team.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们解析文档创建了一个Python字典，我们就可以看到各种部分。例如，字段`teams`包含了每个团队的所有结果。它是一个数组，该数组中的第0项是第一个团队。
- en: 'The data for each team will be a dictionary with two keys: `name` and `position`
    . We can combine the various keys to get the name of the first team:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 每个团队的数据将是一个带有两个键`name`和`position`的字典。我们可以组合各种键来获得第一个团队的名称：
- en: '[PRE71]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'We can look inside the `legs` field to see the names of each leg of the race:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看`legs`字段内的每条赛道的名称：
- en: '[PRE72]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Note that the JSON source file included a `'\u00cd'` Unicode escape sequence.
    This was parsed properly and the Unicode output shows the proper Í character.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，JSON源文件包含了`'\u00cd'`的Unicode转义序列。这被正确解析，Unicode输出显示了正确的Í字符。
- en: How it works...
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: A JSON document is a data structure in JavaScript Object Notation. JavaScript
    programs can parse the document trivially. Other languages must do a little more
    work to translate the JSON to a native data structure.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: JSON文档是JavaScript对象表示法中的数据结构。JavaScript程序可以轻松解析文档。其他语言必须多做一些工作来将JSON转换为本地数据结构。
- en: 'A JSON document contains three kinds of structures:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 一个JSON文档包含三种结构：
- en: '**Objects that map to Python dictionaries** : JSON has a syntax similar to
    Python: `{"key": "value"}` . Unlike Python, JSON only uses `"` for string quotation
    marks. JSON notation is intolerant of an extra , at the end of the dictionary
    value. Other than this, the two notations are similar.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**映射到Python字典的对象**：JSON的语法类似于Python：`{"key": "value"}`。与Python不同，JSON只使用`"`作为字符串引号。JSON表示对字典值末尾的额外`,`不容忍。除此之外，这两种表示法是相似的。'
- en: '**Arrays that map to Python lists** : JSON syntax uses `[item, ...]` , which
    looks like Python. JSON is intolerant of extra , at the end of the array value.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**映射到Python列表的数组**：JSON语法使用`[item, ...]`，看起来像Python。JSON不容忍数组值末尾的额外`,`。'
- en: '**Primitive values** : There are five classes of values: string, number, `true`
    , `false` , and `null` . Strings are enclosed in `"` and use a variety of `\escape`
    sequences, which are similar to Python''s. Numbers follow the rules for floating-point
    values. The other three values are simple literals; these parallel Python''s `True`
    , `False` , and `None` literals.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基本值**：有五种值：字符串，数字，`true`，`false`和`null`。字符串用`"`括起来，并使用各种`\转义`序列，这与Python的类似。数字遵循浮点值的规则。其他三个值是简单的文字；这些与Python的`True`，`False`和`None`相对应。'
- en: There is no provision for any other kinds of data. This means that Python programs
    must convert complex Python objects to a simpler representation so that they can
    be serialized in JSON notation.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 没有其他类型的数据规定。这意味着Python程序必须将复杂的Python对象转换为更简单的表示，以便它们可以以JSON表示法进行序列化。
- en: Conversely, we often apply additional conversions to reconstruct complex Python
    objects from the simplified JSON representation. The `json` module has places
    where we can apply additional processing to the simple structures to create more
    sophisticated Python objects.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们经常应用额外的转换来从简化的JSON表示中重建复杂的Python对象。`json`模块有一些地方可以应用额外的处理来创建更复杂的Python对象。
- en: There's more...
  id: totrans-442
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: A file, generally, contains a single JSON document. The standard doesn't provide
    an easy way to encode multiple documents in a single file. If we want to analyze
    a web log, for example, JSON may not be the best notation for preserving a huge
    volume of information.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，一个文件包含一个单独的JSON文档。标准没有提供一种简单的方法在单个文件中编码多个文档。例如，如果我们想要分析网站日志，JSON可能不是保留大量信息的最佳表示法。
- en: 'There are two additional problems that we often have to tackle:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常需要解决的另外两个问题：
- en: Serializing complex objects so that we can write them to files
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列化复杂对象以便将它们写入文件
- en: Deserializing complex objects from the text that's read from a file
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从从文件读取的文本中反序列化复杂对象
- en: When we represent a Python object's state as a string of text characters, we've
    serialized the object. Many Python objects need to be saved in a file or transmitted
    to another process. These kinds of transfers require a representation of object
    state. We'll look at serializing and deserializing separately.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将Python对象的状态表示为一串文本字符时，我们已经对对象进行了序列化。许多Python对象需要保存在文件中或传输到另一个进程。这些传输需要对象状态的表示。我们将分别查看序列化和反序列化。
- en: Serializing a complex data structure
  id: totrans-448
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 序列化复杂数据结构
- en: We can also create JSON documents from Python data structures. Because Python
    is extremely sophisticated and flexible, we can easily create Python data structures
    that cannot possibly be represented in JSON.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以从Python数据结构创建JSON文档。因为Python非常复杂和灵活，我们可以轻松地创建无法在JSON中表示的Python数据结构。
- en: The serialization to JSON works out the best if we create Python objects that
    are limited to simple `dict` , `list` , `str` , `int` , `float` , `bool` , and
    `None` values. If we're careful, we can build objects that serialize rapidly and
    can be used widely by a number of programs written in different languages.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们创建的Python对象仅限于简单的`dict`，`list`，`str`，`int`，`float`，`bool`和`None`值，那么将其序列化为JSON会得到最佳结果。如果我们小心谨慎，我们可以构建快速序列化并可以被不同语言编写的多个程序广泛使用的对象。
- en: None of these types of values involve Python `sets` , or other class definitions.
    This means that we're often forced to convert complex Python objects into dictionaries
    to represent them in a JSON document.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的值都不涉及Python`sets`或其他类定义。这意味着我们经常被迫将复杂的Python对象转换为字典以在JSON文档中表示它们。
- en: 'As an example, let''s assume we''ve analyzed some data and created a resulting
    `Counter` object:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们已经分析了一些数据并创建了一个结果为`Counter`对象：
- en: '[PRE73]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: We've dumped the data in JSON notation, with the keys sorted into order. This
    assures consistent output. The indent of two will show each `{}` object and each
    `[]` array indented visually to make it easier to see the document's structure.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经以JSON表示法转储了数据，并将键排序为顺序。这确保了一致的输出。缩进为两个将显示每个`{}`对象和每个`[]`数组在视觉上缩进，以便更容易看到文档的结构。
- en: 'We can write this to a file with a relatively simple operation:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一个相对简单的操作将其写入文件：
- en: '[PRE74]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: When we reread this document, we will not get a `Counter` object from the JSON
    load operation. We'll only get a dictionary instance. This is a consequence of
    JSON's reduction to very simple values.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们重新阅读这个文档时，我们将不会从JSON加载操作中得到一个`Counter`对象。我们只会得到一个字典实例。这是JSON简化为非常简单值的结果。
- en: 'One commonly-used data structure that doesn''t serialize easily is a `datetime.datetime`
    object. Here''s what happens when we try:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常用的数据结构，不容易序列化的是`datetime.datetime`对象。当我们尝试时会发生什么：
- en: '[PRE75]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: We've created a simple document that has a single field. The value of the field
    is a `datetime` instance. What happens when we try to serialize this in JSON?
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个简单的文档，其中只有一个字段。字段的值是一个`datetime`实例。当我们尝试将其序列化为JSON时会发生什么？
- en: '[PRE76]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: This shows that objects that cannot be serialized will raise a `TypeError` exception.
    Avoiding this exception can done in one of two ways. We can either convert the
    data before building the document, or we can add a hook to the JSON serialization
    process.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明无法序列化的对象将引发`TypeError`异常。避免此异常可以通过两种方式之一来完成。我们可以在构建文档之前转换数据，或者我们可以向JSON序列化过程添加一个钩子。
- en: 'One technique is to convert the `datetime` object into a string prior to serializing
    it as JSON:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 一种技术是在将其序列化为JSON之前将`datetime`对象转换为字符串：
- en: '[PRE77]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: This uses the ISO format for dates to create a string that can be serialized.
    An application that reads this data can then convert the string back into a `datetime`
    object.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用ISO日期格式创建一个可以序列化的字符串。读取此数据的应用程序然后可以将字符串转换回`datetime`对象。
- en: 'The other technique for serializing complex data is to provide a default function
    that''s used automatically during serialization. This function must convert a
    complex object to something that can be safely serialized. Often it will create
    a simple dictionary with string and numeric values. It might also create a simple
    string value:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化复杂数据的另一种技术是提供一个在序列化期间自动使用的默认函数。这个函数必须将一个复杂对象转换为可以安全序列化的东西。通常它会创建一个具有字符串和数值的简单字典。它还可能创建一个简单的字符串值。
- en: '[PRE78]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: We've defined a function, `default_date()` , which will apply special conversion
    rules to `datetime` objects. These will be massaged into string objects that can
    be serialized by the `json.dumps()` function.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个函数`default_date()`，它将对`datetime`对象应用特殊的转换规则。这些将被转换为可以由`json.dumps()`函数序列化的字符串对象。
- en: 'We provide this function to the `dumps()` function using the `default` parameter,
    as follows:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`default`参数将此函数提供给`dumps()`函数，如下所示：
- en: '[PRE79]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: In any given application, we'll need to expand this function to handle any of
    the more complex Python objects that we might want to serialize in JSON notation.
    If there are a large number of very complex data structures, we often want a somewhat
    more general solution than meticulously converting each object to something serializable.
    There are a number of design patterns for including type information along with
    serialized details of an object's state.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何给定的应用程序中，我们需要扩展这个函数，以处理我们可能想要以JSON表示的更复杂的Python对象。如果有大量非常复杂的数据结构，我们通常希望有一个比精心将每个对象转换为可序列化对象更一般的解决方案。有许多设计模式可以在对象状态的序列化细节中包含类型信息。
- en: Deserializing a complex data structure
  id: totrans-472
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反序列化复杂数据结构
- en: When deserializing JSON to create Python objects, there's another hook that
    can be used to convert data from a JSON dictionary into a more complex Python
    object. This is called the `object_hook` and it is used during `json.loads()`
    processing to examine each complex object to see if something else should be created
    from that dict.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 在将JSON反序列化为Python对象时，还有另一个钩子可以用于将数据从JSON字典转换为更复杂的Python对象。这称为`object_hook`，它在`json.loads()`处理期间用于检查每个复杂对象，以查看是否应该从该字典创建其他内容。
- en: 'The function we provide will either create a more complex Python object, or
    it will simply leave the dict alone:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供的函数要么创建一个更复杂的Python对象，要么只是保持字典不变：
- en: '[PRE80]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: This function will check each object that's decoded to see if the object has
    a field named `date` . If it does, the value of the entire object is replaced
    with a `datetime` object.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将检查解码的每个对象，看看对象是否有一个名为`date`的字段。如果有，整个对象的值将被替换为`datetime`对象。
- en: 'We provide a function to the `json.loads()` function as follows:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 我们向`json.loads()`函数提供一个函数，如下所示：
- en: '[PRE81]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: This parses a very small JSON document that meets the criteria for containing
    a date. The resulting Python object is built from the string value found in the
    JSON serialization.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 这解析了一个非常小的JSON文档，符合包含日期的标准。从JSON序列化中找到的字符串值构建了生成的Python对象。
- en: In a larger context, this particular example of handling dates isn't ideal.
    The presence of a single `'date'` field to indicate a date object could lead to
    problems with more complex objects being de-serialized using this `as_date()`
    function.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 在更大的上下文中，处理日期的这个特定示例并不理想。使用单个`'date'`字段表示日期对象可能会导致使用`as_date()`函数反序列化更复杂对象时出现问题。
- en: A more general approach would either look for something unique and non-Python
    like, such as `'$date'` . An additional feature would confirm that the special
    indicator was the only key for the object. When these two criteria were met, then
    the object could be processed specially.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更一般的方法要么寻找一些独特的、非Python的东西，比如`'$date'`。另一个特性是确认特殊指示符是对象的唯一键。当满足这两个标准时，对象可以被特殊处理。
- en: We may also want to design our application classes to provide additional methods
    to help with serialization. A class might include a `to_json()` method that will
    serialize the objects in a uniform way. This method might provide class information.
    It can avoid serializing any derived attributes or computed properties. Similarly,
    we might need to provide a static `from_json()` method that can be used to determine
    if a given dictionary object is actually an instance of the given class.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能希望设计我们的应用程序类，以提供额外的方法来帮助序列化。一个类可能包括一个`to_json()`方法，以统一的方式序列化对象。这种方法可能提供类信息。它可以避免序列化任何派生属性或计算属性。同样，我们可能需要提供一个静态的`from_json()`方法，用于确定给定的字典对象实际上是给定类的实例。
- en: See also
  id: totrans-483
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Reading HTML documents* recipe will show how we prepared this data from
    an HTML source
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*阅读HTML文档*的示例将展示我们如何从HTML源准备这些数据'
- en: Reading XML documents
  id: totrans-485
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读XML文档
- en: The XML markup language is widely used to organize data. For details, see [http://www.w3.org/TR/REC-xml/](http://www.w3.org/TR/REC-xml/)
    . Python includes a number of libraries for parsing XML documents.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: XML标记语言被广泛用于组织数据。有关详细信息，请参阅[http://www.w3.org/TR/REC-xml/](http://www.w3.org/TR/REC-xml/)。Python包括许多用于解析XML文档的库。
- en: XML is called a markup language because the content of interest is marked with
    `<tag>` and `</tag>` constructs that define the structure of the data. The overall
    file includes the content plus the XML markup text.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: XML被称为标记语言，因为感兴趣的内容是用`<tag>`和`</tag>`构造标记的，这些标记定义了数据的结构。整个文件包括内容和XML标记文本。
- en: Because the markup is intermingled with our text, there are some additional
    syntax rules that must be used. In order to include the `<` character in our data,
    we'll use XML character entity references to avoid confusion. We use `&lt;` to
    be able to include `<` in our text. Similarly, `&gt;` is used instead of `>` ,
    `&amp;` is used instead of `&` , and `&quot;` is also used to embed a `"` in an
    attribute value.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 因为标记与我们的文本交织在一起，所以必须使用一些额外的语法规则。为了在我们的数据中包含`<`字符，我们将使用XML字符实体引用以避免混淆。我们使用`&lt;`来在文本中包含`<`。类似地，`&gt;`代替`>`，`&amp;`代替`&`，`&quot;`也用于嵌入属性值中的`"`。
- en: 'A document, then, will have items as follows:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，文档将包含以下项目：
- en: '[PRE82]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Most XML processing allows additional `\n` and space characters in the XML
    to make the structure more obvious:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数XML处理允许在XML中添加额外的`\n`和空格字符，以使结构更加明显：
- en: '[PRE83]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: In general, content is surrounded by the tags. The overall document forms a
    large, nested collection of containers. Viewed another way, the document forms
    a tree with a root tag that contains all of the other tags and their embedded
    content. Between tags, there is additional content entirely whitespace in this
    example that will be ignored.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，内容被标签包围。整个文档形成了一个大的、嵌套的容器集合。从另一个角度来看，文档形成了一个树，根标签包含了所有其他标签及其嵌入的内容。在标签之间，有额外的内容完全是空白的，在这个例子中将被忽略。
- en: It's very, very difficult to parse this with regular expressions. We need more
    sophisticated parsers to handle the nested syntax.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正则表达式非常困难。我们需要更复杂的解析器来处理嵌套的语法。
- en: There are two binary libraries that are available for parsing XML-SAX and Expat.
    Python includes `xml.sax` and `xml.parsers.expat` to exploit these two modules.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个可用于解析XML-SAX和Expat的二进制库。Python包括`xml.sax`和`xml.parsers.expat`来利用这两个模块。
- en: In addition to these, there's a very sophisticated set of tools in the `xml.etree`
    package. We'll focus on using the `ElementTree` module to parse and analyze XML
    documents.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，在`xml.etree`包中还有一套非常复杂的工具。我们将专注于使用`ElementTree`模块来解析和分析XML文档。
- en: How do we use the `xml.etree` module to parse XML data in Python?
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何使用`xml.etree`模块在Python中解析XML数据？
- en: Getting ready
  id: totrans-498
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We've gathered some sailboat racing results in `race_result.xml` . This file
    has information on teams, legs, and the orders in which the various teams finished
    each leg.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经收集了`race_result.xml`中的一些帆船比赛结果。该文件包含了关于团队、赛段以及各个团队完成每个赛段的顺序的信息。
- en: In many cases, there are empty values when a boat did not start, did not finish,
    or was disqualified from the race. In those cases, the score will be one more
    than the number of boats. If there are seven boats, then the team is given eight
    points. This is a hefty penalty.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，当船只没有起航，没有完成比赛或被取消资格时，会出现空值。在这些情况下，得分将比船只数量多一个。如果有七艘船，那么团队将得到八分。这是一个很大的惩罚。
- en: 'The root tag is the `<results>` document. This has the following schema:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 根标签是`<results>`文档。这是以下模式：
- en: The `<legs>` tag contains individual `<leg>` tags that name each leg of the
    race. The leg names contain both a starting port and an ending port in the text.
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<legs>`标签包含命名每个赛段的单独的`<leg>`标签。赛段名称在文本中包含起始港口和终点港口。'
- en: 'The `<teams>` tag contains a number of `<team>` tags with details of each team.
    Each team has data structured with internal tags:'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<teams>`标签包含一些`<team>`标签，其中包含每个团队的详细信息。每个团队都有用内部标签结构化的数据：'
- en: The `<name>` tag contains the team name.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<name>`标签包含团队名称。'
- en: The `<position>` tag contains a number of `<leg>` tags with the finish position
    for the given leg. Each leg is numbered and the numbering matches the leg definitions
    in the `<legs>` tag.
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<position>`标签包含一些`<leg>`标签，其中包含给定赛段的完成位置。每个赛段都有编号，编号与`<legs>`标签中的赛段定义相匹配。'
- en: 'The data looks as follows:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 数据如下所示：
- en: '[PRE84]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: We've only shown the first team. There were a total of seven teams in this particular
    race.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只展示了第一个团队。在这场比赛中总共有七个团队。
- en: In XML notation, the application data shows up in two kinds of places. Between
    tags; for example, `<name>Abu Dhabi Ocean Racing</name>` . The tag is `<name>`
    , the text between `<name>` and `</name>` is the value of this tag.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 在XML标记中，应用程序数据显示在两种地方。在标签之间；例如，`<name>阿布扎比海洋赛艇</name>`。标签是`<name>`，在`<name>`和`</name>`之间的文本是该标签的值。
- en: Also, data shows up as an attribute of a tag. For example, in `<leg n="1">`
    . The tag is `<leg>` ; the tag has an attribute, `n` , with a value of `1` . A
    tag can have an indefinite number of attributes.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，数据显示为标签的属性。例如，在`<leg n="1">`中。标签是`<leg>`；标签具有一个名为`n`的属性，其值为`1`。标签可以具有无限数量的属性。
- en: The `<leg>` tags include the leg number given as an attribute, `n` , and the
    position in the leg given as the text inside the tag. The general approach is
    to put important data inside the tags, and supplemental, or clarifying data in
    the attributes. The line between the two is very blurry.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: '`<leg>`标签包括作为属性`n`给出的腿编号，以及作为标签内文本给出的腿的位置。一般的方法是将重要数据放在标签内，将补充或澄清数据放在属性中。两者之间的界限非常模糊。'
- en: 'XML permits a **mixed content model** . This reflects the case where XML is
    mixed in with text, there will be text inside and outside XML tags. Here''s an
    example of mixed content:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: XML允许**混合内容模型**。这反映了XML与文本混合的情况，XML标记内外都会有文本。以下是混合内容的示例：
- en: '[PRE85]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Some of the text is inside the `<p>` tag, and some of the text is inside the
    `<strong>` tag. The content of the `<p>` tag is a mixture of text and tags with
    more text.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 一些文本位于`<p>`标签内，一些文本位于`<strong>`标签内。`<p>`标签的内容是文本和带有更多文本的标签的混合。
- en: We'll use the `xml.etree` module to parse the data. This involves reading the
    data from a file and providing it to the parser. The resulting document will be
    rather complex.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`xml.etree`模块来解析数据。这涉及从文件中读取数据并将其提供给解析器。生成的文档将会相当复杂。
- en: We have not provided a formal schema definition for our sample data, nor have
    we provided a **Document Type Definition** ( **DTD** ). This means that the XML
    defaults to mixed content mode. Furthermore, the XML structure can't be validated
    against the schema or DTD.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有为我们的示例数据提供正式的模式定义，也没有提供**文档类型定义**（**DTD**）。这意味着XML默认为混合内容模式。此外，XML结构无法根据模式或DTD进行验证。
- en: How to do it...
  id: totrans-517
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We''ll need two modules—`xml.etree` and `pathlib` :'
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要两个模块—`xml.etree`和`pathlib`：
- en: '[PRE86]'
  id: totrans-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: We've changed the `ElementTree` module name name to `XML` to make it slightly
    easier to type. It's also common to rename this to something like `ET` .
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将`ElementTree`模块名称更改为`XML`，以使其更容易输入。通常也会将其重命名为类似`ET`的名称。
- en: 'Define a `Path` object that locates the source document:'
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个定位源文档的`Path`对象：
- en: '[PRE87]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Create the internal `ElementTree` version of the document by parsing the source
    file:'
  id: totrans-523
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过解析源文件创建文档的内部`ElementTree`版本：
- en: '[PRE88]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: The XML parser doesn't readily work with `Path` objects. We've elected to read
    the text from the `Path` object and then parse that text.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: XML解析器不太容易使用`Path`对象。我们选择从`Path`对象中读取文本，然后解析该文本。
- en: 'Once we have the document, we can then search it for the relevant pieces of
    data. In this example, we''ll use the `find()` method to locate the first instance
    of a given tag:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了文档，就可以搜索其中的相关数据。在这个例子中，我们将使用`find()`方法来定位给定标签的第一个实例：
- en: '[PRE89]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: In this case, we located the `<teams>` tag, and then found the first instance
    of the `<team>` tag inside that list. Within the `<team>` tag, we located the
    first `<name>` tag to get the value of the team's name.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们定位了`<teams>`标签，然后找到该列表中第一个`<team>`标签的实例。在`<team>`标签内，我们定位了第一个`<name>`标签，以获取团队名称的值。
- en: Because XML is a mixed content model, all of the `\n` , `\t` , and space characters
    in the content are perfectly preserved in the data. We rarely want any of this
    whitespace, and it makes sense to use the `strip()` method to remove all extraneous
    characters before and after the meaningful content.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 因为XML是混合内容模型，内容中的所有`\n`、`\t`和空格字符都会被完全保留。我们很少需要这些空白字符，因此在处理有意义的内容之前和之后使用`strip()`方法去除所有多余的字符是有意义的。
- en: How it works...
  id: totrans-530
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The XML parser modules transform XML documents into fairly complex objects based
    on the document object model. In the case of the `etree` module, the document
    will be built from `Element` objects that generally represent tags and text.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: XML解析器模块将XML文档转换为基于文档对象模型的相当复杂的对象。在`etree`模块的情况下，文档将由通常表示标签和文本的`Element`对象构建。
- en: XML also includes processing instructions and comments. These are commonly ignored
    by many XML processing applications.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: XML还包括处理指令和注释。这些通常被许多XML处理应用程序忽略。
- en: Parsers for XML often have two levels of operation. At the bottom level, they
    recognize events. The events that are found by the parser include element starts,
    element ends, comment starts, comment ends, runs of text, and similar lexical
    objects. At the higher level, the events are used to build the various `Elements`
    of the document.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: XML的解析器通常具有两个操作级别。在底层，它们识别事件。解析器找到的事件包括元素开始、元素结束、注释开始、注释结束、文本运行和类似的词法对象。在更高的级别上，这些事件用于构建文档的各种`元素`。
- en: Each `Element` instance has a tag, text, attributes, and a tail. The tag is
    the name inside the `<tag>` . The attributes are the fields that follow the tag
    name. For example, the `<leg n="1">` tag has a tag name of `leg` and an attribute
    named `n` . Values are always strings in XML.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`Element`实例都有一个标签、文本、属性和尾部。标签是`<tag>`内的名称。属性是跟在标签名称后面的字段。例如，`<leg n="1">`标签的标签名称是`leg`，属性名为`n`。在XML中，值始终是字符串。
- en: The text is contained between the start and end of a tag. Therefore, a tag such
    as `<name>Team SCA</name>` has `"Team SCA"` for the value of the `text` attribute
    of the `Element` that represents the `<name>` tag.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 文本包含在标签的开始和结束之间。因此，例如`<name>SCA团队</name>`这样的标签，对于代表`<name>`标签的`Element`的`text`属性来说是`"SCA团队"`。
- en: 'Note that a tag also has a tail attribute:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，标签还有一个尾部属性：
- en: '[PRE90]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: There's a `\n` character after the closing `</name>` tag and before the opening
    of the `<position>` tag. This is the tail of the `<name>` tag. The tail values
    can be important when working with a mixed content model. The tail values are
    generally whitespace when working in a non-mixed content model.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 在`</name>`标签关闭后和`<position>`标签打开前有一个`\n`字符。这是`<name>`标签的尾部。当使用混合内容模型时，尾部值可能很重要。在非混合内容模型中，尾部值通常是空白。
- en: There's more...
  id: totrans-539
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Because we can't trivially translate an XML document to a Python dictionary,
    we need a handy way to search through the document content. The `ElementTree`
    module provides a search technique that's a partial implementation of the **XML
    Path Language** ( **XPath** ) for specifying a location in an XML document. The
    XPath notation gives us considerable flexibility.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们不能简单地将XML文档转换为Python字典，所以我们需要一种方便的方法来搜索文档内容。`ElementTree`模块提供了一种搜索技术，这是**XML路径语言**（**XPath**）的部分实现，用于指定XML文档中的位置。XPath表示法给了我们相当大的灵活性。
- en: 'The XPath queries are used with the `find()` and `findall()` methods. Here''s
    how we can find all of the names:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: XPath查询与`find()`和`findall()`方法一起使用。以下是我们如何找到所有的名称：
- en: '[PRE91]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: We've looked for the top-level `<teams>` tags. Within that tag, we want `<team>`
    tags. Within those tags, we want the `<name>` tags. This will search for all instances
    of this nested tag structure.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经查找了顶级的`<teams>`标签。在该标签内，我们想要`<team>`标签。在这些标签内，我们想要`<name>`标签。这将搜索所有这种嵌套标签结构的实例。
- en: We can search for attribute values, also. This can make it handy to find how
    all teams did on a particular leg of the race. The data is found in the `<leg>`
    tag within the `<position>` tag for each team.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以搜索属性值。这可以方便地找到每个队伍在比赛的特定赛段上的表现。数据位于每个队伍的`<position>`标签内的`<leg>`标签中。
- en: 'Furthermore, each `<leg>` has an attribute value of n that shows which of the
    race legs it represents. Here''s how we can use this to extract specific data
    from the XML document:'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每个`<leg>`都有一个属性值n，显示它代表比赛的哪个赛段。以下是我们如何使用这个属性从XML文档中提取特定数据的方法：
- en: '[PRE92]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: This shows us the finish position of each team on leg 8 of the race. We're looking
    for all tags with `<leg n="8">` and displaying the text within that tag. We have
    to match these values with the team names to see that Team SCA finished first,
    and Dongfeng Race Team finished last on this leg.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了每个队伍在比赛的第8赛段上的完赛位置。我们正在寻找所有带有`<leg n="8">`的标签，并显示该标签内的文本。我们必须将这些值与队名匹配，以查看Team
    SCA在这个赛段上第一名，而东风队在这个赛段上最后一名。
- en: See also
  id: totrans-548
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Reading HTML documents* recipe shows how we prepared this data from an
    HTML source
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*阅读HTML文档*的示例展示了我们如何从HTML源准备这些数据'
- en: Reading HTML documents
  id: totrans-550
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读HTML文档
- en: A great deal of content on the Web is presented using HTML markup. A browser
    renders the data very nicely. How can we parse this data to extract the meaningful
    content from the displayed web page?
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 网络上有大量使用HTML标记的内容。浏览器可以很好地呈现数据。我们如何解析这些数据，以从显示的网页中提取有意义的内容？
- en: We can use the standard library `html.parser` module, but it's not helpful.
    It only provides low-level lexical scanning information, but doesn't provide a
    high-level data structure that describes the original web page.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用标准库`html.parser`模块，但这并不是有帮助的。它只提供低级别的词法扫描信息，但并不提供描述原始网页的高级数据结构。
- en: We'll use the Beautiful Soup module to parse HTML pages. This is available from
    the **Python Package Index** ( **PyPI** ). See [https://pypi.python.org/pypi/beautifulsoup4](https://pypi.python.org/pypi/beautifulsoup4)
    .
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Beautiful Soup模块来解析HTML页面。这可以从**Python包索引**（**PyPI**）中获得。请参阅[https://pypi.python.org/pypi/beautifulsoup4](https://pypi.python.org/pypi/beautifulsoup4)。
- en: This must be downloaded and installed to be useful. Generally, the `pip` command
    does this job very nicely.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 这必须下载并安装才能使用。通常情况下，`pip`命令可以很好地完成这项工作。
- en: 'Often, this is as simple as the following:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，这很简单，就像下面这样：
- en: '[PRE93]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'For Mac OS X and Linux users, the `sudo` command is required to escalate the
    user''s privileges:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Mac OS X和Linux用户，需要使用`sudo`命令来提升用户的权限：
- en: '[PRE94]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: This will prompt for the user's password. The user must be able to elevate themselves
    to have root privileges.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 这将提示用户输入密码。用户必须能够提升自己以获得根权限。
- en: 'In the rare case that you have multiple versions of Python, be sure to use
    the matching version of pip. In some cases, we might have to use the following:'
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 在极少数情况下，如果您有多个版本的Python，请确保使用匹配的pip版本。在某些情况下，我们可能需要使用以下内容：
- en: '[PRE95]'
  id: totrans-561
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Use the `pip` that goes with Python 3.5.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与Python 3.5配套的`pip`。
- en: Getting ready
  id: totrans-563
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We've gathered some sailboat racing results in `Volvo Ocean Race.html` . This
    file has information on teams, legs, and the order in which the various teams
    finished each leg. It's scraped from the Volvo Ocean Race website, and it looks
    wonderful when opened in a browser.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经收集了一些帆船赛的结果，保存在`Volvo Ocean Race.html`中。这个文件包含了关于队伍、赛段以及各个队伍在每个赛段中的完成顺序的信息。它是从Volvo
    Ocean Race网站上抓取的，并且在浏览器中打开时看起来很棒。
- en: HTML notation is very similar to XML. The content is surrounded by `<tag>` marks
    that show the structure and presentation of the data. HTML predates XML, and the
    XHTML standard reconciles the two Browsers; however, must be tolerant of older
    HTML and even improperly structured HTML. The presence of damaged HTML can make
    it difficult to analyze data from the World Wide Web.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: HTML标记非常类似于XML。内容被`<tag>`标记包围，显示数据的结构和呈现方式。HTML早于XML，XHTML标准调和了两者。浏览器必须能够容忍旧的HTML甚至结构不正确的HTML。损坏的HTML的存在可能会使分析来自万维网的数据变得困难。
- en: 'HTML pages include a great deal of overhead. There are often vast code and
    style sheet sections, as well as invisible metadata. The content may be surrounded
    by advertising and other information. Generally, an HTML page has the following
    overall structure:'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: HTML页面包含大量的开销。通常有大量的代码和样式表部分，以及不可见的元数据。内容可能被广告和其他信息包围。一般来说，HTML页面具有以下整体结构：
- en: '[PRE96]'
  id: totrans-567
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Within the `<head>` tag there will be links to JavaScript libraries, and links
    to **Cascading Style Sheet** ( **CSS** ) documents. These are generally used to
    provide interactive features and define the presentation of the content.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 在`<head>`标签中将会有指向JavaScript库的链接，以及指向**层叠样式表**（**CSS**）文档的链接。这些通常用于提供交互功能和定义内容的呈现。
- en: The bulk of the content is in the `<body>` tag. Many web pages are very busy
    and provide a tremendously complex mix of content. The design of web pages is
    a sophisticated art, and the content is designed to look good on most browsers.
    It can be difficult to track down the relevant data on a web page, because the
    focus is on how people see it more than how automated tools can process it.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分内容在`<body>`标签中。许多网页非常繁忙，提供了一个非常复杂的内容混合。网页设计是一门复杂的艺术，内容被设计成在大多数浏览器上看起来很好。在网页上跟踪相关数据可能很困难，因为重点是人们如何看待它，而不是自动化工具如何处理它。
- en: 'In this case, the race results are in an HTML `<table>` tag, making them easy
    to find. What we see is the following overall structure to the relevant content
    in the page:'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，比赛结果在HTML的`<table>`标签中，很容易找到。我们看到页面中相关内容的整体结构如下：
- en: '[PRE97]'
  id: totrans-571
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: The `<thead>` tag includes the column titles for the table. There's a single
    table row tag, `<tr>` , with table heading, `<th>` , tags that include the content.
    The content has two parts; the essential display is a number for each leg of the
    race. This is the content of the tag. In addition to the displayed content, there's
    also an attribute value that's used by a JavaScript function. This attribute value
    is displayed when the cursor hovers over a column heading. The JavaScript function
    pops up the leg name.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '`<thead>`标签包括表格的列标题。有一个单一的表格行标签`<tr>`，包含表头`<th>`标签，其中包含内容。内容有两部分；基本显示是比赛每条腿的编号。这是标签的内容。除了显示的内容，还有一个属性值，被一个JavaScript函数使用。当光标悬停在列标题上时，这个属性值会显示。JavaScript函数会弹出腿部名称。'
- en: The `<tbody>` tag includes the team name and the results for each race. The
    table row (`<tr>` ) contains the details for each team. The team name (and graphic
    and overall finish rank) is shown in the first three columns of table data, `<td>`
    . The remaining columns of table data contain the finish position for a given
    leg of the race.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: '`<tbody>`标签包括团队名称和每场比赛的结果。表格行（`<tr>`）包含每个团队的详细信息。团队名称（以及图形和总体完成排名）显示在表格数据`<td>`的前三列中。表格数据的其余列包含比赛每条腿的完成位置。'
- en: Because of the relative complexity of sailboat racing, there are additional
    notes in some of the table data cells. These are included as attributes that are
    used to provide supplemental data on the reason for the cell's value. In some
    cases, teams did not start a leg, or did not finish a leg, or retired from a leg.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 由于帆船比赛的相对复杂性，一些表格数据单元格中包含了额外的注释。这些被包含为属性，用于提供关于单元格值原因的补充数据。在某些情况下，团队没有开始一条腿，或者没有完成一条腿，或者退出了一条腿。
- en: 'Here''s a typical `<tr>` row from the HTML:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 这是HTML中典型的`<tr>`行：
- en: '[PRE98]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: The `<tr>` tag has a class attribute that defines the style for this row. The
    CSS provides the style rules for this class of data. The `class` attribute on
    this tag helps our data gathering application locate the relevant content.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: '`<tr>`标签具有一个类属性，用于定义此行的样式。CSS为这个数据类提供了样式规则。此标签上的`class`属性帮助我们的数据收集应用程序定位相关内容。'
- en: The `<td>` tags also have class attributes that define the style for the individual
    cells of data. In this case, class information clarifies what the content of the
    cell means.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: '`<td>`标签也有类属性，用于定义数据单元格的样式。在这种情况下，类信息澄清了单元格内容的含义。'
- en: One of the cells has no content. That cell has an attribute of `data-title`
    . This is used by a JavaScript function to display additional information in the
    cell.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个单元格没有内容。该单元格具有`data-title`属性。这被一个JavaScript函数用来在单元格中显示额外信息。
- en: How to do it...
  id: totrans-580
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We''ll need two modules: bs4 and pathlib:'
  id: totrans-581
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要两个模块：bs4和pathlib：
- en: '[PRE99]'
  id: totrans-582
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: We've only imported the `BeautifulSoup` class from the `bs4` module. This class
    will provide all of the features required to parse and analyze HTML documents.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只从`bs4`模块中导入了`BeautifulSoup`类。这个类将提供解析和分析HTML文档所需的所有功能。
- en: 'Define a `Path` object that names the source document:'
  id: totrans-584
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个命名源文档的`Path`对象：
- en: '[PRE100]'
  id: totrans-585
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Create the soup structure from the HTML content. We''ll assign it to a variable,
    `soup` :'
  id: totrans-586
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从HTML内容创建soup结构。我们将把它分配给一个变量`soup`：
- en: '[PRE101]'
  id: totrans-587
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: We've used a context manager to access the file. As an alternative we could
    simply read the content with `source_path.read_text(encodig='utf8')` . This works
    as well as providing an open file to the `BeautifulSoup` class.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上下文管理器来访问文件。作为替代，我们可以简单地使用`source_path.read_text(encodig='utf8')`来读取内容。这与为`BeautifulSoup`类提供一个打开的文件一样有效。
- en: 'The soup structure in the variable `soup` can then be processed to locate the
    various pieces of content. For example, we can extract the leg details as follows:'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`soup`中的soup结构可以被处理，以定位各种内容。例如，我们可以提取腿部细节如下：
- en: '[PRE102]'
  id: totrans-590
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: The expression `soup.table.thead.tr` will find the first `<table>` tag. Within
    that, the first `<thead>` tag; and within that, the first `<tr>` tag. We assigned
    this `<tr>` tag to a variable named, perhaps misleadingly, `thead` . We can then
    do a `findall()` to locate all `<th>` tags within this container.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式`soup.table.thead.tr`将找到第一个`<table>`标签。在其中，第一个`<thead>`标签；在其中，第一个`<tr>`标签。我们将这个`<tr>`标签分配给一个名为`thead`的变量，可能会误导。然后我们可以使用`findall()`来定位容器内的所有`<th>`标签。
- en: 'We''ll check each tag''s attributes to locate the `data-title` attribute values.
    This will have the leg name information. The leg name content looks as follows:'
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将检查每个标签的属性，以定位`data-title`属性的值。这将包含腿部名称信息。腿部名称内容如下：
- en: '[PRE103]'
  id: totrans-593
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: The `data-title` attribute value includes some additional HTML markup within
    the value. This is not a standard part of HTML and the `BeautifulSoup` parser
    doesn't look for this HTML within an attribute value.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: '`data-title`属性值包括值内的一些额外的HTML标记。这不是HTML的标准部分，`BeautifulSoup`解析器不会在属性值内查找这个HTML。'
- en: 'We have a small bit of HTML to parse, so we can create a small `soup` object
    just to parse that piece of text:'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一小段HTML需要解析，所以我们可以创建一个小的`soup`对象来解析这段文本：
- en: '[PRE104]'
  id: totrans-596
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: We create a small `BeautifulSoup` object from just the value of the `data-title`
    attribute. This soup will have information about the tag, `<strong>` , and the
    text. We used the text attribute to get all of the text without any tag information.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`data-title`属性的值创建一个小的`BeautifulSoup`对象。这个soup将包含关于标签`<strong>`和文本的信息。我们使用文本属性来获取所有文本，而不包含任何标签信息。
- en: How it works...
  id: totrans-598
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `BeautifulSoup` class transforms HTML documents into fairly complex objects
    based on a **document object model** ( **DOM** ). The resulting structure will
    be built from instances of the `Tag` , `NavigableString` , and `Comment` classes.
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '`BeautifulSoup`类将HTML文档转换为基于**文档对象模型**（**DOM**）的相当复杂的对象。结果结构将由`Tag`、`NavigableString`和`Comment`类的实例构建。'
- en: Generally, we're interested in the tags that contain the string content of the
    web page. These are objects of the `Tag` and `NavigableString` classes.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们对包含网页内容的标签感兴趣。这些是`Tag`和`NavigableString`类的对象。
- en: Each `Tag` instance has a name, string, and attributes. The name is the word
    inside the `<` and `>` . The attributes are the fields that follow the tag name.
    For example, `<td class="ranking-number">1</td>` has a tag name of `td` and an
    attribute named `class` . Values are often strings, but in a few cases, the value
    can be a list of strings. The string attribute of the `Tag` object is the content
    enclosed by the tag; in this case, it's a very short string, `1` .
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`Tag`实例都有一个名称、字符串和属性。名称是`<`和`>`之间的单词。属性是跟在标签名称后面的字段。例如，`<td class="ranking-number">1</td>`的标签名称是`td`，有一个名为`class`的属性。值通常是字符串，但在一些情况下，值可以是字符串列表。`Tag`对象的字符串属性是标签包围的内容；在这种情况下，它是一个非常短的字符串`1`。
- en: HTML is a mixed content model. This means that a tag can contain child tags
    in addition to navigable text. The text is mixed, it can be inside as well as
    outside any of the child tags. When looking at the children of a given tag, there
    will be a sequence of tags and text freely intermixed.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: HTML是一个混合内容模型。这意味着标签可以包含除可导航文本之外的子标签。文本是混合的，它可以在任何子标签内部或外部。当查看给定标签的子级时，将会有一系列标签和文本自由混合。
- en: 'One of the most common features of HTML are small blocks of navigable text
    that contain only newline characters. When we have a soup like this:'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: HTML的最常见特性之一是包含换行字符的可导航文本小块。当我们有这样的一段代码时：
- en: '[PRE105]'
  id: totrans-604
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'There are three children within the `<tr>` tag. Here''s a display of the children
    of this tag:'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: '`<tr>`标签内有三个子元素。以下是该标签的子元素的显示：'
- en: '[PRE106]'
  id: totrans-606
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: The two newline characters are peers to the `<td>` tag, and are preserved by
    the parser. This is navigable text that surrounds the child tag.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: 两个换行字符是`<td>`标签的同级，并且被解析器保留。这是包围子标签的可导航文本。
- en: The `BeautifulSoup` parser depends on another, lower-level process. The lower-level
    process can be the built-in `html.parser` module. There are alternatives that
    can be installed, also. The `html.parser` is easiest to use and covers the most
    common use cases. There are alternatives available, the Beautiful Soup documentation
    lists the other low-level parsers that can be used to solve particular web parsing
    problems.
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: '`BeautifulSoup`解析器依赖于另一个更低级的过程。较低级的过程可以是内置的`html.parser`模块。也有其他可安装的替代方案。`html.parser`是最容易使用的，覆盖了最常见的用例。还有其他可用的替代方案，Beautiful
    Soup文档列出了可以用来解决特定网页解析问题的其他低级解析器。'
- en: The lower-level parser recognizes events; these include element starts, element
    ends, comment starts, comment ends, runs of text, and similar lexical objects.
    At the higher level, the events are used to build the various objects of the Beautiful
    Soup document.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 较低级的解析器识别事件；这些事件包括元素开始、元素结束、注释开始、注释结束、文本运行和类似的词法对象。在更高的层次上，这些事件用于构建Beautiful
    Soup文档的各种对象。
- en: There's more...
  id: totrans-610
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The `Tag` objects of Beautiful Soup represent the hierarchy of the document''s
    structure. There are several kinds of navigation among tags:'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: Beautiful Soup的`Tag`对象表示文档结构的层次结构。标签之间有几种导航方式：
- en: All tags except a special root `[document]` container will have a parent. The
    top `<html>` tag will often be the only child of the root document container.
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了特殊的根`[document]`容器，所有标签都会有一个父级。顶级`<html>`标签通常是根文档容器的唯一子级。
- en: The `parents` attribute is a generator for all parents of a tag. It's a path
    through the hierarchy to a given tag.
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`parents`属性是一个给定标签的所有父级的生成器。这是通过层次结构到达给定标签的路径。'
- en: All `Tag` objects can have children. A few tags such as `<img/>` and `<hr/>`
    have no children. The `children` attribute is a generator that yields the children
    of a tag.
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有`Tag`对象都可以有子级。一些标签，如`<img/>`和`<hr/>`没有子级。`children`属性是一个生成器，产生标签的子级。
- en: A tag with children may have multiple levels of tags under it. The overall `<html>`
    tag, for example, has the entire document as descendants. The `children` attribute
    has the immediate children; the `descendants` attribute generates all children
    of children.
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有子级的标签可能有多个级别的标签。例如，整个`<html>`标签具有整个文档作为后代。`children`属性具有直接子级；`descendants`属性生成所有子级的子级。
- en: A tag can also have siblings, which are other tags within the same container.
    Since the tags have a defined order, there's a `next_sibling` and `previous_sibling`
    attribute to help step through the peers of a tag.
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签也可以有兄弟标签，这些标签位于同一个容器内。由于标签有一个定义好的顺序，所以有一个`next_sibling`和`previous_sibling`属性来帮助遍历标签的同级。
- en: 'In some cases, a document will have a generally straight-forward organization
    and a simple search by the `id` attribute or `class` attribute will find the relevant
    data. Here''s a typical search for a given structure:'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，文档将具有一般直观的组织结构，通过`id`属性或`class`属性的简单搜索将找到相关数据。以下是对给定结构的典型搜索：
- en: '[PRE107]'
  id: totrans-618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Note that we have to use `class_` in our Python query to search for the attribute
    named `class` . Given the overall document, we're searching for any `<table class="ranking-list">`
    tag. This will find the first such table in a web page. Since we know there will
    only be one of these, this attribute-based search helps distinguish between any
    other tabular data on a web page.
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们必须在Python查询中使用`class_`来搜索名为`class`的属性。鉴于整个文档，我们正在搜索任何`<table class="ranking-list">`标签。这将在网页中找到第一个这样的表。由于我们知道只会有一个这样的表，这种基于属性的搜索有助于区分网页上的任何其他表格数据。
- en: 'Here''s the parents of this `<table>` tag:'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这个`<table>`标签的父级：
- en: '[PRE108]'
  id: totrans-621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: We've displayed just the tag name for each parent above the given `<table>`
    . Note that there are four nested `<div>` tags that wrap the `<section>` that
    contains the `<table>` . Each of these `<div>` tags likely has a different class
    attribute to properly define the content and the style for the content.
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只显示了上面给定的`<table>`的每个父级标签的标签名。请注意，有四个嵌套的`<div>`标签包裹着包含`<table>`的`<section>`。这些`<div>`标签中的每一个可能都有一个不同的class属性，以正确定义内容和内容样式。
- en: The `[document]` is the overall `BeautifulSoup` container that holds the various
    tags that were parsed. This is displayed distinctively to emphasize that it's
    not a real tag, but a container for the top-level `<html>` tag.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: '`[document]`是包含各种标签的`BeautifulSoup`容器。这是以独特的方式显示出来，以强调它不是一个真正的标签，而是顶级`<html>`标签的容器。'
- en: See also
  id: totrans-624
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Reading JSON documents* and *Reading XML documents* recipes both use similar
    data. The example data was created for them by scraping the HTML page using these
    techniques.
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*读取JSON文档*和*读取XML文档*配方都使用类似的数据。示例数据是通过使用这些技术从HTML页面抓取而为它们创建的。'
- en: Upgrading CSV from DictReader to namedtuple reader
  id: totrans-626
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从DictReader升级CSV到命名元组读取器
- en: 'When we read data from a CSV format file, we have two general choices for the
    resulting data structure:'
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从CSV格式文件中读取数据时，对于结果数据结构有两种一般选择：
- en: When we use `csv.reader()` , each row becomes a simple list of column values.
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用`csv.reader()`时，每一行都变成了一个简单的列值列表。
- en: When we use `csv.DictReader` , each row becomes a dictionary. By default, the
    contents of the first row become the keys for the row dictionary. The alternative
    is to provide a list of values that will be used as the keys.
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用`csv.DictReader`时，每一行都变成了一个字典。默认情况下，第一行的内容成为行字典的键。另一种方法是提供一个值列表，将用作键。
- en: 'In both cases, referring to data within the row is awkward because it involves
    rather complex-looking syntax. When we use a `csv` reader, we must use `row[2]`
    : the semantics of this are completely obscure. When we use a `DictReader` , we
    can use `row[''date'']` , which is less obscure, but is still a lot of typing.'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，引用行内的数据都很笨拙，因为它涉及相当复杂的语法。当我们使用`csv`读取器时，我们必须使用`row[2]`：这个语义完全晦涩。当我们使用`DictReader`时，我们可以使用`row['date']`，这不那么晦涩，但仍然需要大量输入。
- en: In some real-world spreadsheets the column names are impossibly long strings.
    It's hard to work with `row['Total of all locations excluding franchisees']` .
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些现实世界的电子表格中，列名是不可能的长字符串。很难处理`row['Total of all locations excluding franchisees']`。
- en: What can we do to replace complex syntax with something simpler?
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做些什么来用更简单的东西替换复杂的语法？
- en: Getting ready
  id: totrans-633
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: One way to improve the readability of programs that work with spreadsheets is
    to replace a list of columns with a `namedtuple` object. This provides easy-to-use
    names defined by the `namedtuple` instead of the possibly haphazard column names
    in the `.csv` file.
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 改善处理电子表格的程序的可读性的一种方法是用`namedtuple`对象替换列的列表。这提供了由`namedtuple`定义的易于使用的名称，而不是`.csv`文件中可能杂乱无章的列名。
- en: More importantly, it permits much nicer syntax for referring to the various
    columns. In addition to `row[0]` , we can also use `row.date` to refer to a column
    named `date` .
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，它允许更好的语法来引用各个列。除了`row[0]`，我们还可以使用`row.date`来引用名为`date`的列。
- en: The column names (and the data types for each column) are part of the schema
    for a given file of data. In some CSV files the first line of the column titles
    is a schema for the file. This schema is limited, it provides only attribute names;
    the data types aren't known and have to be treated as strings.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 列名（以及每列的数据类型）是给定数据文件的模式的一部分。在一些CSV文件中，列标题的第一行是文件的模式。这个模式是有限的，它只提供属性名称；数据类型是未知的，必须被视为字符串处理。
- en: 'This points to two reasons for imposing an external schema on the rows of a
    spreadsheet:'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 这指出了在电子表格的行上强加外部模式的两个原因：
- en: We can supply meaningful names
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以提供有意义的名称
- en: We can perform data conversions where necessary
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以在必要时执行数据转换
- en: 'We''ll look at a relatively simple CSV file that has some real-time data recorded
    from the log of a sailboat. This is the `waypoints.csv` file, and the data looks
    as follows:'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看一个相对简单的CSV文件，其中记录了一艘帆船的日志中的一些实时数据。这是`waypoints.csv`文件，数据如下：
- en: '[PRE109]'
  id: totrans-641
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: The data has four columns. Two of the columns are the latitude and longitude
    of the waypoint. It has a column with the date and the time as separate values.
    This isn't ideal, and we'll look at various data cleansing steps separately.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有四列。其中两列是航点的纬度和经度。它有一个包含日期和时间的列。这并不理想，我们将分别查看各种数据清洗步骤。
- en: In this case, the column titles happen to be valid Python variable names. This
    is rare, but it can lead to a slight simplification. We'll look at the alternatives
    in the following section.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，列标题恰好是有效的Python变量名。这很少见，但可能会导致略微简化。我们将在下一节中看看其他选择。
- en: The most important step is to gather the data as `namedtuples` .
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的一步是将数据收集为`namedtuples`。
- en: How to do it...
  id: totrans-645
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the modules and definitions required. In this case, they will be from
    `collections` , `csv` , and `pathlib` :'
  id: totrans-646
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的模块和定义。在这种情况下，它们将来自`collections`，`csv`和`pathlib`：
- en: '[PRE110]'
  id: totrans-647
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Define the `namedtuple` that matches the actual data. In this case, we''ve
    called it `Waypoint` and provided names for the four columns of data. In this
    example, the attributes happen to match the column names; it''s not a requirement
    that the names match:'
  id: totrans-648
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义与实际数据匹配的`namedtuple`。在这种情况下，我们称之为`Waypoint`并为四列数据提供名称。在这个例子中，属性恰好与列名匹配；这不是必须的：
- en: '[PRE111]'
  id: totrans-649
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'Define the `Path` object that refers to the data:'
  id: totrans-650
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义引用数据的`Path`对象：
- en: '[PRE112]'
  id: totrans-651
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Create the processing context for the open file:'
  id: totrans-652
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为打开的文件创建处理上下文：
- en: '[PRE113]'
  id: totrans-653
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Define a CSV reader for the data. We''ll call this a raw reader. In the long
    run, we''ll follow the *Using stacked generator expressions* recipe in [Chapter
    8](text00088.html#page "Chapter 8. Functional and Reactive Programming Features")
    , *Functional And Reactive Programming Features* and *Use a stack of generator
    expressions* recipe in [Chapter 8](text00088.html#page "Chapter 8. Functional
    and Reactive Programming Features") , *Functional And Reactive Programming Features*
    to cleanse and filter the data:'
  id: totrans-654
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为数据定义一个CSV读取器。我们将其称为原始读取器。从长远来看，我们将遵循[第8章](text00088.html#page "第8章。功能和响应式编程特性")中的*使用堆叠的生成器表达式*配方，*功能和响应式编程特性*和[第8章](text00088.html#page
    "第8章。功能和响应式编程特性")中的*使用一堆生成器表达式*配方，*功能和响应式编程特性*来清理和过滤数据：
- en: '[PRE114]'
  id: totrans-655
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Define a generator that builds `Waypoint` objects from tuples of input data:'
  id: totrans-656
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个生成器，从输入数据的元组构建`Waypoint`对象：
- en: '[PRE115]'
  id: totrans-657
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'We can now process rows using the `waypoints_reader` generator expression:'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`waypoints_reader`生成器表达式来处理行：
- en: '[PRE116]'
  id: totrans-659
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: The `waypoints_reader` object will also provide the heading row, which we want
    to ignore. We'll look at filtering and conversion in the following section.
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: '`waypoints_reader`对象还将提供标题行，我们希望忽略它。我们将在下一节讨论过滤和转换。'
- en: The expression `(Waypoint(*row) for row in raw_reader)` expands each value of
    the `row` tuple to be a positional argument value for the `Waypoint` function.
    This works because the column order in the CSV file matches the column order in
    the `namedtuple` definition.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式`(Waypoint(*row) for row in raw_reader)`会将`row`元组的每个值扩展为`Waypoint`函数的位置参数值。这是因为CSV文件中的列顺序与`namedtuple`定义中的列顺序匹配。
- en: This construction can also be performed using the `itertools` module, also.
    The `starmap()` function can be used as `starmap(Waypoint, raw_reader)` . This
    will also expand each tuple from the `raw_reader` to be a positional argument
    to the `Waypoint` function. Note that we can't use the built-in `map()` function
    for this. The `map()` function assumes that the function takes a single argument
    value. We don't want each four-item `row` tuple to be used as the only argument
    to the `Waypoint` function. We need to split the four items into four positional
    argument values.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 这种构造也可以使用`itertools`模块来执行。`starmap()`函数可以用作`starmap(Waypoint, raw_reader)`。这也将使`raw_reader`中的每个元组扩展为`Waypoint`函数的位置参数。请注意，我们不能使用内置的`map()`函数。`map()`函数假定函数接受单个参数值。我们不希望每个四项`row`元组都被用作`Waypoint`函数的唯一参数。我们需要将四个项目拆分为四个位置参数值。
- en: How it works...
  id: totrans-663
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: There are several parts to this recipe. Firstly, we've used the `csv` module
    for the essential parsing of rows and columns of data. We've leveraged the *Reading
    delimited files with the cvs module* recipe to process the physical format of
    the data.
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方有几个部分。首先，我们使用`csv`模块对数据的行和列进行基本解析。我们利用了*使用cvs模块读取分隔文件*配方来处理数据的物理格式。
- en: Secondly, we've defined a `namedtuple()` that provides a minimal schema for
    our data. This is not very rich or detailed. It provides a sequence of column
    names. It also simplifies the syntax for accessing a particular column.
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们定义了一个`namedtuple()`，为我们的数据提供了一个最小的模式。这并不是非常丰富或详细。它提供了一系列列名。它还简化了访问特定列的语法。
- en: Finally, we've wrapped the `csv` reader in a generator function to build `namedtuple`
    objects for each row. This is a tiny change to the default processing, but it
    leads to a nicer style for the subsequent programming.
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将`csv`读取器包装在一个生成器函数中，为每一行构建`namedtuple`对象。这对默认处理来说是一个微小的改变，但它会导致后续编程的更好风格。
- en: Instead of `row[2]` or `row['date']` , we can now use `row.date` to refer to
    a specific column. This is a small change that can simplify the presentation of
    complex algorithms.
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`row.date`而不是`row[2]`或`row['date']`来引用特定的列。这是一个可以简化复杂算法呈现的小改变。
- en: There's more...
  id: totrans-668
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The initial example of processing the input has two additional problems. Firstly,
    the header row is mixed in with the useful rows of data; this header row needs
    to be rejected by a filter of some kind. Secondly, the data is all strings, and
    some conversion is necessary. We'll solve each of these by extending the recipe.
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: 处理输入的初始示例存在两个额外的问题。首先，标题行与有用的数据行混在一起；这个标题行需要通过某种过滤器被拒绝。其次，数据都是字符串，需要进行一些转换。我们将通过扩展配方来解决这两个问题。
- en: 'There are two common techniques for discarding the unneeded header row:'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种常见的技术可以丢弃不需要的标题行：
- en: 'We can use an explicit iterator and discard the first item. The general idea
    is as follows:'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用显式迭代器并丢弃第一项。总体思路如下：
- en: '[PRE117]'
  id: totrans-672
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: This snippet shows how to create an iterator object, `waypoints_iter` , from
    the raw CSV reader. We can use the `next()` function to skip a single item from
    this reader. The remaining items can be used to build useful rows of data. We
    can also use the `itertools.islice()` function for this.
  id: totrans-673
  prefs: []
  type: TYPE_NORMAL
  zh: 这个片段展示了如何从原始CSV读取器创建一个迭代器对象`waypoints_iter`。我们可以使用`next()`函数从这个读取器中跳过一个项目。剩下的项目可以用来构建有用的数据行。我们也可以使用`itertools.islice()`函数来实现这一点。
- en: 'We can write a generator or use the `filter()` function to exclude selected
    rows:'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以编写一个生成器或使用`filter()`函数来排除选定的行：
- en: '[PRE118]'
  id: totrans-675
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: This example shows how to create filtered generator, `skip_header` , from the
    raw CSV reader. The filter uses a simple expression, `row[0] != 'lat'` , to determine
    if a row is a header or has useful data. Only the useful rows are passed by this
    filter. The header row is rejected.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了如何从原始CSV读取器创建过滤生成器`skip_header`。过滤器使用一个简单的表达式`row[0] != 'lat'`来确定一行是否是标题或者有用的数据。只有有用的行通过了这个过滤器。标题行被拒绝了。
- en: 'The other thing we''ll need to do is to convert the various data items to more
    useful values. We''ll follow the example of the *Simplifying complex algorithms
    with immutable data structures* recipe in [Chapter 8](text00088.html#page "Chapter 8. Functional
    and Reactive Programming Features") , *Functional And Reactive Programming Features*
    and build a new `namedtuple` from the raw input data:'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要做的另一件事是将各种数据项转换为更有用的值。我们将遵循[第8章](text00088.html#page "第8章。功能和反应式编程特性")中的*Simplifying
    complex algorithms with immutable data structures*配方的例子，从原始输入数据构建一个新的`namedtuple`：
- en: '[PRE119]'
  id: totrans-678
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'At this point in most projects, it becomes clear that the original name of
    the `Waypoint namedtuple` was poorly chosen. The code will need to be refactored
    to change the names to clarify the role of the original `Waypoint` tuple. This
    renaming and refactoring will occur several times as the design evolves. It''s
    important to rename things as needed. We won''t do the renaming here: we''ll leave
    it for the reader to redesign the names.'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数项目的这个阶段，很明显`Waypoint namedtuple`的原始名称选择不当。代码需要重构以更改名称以澄清原始`Waypoint`元组的角色。随着设计的演变，这种重命名和重构将多次发生。根据需要重命名是很重要的。我们不会在这里进行重命名：我们将把它留给读者重新设计名称。
- en: To do the conversions, we need a function to handle the individual fields of
    a single `Waypoint` . This will create more useful values. It will involve using
    `float()` on the latitude and longitude values. It also requires some careful
    parsing of the date values.
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行转换，我们需要一个处理单个`Waypoint`字段的函数。这将创建更有用的值。它涉及对纬度和经度值使用`float()`。它还需要对日期值进行一些仔细的解析。
- en: 'Here''s the first part of working with the separate date and time. These are
    two lambda objects-small functions with only a single expression that convert
    date or time strings to date or time values:'
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 这是处理单独的日期和时间的第一部分。这是两个lambda对象-只有一个单一表达式的小函数，将日期或时间字符串转换为日期或时间值：
- en: '[PRE120]'
  id: totrans-682
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'We can use these to build a new `Waypoint_data` object from the original `Waypoint`
    object:'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这些来从原始`Waypoint`对象构建一个新的`Waypoint_data`对象：
- en: '[PRE121]'
  id: totrans-684
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: We've applied a series of functions that build a new data structure from an
    existing data structure. The latitude and longitude values were converted with
    the `float()` function. The date and time values were converted to a `datetime`
    object using the `parse_date` and `parse_time` lambdas with the `combine()` method
    of the `datetime` class.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了一系列函数，从现有的数据结构构建了一个新的数据结构。纬度和经度值使用`float()`函数进行转换。日期和时间值使用`parse_date`和`parse_time`
    lambda与`datetime`类的`combine()`方法转换为`datetime`对象。
- en: 'This function allows us to build a more complete stack of processing steps
    for the source data:'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数允许我们为源数据构建一个更完整的处理步骤堆栈：
- en: '[PRE122]'
  id: totrans-687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: The original reader has been supplemented with a filter function to skip the
    header, a generator to create `Waypoint` objects, and another generator to create
    `Waypoint_Data` objects. Within the body of the `for` statement, we have a simple
    and easy-to-use data structure with pleasant names. We can refer to `row.lat`
    instead of `row[0]` or `row['lat']` .
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 原始读取器已经补充了一个跳过标题的过滤函数，一个用于创建`Waypoint`对象的生成器，以及另一个用于创建`Waypoint_Data`对象的生成器。在`for`语句的主体中，我们有一个简单易用的数据结构，具有愉快的名称。我们可以引用`row.lat`而不是`row[0]`或`row['lat']`。
- en: Note that each generator function is lazy, it doesn't fetch any more input than
    is minimally required to produce some output. This stack of generator functions
    uses very little memory and can process files of unlimited size.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，每个生成器函数都是惰性的，它不会获取比产生一些输出所需的更多输入。这个生成器函数堆栈使用的内存很少，可以处理无限大小的文件。
- en: See also
  id: totrans-690
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Upgrading CSV from dict reader to namespace reader* recipe does this with
    mutable `SimpleNamespace` data structure
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*从dict reader升级CSV到namespace reader*配方使用了可变的`SimpleNamespace`数据结构'
- en: Upgrading CSV from a DictReader to a namespace reader
  id: totrans-692
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从DictReader升级CSV到命名空间读取器
- en: 'When we read data from a CSV format file, we have two general choices for the
    resulting data structure:'
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从CSV格式文件中读取数据时，我们有两种一般的选择结果数据结构：
- en: When we use `csv.reader()` , each row becomes a simple list of column values.
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用`csv.reader()`时，每一行都变成了一个简单的列值列表。
- en: When we use `csv.DictReader` , each row becomes a dictionary. By default, the
    contents of the first row become the keys for the row dictionary. We can also
    provide a list of values that will be used as the keys.
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用`csv.DictReader`时，每一行都变成了一个字典。默认情况下，第一行的内容成为行字典的键。我们还可以提供一个值列表，将用作键。
- en: In both cases, referring to data within the row is awkward because it involves
    rather complex-looking syntax. When we use a reader, we must use `row[0]` , the
    semantics of this are completely obscure. When we use a `DictReader` , we can
    use `row['date']` , which is less obscure, but is a lot of typing.
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，引用行内的数据都很笨拙，因为它涉及相当复杂的语法。当我们使用读取器时，我们必须使用`row[0]`，这个语义完全晦涩。当我们使用`DictReader`时，我们可以使用`row['date']`，这不那么晦涩，但是要输入很多。
- en: In some real-world spreadsheets, the column names are impossibly long strings.
    It's hard to work with `row['Total of all locations excluding franchisees']` .
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些现实世界的电子表格中，列名是不可能很长的字符串。很难使用`row['Total of all locations excluding franchisees']`。
- en: What can we do to replace complex syntax with something simpler?
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用什么简单的方法来替换复杂的语法？
- en: Getting ready
  id: totrans-699
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The column names (and the data types for each column) are a schema for our data.
    The column titles are a schema that's embedded in the first row of the CSV data.
    This schema provides only attribute names; the data types aren't known and have
    to be treated as strings.
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 列名（以及每列的数据类型）是我们数据的模式。列标题是嵌入在CSV数据的第一行中的模式。这个模式只提供了属性名称；数据类型是未知的，必须被视为字符串。
- en: 'This points up two reasons for imposing an external schema on the rows of a
    spreadsheet:'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 这指出了在电子表格的行上强加外部模式的两个原因：
- en: We can supply meaningful names.
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以提供有意义的名称。
- en: We can perform data conversions where necessary.
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以在必要时进行数据转换。
- en: We can also use a schema to define data quality and cleansing processing. This
    can become quite sophisticated (and complicated). We'll limit our use of schema
    to providing column names and data conversions.
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用模式来定义数据质量和清洗处理。这可能变得非常复杂。我们将限制使用模式来提供列名和数据转换。
- en: 'We''ll look at a relatively simple CSV file that has some real-time data recorded
    from the log of a sailboat. This is the `waypoints.csv` file. The data looks like
    the following:'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看一个相对简单的CSV文件，其中记录了一艘帆船日志的实时数据。这是`waypoints.csv`文件。数据看起来像下面这样：
- en: '[PRE123]'
  id: totrans-706
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: This spreadsheet has four columns. Two of them are the latitude and longitude
    of the waypoint. It has a column with the date and the time as separate values.
    This isn't ideal, and we'll look at various data cleansing steps separately.
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 这个电子表格有四列。其中两列是航点的纬度和经度。它有一个包含日期和时间的列。这并不理想，我们将分别查看各种数据清洗步骤。
- en: In this case, the column titles are valid Python variable names. This leads
    to an important simplification in the processing. In the cases where there are
    no column names, or the column names aren't Python variables, we'll have to apply
    a mapping from column name to preferred attribute name.
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，列标题是有效的Python变量名。这导致了处理中的一个重要简化。在没有列名或列名不是Python变量的情况下，我们将不得不应用从列名到首选属性名的映射。
- en: How to do it...
  id: totrans-709
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the modules and definitions required. In this case, it will be from
    `types` , `csv` , and `pathlib` :'
  id: totrans-710
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的模块和定义。在这种情况下，它将是来自`types`，`csv`和`pathlib`：
- en: '[PRE124]'
  id: totrans-711
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: 'Import `csv` and define a `Path` object that refers to the data:'
  id: totrans-712
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`csv`并定义一个指向数据的`Path`对象：
- en: '[PRE125]'
  id: totrans-713
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'Create the processing context for the open file:'
  id: totrans-714
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为打开的文件创建处理上下文：
- en: '[PRE126]'
  id: totrans-715
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'Define a CSV reader for the data. We''ll call this a raw reader. In the long
    run, we''ll follow the *Using stacked generator expressions* recipe in [Chapter
    8](text00088.html#page "Chapter 8. Functional and Reactive Programming Features")
    , *Functional And Reactive Programming Features* and use multiple generator expressions
    to cleanse and filter the data:'
  id: totrans-716
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为数据定义一个CSV读取器。我们将其称为原始读取器。从长远来看，我们将遵循[第8章](text00088.html#page "第8章。功能和响应式编程特性")中的*使用堆叠的生成器表达式*，*功能和响应式编程特性*并使用多个生成器表达式来清理和过滤数据：
- en: '[PRE127]'
  id: totrans-717
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'Define a generator that will convert these dictionaries into `SimpleNamespace`
    objects:'
  id: totrans-718
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个生成器，将这些字典转换为`SimpleNamespace`对象：
- en: '[PRE128]'
  id: totrans-719
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: This uses the generic `SimpleNamespace` class. When we need to use a more specific
    class, we can replace the `SimpleNamespace` with an application-specific class
    name. That class `__init__` must use keyword parameters that match the spreadsheet
    column names.
  id: totrans-720
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用了通用的`SimpleNamespace`类。当我们需要使用更具体的类时，我们可以用应用程序特定的类名替换`SimpleNamespace`。该类的`__init__`必须使用与电子表格列名匹配的关键字参数。
- en: 'We can now process rows from this generator expression:'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以从这个生成器表达式中处理行：
- en: '[PRE129]'
  id: totrans-722
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: How it works...
  id: totrans-723
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: There are several parts to this recipe. Firstly, we've used the `csv` module
    for the essential parsing of rows and columns of data. We've leveraged the *Reading
    delimited files with the cvs module* recipe to process the physical format of
    the data. The idea of the CSV format is to have columns of text that are comma
    separated in each row. There are rules for using quotes to allow the data within
    a column to contain a comma. The rules are all implemented within the `csv` module,
    saving us from writing a parser for this.
  id: totrans-724
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱有几个部分。首先，我们使用了`csv`模块来对数据的行和列进行基本解析。我们利用了*使用cvs模块读取分隔文件*的方法来处理数据的物理格式。CSV格式的想法是在每一行中有逗号分隔的文本列。有规则可以使用引号来允许列内的数据包含逗号。所有这些规则都在`csv`模块中实现，省去了我们编写解析器的麻烦。
- en: Secondly, we've wrapped the `csv` reader in a generator function to build a
    `SimpleNamespace` object for each row. This is a tiny extension to the default
    processing, but it leads to a nicer style for the subsequent programming. Instead
    of `row[2]` or `row['date']` , we can now use `row.date` to refer to a specific
    column. This is a small change that can simplify the presentation of complex algorithms.
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们将`csv`读取器包装在一个生成器函数中，为每一行构建一个`SimpleNamespace`对象。这是对默认处理的微小扩展，但可以使后续编程风格更加优雅。现在我们可以使用`row.date`来引用特定列，而不是`row[2]`或`row['date']`。这是一个小改变，可以简化复杂算法的呈现。
- en: There's more...
  id: totrans-726
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We may have two additional problems to solve. Whether or not these are needed
    depends on the data and the use for the data:'
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能有两个额外的问题要解决。是否需要这些取决于数据和数据的用途：
- en: How do we handle spreadsheet names that aren't proper Python variables?
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何处理不是合适的Python变量的电子表格名称？
- en: How can we convert data from text to a Python object?
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何将数据从文本转换为Python对象？
- en: 'It turns out that both of these needs can be handled elegantly with a function
    that does row by row conversion of data, and also handles any necessary renaming
    of columns:'
  id: totrans-730
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，这两个需求都可以通过一个逐行转换数据的函数来优雅处理，并且还可以处理任何必要的列重命名：
- en: '[PRE130]'
  id: totrans-731
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'This function is in effect the schema definition for the original spreadsheet.
    Each line in this function provides several important pieces of information:'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数实际上是原始电子表格的模式定义。这个函数中的每一行提供了几个重要的信息：
- en: The attribute name in the `SimpleNamespace`
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SimpleNamespace`中的属性名称'
- en: The conversion from the source data
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从源数据转换
- en: The source column names that were mapped to the final result
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射到最终结果的源列名称
- en: The goal is to define any helper or support functions required to be sure that
    each line of the conversion function is similar to the ones shown. Each line of
    this function is complete specification for a result column. As a bonus benefit,
    each line is written in Python notation.
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是定义任何必要的辅助或支持函数，以确保转换函数的每一行与所示的行类似。该函数的每一行都是结果列的完整规范。作为额外的好处，每一行都是用Python符号表示的。
- en: 'This function can replace `SimpleNamespace` in the `ns_reader` statement. All
    of the conversion work is now focused into a single place:'
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数可以替换`ns_reader`语句中的`SimpleNamespace`。现在所有的转换工作都集中在一个地方：
- en: '[PRE131]'
  id: totrans-738
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'This row transformation function relies on a `make_timestamp()` function. This
    function converts two source columns to one resulting `datetime` object. The function
    looks like the following:'
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行变换函数依赖于`make_timestamp()`函数。该函数将两个源列转换为一个结果为`datetime`对象的函数。该函数如下所示：
- en: '[PRE132]'
  id: totrans-740
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: The `make_timestamp()` function breaks the timestamp creation into three parts.
    The first two parts are so simple that a lambda object was all that was needed.
    These are conversions from text to make `datetime.date` or `datetime.time` objects.
    Each conversion use the `strptime()` method to parse the date or time strings
    and return the appropriate class of object.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: '`make_timestamp()`函数将时间戳的创建分为三个部分。前两部分非常简单，只需要一个lambda对象。这些是从文本转换为`datetime.date`或`datetime.time`对象。每个转换使用`strptime()`方法来解析日期或时间字符串，并返回适当的对象类。'
- en: The third part could also have been a lambda, since it's also a single expression.
    However, it's a long expression, and it seemed slightly more clear to wrap it
    as a `def` statement. This expression uses the `combine()` method of `datetime`
    to combine a date and time into a single object.
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 第三部分也可以是lambda，因为它也是一个单一表达式。但是，它是一个很长的表达式，将其包装为`def`语句似乎更清晰一些。这个表达式使用`datetime`的`combine()`方法将日期和时间组合成一个对象。
- en: See also
  id: totrans-743
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Upgrading CSV from dict reader to namedtuple reader* recipe does this with
    an immutable `namedtuple` data structure instead of a `SimpleNamespace`
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*从字典读取器升级CSV到命名元组读取器*的方法是使用不可变的`namedtuple`数据结构，而不是`SimpleNamespace`'
- en: Using multiple contexts for reading and writing files
  id: totrans-745
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多个上下文来读写文件
- en: It's common to need to convert data from one format to another. For example,
    we might have a complex web log that we'd like to convert to a simpler format.
  id: totrans-746
  prefs: []
  type: TYPE_NORMAL
  zh: 通常需要将数据从一种格式转换为另一种格式。例如，我们可能有一个复杂的网络日志，我们希望将其转换为更简单的格式。
- en: See the *Reading complex formats using regular expressions* recipe for a complex
    web log format. We'd like to do this parsing just one time.
  id: totrans-747
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅*使用正则表达式读取复杂格式*食谱以了解复杂的网络日志格式。我们希望只进行一次解析。
- en: After that, we'd like to work with a simpler file format, more like the format
    shown in the *Upgrading CSV from dict reader to namedtuple reader* or *Upgrading
    CSV from dict reader to namespace reader* recipe. A file that's in CSV notation
    can be read and parsed with the `csv` module, simplifying the physical format
    considerations.
  id: totrans-748
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们希望使用更简单的文件格式，更像*从字典读取器升级CSV到命名元组读取器*或*从字典读取器升级CSV到命名空间读取器*的格式。CSV格式的文件可以使用`csv`模块进行读取和解析，简化物理格式的考虑。
- en: How can we convert from one format to another?
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何从一种格式转换为另一种格式？
- en: Getting ready
  id: totrans-750
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Converting a file of data from one format to another means that the program
    will need to have two open contexts: one for reading and one for writing. Python
    makes this easy. The use of `with` statement contexts assures that the files are
    properly closed and all of the related OS resources are completely released.'
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据文件从一种格式转换为另一种格式意味着程序需要有两个打开的上下文：一个用于读取，一个用于写入。Python使这变得容易。使用`with`语句上下文确保文件被正确关闭，并且所有相关的操作系统资源都被完全释放。
- en: 'We''ll look at a common problem of summarizing many web log files. The source
    is in a format that we''ve seen in the *Writing generator functions with the yield
    statement* recipe in [Chapter 8](text00088.html#page "Chapter 8. Functional and
    Reactive Programming Features") , *Functional And Reactive Programming Features*
    and also *Reading complex formats using regular expressions* recipe in this chapter.
    The rows look like the following:'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究总结许多网络日志文件的常见问题。源代码格式与[第8章](text00088.html#page "第8章. 函数式和响应式编程特性")中*使用yield语句编写生成器函数*食谱中看到的格式相同，也与本章中*使用正则表达式读取复杂格式*食谱中看到的格式相同。行如下所示：
- en: '[PRE133]'
  id: totrans-753
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: These are difficult to process. The regular expression required to parse them
    is complex. For large volumes of data, it's also rather slow.
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 这些很难处理。需要复杂的正则表达式来解析它们。对于大量的数据，它也相当慢。
- en: 'Here''s the regular expression pattern for the various elements of the line:'
  id: totrans-755
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是行中各个元素的正则表达式模式：
- en: '[PRE134]'
  id: totrans-756
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'There are four parts to this complex regular expression:'
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 这个复杂的正则表达式有四个部分：
- en: The date-time stamp is surrounded with `[ ]` and has a variety of digits, hyphens,
    colons, and a comma. It will be captured and assigned the name `date` by the `?P<date>`
    prefix on the `()` group.
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期时间戳用`[ ]`括起来，包含各种数字、连字符、冒号和逗号。它将被捕获并通过`?P<date>`前缀分配名称`date`给`()`组。
- en: The severity level, which is a run of characters. This is captured and given
    the name level by the `?P<level>` prefix on the next `()` group.
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 严重级别，这是一系列字符。这是通过下一个`()`组的`?P<level>`前缀捕获并命名为level。
- en: The module is a sequence of characters including `_` and `.` . It's sandwiched
    between `in` and a `:` . The is assigned the name `module` .
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模块是一个包括`_`和`.`的字符序列。它被夹在`in`和`:`之间。被分配名称`module`。
- en: Finally, there's a message that extends to the end of the line. This is assigned
    to the message by the `?P<message>` inside the final `()` .
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，有一条消息延伸到行尾。这是通过最后一个`()`内的`?P<message>`分配给消息的。
- en: The pattern also includes runs of whitespace, `\s+` , which are not captured
    in any `()` groups. They're quietly ignored.
  id: totrans-762
  prefs: []
  type: TYPE_NORMAL
  zh: 模式还包括空白符的运行，`\s+`，它们不在任何`()`组中捕获。它们被静默忽略。
- en: When we create a `match` object using this regular expression, the `groupdict()`
    method of that `match` object will produce a dictionary with the names and values
    from each line. This matches the way the `csv` reader works. It provides a common
    framework for processing complex data.
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用这个正则表达式创建一个`match`对象时，该`match`对象的`groupdict()`方法将生成一个包含每行名称和值的字典。这与`csv`读取器的工作方式相匹配。它提供了处理复杂数据的通用框架。
- en: 'We''ll use this in a function that iterates through rows of log data. The function
    will apply the regular expression, and yield the group dictionaries:'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在迭代日志数据行的函数中使用这个。该函数将应用正则表达式，并生成组字典：
- en: '[PRE135]'
  id: totrans-765
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: This function looks at each line in the given input file. It applies the regular
    expression to the line. If the line matches, this will capture the relevant fields
    of data. If there is no match, the line didn't follow the expected format; this
    may deserve an error message. There's no useful data to yield, so the `continue`
    statement skips the rest of the body of the `for` statement.
  id: totrans-766
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数查看给定输入文件中的每一行。它将正则表达式应用于该行。如果该行匹配，它将捕获相关的数据字段。如果没有匹配，该行没有遵循预期的格式；这可能值得一个错误消息。没有有用的数据可以产生，所以`continue`语句跳过了`for`语句的其余部分。
- en: The `yield` statement produces the dictionaries of matches. Each dictionary
    will have the four named fields and the captured data from the log. The data will
    be text only, so additional conversions will have to be applied separately.
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: '`yield`语句产生匹配的字典。每个字典将有四个命名字段和从日志中捕获的数据。数据将仅为文本，因此额外的转换将需要分别应用。'
- en: We can use the `DictWriter` class from the `csv` module to emit a CSV file with
    these various data elements neatly separated. Once we've created a CSV file, we
    can process the data simply and much more quickly than the raw log rows.
  id: totrans-768
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`csv`模块中的`DictWriter`类来发出一个CSV文件，其中这些各种数据元素被整齐地分隔。一旦我们创建了一个CSV文件，我们就可以简单地处理数据，比原始日志行快得多。
- en: How to do it...
  id: totrans-769
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This recipe will need three components:'
  id: totrans-770
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个食谱将需要三个组件：
- en: '[PRE136]'
  id: totrans-771
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'Here''s the pattern that matches the simple Flask logs. For other kinds of
    logs, or other formats configured into Flask, a different pattern will be required:'
  id: totrans-772
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是匹配简单Flask日志的模式。对于其他类型的日志，或者配置到Flask中的其他格式，将需要不同的模式：
- en: '[PRE137]'
  id: totrans-773
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'Here''s the function that yields dictionaries for the matching rows. This applies
    the regular expression pattern. Non-matches are silently skipped. The matches
    will yield a dictionary of item names and their values:'
  id: totrans-774
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是产生匹配行的字典的函数。这应用了正则表达式模式。不匹配的行将被静默跳过。匹配将产生一个项目名称及其值的字典：
- en: '[PRE138]'
  id: totrans-775
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: 'We''ll define the `Path` object for the resulting log summary file:'
  id: totrans-776
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为生成的日志摘要文件定义`Path`对象：
- en: '[PRE139]'
  id: totrans-777
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: 'We can then open the results context. Because we''re using a `with` statement,
    we''re assured that the file will be properly closed no matter what else happens
    in this script:'
  id: totrans-778
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以打开结果上下文。因为我们使用了`with`语句，所以可以确保无论在脚本中发生什么，文件都会被正确关闭：
- en: '[PRE140]'
  id: totrans-779
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: 'Since we''re writing a CSV file based on a dictionary, we''ll define a `csv.DictWriter`
    . This is indented four spaces inside the `with` statement. We must provide the
    expected keys from the input dictionary. This will define the order for the columns
    in the resulting file:'
  id: totrans-780
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们正在基于字典编写CSV文件，我们将定义一个`csv.DictWriter`。这是在`with`语句内缩进了四个空格。我们必须提供输入字典中的预期键。这将定义结果文件中列的顺序：
- en: '[PRE141]'
  id: totrans-781
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'We''ll define a `Path` object for the source directory with log files. In this
    case, the log files happen to be in the directory with the script. This is rare,
    and using an environment variable might be a lot more useful:'
  id: totrans-782
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为包含日志文件的源目录定义`Path`对象。在这种情况下，日志文件碰巧在脚本所在的目录中。这是罕见的，使用环境变量可能会更有用：
- en: '[PRE142]'
  id: totrans-783
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: We can imagine using `os.environ.get('LOG_PATH', '/var/log')` as a more general
    solution than a hard-coded path.
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以想象使用`os.environ.get('LOG_PATH', '/var/log')`作为一个比硬编码路径更一般的解决方案。
- en: 'We''ll use the `glob()` method of a `Path` object to find all files that match
    the required name:'
  id: totrans-785
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`Path`对象的`glob()`方法来查找所有与所需名称匹配的文件：
- en: '[PRE143]'
  id: totrans-786
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: This, too, could benefit from having the pattern string fetched from an environment
    variable or command-line parameter.
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可以从环境变量或命令行参数中获取模式字符串。
- en: 'We''ll define a context for reading each source file. This context manager
    will guarantee that the input files are properly closed and the resources released.
    Note that this is indented inside the previous `with` and `for` statements, a
    total of eight spaces. This is particularly important when processing a large
    number of files:'
  id: totrans-788
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为每个源文件定义一个读取上下文。这个上下文管理器将确保输入文件被正确关闭并释放资源。请注意，这是在前面的`with`和`for`语句内缩进，总共有八个空格。在处理大量文件时，这一点尤为重要：
- en: '[PRE144]'
  id: totrans-789
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: 'We''ll use the writer''s `writerows()` method to write all valid rows from
    the `extract_row_iter()` function. This is indented inside both `with` statements,
    as well as the `for` statement. This is the core of the process:'
  id: totrans-790
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用写入器的`writerows()`方法来从`extract_row_iter()`函数中写入所有有效行。这是在两个`with`语句以及`for`语句内缩进的。这是整个过程的核心：
- en: '[PRE145]'
  id: totrans-791
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: 'We can also write a summary. This is indented inside the outer with and `for`
    statements. It summarizes the processing of the preceding with statement:'
  id: totrans-792
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以编写一个摘要。这是在外部`with`和`for`语句内缩进的。它总结了前面的`with`语句的处理：
- en: '[PRE146]'
  id: totrans-793
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: How it works...
  id: totrans-794
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Python works nicely with multiple context managers. We can easily have deeply-nested
    `with` statements. Each `with` statement can manage a different context object.
  id: totrans-795
  prefs: []
  type: TYPE_NORMAL
  zh: Python与多个上下文管理器很好地配合。我们可以轻松地有深度嵌套的`with`语句。每个`with`语句可以管理不同的上下文对象。
- en: Since open files are context objects, it makes the most sense to wrap every
    open file in a `with` statement to be sure that the file is properly closed and
    all OS resources are released from the file.
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 由于打开的文件是上下文对象，将每个打开的文件包装在`with`语句中是最合理的，以确保文件被正确关闭并且所有操作系统资源都从文件中释放。
- en: We've used `Path` objects to represent the filesystem locations. This gives
    us the ability to easily create output names based on input names, or rename the
    files after they've been processed. For more information on this, see the *Using
    pathlib to work with filenames* recipe.
  id: totrans-797
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`Path`对象来表示文件系统位置。这使我们能够根据输入名称轻松创建输出名称，或在处理后重命名文件。有关更多信息，请参阅*使用pathlib处理文件名*配方。
- en: We've used a generator function to combine two operations. Firstly, there's
    a mapping from source text to individual fields. Secondly, there's a filter that
    excludes source text that doesn't match the expected pattern. In many cases, we
    can use the `map()` and `filter()` functions to make this a little more clear.
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用生成器函数来组合两个操作。首先，有一个从源文本到单独字段的映射。其次，有一个排除不匹配预期模式的源文本的过滤器。在许多情况下，我们可以使用`map()`和`filter()`函数来使这一点更清晰。
- en: When using regular expression matching; however, it's not as easy to separate
    the mapping and filter parts of the operation. The regular expression may not
    match some input lines, which becomes a kind of filtering that's bundled in to
    the mapping. Because of this, a generator function works out very nicely.
  id: totrans-799
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在使用正则表达式匹配时，要分离操作的映射和过滤部分就不那么容易了。正则表达式可能不匹配一些输入行，这就成了一种捆绑到映射中的过滤。因此，生成器函数非常有效。
- en: The `csv` writers have a `writerows()` method. This method accepts an iterator
    as it's parameter value. This makes it easy to provide a generator function to
    the writer. The writer will consume objects as they're produced by the generator.
    Very large files can be handled this way because the entire file isn't read into
    memory, just enough of the file is read to create a complete line of data.
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: '`csv`写入器有一个`writerows()`方法。这个方法接受一个迭代器作为参数值。这样很容易向写入器提供一个生成器函数。写入器将消耗生成器产生的对象。这种方式可以处理非常大的文件，因为不会将整个文件读入内存，只需读取足够的文件来创建完整的数据行。'
- en: There's more...
  id: totrans-801
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: It's often essential to have a summary count of the number of lines of log file
    read from each source, the number of lines discarded because they didn't match,
    and the number of lines finally written to the summary file.
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 通常需要对从每个源文件读取的日志文件行数、因为它们不匹配而被丢弃的行数以及最终写入摘要文件的行数进行摘要计数。
- en: This is challenging when using generators. The generator produces lots of rows
    of data. How can it also produce a summary?
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用生成器时，这是具有挑战性的。生成器产生大量数据行。它如何产生一个摘要呢？
- en: The answer is that we can provide a mutable object as a parameter to the generator.
    The ideal kind of mutable object is an instance of `collections.Counter` . We
    can use this to count events including a valid record, an invalid record, or even
    occurrences of specific data values. The mutable object can be shared by the generator
    and the overall main program so that the main program can print the count information
    to a log.
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是我们可以向生成器提供一个可变对象作为参数。理想的可变对象是`collections.Counter`的一个实例。我们可以用它来计算包括有效记录、无效记录，甚至特定数据值的出现次数。可变对象可以被生成器和整个主程序共享，以便主程序可以将计数信息打印到日志中。
- en: 'Here''s the map-filter function that converts text to useful dictionary objects.
    We''ve written a second version called `counting_extract_row_iter()` to emphasize
    the additional feature:'
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将文本转换为有用的字典对象的映射-过滤函数。我们编写了一个名为`counting_extract_row_iter()`的第二个版本，以强调额外的特性：
- en: '[PRE147]'
  id: totrans-806
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: We've provided an additional argument, `counts` . When we find rows that don't
    match the regular expression, we can increment the `non-match` key in the `Counter`
    . When we find rows that do match properly, we can increment the `valid` key in
    the `Counter` . This provides a summary that shows how may rows were processed
    from the given file.
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个额外的参数`counts`。当我们发现不匹配正则表达式的行时，我们可以增加`Counter`中的`non-match`键。当我们发现正确匹配的行时，我们可以增加`Counter`中的`valid`键。这提供了一个摘要，显示了从给定文件中处理了多少行。
- en: 'The overall processing script looks like the following:'
  id: totrans-808
  prefs: []
  type: TYPE_NORMAL
  zh: 整体处理脚本如下所示：
- en: '[PRE148]'
  id: totrans-809
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'We''ve made three small changes:'
  id: totrans-810
  prefs: []
  type: TYPE_NORMAL
  zh: 我们做了三个小改动：
- en: Create an empty `Counter` object just before processing a source log file.
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理源日志文件之前，创建一个空的`Counter`对象。
- en: Provide the `Counter` object to the `counting_extract_row_iter()` function.
    The function will update the counter as it processes rows.
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`Counter`对象提供给`counting_extract_row_iter()`函数。该函数在处理行时会更新计数器。
- en: Print the value of the `counter` after processing the files. The unadorned output
    isn't very pretty, but it tells an important story.
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理文件后打印`counter`的值。这种未加修饰的输出并不太美观，但它讲述了一个重要的故事。
- en: 'We might see output like the following:'
  id: totrans-814
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会看到以下输出：
- en: '[PRE149]'
  id: totrans-815
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: This kind of output shows us how large the `summary_log.csv` will be, and it
    also shows that something was wrong in the `20160613.log` file.
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: 这种输出方式向我们展示了`summary_log.csv`的大小，也显示了`20160613.log`文件中出现了问题。
- en: We can easily extend this to combine all of the individual source file counters
    to produce a single large output at the end of the process. We can combine multiple
    `Counter` objects using the `+` operator to create a grand sum of all of the data.
    Details are left as an exercise for the reader.
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地扩展这一点，将所有单独的源文件计数器组合起来，在处理结束时产生一个单一的大输出。我们可以使用`+`运算符来组合多个`Counter`对象，以创建所有数据的总和。具体细节留给读者作为练习。
- en: See also
  id: totrans-818
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: For the basics of a context, see the *Reading and writing files with context
    managers* recipe
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关上下文的基础知识，请参阅*使用上下文管理器读写文件*配方
