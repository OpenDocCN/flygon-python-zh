- en: Chapter 8. Client and Server Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。客户端和服务器应用程序
- en: 'In the previous chapter, we looked at exchanging data between devices by using
    the sockets interface. In this chapter, we''re going to use sockets to build network
    applications. Sockets follow one of the main models of computer networking, that
    is, the **client/server** model. We''ll look at this with a focus on structuring
    server applications. We''ll cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们通过使用套接字接口来查看设备之间的数据交换。在本章中，我们将使用套接字来构建网络应用程序。套接字遵循计算机网络的主要模型之一，即**客户端/服务器**模型。我们将重点关注构建服务器应用程序。我们将涵盖以下主题：
- en: Designing a simple protocol
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个简单的协议
- en: Building an echo server and client
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建回声服务器和客户端
- en: Building a chat server and client
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建聊天服务器和客户端
- en: Multithreaded and event-driven server architectures
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程和事件驱动的服务器架构
- en: The `eventlet` and `asyncio` libraries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eventlet`和`asyncio`库'
- en: The examples in this chapter are best run on Linux or a Unix operating system.
    The Windows sockets implementation has some idiosyncrasies, and these can create
    some error conditions, which we will not be covering here. Note that Windows does
    not support the `poll` interface that we'll use in one example. If you do use
    Windows, then you'll probably need to use *ctrl* + *break* to kill these processes
    in the console, rather than using *ctrl* - *c* because Python in a Windows command
    prompt doesn't respond to *ctrl* – *c* when it's blocking on a socket send or
    receive, which will be quite often in this chapter! (and if, like me, you're unfortunate
    enough to try testing these on a Windows laptop without a *break* key, then be
    prepared to get very familiar with the Windows Task Manager's **End task** button).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例最好在Linux或Unix操作系统上运行。Windows套接字实现有一些特殊之处，这可能会导致一些错误条件，我们在这里不会涉及。请注意，Windows不支持我们将在一个示例中使用的`poll`接口。如果您使用Windows，那么您可能需要使用*ctrl*
    + *break*来在控制台中终止这些进程，而不是使用*ctrl* - *c*，因为在Windows命令提示符中，当Python在套接字发送或接收时阻塞时，它不会响应*ctrl*
    - *c*，而在本章中这种情况会经常发生！（如果像我一样，不幸地尝试在没有*break*键的Windows笔记本上测试这些内容，那么请准备好熟悉Windows任务管理器的**结束任务**按钮）。
- en: Client and server
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户端和服务器
- en: The basic setup in the client/server model is one device, the server that runs
    a service and patiently waits for clients to connect and make requests to the
    service. A 24-hour grocery shop may be a real world analogy. The shop waits for
    customers to come in and when they do, they request certain products, purchase
    them and leave. The shop might advertise itself so people know where to find it,
    but the actual transactions happen while the customers are visiting the shop.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端/服务器模型中的基本设置是一个设备，即运行服务并耐心等待客户端连接并请求服务的服务器。一个24小时的杂货店可能是一个现实世界的类比。商店等待顾客进来，当他们进来时，他们请求某些产品，购买它们然后离开。商店可能会进行广告以便人们知道在哪里找到它，但实际的交易发生在顾客访问商店时。
- en: A typical computing example is a web server. The server listens on a TCP port
    for clients that need its web pages. When a client, for example a web browser,
    requires a web page that the server hosts, it connects to the server and then
    makes a request for that page. The server replies with the content of the page
    and then the client disconnects. The server advertises itself by having a hostname,
    which the clients can use to discover the IP address so that they can connect
    to it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的计算示例是一个Web服务器。服务器在TCP端口上监听需要其网页的客户端。例如，当客户端，例如Web浏览器，需要服务器托管的网页时，它连接到服务器然后请求该页面。服务器回复页面的内容，然后客户端断开连接。服务器通过具有主机名来进行广告，客户端可以使用该主机名来发现IP地址，以便连接到它。
- en: In both of these situations, it is the client that initiates any interaction
    – the server is purely responsive to that interaction. So, the needs of the programs
    that run on the client and server are quite different.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，都是客户端发起任何交互-服务器纯粹是对该交互的响应。因此，运行在客户端和服务器上的程序的需求是非常不同的。
- en: Client programs are typically oriented towards the interface between the user
    and the service. They retrieve and display the service, and allow the user to
    interact with it. Server programs are written to stay running for indefinite periods
    of time, to be stable, to efficiently deliver the service to the clients that
    are requesting it, and to potentially handle a large number of simultaneous connections
    with a minimal impact on the experience of any one client.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端程序通常面向用户和服务之间的接口。它们检索和显示服务，并允许用户与之交互。服务器程序被编写为长时间运行，保持稳定，高效地向请求服务的客户端提供服务，并可能处理大量同时连接而对任何一个客户端的体验影响最小化。
- en: In this chapter, we will look at this model by writing a simple echo server
    and client, and then upgrading it to a chat server, which can handle a session
    with multiple clients. The `socket` module in Python perfectly suits this task.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过编写一个简单的回声服务器和客户端来查看这个模型，然后将其升级为一个可以处理多个客户端会话的聊天服务器。Python中的`socket`模块非常适合这项任务。
- en: An echo protocol
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回声协议
- en: Before we write our first client and server programs, we need to decide how
    they are going to interact with each other, that is we need to design a protocol
    for their communication.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写我们的第一个客户端和服务器程序之前，我们需要决定它们将如何相互交互，也就是说，我们需要为它们的通信设计一个协议。
- en: 'Our echo server should listen until a client connects and sends a bytes string,
    then we want it to echo that string back to the client. We only need a few basic
    rules for doing this. These rules are as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的回声服务器应该保持监听，直到客户端连接并发送一个字节字符串，然后我们希望它将该字符串回显给客户端。我们只需要一些基本规则来做到这一点。这些规则如下：
- en: Communication will take place over TCP.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通信将通过TCP进行。
- en: The client will initiate an echo session by creating a socket connection to
    the server.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端将通过创建套接字连接到服务器来启动回声会话。
- en: The server will accept the connection and listen for the client to send a bytes
    string.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器将接受连接并监听客户端发送的字节字符串。
- en: The client will send a bytes string to the server.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端将向服务器发送一个字节字符串。
- en: Once it sends the bytes string, the client will listen for a reply from the
    server
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦它发送了字节字符串，客户端将等待服务器的回复
- en: When it receives the bytes string from the client, the server will send the
    bytes string back to the client.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当服务器从客户端接收到字节字符串时，它将把字节字符串发送回客户端。
- en: When the client has received the bytes string from the server, it will close
    its socket to end the session.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当客户端从服务器接收了字节字符串后，它将关闭其套接字以结束会话。
- en: These steps are straightforward enough. The missing element here is how the
    server and the client will know when a complete message has been sent. Remember
    that an application sees a TCP connection as an endless stream of bytes, so we
    need to decide what in that byte stream will signal the end of a message.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤足够简单。这里缺少的元素是服务器和客户端如何知道何时发送了完整的消息。请记住，应用程序将TCP连接视为无尽的字节流，因此我们需要决定字节流中的什么将表示消息的结束。
- en: Framing
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 框架
- en: 'This problem is called **framing**, and there are several approaches that we
    can take to handle it. The main ones are described here:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题被称为**分帧**，我们可以采取几种方法来处理它。主要方法如下：
- en: Make it a protocol rule that only one message will be sent per connection, and
    once a message has been sent, the sender will immediately close the socket.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其作为协议规则，每次连接只发送一个消息，一旦发送了消息，发送方将立即关闭套接字。
- en: Use fixed length messages. The receiver will read the number of bytes and know
    that they have the whole message.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用固定长度的消息。接收方将读取字节数，并知道它们有整个消息。
- en: Prefix the message with the length of the message. The receiver will read the
    length of the message from the stream first, then it will read the indicated number
    of bytes to get the rest of the message.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在消息前加上消息的长度。接收方将首先从流中读取消息的长度，然后读取指示的字节数以获取消息的其余部分。
- en: Use special character delimiters for indicating the end of a message. The receiver
    will scan the incoming stream for a delimiter, and the message comprises everything
    up to the delimiter.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用特殊字符定界符指示消息的结束。接收方将扫描传入的流以查找定界符，并且消息包括定界符之前的所有内容。
- en: Option 1 is a good choice for very simple protocols. It's easy to implement
    and it doesn't require any special handling of the received stream. However, it
    requires the setting up and tearing down of a socket for every message, and this
    can impact performance when a server is handling many messages at once.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 选项1是非常简单协议的一个很好选择。它易于实现，不需要对接收到的流进行任何特殊处理。但是，它需要为每条消息建立和拆除套接字，当服务器同时处理多条消息时，这可能会影响性能。
- en: Option 2 is again simple to implement, but it only makes efficient use of the
    network when our data comes in neat, fixed-length blocks. For example in a chat
    server the message lengths are variable, so we will have to use a special character,
    such as the null byte, to pad messages to the block size. This only works where
    we know for sure that the padding character will never appear in the actual message
    data. There is also the additional issue of how to handle messages longer than
    the block length.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 选项2再次实现简单，但只有在我们的数据以整齐的固定长度块出现时才能有效利用网络。例如，在聊天服务器中，消息长度是可变的，因此我们将不得不使用特殊字符，例如空字节，来填充消息到块大小。这仅适用于我们确切知道填充字符永远不会出现在实际消息数据中的情况。还有一个额外的问题，即如何处理长于块长度的消息。
- en: Option 3 is usually considered as one of the best approaches. Although it can
    be more complex to code than the other options, the implementations are still
    reasonably straightforward, and it makes efficient use of bandwidth. The overhead
    imposed by including the length of each message is usually minimal as compared
    to the message length. It also avoids the need for any additional processing of
    the received data, which may be needed by certain implementations of option 4.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 选项3通常被认为是最佳方法之一。虽然编码可能比其他选项更复杂，但实现仍然相当简单，并且它有效地利用了带宽。包括每条消息的长度所带来的开销通常与消息长度相比是微不足道的。它还避免了对接收到的数据进行任何额外处理的需要，这可能是选项4的某些实现所需要的。
- en: Option 4 is the most bandwidth-efficient option, and is a good choice when we
    know that only a limited set of characters, such as the ASCII alphanumeric characters,
    will be used in messages. If this is the case, then we can choose a delimiter
    character, such as the null byte, which will never appear in the message data,
    and then the received data can be easily broken into messages as this character
    is encountered. Implementations are usually simpler than option 3\. Although it
    is possible to employ this method for arbitrary data, that is, where the delimiter
    could also appear as a valid character in a message, this requires the use of
    character escaping, which needs an additional round of processing of the data.
    Hence in these situations, it's usually simpler to use length-prefixing.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 选项4是最节省带宽的选项，当我们知道消息中只会使用有限的字符集，例如ASCII字母数字字符时，这是一个很好的选择。如果是这种情况，那么我们可以选择一个定界字符，例如空字节，它永远不会出现在消息数据中，然后当遇到这个字符时，接收到的数据可以很容易地被分成消息。实现通常比选项3简单。虽然可以将此方法用于任意数据，即定界符也可能出现为消息中的有效字符，但这需要使用字符转义，这需要对数据进行额外的处理。因此，在这些情况下，通常更简单的是使用长度前缀。
- en: For our echo and chat applications, we'll be using the UTF-8 character set to
    send messages. The null byte isn't used in any character in UTF-8 except for the
    null byte itself, so it makes a good delimiter. Thus, we'll be using method 4
    with the null byte as the delimiter to frame our messages.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的回显和聊天应用程序，我们将使用UTF-8字符集发送消息。在UTF-8中，除了空字节本身，空字节在任何字符中都不使用，因此它是一个很好的分隔符。因此，我们将使用空字节作为定界符来对我们的消息进行分帧。
- en: 'So, our rule number 8 will become:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的规则8将变为：
- en: '*Messages will be encoded in the UTF-8 character set for transmission, and
    they will be terminated by the null byte.*'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*消息将使用UTF-8字符集进行编码传输，并以空字节终止。*'
- en: Now, let's write our echo programs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写我们的回显程序。
- en: A simple echo server
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的回显服务器
- en: 'As we work through this chapter, we''ll find ourselves reusing several pieces
    of code, so to save ourselves from repetition, we''ll set up a module with useful
    functions that we can reuse as we go along. Create a file called `tincanchat.py`
    and save the following code in it:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章中工作时，我们会发现自己在重复使用几段代码，因此为了避免重复，我们将设置一个具有有用函数的模块，我们可以在以后重复使用。创建一个名为`tincanchat.py`的文件，并将以下代码保存在其中：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: First we define a default interface and a port number to listen on. The empty
    `''` interface, specified in the `HOST` variable, tells `socket.bind()` to listen
    on all available interfaces. If you want to restrict access to just your machine,
    then change the value of the `HOST` variable at the beginning of the code to `127.0.0.1`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义一个默认接口和要侦听的端口号。在`HOST`变量中指定的空的`''`接口告诉`socket.bind（）`侦听所有可用的接口。如果要将访问限制为仅限于您的计算机，则将代码开头的`HOST`变量的值更改为`127.0.0.1`。
- en: We'll be using `create_listen_socket()` to set up our server listening connections.
    This code is the same for several of our server programs, so it makes sense to
    reuse it.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`create_listen_socket（）`来设置我们的服务器监听连接。这段代码对于我们的几个服务器程序是相同的，因此重复使用它是有意义的。
- en: The `recv_msg()` function will be used by our echo server and client for receiving
    messages from a socket. In our echo protocol, there isn't anything that our programs
    may need to do while they're waiting to receive a message, so this function just
    calls `socket.recv()` in a loop until it has received the whole message. As per
    our framing rule, it will check the accumulated data on each iteration to see
    if it has received a null byte, and if so, then it will return the received data,
    stripping off the null byte and decoding it from UTF-8.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`recv_msg（）`函数将被我们的回显服务器和客户端用于从套接字接收消息。在我们的回显协议中，我们的程序在等待接收消息时不需要做任何事情，因此此函数只是在循环中调用`socket.recv（）`，直到接收到整个消息为止。根据我们的分帧规则，它将在每次迭代中检查累积的数据，以查看是否收到了空字节，如果是，则将返回接收到的数据，去掉空字节并解码为UTF-8。'
- en: The `send_msg()` and `prep_msg()` functions work together for framing and sending
    a message. We've separated the null byte termination and the UTF-8 encoding into
    `prep_msg()` because we will use them in isolation later on.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`send_msg（）`和`prep_msg（）`函数一起用于对消息进行分帧和发送。我们将空字节终止和UTF-8编码分离到`prep_msg（）`中，因为我们将在以后单独使用它们。'
- en: Handling the received data
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理接收到的数据
- en: Note that we're drawing ourselves a careful line with these send and receive
    functions as regards string encoding. Python 3 strings are Unicode, while the
    data that we receive over the network is bytes. The last thing that we want to
    be doing is handling a mixture of these in the rest of our program code, so we're
    going to carefully encode and decode the data at the boundary of our program,
    where the data enters and leaves the network. This will ensure that any functions
    in the rest of our code can assume that they'll be working with Python strings,
    which will later on make things much easier for us.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，就字符串编码而言，我们在发送和接收函数之间划定了一条谨慎的界限。Python 3字符串是Unicode，而我们通过网络接收的数据是字节。我们最不想做的最后一件事就是在程序的其余部分处理这些数据的混合，因此我们将在程序的边界处仔细编码和解码数据，数据进入和离开网络的地方。这将确保我们代码的其余部分可以假定它们将使用Python字符串，这将在以后为我们带来很多便利。
- en: Of course, not all the data that we may want to send or receive over a network
    will be text. For example, images, compressed files, and music, can't be decoded
    to a Unicode string, so a different kind of handling is needed. Usually this will
    involve loading the data into a class, such as a **Python Image Library** (**PIL**)
    image for example, if we are going to manipulate the object in some way.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，并非我们可能想要通过网络发送或接收的所有数据都是文本。例如，图像、压缩文件和音乐无法解码为Unicode字符串，因此需要一种不同的处理方式。通常，这将涉及将数据加载到类中，例如**Python
    Image Library**（**PIL**）图像，如果我们要以某种方式操作对象。
- en: 'There are basic checks that could be done here on the received data, before
    performing full processing on it, to quickly flag any problems with the data.
    Some examples of such checks are as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在对接收到的数据进行完整处理之前，可以在此处对接收到的数据进行基本检查，以快速标记数据中的任何问题。此类检查的一些示例如下：
- en: Checking the length of the received data
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查接收到的数据的长度
- en: Checking the first few bytes of a file for a magic number to confirm a file
    type
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查文件的前几个字节是否有魔术数字来确认文件类型
- en: Checking values of higher level protocol headers, such as the `Host` header
    in an `HTTP` request
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查更高级别协议头的值，例如`HTTP`请求中的`Host`头
- en: This kind of checking will allow our application to fail fast if there is an
    obvious problem.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种检查将允许我们的应用程序在出现明显问题时快速失败。
- en: The server itself
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务器本身
- en: 'Now, let''s write our echo server. Open a new file called `1.1-echo-server-uni.py`
    and save the following code in it:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写我们的回显服务器。打开一个名为`1.1-echo-server-uni.py`的新文件，并将以下代码保存在其中：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is about as simple as a server can get! First, we set up our listening
    socket with the `create_listen_socket()` call. Second, we enter our main loop,
    where we listen forever for incoming connections from clients, blocking on `listen_sock.accept()`.
    When a client connection comes in, we invoke the `handle_client()` function, which
    handles the client as per our protocol. We've created a separate function for
    this code, partly to keep the main loop tidy, and partly because we'll want to
    reuse this set of operations in later programs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个服务器可以变得多么简单的例子！首先，我们使用`create_listen_socket（）`调用设置我们的监听套接字。其次，我们进入我们的主循环，在那里我们永远监听来自客户端的传入连接，阻塞在`listen_sock.accept（）`上。当客户端连接进来时，我们调用`handle_client（）`函数，根据我们的协议处理客户端。我们为此代码创建了一个单独的函数，部分原因是为了保持主循环的整洁，部分原因是因为我们将来会想要在后续程序中重用这组操作。
- en: That's our server, now we just need to make a client to talk to it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们的服务器，现在我们只需要创建一个客户端来与它通信。
- en: A simple echo client
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的回显客户端
- en: 'Create a file called `1.2-echo_client-uni.py` and save the following code in
    it:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`1.2-echo_client-uni.py`的文件，并将以下代码保存在其中：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If we're running our server on a different machine from the one on which we
    are running the client, then we can supply the IP address or the hostname of the
    server as a command line argument to the client program. If we don't, then it
    will default to trying to connect to the localhost.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在与运行客户端的计算机不同的计算机上运行服务器，则可以将服务器的IP地址或主机名作为命令行参数提供给客户端程序。如果不这样做，它将默认尝试连接到本地主机。
- en: The third and forth lines of the code check the command line arguments for a
    server address. Once we've determined which server to connect to, we enter our
    main loop, which loops forever until we kill the client by entering `q` as a message.
    Within the main loop, we first create a connection to the server. Second, we prompt
    the user to enter the message to send and then we send the message using the `tincanchat.send_msg()`
    function. We then wait for the server's reply. Once we get the reply, we print
    it and then we close the connection as per our protocol.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的第三和第四行检查服务器地址的命令行参数。一旦确定要连接的服务器，我们进入我们的主循环，该循环将一直循环，直到我们通过输入`q`来终止客户端。在主循环中，我们首先创建与服务器的连接。其次，我们提示用户输入要发送的消息，然后使用`tincanchat.send_msg()`函数发送消息。然后我们等待服务器的回复。一旦收到回复，我们打印它，然后根据我们的协议关闭连接。
- en: 'Give our client and server a try. Run the server in a terminal by using the
    following command:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试运行我们的客户端和服务器。通过使用以下命令在终端中运行服务器：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In another terminal, run the client and note that you will need to specify
    the server if you need to connect to another computer, as shown here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个终端中，运行客户端并注意，如果您需要连接到另一台计算机，您将需要指定服务器，如下所示：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Running the terminals side by side is a good idea, because you can simultaneously
    see how the programs behave.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 并排运行终端是一个好主意，因为您可以同时看到程序的行为。
- en: Type a few messages into the client and see how the server picks them up and
    sends them back. Disconnecting with the client should also prompt a notification
    on the server.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在客户端中输入一些消息，看看服务器如何接收并将它们发送回来。与客户端断开连接也应该在服务器上提示通知。
- en: Concurrent I/O
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发I/O
- en: If you're adventurous, then you may have tried connecting to our server using
    more than one client at once. If you tried sending messages from both of them,
    then you'd have seen that it does not work as we might have hoped. If you haven't
    tried this, then give it a go.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有冒险精神，那么您可能已经尝试过同时使用多个客户端连接到我们的服务器。如果您尝试从它们中的两个发送消息，那么您会发现它并不像我们希望的那样工作。如果您还没有尝试过，请试一试。
- en: 'A working echo session on the client should look like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端上的工作回显会话应该是这样的：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'However, when trying to send a message by using a second connected client,
    we''ll see something like this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当尝试使用第二个连接的客户端发送消息时，我们会看到类似这样的情况：
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The client will hang when the message is sent, and it won't get an echo reply.
    You may also notice that if we send a message by using the first connected client,
    then the second client will get its response. So, what's going on here?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当发送消息时，客户端将挂起，并且不会收到回显回复。您还可能注意到，如果我们使用第一个连接的客户端发送消息，那么第二个客户端将收到其响应。那么，这里发生了什么？
- en: The problem is that the server can only listen for the messages from one client
    at a time. As soon as the first client connects, the server blocks at the `socket.recv()`
    call in `tincanchat.recv_msg()`, waiting for the first client to send a message.
    The server isn't able to receive messages from other clients while this is happening
    and so, when another client sends a message, that client blocks too, waiting for
    the server to send a reply.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于服务器一次只能监听来自一个客户端的消息。一旦第一个客户端连接，服务器就会在`tincanchat.recv_msg()`中的`socket.recv()`调用处阻塞，等待第一个客户端发送消息。在此期间，服务器无法接收其他客户端的消息，因此当另一个客户端发送消息时，该客户端也会阻塞，等待服务器发送回复。
- en: This is a slightly contrived example. The problem in this case could easily
    be fixed in the client end by asking the user for an input before establishing
    a connection to the server. However in our full chat service, the client will
    need to be able to listen for messages from the server while simultaneously waiting
    for user input. This is not possible in our present procedural setup.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个稍微牵强的例子。在这种情况下，可以通过在建立与服务器的连接之前要求用户输入来轻松解决客户端端的问题。但是在我们完整的聊天服务中，客户端需要能够同时监听来自服务器的消息，同时等待用户输入。这在我们目前的程序设置中是不可能的。
- en: There are two solutions to this problem. We can either use more than one thread
    or process, or use **non-blocking** sockets along with an **event-driven** architecture.
    We're going to look at both of these approaches, starting with **multithreading**.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题有两种方法。我们可以使用多个线程或进程，或者使用**非阻塞**套接字以及**事件驱动**架构。我们将研究这两种方法，首先从**多线程**开始。
- en: Multithreading and multiprocessing
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程和多进程
- en: Python has APIs that allow us to write both multithreading and multiprocessing
    applications. The principle behind multithreading and multiprocessing is simply
    to take copies of our code and run them in additional threads or processes. The
    operating system automatically schedules the threads and processes across available
    CPU cores to provide fair processing time allocation to all the threads and processes.
    This effectively allows a program to simultaneously run multiple operations. In
    addition, when a thread or process blocks, for example, when waiting for IO, the
    thread or process can be de-prioritized by the OS, and the CPU cores can be allocated
    to other threads or processes that have actual computation to do.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Python具有允许我们编写多线程和多进程应用程序的API。多线程和多进程背后的原则很简单，即复制我们的代码并在额外的线程或进程中运行它们。操作系统会自动调度可用CPU核心上的线程和进程，以提供公平的处理时间分配给所有线程和进程。这有效地允许程序同时运行多个操作。此外，当线程或进程阻塞时，例如等待IO时，操作系统可以将线程或进程降低优先级，并将CPU核心分配给其他有实际计算任务的线程或进程。
- en: 'Here is an overview of how threads and processes relate to each other:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是线程和进程之间关系的概述：
- en: '![Multithreading and multiprocessing](graphics/6008OS_08_01.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![多线程和多进程](graphics/6008OS_08_01.jpg)'
- en: Threads exist within processes. A process can contain multiple threads but it
    always contains at least one thread, sometimes called the **main thread**. Threads
    within the same process share memory, so data transfer between threads is just
    a case of referencing the shared objects. Processes do not share memory, so other
    interfaces, such as files, sockets, or specially allocated areas of shared memory,
    must be used for transferring data between processes.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 线程存在于进程内。 一个进程可以包含多个线程，但它始终至少包含一个线程，有时称为**主线程**。 同一进程中的线程共享内存，因此线程之间的数据传输只是引用共享对象的情况。
    进程不共享内存，因此必须使用其他接口（如文件，套接字或专门分配的共享内存区域）来在进程之间传输数据。
- en: When threads have operations to execute, they ask the operating system thread
    scheduler to allocate them some time on a CPU, and the scheduler allocates the
    waiting threads to CPU cores based on various parameters, which vary from OS to
    OS. Threads in the same process may run on separate CPU cores at the same time.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当线程有操作要执行时，它们会请求操作系统线程调度程序为它们分配一些CPU时间，调度程序会根据各种参数（从OS到OS不等）将等待的线程分配给CPU核心。
    同一进程中的线程可以同时在不同的CPU核心上运行。
- en: Although two processes have been displayed in the preceding diagram, multiprocessing
    is not going on here, since the processes belong to different applications. The
    second process is displayed to illustrate a key difference between Python threading
    and threading in most other programs. This difference is the presence of the GIL.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在前面的图中显示了两个进程，但这里并没有进行多进程处理，因为这些进程属于不同的应用程序。 显示第二个进程是为了说明Python线程和大多数其他程序中线程之间的一个关键区别。
    这个区别就是GIL的存在。
- en: Threading and the GIL
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线程和GIL
- en: The CPython interpreter (the standard version of Python available for download
    from [www.python.org](http://www.python.org)) contains something called the **Global
    Interpreter Lock** (**GIL**). The GIL exists to ensure that only a single thread
    in a Python process can run at a time, even if multiple CPU cores are present.
    The reason for having the GIL is that it makes the underlying C code of the Python
    interpreter much easier to write and maintain. The drawback of this is that Python
    programs using multithreading cannot take advantage of multiple cores for parallel
    computation.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: CPython解释器（可从[www.python.org](http://www.python.org)下载的Python标准版本）包含一个称为**全局解释器锁**（**GIL**）的东西。
    GIL的存在是为了确保在Python进程中只能同时运行一个线程，即使存在多个CPU核心。 有GIL的原因是它使Python解释器的底层C代码更容易编写和维护。
    这样做的缺点是，使用多线程的Python程序无法利用多个核心进行并行计算。
- en: 'This is a cause of much contention; however, for us this is not so much of
    a problem. Even with the GIL present, threads that are blocking on I/O are still
    de-prioritized by the OS and put into the background, so threads that do have
    computational work to do can run instead. The following figure is a simplified
    illustration of this:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个引起很多争议的原因； 但是，对我们来说，这并不是一个大问题。 即使有GIL存在，仍然在I/O阻塞的线程被OS降低优先级并置于后台，因此有计算工作要做的线程可以运行。
    以下图是这一点的简化说明：
- en: '![Threading and the GIL](graphics/6008OS_08_02.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![线程和全局解释器锁](graphics/6008OS_08_02.jpg)'
- en: The **Waiting for GIL** state is where a thread has sent or received some data
    and so is ready to come out of the blocking state, but another thread has the
    GIL, so the ready thread is forced to wait. In many network applications, including
    our echo and chat servers, the time spent waiting on I/O is much higher than the
    time spent processing data. As long as we don't have a very large number of connections
    (a situation we'll discuss later on when we come to event driven architectures),
    thread contention caused by the GIL is relatively low, and hence threading is
    still a suitable architecture for these network server applications.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**等待GIL**状态是指线程已发送或接收了一些数据，因此准备退出阻塞状态，但另一个线程拥有GIL，因此准备好的线程被迫等待。 在许多网络应用程序中，包括我们的回显和聊天服务器，等待I/O的时间远远高于处理数据的时间。
    只要我们没有非常多的连接（这是我们在后面讨论事件驱动架构时会讨论的情况），由GIL引起的线程争用相对较低，因此线程仍然是这些网络服务器应用程序的合适架构。'
- en: With this in mind, we're going to use multithreading rather than multiprocessing
    in our echo server. The shared data model will simplify the code that we'll need
    for allowing our chat clients to exchange messages with each other, and because
    we're I/O bound, we don't need processes for parallel computation. Another reason
    for not using processes in this case is that processes are more "heavyweight"
    in terms of the OS resources, so creating a new process takes longer than creating
    a new thread. Processes also use more memory.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，我们将在我们的回显服务器中使用多线程而不是多进程。 共享数据模型将简化我们需要允许聊天客户端彼此交换消息的代码，并且因为我们是I/O绑定的，所以我们不需要进程进行并行计算。
    在这种情况下不使用进程的另一个原因是，进程在OS资源方面更“笨重”，因此创建新进程比创建新线程需要更长的时间。 进程还使用更多内存。
- en: 'One thing to note is that if you need to perform an intensive computation in
    your network server application (maybe you need to compress a large file before
    sending it over the network), then you should investigate methods for running
    this in a separate process. Because of quirks in the implementation of the GIL,
    having even a single computationally intensive thread in a mainly I/O bound process
    when multiple CPU cores are available can severely impact the performance of all
    the I/O bound threads. For more details, go through the David Beazley presentations
    linked to in the following information box:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，如果您需要在网络服务器应用程序中执行密集计算（也许您需要在将大型文件发送到网络之前对其进行压缩），那么您应该调查在单独的进程中运行此操作的方法。
    由于GIL的实现中存在一些怪癖，即使在多个CPU核心可用时，将单个计算密集型线程放在主要是I/O绑定的进程中也会严重影响所有I/O绑定线程的性能。 有关更多详细信息，请查看以下信息框中链接到的David
    Beazley演示文稿：
- en: Note
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Processes and threads are different beasts, and if you're not clear on the distinctions,
    it's worthwhile to read up. A good starting point is the Wikipedia article on
    threads, which can be found at [http://en.wikipedia.org/wiki/Thread_(computing)](http://en.wikipedia.org/wiki/Thread_(computing)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 进程和线程是不同的东物，如果你对这些区别不清楚，值得阅读一下。一个很好的起点是维基百科关于线程的文章，可以在[http://en.wikipedia.org/wiki/Thread_(computing)](http://en.wikipedia.org/wiki/Thread_(computing))找到。
- en: A good overview of the topic is given in *Chapter 4* of Benjamin Erb's thesis,
    which is available at [http://berb.github.io/diploma-thesis/community/](http://berb.github.io/diploma-thesis/community/).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本主题的一个很好的概述在Benjamin Erb的论文*第4章*中给出，可以在[http://berb.github.io/diploma-thesis/community/](http://berb.github.io/diploma-thesis/community/)找到。
- en: Additional information on the GIL, including the reasoning behind keeping it
    in Python can be found in the official Python documentation at [https://wiki.python.org/moin/GlobalInterpreterLock](https://wiki.python.org/moin/GlobalInterpreterLock).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 关于GIL的更多信息，包括保持它在Python中的原因，可以在官方Python文档中找到，网址为[https://wiki.python.org/moin/GlobalInterpreterLock](https://wiki.python.org/moin/GlobalInterpreterLock)。
- en: You can also read more on this topic in Nick Coghlan's Python 3 Q&A, which can
    be found at [http://python-notes.curiousefficiency.org/en/latest/python3/questions_and_answers.html#but-but-surely-fixing-the-gil-is-more-important-than-fixing-unicode](http://python-notes.curiousefficiency.org/en/latest/python3/questions_and_answers.html#but-but-surely-fixing-the-gil-is-more-important-than-fixing-unicode).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在Nick Coghlan的Python 3问答中阅读更多关于这个主题的内容，网址为[http://python-notes.curiousefficiency.org/en/latest/python3/questions_and_answers.html#but-but-surely-fixing-the-gil-is-more-important-than-fixing-unicode](http://python-notes.curiousefficiency.org/en/latest/python3/questions_and_answers.html#but-but-surely-fixing-the-gil-is-more-important-than-fixing-unicode)。
- en: Finally, David Beazley has done some fascinating research on the performance
    of the GIL on multi-core systems. Two presentations of importance are available
    online. They give a good technical background, which is relevant to this chapter.
    These can be found at [http://pyvideo.org/video/353/pycon-2010--understanding-the-python-gil---82](http://pyvideo.org/video/353/pycon-2010--understanding-the-python-gil---82)
    and at [https://www.youtube.com/watch?v=5jbG7UKT1l4](https://www.youtube.com/watch?v=5jbG7UKT1l4).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，David Beazley对多核系统上GIL的性能进行了一些引人入胜的研究。两个重要的演示资料可以在线找到。它们提供了一个与本章相关的很好的技术背景。这些可以在[http://pyvideo.org/video/353/pycon-2010--understanding-the-python-gil---82](http://pyvideo.org/video/353/pycon-2010--understanding-the-python-gil---82)和[https://www.youtube.com/watch?v=5jbG7UKT1l4](https://www.youtube.com/watch?v=5jbG7UKT1l4)找到。
- en: A multithreaded echo server
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程回显服务器
- en: A benefit of the multithreading approach is that the OS handles the thread switches
    for us, which means we can continue to write our program in a procedural style.
    Hence we only need to make small adjustments to our server program to make it
    multithreaded, and thus, capable of handling multiple clients simultaneously.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程方法的一个好处是操作系统为我们处理线程切换，这意味着我们可以继续以过程化的方式编写程序。因此，我们只需要对服务器程序进行小的调整，使其成为多线程，并因此能够同时处理多个客户端。
- en: 'Create a new file called `1.3-echo_server-multi.py` and add the following code
    to it:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`1.3-echo_server-multi.py`的新文件，并将以下代码添加到其中：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can see that we've just imported an extra module and modified our main loop
    to run our `handle_client()` function in separate threads, rather than running
    it in the main thread. For each client that connects, we create a new thread that
    just runs the `handle_client()` function. When the thread blocks on a receive
    or send, the OS checks the other threads to see if they have come out of a blocking
    state, and if any have, then it switches to one of them.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，我们刚刚导入了一个额外的模块，并修改了我们的主循环，以在单独的线程中运行`handle_client()`函数，而不是在主线程中运行它。对于每个连接的客户端，我们创建一个新的线程，只运行`handle_client()`函数。当线程在接收或发送时阻塞时，操作系统会检查其他线程是否已经退出阻塞状态，如果有任何线程退出了阻塞状态，那么它就会切换到其中一个线程。
- en: Notice that we have set the `daemon` argument in the thread constructor call
    to `True`. This will allow the program to exit if we hit *ctrl* - *c* without
    us having to explicitly close all of our threads first.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在线程构造函数调用中设置了`daemon`参数为`True`。这将允许程序在我们按下*ctrl* - *c*时退出，而无需我们显式关闭所有线程。
- en: If you try this echo server with multiple clients, then you'll see that a second
    client that connects and sends a message will immediately get a response.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尝试使用多个客户端进行此回显服务器，则会发现第二个连接并发送消息的客户端将立即收到响应。
- en: Designing a chat server
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计聊天服务器
- en: We've got a working echo server and it can handle multiple clients simultaneously,
    so we're pretty close to having a functional chat client. However, our server
    needs to broadcast the messages it receives to all the connected clients. Sounds
    simple, but there are two problems that we need to overcome to make this happen.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有一个工作的回显服务器，它可以同时处理多个客户端，所以我们离一个功能齐全的聊天客户端很近了。然而，我们的服务器需要将接收到的消息广播给所有连接的客户端。听起来很简单，但我们需要克服两个问题才能实现这一点。
- en: 'First, our protocol needs an overhaul. If we think about what needs to happen
    from a client''s point of view, then we can no longer rely on the simple work
    flow:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们的协议需要进行改进。如果我们考虑从客户端的角度来看需要发生什么，那么我们就不能再依赖简单的工作流程：
- en: client connect > client send > server send > client disconnect.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端连接 > 客户端发送 > 服务器发送 > 客户端断开连接。
- en: Clients can now potentially receive messages at any time, and not just when
    they send a message to the server themselves.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 客户现在可能随时接收消息，而不仅仅是当他们自己向服务器发送消息时。
- en: Second, we need to modify our server to send messages to all of the connected
    clients. As we are using multiple threads to handle our clients, this means that
    we need to set up communication between the threads. With this, we're dipping
    our toe into the world of concurrent programming, and it should be approached
    with care and forethought. While the shared state of threads is useful, it is
    also deceptive in its simplicity. Having multiple threads of control asynchronously
    accessing and changing the same resources is a perfect breeding ground for race
    conditions and subtle deadlock bugs. While a full discussion on concurrent programming
    is well beyond the scope of this text, we'll cover some simple principles, which
    can help preserve your sanity.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们需要修改我们的服务器，以便向所有连接的客户端发送消息。由于我们使用多个线程来处理客户端，这意味着我们需要在线程之间建立通信。通过这样做，我们正在涉足并发编程的世界，这需要谨慎和深思熟虑。虽然线程的共享状态很有用，但在其简单性中也是具有欺骗性的。有多个控制线程异步访问和更改相同资源是竞争条件和微妙死锁错误的理想滋生地。虽然关于并发编程的全面讨论远远超出了本文的范围，但我们将介绍一些简单的原则，这些原则可以帮助保持您的理智。
- en: A chat protocol
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个聊天协议
- en: The main purpose of our protocol update will be to specify that clients must
    be able to accept all messages that are sent to them, whenever they are sent.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们协议更新的主要目的是规定客户端必须能够接受发送给它们的所有消息，无论何时发送。
- en: In theory, one solution for this would be for our client itself to set up a
    listening socket, so that the server can connect to it whenever it has a new message
    to deliver. In the real world, this solution will rarely be applicable. Clients
    are almost always protected by some kind of firewall, which prevents any new inbound
    connections from connecting to the client. In order for our server to make a connection
    to a port on our client, we would need to ensure that any intervening firewalls
    are configured to allow our server to connect. This requirement would make our
    software much less appealing to most users since there are already chat solutions
    which don't require this.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，一个解决方案是让我们的客户端自己建立一个监听套接字，这样服务器在有新消息要传递时就可以连接到它。在现实世界中，这个解决方案很少适用。客户端几乎总是受到某种防火墙的保护，防止任何新的入站连接连接到客户端。为了让我们的服务器连接到客户端的端口，我们需要确保任何中间的防火墙都配置为允许我们的服务器连接。这个要求会让我们的软件对大多数用户不那么吸引，因为已经有一些不需要这样做的聊天解决方案了。
- en: If we can't assume that the server can connect to the client, then we need to
    meet our requirement by only using the client-initiated connection to the server.
    There are two ways in which we can do this. First, we can have our clients run
    in a disconnected state by default, then have them periodically connect to the
    server, download any waiting messages, and then disconnect again. Alternatively,
    we can have our clients connect to the server and then leave the connection open.
    They can then continuously listen on the connection and handle new messages sent
    by the server in one thread, while accepting user input and sending messages over
    the same connection in another thread.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不能假设服务器能够连接到客户端，那么我们需要通过仅使用客户端发起的连接到服务器来满足我们的要求。我们可以通过两种方式来做到这一点。首先，我们可以让我们的客户端默认运行在断开状态，然后定期连接到服务器，下载任何等待的消息，然后再次断开连接。或者，我们可以让我们的客户端连接到服务器，然后保持连接打开。然后他们可以持续监听连接，并在一个线程中处理服务器发送的新消息，同时在另一个线程中接受用户输入并通过相同的连接发送消息。
- en: You may recognize these scenarios as the **pull** and **push** options that
    are available in some e-mail clients. They are called pull and push because of
    how the operations appear to the client. The client either pulls data from the
    server, or the server pushes data to the client.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会认出这些情景，它们是一些电子邮件客户端中可用的**拉**和**推**选项。它们被称为拉和推，是因为操作对客户端的外观。客户端要么从服务器拉取数据，要么服务器向客户端推送数据。
- en: There are pros and cons to using either of the two approaches, and the decision
    depends on an application's needs. Pull results in a lower load on the server,
    but higher latency for the client in receiving messages. While this is fine for
    many applications, such as e-mail, in a chat server we usually expect immediate
    updates. While we could poll very frequently, this imposes unneeded load on the
    client, server, and network as the connections are repeatedly set up and torn
    down.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两种方法都有利有弊，决定取决于应用程序的需求。拉取会减少服务器的负载，但会增加客户端接收消息的延迟。虽然这对于许多应用程序来说是可以接受的，比如电子邮件，在聊天服务器中，我们通常希望立即更新。虽然我们可以频繁轮询，但这会给客户端、服务器和网络带来不必要的负载，因为连接会反复建立和拆除。
- en: Push is better suited for a chat server. As the connection remains open continuously
    the amount of network traffic is limited to the initial connection setup, and
    the messages themselves. Also, the client gets new messages from the server almost
    immediately.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 推送更适合聊天服务器。由于连接保持持续打开，网络流量的量仅限于初始连接设置和消息本身。此外，客户端几乎可以立即从服务器获取新消息。
- en: 'So, we''ll use a push approach, and we will now write our chat protocol as
    follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将使用推送方法，现在我们将编写我们的聊天协议如下：
- en: Communication will be conducted over TCP.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通信将通过TCP进行。
- en: The client will initiate a chat session by creating a socket connection to the
    server.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端将通过创建套接字连接到服务器来启动聊天会话。
- en: The server will accept the connection, listen for any messages from the client,
    and accept them.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器将接受连接，监听来自客户端的任何消息，并接受它们。
- en: The client will listen on the connection for any messages from the server, and
    accept them.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端将在连接上监听来自服务器的任何消息，并接受它们。
- en: The server will send any messages from the client to all the other connected
    clients.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器将把来自客户端的任何消息发送给所有其他连接的客户端。
- en: Messages will be encoded in the UTF-8 character set for transmission, and they
    will be terminated by the null byte.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消息将以UTF-8字符集进行编码传输，并以空字节终止。
- en: Handling data on persistent connections
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理持久连接上的数据
- en: A new problem which our persistent connection approach raises is that we can
    no longer assume that our `socket.recv()` call will contain data from only one
    message. In our echo server, because of how we have defined the protocol, we know
    that as soon as we see a null byte, the message that we have received is complete,
    and that the sender won't be sending anything further. That is, everything we
    read in the last `socket.recv()` call is a part of that message.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们持久连接方法引发的一个新问题是，我们不能再假设我们的 `socket.recv()` 调用将只包含来自一个消息的数据。在我们的回显服务器中，由于我们已经定义了协议，我们知道一旦看到空字节，我们收到的消息就是完整的，并且发送者不会再发送任何内容。也就是说，我们在最后一个
    `socket.recv()` 调用中读取的所有内容都是该消息的一部分。
- en: 'In our new setup, we''ll be reusing the same connection to send an indefinite
    number of messages, and these won''t be synchronized with the chunks of data that
    we will pull from each `socket.recv()`. Hence, it''s quite possible that the data
    from one `recv()` call will contain data from multiple messages. For example,
    if we send the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的新设置中，我们将重用同一连接来发送无限数量的消息，这些消息不会与我们从每个 `socket.recv()` 中提取的数据块同步。因此，很可能从一个
    `recv()` 调用中获取的数据将包含多个消息的数据。例如，如果我们发送以下内容：
- en: '[PRE8]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then on the wire they will look like this:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在传输中它们将如下所示：
- en: '[PRE9]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Due to the vagaries of network transmission though, a set of successive `recv()`
    calls may receive them as:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于网络传输的变化，一系列连续的 `recv()` 调用可能会接收到它们：
- en: '[PRE10]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Notice that `recv 1` and `recv 2,` when taken together contain a complete message,
    but they also contain the beginning of the next message. Clearly, we need to update
    our parsing. One option is to read data from the socket one byte at a time, that
    is, use `recv(1)`, and check every byte to see if it''s a null byte. This is a
    dismally inefficient way to use a network socket though. We want to read as much
    data in our call to `recv()` as we can. Instead, when we encounter an incomplete
    message we can cache the extraneous bytes and use them when we next call `recv()`.
    Lets do this, add these functions to the `tincanchat.py` file:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`recv 1` 和 `recv 2` 一起包含一个完整的消息，但它们也包含下一个消息的开头。显然，我们需要更新我们的解析。一种选择是逐字节从套接字中读取数据，也就是使用
    `recv(1)`，并检查每个字节是否为空字节。然而，这是一种非常低效的使用网络套接字的方式。我们希望在调用 `recv()` 时尽可能多地读取数据。相反，当我们遇到不完整的消息时，我们可以缓存多余的字节，并在下次调用
    `recv()` 时使用它们。让我们这样做，将这些函数添加到 `tincanchat.py` 文件中：
- en: '[PRE11]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: From now on, we'll be using `recv_msgs()` wherever we were using `recv_msg()`
    before. So, what are we doing here? Starting with a quick scan through `recv_msgs()`,
    you can see that it's similar to `recv_msg()`. We make repeated calls to `recv()`
    and accumulate the received data as before, but now we will be using `parse_recvd_data()`
    to parse it, with the expectation that it may contain multiple messages. When
    `parse_recvd_data()` finds one or more complete messages in the received data,
    it splits them into a list and returns them, and if there is anything left after
    the last complete message, then it additionally returns this using the `rest`
    variable. The `recv_msgs()` function then decodes the messages from UTF-8, and
    returns them and the `rest` variable.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将在以前使用 `recv_msg()` 的地方使用 `recv_msgs()`。那么，我们在这里做什么呢？通过快速浏览 `recv_msgs()`，您可以看到它与
    `recv_msg()` 类似。我们重复调用 `recv()` 并像以前一样累积接收到的数据，但现在我们将使用 `parse_recvd_data()` 进行解析，期望它可能包含多个消息。当
    `parse_recvd_data()` 在接收到的数据中找到一个或多个完整的消息时，它将将它们拆分成列表并返回它们，如果在最后一个完整消息之后还有任何剩余内容，则使用
    `rest` 变量另外返回这些内容。然后，`recv_msgs()` 函数解码来自 UTF-8 的消息，并返回它们和 `rest` 变量。
- en: The `rest` value is important because we will feed it back to `recv_msgs()`
    next time we call it, and it will be prefixed to the data from the `recv()` calls.
    In this way, the leftover data from the last `recv_msgs()` call won't be lost.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`rest` 值很重要，因为我们将在下次调用 `recv_msgs()` 时将其返回，并且它将被添加到 `recv()` 调用的数据前缀。这样，上次
    `recv_msgs()` 调用的剩余数据就不会丢失。'
- en: 'So, in our preceding example, parsing the messages would take place as shown
    here:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们之前的例子中，解析消息将按照以下方式进行：
- en: '| `recv_msgs call` | `data` argument | `recv` result | Accumulated `data` |
    `msgs` | `rest` |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `recv_msgs` 调用 | `data` 参数 | `recv` 结果 | 累积的 `data` | `msgs` | `rest` |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 1 | - | `''caerphil''` | `''caerphil''` | `[]` | `b''''` |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 1 | - | `''caerphil''` | `''caerphil''` | `[]` | `b''''` |'
- en: '| 1 | - | `''ly\0illches''` | `''caerphilly\0illches''` | `[''caerphilly'']`
    | `''illches''` |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 1 | - | `''ly\0illches''` | `''caerphilly\0illches''` | `[''caerphilly'']`
    | `''illches''` |'
- en: '| 2 | `''illches''` | `''ter\0brie\0''` | `''illchester\0brie\0''` | `[''illchester'',
    ''brie'']` | `b''''` |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 2 | `''illches''` | `''ter\0brie\0''` | `''illchester\0brie\0''` | `[''illchester'',
    ''brie'']` | `b''''` |'
- en: Here, we can see that the first `recv_msgs()` call doesn't return after its
    first iteration. It loops again because `msgs` is still empty. This is why the
    `recv_msgs` call numbers are 1, 1, and 2.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到第一个 `recv_msgs()` 调用在其第一次迭代后没有返回。它循环是因为 `msgs` 仍然为空。这就是为什么 `recv_msgs`
    调用编号为 1、1 和 2 的原因。
- en: A multithreaded chat server
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个多线程聊天服务器
- en: 'So let''s put this to use and write our chat server. Make a new file called
    `2.1-chat_server-multithread.py` and put the following code in it:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们利用这一点并编写我们的聊天服务器。创建一个名为 `2.1-chat_server-multithread.py` 的新文件，并将以下代码放入其中：
- en: '[PRE12]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We're now using two threads per client. One thread handles the messages received
    and the other thread handles the task of sending messages. The idea here is to
    break out each place a block might happen into its own thread. This will give
    us the lowest latency for each client, but it does come at the cost of system
    resources. We're reducing the potential number of clients that we may be able
    to handle simultaneously. There are other models that we could use, such as having
    a single thread for each client which receives messages and then sends them itself
    to all the connected clients, but I've chosen to optimize for latency.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们为每个客户端使用两个线程。一个线程处理接收到的消息，另一个线程处理发送消息的任务。这里的想法是将可能发生阻塞的每个地方都分解成自己的线程。这将为每个客户端提供最低的延迟，但这会以系统资源为代价。我们减少了可能同时处理的客户端数量。我们可以使用其他模型，比如为每个客户端使用单个线程接收消息，然后自己将消息发送给所有连接的客户端，但我选择了优化延迟。
- en: To facilitate the separate threads, we've broken the receiving code and the
    sending code into the `handle_client_recv()` function and `handle_client_send()`
    function respectively.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便分开线程，我们将接收代码和发送代码分别放入`handle_client_recv()`函数和`handle_client_send()`函数中。
- en: Our `handle_client_recv` threads are tasked with receiving messages from the
    clients, and our `handle_client_send` threads are tasked with sending messages
    to the clients, but how do the received messages get from the receive threads
    to the send threads? This is where the `queue`, `send_queue`, `dict` and `lock`
    objects come in.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`handle_client_recv`线程负责从客户端接收消息，而`handle_client_send`线程负责向客户端发送消息，但是接收到的消息如何从接收线程传递到发送线程呢？这就是`queue`、`send_queue`、`dict`和`lock`对象发挥作用的地方。
- en: Queues
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 队列
- en: A `Queue` is a **first-in first-out** (**FIFO**) pipe. You add items to it by
    using the `put()` method, and pull them out by using the `get()` method. The important
    thing about `Queue` objects is that they are completely **thread safe**. Objects
    in Python are generally not thread safe unless it is explicitly specified in their
    documentation. Being thread safe means that operations on the object are guaranteed
    to be **atomic**, that is, they will always complete without any chance of another
    thread getting to that object and doing something unexpected to it.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`Queue`是一个**先进先出**（**FIFO**）管道。您可以使用`put()`方法向其中添加项目，并使用`get()`方法将它们取出。`Queue`对象的重要之处在于它们完全是**线程安全**的。在Python中，除非在其文档中明确指定，否则对象通常不是线程安全的。线程安全意味着对对象的操作保证是**原子**的，也就是说，它们将始终在没有其他线程可能到达该对象并对其执行意外操作的情况下完成。'
- en: Hang on, you might ask, earlier, didn't you say that because of the GIL the
    OS is running only one Python thread per process at any given moment in time?
    If that's so, then how could two threads perform an operation on an object simultaneously?
    Well, this is a fair question. Most operations in Python are, in fact, made up
    of many operations at the OS level, and it is at the OS level that threads are
    scheduled. A thread could start an operation on an object—say by appending an
    item to a `list`—and when the thread gets halfway through its OS level operations
    the OS could switch to another thread, which also starts appending to the same
    `list`. Since `list` objects provide no warranty of their behavior when abused
    like this by threads (they're not thread safe), anything could happen next, and
    it's unlikely to be a useful outcome. This situation can be called a **race condition**.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 等一下，你可能会问，之前，你不是说由于全局解释器锁（GIL），操作系统在任何给定时刻只能运行一个Python线程吗？如果是这样，那么两个线程如何能同时对一个对象执行操作呢？嗯，这是一个公平的问题。实际上，Python中的大多数操作实际上由许多操作组成，这些操作是在操作系统级别进行的，线程是在操作系统级别进行调度的。一个线程可以开始对一个对象进行操作，比如向`list`中添加一个项目，当线程进行到操作系统级别的操作的一半时，操作系统可能会切换到另一个线程，这个线程也开始向同一个`list`中添加。由于`list`对象在被线程滥用时（它们不是线程安全的）没有对其行为提供任何保证，接下来可能发生任何事情，而且不太可能是一个有用的结果。这种情况可以称为**竞争条件**。
- en: Thread safe objects remove this possibility, so they should absolutely be preferred
    for sharing state among threads.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 线程安全对象消除了这种可能性，因此在线程之间共享状态时，绝对应该优先选择它们。
- en: Getting back to our server, the other useful behavior of `Queues` is that if
    `get()` is called on an empty `Queue`, then it will block until something is added
    to the `Queue`. We take advantage of this in our send threads. Notice, how we
    go into an infinite loop, with the first operation being a `get()` method call
    on a `Queue`. The thread will block there and patiently wait until something is
    added to its `Queue`. And, you've probably guessed it, our receive threads add
    the messages to the queues.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的服务器，`Queues`的另一个有用的行为是，如果在空的`Queue`上调用`get()`，那么它将阻塞，直到有东西被添加到`Queue`中。我们利用这一点在我们的发送线程中。注意，我们进入一个无限循环，第一个操作是对`Queue`调用`get()`方法。线程将在那里阻塞并耐心等待，直到有东西被添加到它的`Queue`中。而且，你可能已经猜到了，我们的接收线程将消息添加到队列中。
- en: We create a `Queue` object for each send thread as it's being created and then
    we store the queues in the `send_queues` dict. For our receive threads to broadcast
    new messages, they just need to add the message to each `Queue` in `send_queues`,
    which we do in the `broadcast_msgs()` function. Our waiting send threads will
    then unblock, pick the message out of their `Queue` and then send it to their
    client.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个发送线程创建一个`Queue`对象，并将队列存储在`send_queues`字典中。为了广播新消息给我们的接收线程，它们只需要将消息添加到`send_queues`中的每个`Queue`中，这是在`broadcast_msgs()`函数中完成的。我们等待的发送线程将解除阻塞，从它们的`Queue`中取出消息，然后将其发送给它们的客户端。
- en: We've also added a `handle_disconnect()` function, which gets called whenever
    a client disconnects or a socket error occurs. This function ensures that queues
    associated with closed connections are cleaned up, and that the socket is closed
    properly from the server end.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还添加了一个`handle_disconnect()`函数，每当客户端断开连接或套接字发生错误时都会调用该函数。该函数确保与关闭连接相关的队列被清理，并且套接字从服务器端正确关闭。
- en: Locks
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 锁
- en: Contrast our use of the `Queues` object with our use of `send_queues`. `Dict`
    objects are not thread safe, and unfortunately there isn't a thread safe associative
    array type in Python. Since we need to share this `dict`, we need to take extra
    precautions whenever we access it, and this is where the `Lock` comes in. `Lock`
    objects are a type of **synchronization primitive**. These are special objects
    built with functionality to help manage our threads and ensure that they don't
    trip over each others' accesses.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们对`Queues`对象的使用与我们对`send_queues`的使用进行对比。`Dict`对象不是线程安全的，不幸的是，在Python中没有线程安全的关联数组类型。由于我们需要共享这个`dict`，所以我们在访问它时需要额外小心，这就是`Lock`发挥作用的地方。`Lock`对象是一种**同步原语**。这些是具有功能的特殊对象，可以帮助管理我们的线程，并确保它们不会互相干扰。
- en: A `Lock` is either locked or unlocked. A thread can lock a thread by either
    calling `acquire()` on it, or as in our program, using it as a context manager.
    If a thread has acquired a lock and another thread also tries to acquire the lock,
    then the second thread will block on the `acquire()` call until the first thread
    releases the lock or exits the context. There is no limit on the number of threads
    that can try to acquire a lock at once – all but the first will block. By wrapping
    all the accesses to a non-thread safe object with a lock, we can ensure that no
    two threads operate on the object at the same time.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`Lock`要么被锁定，要么被解锁。线程可以通过调用`acquire()`来锁定线程，或者像我们的程序一样，将其用作上下文管理器。如果一个线程已经获取了锁，另一个线程也试图获取锁，那么第二个线程将在`acquire()`调用上阻塞，直到第一个线程释放锁或退出上下文。一次可以有无限多个线程尝试获取锁
    - 除了第一个之外，所有线程都会被阻塞。通过用锁包装对非线程安全对象的所有访问，我们可以确保没有两个线程同时操作该对象。'
- en: So, every time we add or remove something from `send_queues`, we wrap it in
    a `Lock` context`.` Notice that we're also protecting `send_queues` when we iterate
    over it. Even though we're not changing it, we want to be sure that it doesn't
    get modified while we're working with it.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每当我们向`send_queues`添加或删除内容时，我们都会将其包装在`Lock`上下文中。请注意，当我们迭代`send_queues`时，我们也在保护它。即使我们没有改变它，我们也希望确保在我们处理它时它不会被修改。
- en: Although we're being careful and using locks and thread safe primitives, we're
    not protected against all possible thread related pitfalls. Since the thread synchronization
    mechanisms themselves block, it's still quite possible to create deadlocks, where
    two threads are simultaneously blocking on objects locked by the other thread.
    The best approach to managing thread communication is to keep all the accesses
    to your shared state restricted to as small an area of your code as you can. In
    the case of this server, this module could be reworked as a class providing a
    minimum number of public methods. It could also be documented such that it discourages
    the changing of any internal state. This will keep this chunk of threading strictly
    confined to this class.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们很小心地使用锁和线程安全的原语，但我们并没有完全保护自己免受所有可能的与线程相关的问题。由于线程同步机制本身会阻塞，因此仍然很可能会出现死锁，即两个线程同时在由另一个线程锁定的对象上阻塞。管理线程通信的最佳方法是将对共享状态的所有访问限制在代码中尽可能小的区域内。在这个服务器的情况下，这个模块可以重新设计为提供最少数量的公共方法的类。它还可以被记录下来，以阻止任何内部状态的更改。这将使线程的这一部分严格限制在这个类中。
- en: A multithreaded chat client
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程聊天客户端
- en: 'Now that we have a new, all receiving and broadcasting chat server, we just
    need a client to go with it. We have mentioned before that we will hit a problem
    with our procedural client when trying to listen for both network data and user
    input at the same time. Well, now that we have some idea of how to employ threads,
    we can have a go at addressing this. Create a new text file called `2.2-chat_client-multithread.py`
    and save the following code in it:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个新的、全接收和广播的聊天服务器，我们只需要一个客户端。我们之前提到，当尝试同时监听网络数据和用户输入时，我们的过程化客户端会遇到问题。现在我们对如何使用线程有了一些想法，我们可以试着解决这个问题。创建一个名为`2.2-chat_client-multithread.py`的新文本文件，并将以下代码保存在其中：
- en: '[PRE13]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We've updated our client to honor our new chat protocol by creating a new thread
    to handle user input and send messages, while handling receiving messages in the
    main thread. This allows the client to deal with the user input and receive the
    messages at the same time.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经更新了我们的客户端，通过创建一个新线程来处理用户输入和发送消息，同时在主线程中处理接收消息，来遵守我们的新聊天协议。这允许客户端同时处理用户输入和接收消息。
- en: Note that there's no shared state here, so we didn't have to get clever with
    `Queues` or synchronization primitives.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里没有共享状态，所以我们不必在`Queues`或同步原语上耍花招。
- en: Let's give our new programs a try. Fire up the multithreaded chat server, and
    then launch at least two clients. If you can, run them in terminals such that
    you can watch all of them at once. Now, try and send some messages from the clients
    and see how they are sent to all of the other clients.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来试试我们的新程序。启动多线程聊天服务器，然后启动至少两个客户端。如果可以的话，在终端中运行它们，这样你就可以同时观看它们。现在，尝试从客户端发送一些消息，看看它们是如何发送到所有其他客户端的。
- en: Event-driven servers
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件驱动服务器
- en: For many purposes threads are great, especially because we can still program
    in the familiar procedural, blocking-IO style. But they suffer from the drawback
    that they struggle when managing large numbers of connections simultaneously,
    because they are required to maintain a thread for each connection. Each thread
    consumes memory, and switching between threads incurs a type of CPU overhead called
    **context switching**. Although these aren't a problem for small numbers of threads,
    they can impact performance when there are many threads to manage. Multiprocessing
    suffers from similar problems.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多目的来说，线程是很好的，特别是因为我们仍然可以以熟悉的过程化、阻塞IO风格进行编程。但是它们的缺点是在同时管理大量连接时会遇到困难，因为它们需要为每个连接维护一个线程。每个线程都会消耗内存，并且在线程之间切换会产生一种称为**上下文切换**的CPU开销。虽然这对于少量线程来说不是问题，但是当需要管理许多线程时，它会影响性能。多进程也面临类似的问题。
- en: An alternative to threading and multiprocessing is using the **event-driven**
    model. In this model, instead of having the OS automatically switch between active
    threads or processes for us, we use a single thread which registers blocking objects,
    such as sockets, with the OS. When these objects become ready to leave the blocking
    state, for example a socket receives some data, the OS notifies our program; our
    program can then access these objects in non-blocking mode, since it knows that
    they are in a state that is ready for immediate use. Calls made to objects in
    non-blocking mode always return immediately. We structure our application around
    a loop, where we wait for the OS to notify us of activity on our blocking objects,
    then we handle that activity, and then we go back to waiting. This loop is called
    the **event loop**.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**事件驱动**模型是线程和多进程的一种替代方法。在这种模型中，我们不是让操作系统自动在活动线程或进程之间切换，而是使用一个单线程，将阻塞对象（如套接字）注册到操作系统中。当这些对象准备好离开阻塞状态时，例如套接字接收到一些数据，操作系统会通知我们的程序；我们的程序可以以非阻塞模式访问这些对象，因为它知道它们处于立即可用的状态。在非阻塞模式下调用对象的调用总是立即返回。我们的应用程序围绕一个循环进行结构化，等待操作系统通知我们阻塞对象上的活动，然后处理该活动，然后回到等待状态。这个循环被称为**事件循环**。
- en: This approach provides comparable performance to threading and multiprocessing,
    but without the memory or context switching overheads, and hence allows for greater
    scaling on the same hardware. The challenge of engineering applications that can
    efficiently handle very large numbers of simultaneous connections has historically
    been called the **c10k problem**, referring to the handling of ten-thousand concurrent
    connections in a single thread. With the help of event-driven architectures, this
    problem was solved, though the term is still often used to refer to the challenges
    of scaling when it comes to handling many concurrent connections.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法提供了与线程和多进程相当的性能，但没有内存或上下文切换的开销，因此可以在相同的硬件上实现更大的扩展。工程应用程序能够有效处理大量同时连接的挑战在历史上被称为**c10k问题**，指的是在单个线程中处理一万个并发连接。借助事件驱动架构，这个问题得到了解决，尽管这个术语在处理许多并发连接时仍经常被使用。
- en: Note
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: On modern hardware it's actually possible to handle ten-thousand concurrent
    connections using a multithreading approach as well, see this Stack Overflow question
    for some numbers [https://stackoverflow.com/questions/17593699/tcp-ip-solving-the-c10k-with-the-thread-per-client-approach](https://stackoverflow.com/questions/17593699/tcp-ip-solving-the-c10k-with-the-thread-per-client-approach).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代硬件上，使用多线程方法实际上可以处理一万个并发连接，也可以参考这个Stack Overflow问题来了解一些数字[https://stackoverflow.com/questions/17593699/tcp-ip-solving-the-c10k-with-the-thread-per-client-approach](https://stackoverflow.com/questions/17593699/tcp-ip-solving-the-c10k-with-the-thread-per-client-approach)。
- en: The modern challenge is the "c10m problem", that is, ten million concurrent
    connections. Solving this involves some drastic software and even operating system
    architecture changes. Although this is unlikely to be manageable with Python any
    time soon, an interesting (though unfortunately incomplete) general introduction
    to the topic can be found at [http://c10m.robertgraham.com/p/blog-page.html](http://c10m.robertgraham.com/p/blog-page.html).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现代挑战是“c10m问题”，即一千万并发连接。解决这个问题涉及一些激进的软件甚至操作系统架构的变化。尽管这在短期内可能无法通过Python来解决，但可以在[http://c10m.robertgraham.com/p/blog-page.html](http://c10m.robertgraham.com/p/blog-page.html)找到有关该主题的有趣（尽管不幸是不完整的）概论。
- en: 'The following diagram shows the relationship of processes and threads in an
    event-driven server:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了事件驱动服务器中进程和线程的关系：
- en: '![Event-driven servers](graphics/6008OS_08_03.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![事件驱动服务器](graphics/6008OS_08_03.jpg)'
- en: Although the GIL and the OS thread scheduler are shown here for completeness,
    in the case of an event-driven server, they have no impact on performance because
    the server only uses a single thread. The scheduling of I/O handling is done by
    the application.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管GIL和操作系统线程调度器在这里是为了完整性而显示的，但在事件驱动服务器的情况下，它们对性能没有影响，因为服务器只使用一个线程。I/O处理的调度是由应用程序完成的。
- en: A low-level event-driven chat server
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 低级事件驱动聊天服务器
- en: So the event-driven architecture has a few great benefits, the catch is that
    for a low-level implementation, we need to write our code in a completely different
    style. Let's write an event-driven chat server to illustrate this.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，事件驱动架构有一些很大的好处，但问题在于，对于低级实现，我们需要以完全不同的风格编写我们的代码。让我们编写一个事件驱动的聊天服务器来说明这一点。
- en: Note that this example will not at all work on Windows as Windows lacks the
    `poll` interface which we will be employing here. There is an older interface,
    called `select`, which Windows does support, however it is slower and more complicated
    to work with. The event-driven frameworks that we look at later do automatically
    switch to `select` for us though, if we're running on Windows.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个例子在Windows上根本无法工作，因为Windows缺乏我们将在这里使用的`poll`接口。然而，Windows支持一个名为`select`的旧接口，但它更慢，更复杂。我们稍后讨论的事件驱动框架会自动切换到`select`，如果我们在Windows上运行的话。
- en: There is a higher performance alternative to `poll` called `epoll`, available
    on Linux operating systems, however it also more complicated to use, so for simplicity
    we'll stick with `poll` here. Again, the frameworks we discuss later automatically
    take advantage of `epoll` if it is available.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个称为`epoll`的`poll`的高性能替代品，它在Linux操作系统上可用，但它也更复杂，所以为了简单起见，我们将在这里坚持使用`poll`。同样，我们稍后讨论的框架会自动利用`epoll`。
- en: Finally, counter-intuitively, Python's `poll` interface lives in a module called
    `select`, hence we will import `select` in our program.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，令人费解的是，Python的`poll`接口位于一个名为`select`的模块中，因此我们将在程序中导入`select`。
- en: 'Create a file called `3.1-chat_server-poll.py` and save the following code
    in it:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`3.1-chat_server-poll.py`的文件，并将以下代码保存在其中：
- en: '[PRE14]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The crux of this program is the `poll` object, which we create at the start
    of execution. This is an interface for the kernel's poll service, which lets us
    register sockets for the OS to watch and notify us when they are ready for us
    work with them.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序的关键是我们在执行开始时创建的`poll`对象。这是一个用于内核`poll`服务的接口，它允许我们注册套接字，以便操作系统在它们准备好供我们使用时通知我们。
- en: We register a socket by calling the `poll.register()` method, passing the socket
    as an argument along with the type of activity that we want the kernel to watch
    out for. There are several conditions which we can monitor by specifying various
    `select.POLL*` constants. We're using `POLLIN` and `POLLOUT` in this program to
    watch out for when a socket is ready to receive and send data respectively. Accepting
    a new incoming connection on our listening socket will be counted as a read.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用`poll.register()`方法注册套接字，将套接字作为参数与我们希望内核监视的活动类型一起传递。我们可以通过指定各种`select.POLL*`常量来监视几种条件。在这个程序中，我们使用`POLLIN`和`POLLOUT`来监视套接字何时准备好接收和发送数据。在我们的监听套接字上接受新的传入连接将被视为读取。
- en: Once a socket is registered with `poll`, the OS will watch it and record when
    the socket is ready to carry out the activity that we requested. When we call
    `poll.poll()`, it returns a list of all the sockets that have become ready for
    us to work with. For each socket, it also returns an `event` flag, which indicates
    the state of the socket. We can use this event flag to tell whether we can read
    from (`POLLIN` event) or write to the socket (`POLLOUT` event), or whether an
    error has occurred (`POLLHUP`, `POLLERR`, `POLLNVAL` events).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦套接字被注册到`poll`中，操作系统将监视它，并记录当套接字准备执行我们请求的活动时。当我们调用`poll.poll()`时，它返回一个列表，其中包含所有已准备好供我们使用的套接字。对于每个套接字，它还返回一个`event`标志，指示套接字的状态。我们可以使用此事件标志来判断我们是否可以从套接字读取（`POLLIN`事件）或向套接字写入（`POLLOUT`事件），或者是否发生了错误（`POLLHUP`，`POLLERR`，`POLLNVAL`事件）。
- en: To make use of this, we enter our event loop, repeatedly calling `poll.poll()`,
    iterating through the ready objects it returns and operating on them as per their
    `event` flags.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用这一点，我们进入我们的事件循环，重复调用`poll.poll()`，迭代返回的准备好的对象，并根据它们的`event`标志对它们进行操作。
- en: 'Because we''re only running in a single thread, we don''t need any of the synchronization
    mechanisms which we had to employ in the multithreaded server. We''re just using
    a regular `dict` to keep track of our clients. If you''ve not come across it before,
    the `SimpleNamespace` object that we use in the `create_client()` function is
    just a new idiom for creating an empty object with a `__dict__` (this is needed
    because `Object` instances don''t have a `__dict__` so they won''t accept arbitrary
    attributes). Previously, we may have used the following to give us an object which
    we can assign arbitrary attributes to:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们只在一个线程中运行，所以我们不需要在多线程服务器中使用的任何同步机制。我们只是使用一个常规的`dict`来跟踪我们的客户端。如果你以前没有遇到过，我们在`create_client()`函数中使用的`SimpleNamespace`对象只是一个创建带有`__dict__`的空对象的新习惯用法（这是必需的，因为`Object`实例没有`__dict__`，所以它们不会接受任意属性）。以前，我们可能会使用以下内容来给我们一个可以分配任意属性的对象：
- en: '[PRE15]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Python version 3.3 and later versions give us the new, more explicit `SimpleNamespace`
    object.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Python版本3.3及更高版本为我们提供了新的更明确的`SimpleNamespace`对象。
- en: We can run our multithreaded client against this server. The server is still
    using the same network protocol, and the architecture of the two programs won't
    affect the communication. Give it a try and verify if it works as expected.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行我们的多线程客户端与这个服务器进行通信。服务器仍然使用相同的网络协议，两个程序的架构不会影响通信。试一试，验证是否按预期工作。
- en: This style of programming, employing `poll` and non-blocking sockets, is often
    referred to as **non-blocking** and **asynchronous,** since we use sockets in
    non-blocking mode, and the thread of control handles I/O reactively, as it needs
    to happen, rather than locking to a single I/O channel until it's done. However,
    you should note that our program isn't completely non-blocking, since it still
    blocks on the `poll.poll()` call. This is pretty much inevitable in an I/O bound
    system because when nothing's happening, you've got to wait for the I/O activity
    somewhere.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编程风格，使用`poll`和非阻塞套接字，通常被称为**非阻塞**和**异步**，因为我们使用非阻塞模式的套接字，并且控制线程根据需要处理I/O，而不是锁定到单个I/O通道直到完成。但是，你应该注意，我们的程序并不完全是非阻塞的，因为它仍然在`poll.poll()`调用上阻塞。在I/O绑定系统中，这几乎是不可避免的，因为当没有发生任何事情时，你必须等待I/O活动。
- en: Frameworks
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 框架
- en: As you can see, writing servers using these lower level threading and `poll`
    APIs can be quite involved, especially considering that various things which would
    be expected in a production system, such as logging and comprehensive error handling,
    haven't been included in our examples due to brevity.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，使用这些较低级别的线程和`poll`API编写服务器可能会相当复杂，特别是考虑到一些在生产系统中预期的事情，比如日志记录和全面的错误处理，由于简洁起见，我们的示例中没有包括。
- en: Many people have hit these problems before us, and several libraries and frameworks
    are available for taking some of the leg work out of writing the network servers.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人在我们之前遇到了这些问题，并且有几个库和框架可用于减少编写网络服务器的工作量。
- en: An eventlet-based chat server
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于eventlet的聊天服务器
- en: The `eventlet` library provides a high-level API for event-driven programming,
    but it does so in a style that mimics the procedural, blocking-IO style that we
    used in our multithreaded servers. The upshot is that we can effectively take
    our multithreaded chat server code, make a few minor modifications to it to use
    `eventlet` instead, and immediately gain the benefits of the event-driven model!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`eventlet`库提供了一个高级API，用于事件驱动编程，但它的风格模仿了我们在多线程服务器中使用的过程式阻塞IO风格。结果是，我们可以有效地采用多线程聊天服务器代码，对其进行一些小的修改，以使用`eventlet`，并立即获得事件驱动模型的好处！'
- en: 'The `eventlet` library is available in PyPi, and it can be installed with `pip`,
    as shown here:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`eventlet`库可在PyPi中找到，并且可以使用`pip`进行安装，如下所示：'
- en: '[PRE16]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `eventlet` library automatically falls back to `select` if `poll` is not
    available, so it will run properly on Windows.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`poll`不可用，`eventlet`库会自动退回到`select`，因此它将在Windows上正常运行。
- en: 'Once it''s installed, create a new file called `4.1-chat_server-eventlet.py`
    and save the following code in it:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，创建一个名为`4.1-chat_server-eventlet.py`的新文件，并将以下代码保存在其中：
- en: '[PRE17]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can test this with our multithreaded client to ensure that it works as expected.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用我们的多线程客户端进行测试，以确保它按预期工作。
- en: As you can see, it's pretty much identical to our multithreaded server, with
    a few changes made so as to use `eventlet`. Notice that we've removed the synchronization
    code and the `lock` around `send_queues`. We're still using queues, although they're
    the `eventlet` library's queues, because we want to retain the blocking behavior
    of `Queue.get()`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，它与我们的多线程服务器几乎完全相同，只是做了一些更改以使用`eventlet`。请注意，我们已经删除了同步代码和`send_queues`周围的`lock`。我们仍然使用队列，尽管它们是`eventlet`库的队列，因为我们希望保留`Queue.get()`的阻塞行为。
- en: Note
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: There are more examples of using eventlet for programming on the eventlet site
    at [http://eventlet.net/doc/examples.html](http://eventlet.net/doc/examples.html).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在eventlet网站上有更多使用eventlet进行编程的示例，网址为[http://eventlet.net/doc/examples.html](http://eventlet.net/doc/examples.html)。
- en: An asyncio-based chat server
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于asyncio的聊天服务器
- en: The `asyncio` Standard Library module is new in Python 3.4 and it is an effort
    at bringing some standardization around asynchronous I/O into the Standard Library.
    The `asyncio` library uses a co-routine based style of programming. It provides
    a powerful loop class, which our programs can submit prepared tasks, called co-routines,
    to, for asynchronous execution. The event loop handles the scheduling of the tasks
    and optimization of performance around blocking I/O calls.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '`asyncio`标准库模块是Python 3.4中的新功能，它是在标准库中围绕异步I/O引入一些标准化的努力。`asyncio`库使用基于协程的编程风格。它提供了一个强大的循环类，我们的程序可以将准备好的任务（称为协程）提交给它，以进行异步执行。事件循环处理任务的调度和性能优化，以处理阻塞I/O调用。'
- en: 'It has built-in support for socket-based networking, which makes building a
    basic server a straightforward task. Let''s see how this can be done. Create a
    new file called `5.1-chat_server-asyncio.py` and save the following code in it:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 它内置支持基于套接字的网络，这使得构建基本服务器成为一项简单的任务。让我们看看如何做到这一点。创建一个名为`5.1-chat_server-asyncio.py`的新文件，并将以下代码保存在其中：
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Again, we can test this with our multithreaded client to make sure that it works
    as we expect it to.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以使用我们的多线程客户端进行测试，以确保它按我们的预期工作。
- en: Let's step through the code, as it's quite different from our previous servers.
    We begin by defining our server behavior in a subclass of the `asyncio.Protocol`
    abstract class. We're required to override the three methods `connection_made()`,
    `data_received()`, and `connection_lost()`. By using this class we can instantiate
    a new server scheduled on the event loop, which will listen on a socket and behave
    according to the contents of these three methods. We perform this instantiation
    in the main section further down with the `loop.create_server()` call.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步了解代码，因为它与我们以前的服务器有很大不同。我们首先定义了服务器行为，它是`asyncio.Protocol`抽象类的子类。我们需要重写三个方法`connection_made()`、`data_received()`和`connection_lost()`。通过使用这个类，我们可以在事件循环上实例化一个新的服务器，它将监听一个套接字，并根据这三种方法的内容进行操作。我们在主要部分中使用`loop.create_server()`调用来执行这个实例化。
- en: The `connection_made()` method is called when a new client connects to our socket,
    which is equivalent to `socket.accept()` receiving a connection. The `transport`
    argument that it receives is a writable stream object, that is, it is an `asyncio.WriteTransport`
    instance. We will use this to write data to the socket, so we hang on to it by
    assigning it to the `self.transport` attribute. We also grab the client's host
    and port by using `transport.get_extra_info('peername')`. This is the transport's
    equivalent of `socket.getpeername()`. We then set up a `rest` attribute to hold
    the leftover data from `tincanchat.parse_recvd_data()` calls, and then we add
    our instance to the global `clients` list so that the other clients can broadcast
    to it.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 当新客户端连接到我们的套接字时，将调用`connection_made()`方法，这相当于`socket.accept()`接收到一个连接。它接收的`transport`参数是一个可写流对象，也就是一个`asyncio.WriteTransport`实例。我们将使用它向套接字写入数据，因此通过将其分配给`self.transport`属性来保留它。我们还通过使用`transport.get_extra_info('peername')`来获取客户端的主机和端口。这是传输的`socket.getpeername()`的等价物。然后我们设置一个`rest`属性来保存从`tincanchat.parse_recvd_data()`调用中剩下的数据，然后我们将我们的实例添加到全局的`clients`列表中，以便其他客户端可以向其进行广播。
- en: The `data_received()` method is where the action happens. This function is called
    every time the `Protocol` instance's socket receives any data. This is equivalent
    to `poll.poll()` returning a `POLLIN` event, and then us performing a `recv()`
    on the socket. When called, this method is passed the data that is received from
    the socket as the `data` argument, which we then parse using `tincanchat.parse_recvd_data()`,
    as we have done before.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`data_received()`方法是发生操作的地方。每次`Protocol`实例的套接字接收到任何数据时，都会调用此函数。这相当于`poll.poll()`返回`POLLIN`事件，然后我们在套接字上执行`recv()`。调用此方法时，将接收到的数据作为`data`参数传递给该方法，然后我们使用`tincanchat.parse_recvd_data()`进行解析，就像以前一样。'
- en: We then iterate over any received messages, and for each one, send it to every
    client in the `clients` list by calling the `write()` method on the clients' transport
    objects. The important thing to note here is that the `Transport.write()` call
    is non-blocking and so returns immediately. The send just gets submitted to the
    event loop, to be scheduled for completion soon. Hence the broadcast itself completes
    quickly.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，我们遍历接收到的任何消息，并对每条消息，通过在客户端的传输对象上调用`write()`方法，将其发送到`clients`列表中的每个客户端。这里需要注意的重要一点是，`Transport.write()`调用是非阻塞的，因此会立即返回。发送只是被提交到事件循环中，以便很快安排完成。 '
- en: The `connection_lost()` method is called when the client disconnects or the
    connection is lost, which is equivalent to a `socket.recv()` returning an empty
    result, or a `ConnectionError`. Here, we just remove the client from the `clients`
    global list.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`connection_lost()`方法在客户端断开连接或连接丢失时被调用，这相当于`socket.recv()`返回一个空结果，或者一个`ConnectionError`。在这里，我们只是从`clients`全局列表中移除客户端。'
- en: In the main module code we acquire an event loop, and then create an instance
    of our `Protocol` server. The call to `loop.run_until_complete()` runs the initialization
    phase of our server on the event loop, setting up the listening socket. Then we
    call `loop.run_forever()`, which starts our server listening for incoming connections.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在主模块代码中，我们获取一个事件循环，然后创建我们的`Protocol`服务器的实例。调用`loop.run_until_complete()`在事件循环上运行我们服务器的初始化阶段，设置监听套接字。然后我们调用`loop.run_forever()`，这将使我们的服务器开始监听传入的连接。
- en: More on frameworks
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多关于框架
- en: I've broken from our usual procedural form and used an object-oriented approach
    in the last example for two reasons. First, although it is possible to write a
    purely procedural style server with `asyncio`, it requires a deeper understanding
    of co-routines than what we were able to provide here. If you're curious, then
    you can go through an example co-routine style echo server, which is in the `asyncio`
    documentation at [https://docs.python.org/3/library/asyncio-stream.html#asyncio-tcp-echo-server-streams](https://docs.python.org/3/library/asyncio-stream.html#asyncio-tcp-echo-server-streams).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个示例中，我打破了我们通常的过程形式，采用了面向对象的方法，原因有两个。首先，虽然可以使用`asyncio`编写纯过程风格的服务器，但这需要比我们在这里提供的更深入的理解协程。如果你感兴趣，可以阅读`asyncio`文档中的一个示例协程风格的回显服务器，网址为[https://docs.python.org/3/library/asyncio-stream.html#asyncio-tcp-echo-server-streams](https://docs.python.org/3/library/asyncio-stream.html#asyncio-tcp-echo-server-streams)。
- en: The second reason is that this kind of class-based approach is generally a more
    manageable model to follow in a full system.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个原因是，这种基于类的方法通常是在完整系统中更易管理的模型。
- en: There is in fact a new module called `selectors` in Python 3.4, which provides
    an API for quickly building an object-oriented server based on the IO primitives
    in the `select` module (including `poll`). The documentation and an example can
    be seen at [https://docs.python.org/3.4/library/selectors.html](https://docs.python.org/3.4/library/selectors.html).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，Python 3.4中有一个名为`selectors`的新模块，它提供了一个基于`select`模块中IO原语快速构建面向对象服务器的API（包括`poll`）。文档和示例可以在[https://docs.python.org/3.4/library/selectors.html](https://docs.python.org/3.4/library/selectors.html)中找到。
- en: There are other third-party event-driven frameworks available, popular ones
    are Tornado ([www.tornadoweb.org](http://www.tornadoweb.org)) and circuits ([https://github.com/circuits/circuits](https://github.com/circuits/circuits)).
    Both are worth investigating for comparison, if you intend to choose a framework
    for a project.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他第三方事件驱动框架可用，流行的有Tornado（[www.tornadoweb.org](http://www.tornadoweb.org)）和circuits（[https://github.com/circuits/circuits](https://github.com/circuits/circuits)）。如果你打算为项目选择一个框架，这两个都值得进行比较。
- en: Moreover, no discussion of Python asynchronous I/O would be complete without
    a mention of the Twisted framework. Until Python 3, this has been the go to solution
    for any serious asynchronous I/O work. It is an event-driven engine, with support
    for a large number of network protocols, good performance, and a large and active
    community. Unfortunately, it hasn't finished the jump to Python 3 yet (a view
    of the migration progress can be seen at [https://rawgit.com/mythmon/twisted-py3-graph/master/index.html](https://rawgit.com/mythmon/twisted-py3-graph/master/index.html)).
    Since we're focused squarely on Python 3 in this book, we decided to not include
    a detailed treatment of it. However, once it does get there, Python 3 will have
    another very powerful asynchronous framework, which will be well worth investigating
    for your projects.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，没有讨论Python异步I/O的内容是完整的，而没有提到Twisted框架。直到Python 3之前，这一直是任何严肃的异步I/O工作的首选解决方案。它是一个事件驱动引擎，支持大量的网络协议，性能良好，并且拥有庞大而活跃的社区。不幸的是，它还没有完全转向Python
    3（迁移进度可以在[https://rawgit.com/mythmon/twisted-py3-graph/master/index.html](https://rawgit.com/mythmon/twisted-py3-graph/master/index.html)中查看）。由于我们在本书中专注于Python
    3，我们决定不对其进行详细处理。然而，一旦它到达那里，Python 3将拥有另一个非常强大的异步框架，这将值得你为你的项目进行调查。
- en: Taking our servers forward
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推动我们的服务器前进
- en: There are a number of things that we can do to improve our servers. For multithreaded
    systems, it's common to have a mechanism for capping the number of threads in
    use at any one time. This can be done by keeping a count of the active threads
    and immediately closing any new incoming connections from clients while it's above
    a threshold.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多事情可以做来改进我们的服务器。对于多线程系统，通常会有一种机制来限制同时使用的线程数量。这可以通过保持活动线程的计数并在超过阈值时立即关闭来自客户端的任何新传入连接来实现。
- en: For all our servers, we would also want to add a logging mechanism. I strongly
    recommend the standard library `logging` module for this, the documentation for
    this is complete and full of good examples. The basic tutorial is a good place
    to start if you've not used it before, and it can be found at [https://docs.python.org/3/howto/logging.html#logging-basic-tutorial](https://docs.python.org/3/howto/logging.html#logging-basic-tutorial).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们所有的服务器，我们还希望添加一个日志记录机制。我强烈推荐使用标准库`logging`模块，它的文档非常完整，包含了很多好的例子。如果你以前没有使用过，基本教程是一个很好的起点，可以在[https://docs.python.org/3/howto/logging.html#logging-basic-tutorial](https://docs.python.org/3/howto/logging.html#logging-basic-tutorial)中找到。
- en: We also want to handle errors more comprehensively. Since the intention is that
    our server should be long running with minimal intervention, we want to make sure
    that nothing less than a critical exception causes the process to exit. We also
    want to make sure that errors that occur when handling one client do not affect
    other connected clients.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望更全面地处理错误。由于我们的服务器意图是长时间运行并且最小干预，我们希望确保除了关键异常之外的任何情况都不会导致进程退出。我们还希望确保处理一个客户端时发生的错误不会影响其他已连接的客户端。
- en: 'Finally there are some basic features of chat programs that it may be fun to
    add: letting users enter a name, which would be shown beside their messages on
    the other clients; adding chat rooms; and adding TLS encryption to the socket
    connections to provide privacy and security.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，聊天程序还有一些基本功能可能会很有趣：让用户输入一个名字，在其他客户端上显示他们的消息旁边；添加聊天室；以及在套接字连接中添加TLS加密以提供隐私和安全性。
- en: Summary
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We looked at how to develop network protocols while considering aspects such
    as the connection sequence, framing of the data on the wire, and the impact these
    choices will have on the architecture of the client and server programs.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了如何在考虑诸如连接顺序、数据传输中的数据帧等方面开发网络协议，以及这些选择对客户端和服务器程序架构的影响。
- en: We worked through different architectures for network servers and clients, demonstrating
    the differences between the multithreaded and event-driven models by writing a
    simple echo server and upgrading it to a multi-client chat server. We discussed
    performance issues around threaded and event-driven architectures. Finally, we
    looked at the `eventlet` and `asyncio` frameworks, which can greatly simplify
    the process of writing servers when using an event-driven approach.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过编写一个简单的回显服务器并将其升级为多客户端聊天服务器，演示了网络服务器和客户端的不同架构，展示了多线程和事件驱动模型之间的差异。我们讨论了围绕线程和事件驱动架构的性能问题。最后，我们看了一下`eventlet`和`asyncio`框架，这些框架在使用事件驱动方法时可以极大地简化服务器编写的过程。
- en: In the next and final chapter of this book, we will look at bringing several
    threads of this book together for writing server-side web applications.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的下一章和最后一章中，我们将探讨如何将本书的几个主题融合起来，用于编写服务器端的Web应用程序。
