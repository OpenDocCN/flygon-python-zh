- en: Creating Scraper Microservices with Docker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker创建爬虫微服务
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Installing Docker
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Docker
- en: Installing a RabbitMQ container from Docker Hub
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从Docker Hub安装RabbitMQ容器
- en: Running a Docker container (RabbitMQ)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行一个Docker容器（RabbitMQ）
- en: Stopping and removing a container and image
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止和删除容器和镜像
- en: Creating an API container
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个API容器
- en: Creating a generic microservice with Nameko
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Nameko创建一个通用微服务
- en: Creating a scraping microservice
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个爬取微服务
- en: Creating a scraper container
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个爬虫容器
- en: Creating a backend (ElasticCache) container
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建后端（ElasticCache）容器
- en: Composing and running the scraper containers with Docker Compose
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Compose组合和运行爬虫容器
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In this chapter, we will learn to containerize our scraper, getting it ready
    for the real world by starting to package it for real, modern, cloud-enabled operations.
    This will involve packaging the different elements of the scraper (API, scraper,
    backend storage) as Docker containers that can be run locally or in the cloud.
    We will also examine implementing the scraper as a microservice that can be independently
    scaled.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将我们的爬虫容器化，使其准备好进入现实世界，开始为真正的、现代的、云启用的操作打包。这将涉及将爬虫的不同元素（API、爬虫、后端存储）打包为可以在本地或云中运行的Docker容器。我们还将研究将爬虫实现为可以独立扩展的微服务。
- en: Much of the focus will be upon using Docker to create our containerized scraper.
    Docker provides us a convenient and easy means of packaging the various components
    of the scraper as a service (the API, the scraper itself, and other backends such
    as Elasticsearch and RabbitMQ). By containerizing these components using Docker,
    we can easily run the containers locally, orchestrate the different containers
    making up the services, and also conveniently publish to Docker Hub. We can then
    deploy them easily to cloud providers to create our scraper in the cloud.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将主要关注使用Docker来创建我们的容器化爬虫。Docker为我们提供了一种方便和简单的方式，将爬虫的各个组件（API、爬虫本身以及其他后端，如Elasticsearch和RabbitMQ）打包为一个服务。通过使用Docker对这些组件进行容器化，我们可以轻松地在本地运行容器，编排组成服务的不同容器，还可以方便地发布到Docker
    Hub。然后我们可以轻松地部署它们到云提供商，以在云中创建我们的爬虫。
- en: One of the great things about Docker (and containers in general) is that we
    can both easily install pre-packaged containers without all the fuss of having
    to get an installer for an application and deal with all of the configuration
    hassle. We can then also package our own software that we wrote into a container,
    and run that container without having to deal with all those details. Additionally,
    we can also publish to a private or public repository to share our software.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Docker（以及容器一般）的一大好处是，我们既可以轻松地安装预打包的容器，而不必费力地获取应用程序的安装程序并处理所有配置的麻烦。我们还可以将我们编写的软件打包到一个容器中，并在不必处理所有这些细节的情况下运行该容器。此外，我们还可以发布到私有或公共存储库以分享我们的软件。
- en: What is really great about Docker is that the containers are, for the most part,
    platform-independent. Any Linux-based container can be run on any operating system,
    including Windows (which uses VirtualBox underneath to virtualize Linux and is
    mostly transparent to the Windows user). So one benefit is that any Linux-based
    Docker container can be run on any Docker supported operating system. No more
    need to create multiple OS versions of your application!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Docker真正伟大的地方在于容器在很大程度上是平台无关的。任何基于Linux的容器都可以在任何操作系统上运行，包括Windows（它在虚拟化Linux时使用VirtualBox，并且对Windows用户来说基本上是透明的）。因此，一个好处是任何基于Linux的Docker容器都可以在任何Docker支持的操作系统上运行。不再需要为应用程序创建多个操作系统版本了！
- en: So let's go and learn a little Docker and put our scraper components into containers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习一些Docker知识，并将我们的爬虫组件放入容器中。
- en: Installing Docker
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Docker
- en: In this recipe, we look at how to install Docker and verify that it is running.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将学习如何安装Docker并验证其是否正在运行。
- en: Getting ready
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Docker is supported on Linux, macOS, and Windows, so it has the major platforms
    covered. The installation process for Docker is different depending on the operating
    system that you are using, and even differs among the different Linux distributions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Docker支持Linux、macOS和Windows，因此它覆盖了主要平台。Docker的安装过程因您使用的操作系统而异，甚至在不同的Linux发行版之间也有所不同。
- en: The Docker website has good documentation on the installation processes, so
    this recipe will quickly walk through the important points of the installation
    on macOS. Once the install is complete, the user experience for Docker, at least
    from the CLI, is identical.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Docker网站对安装过程有很好的文档，因此本教程将快速浏览macOS上安装的重要要点。安装完成后，至少从CLI方面来看，Docker的用户体验是相同的。
- en: For reference, the main page for installation instructions for Docker is found
    at: [https://docs.docker.com/engine/installation/](https://docs.docker.com/engine/installation/)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献，Docker的安装说明主页位于：[https://docs.docker.com/engine/installation/](https://docs.docker.com/engine/installation/)
- en: How to do it
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We will be proceeding with the recipe as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下步骤进行：
- en: We will be using a variant of Docker known as Docker Community Edition, and
    walk through the installation on macOS. On the download page for macOS you will
    see the following section. Click on the download for the Stable channel, unless
    you are feeling brave and want to use the Edge channel.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用一个名为Docker社区版的Docker变体，并在macOS上进行安装。在macOS的下载页面上，您将看到以下部分。点击稳定频道的下载，除非您感到勇敢并想使用Edge频道。
- en: '![](assets/3fe42443-f9f8-4dc5-8679-221293a203fa.png)The docker download page'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/3fe42443-f9f8-4dc5-8679-221293a203fa.png)Docker下载页面'
- en: 'This will download a `Docker.dmg` file. Open the DMG and you will be presented
    with the following window:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将下载一个`Docker.dmg`文件。打开DMG，您将看到以下窗口：
- en: '![](assets/b2a7044a-5f06-4874-96c6-112496770357.png)The Docker for Mac installer
    window'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/b2a7044a-5f06-4874-96c6-112496770357.png)Docker for Mac安装程序窗口'
- en: 'Drag *Moby* the whale into your applications folder. Then open `Docker.app`.
    You will be asked to authenticate the installation, so enter your password and
    the installation will complete. When that is done, you will see Moby in your status
    bar:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将*Moby*鲸鱼拖到您的应用程序文件夹中。然后打开`Docker.app`。您将被要求验证安装，因此输入密码，安装将完成。完成后，您将在状态栏中看到Moby：
- en: '![](assets/db37ccda-6c94-44dd-b327-f943fe3afbdb.png)The Moby toolbar icon'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/db37ccda-6c94-44dd-b327-f943fe3afbdb.png)Moby工具栏图标'
- en: There are number of configuration settings, statuses, and pieces of information
    available by clicking on Moby. We will mostly use the command-line tools. To verify
    things are working from the command line, open a terminal and enter the command,
    docker info. Docker will give you some information on its configuration and status.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击Moby可以获得许多配置设置、状态和信息。我们将主要使用命令行工具。要验证命令行是否正常工作，请打开终端并输入命令docker info。Docker将为您提供有关其配置和状态的一些信息。
- en: Installing a RabbitMQ container from Docker Hub
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Docker Hub安装RabbitMQ容器
- en: Pre-built containers can be obtained from a number of container repositories.
    Docker is preconfigured with connectivity to Docker Hub, where many software vendors,
    and also enthusiasts, publish containers with one or more configurations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从许多容器存储库获取预构建的容器。Docker预先配置了与Docker Hub的连接，许多软件供应商和爱好者在那里发布一个或多个配置的容器。
- en: In this recipe, we will install RabbitMQ, which will be used by another tool
    we use in another recipe, Nameko, to function as the messaging bus for our scraping
    microservice.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将安装RabbitMQ，这将被我们在另一个教程中使用的另一个工具Nameko所使用，以作为我们的抓取微服务的消息总线。
- en: Getting ready
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Normally, the installation of RabbitMQ is a fairly simple process, but it does
    require several installers: one for Erlang, and then one for RabbitMQ itself.
    If management tools, such as the web-based administrative GUI are desired, that
    is yet one more step (albeit a fairly small one). By using Docker, we can simply
    get the container with all of this preconfigured. Let''s go do that.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，安装RabbitMQ是一个相当简单的过程，但它确实需要几个安装程序：一个用于Erlang，然后一个用于RabbitMQ本身。如果需要管理工具，比如基于Web的管理GUI，那就是另一步（尽管是一个相当小的步骤）。通过使用Docker，我们可以简单地获取所有这些预配置的容器。让我们去做吧。
- en: How to do it
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行教程：
- en: 'Containers can be obtained using the `docker pull` command.  This command will
    check and see if a container is installed locally, and if not, go and fetch it
    for us. Try the command from the command line, including the `--help flag. `You
    will get the following, informing you that you need at least one more parameter:
    the name and possibly tag for the container:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用`docker pull`命令获取容器。此命令将检查并查看本地是否已安装容器，如果没有，则为我们获取。从命令行尝试该命令，包括`--help`标志。您将得到以下信息，告诉您至少需要一个参数：容器的名称和可能的标签：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We are going to pull the `rabbitmq:3-management` container. The portion before
    the colon is the container name, and the second part is a tag. Tags often represent
    a version of the container, or a specific configuration. In this case, we will
    want to get the RabbitMQ container with tag 3-management. This tag means we want
    the container version with version 3 of RabbitMQ and with the management tools
    installed.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将拉取`rabbitmq:3-management`容器。冒号前的部分是容器名称，第二部分是标签。标签通常代表容器的版本或特定配置。在这种情况下，我们希望获取带有3-management标签的RabbitMQ容器。这个标签意味着我们想要带有RabbitMQ版本3和管理工具安装的容器版本。
- en: 'Before we do this, you might be thinking where this comes from. It comes from
    Docker Hub (`hub.docker.com`), from the RabbitMQ repository. The page for this
    repository is at [https://hub.docker.com/_/rabbitmq/](https://hub.docker.com/_/rabbitmq/),
    and will look like the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这样做之前，您可能会想知道这是从哪里来的。它来自Docker Hub（`hub.docker.com`），来自RabbitMQ存储库。该存储库的页面位于[https://hub.docker.com/_/rabbitmq/](https://hub.docker.com/_/rabbitmq/)，并且看起来像下面这样：
- en: '![](assets/2210e62e-0f9d-4a21-b71c-41c37d0dd8c6.png)Page for RabbitMQ repositoryNote
    the section showing tags, and that it has the 3-management tag. If you scroll
    down, you will also see a lot more information about the container and tags, and
    what they comprise.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/2210e62e-0f9d-4a21-b71c-41c37d0dd8c6.png)RabbitMQ存储库页面请注意显示标签的部分，以及它具有3-management标签。如果您向下滚动，还会看到有关容器和标签的更多信息，以及它们的组成。'
- en: 'Now let''s pull this container. Issue the following command from the terminal:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们拉取这个容器。从终端发出以下命令：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Docker will go out to Docker Hub and start the download. You''ll see this in
    action with output similar to the following, which will likely run for a few minutes
    depending on your download speed:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker将访问Docker Hub并开始下载。您将在类似以下的输出中看到这一过程，这可能会根据您的下载速度运行几分钟：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Congratulations! If this is your first time using Docker, you have downloaded
    your first container image. You can verify it is downloaded and installed using
    the docker images command.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！如果这是您第一次使用Docker，您已经下载了您的第一个容器镜像。您可以使用docker images命令验证它是否已下载和安装。
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Running a Docker container (RabbitMQ)
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Docker容器（RabbitMQ）
- en: In this recipe we learn how to run a docker image, thereby making a container.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将学习如何运行docker镜像，从而创建一个容器。
- en: Getting ready
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will start the RabbitMQ container image that we downloaded in the previous
    recipe. This process is representative of how many containers are run, so it makes
    a good example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将启动我们在上一个教程中下载的RabbitMQ容器镜像。这个过程代表了许多容器的运行方式，因此它是一个很好的例子。
- en: How to do it
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行教程：
- en: What we have downloaded so far is an image that can be run to create an actual
    container. A container is an actual instantiation of an image with specific parameters
    needed to configure the software in the container. We run the container by running
    an image using docker run and passing the image name/tag, and any other parameters
    required to run the image (these are specific to the image and normally can be
    found on the Docker Hub page for the image).
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经下载了一个可以运行以创建实际容器的镜像。容器是使用特定参数实例化的镜像，这些参数需要配置容器中的软件。我们通过运行docker run并传递镜像名称/标签以及运行镜像所需的任何其他参数来运行容器（这些参数特定于镜像，通常可以在Docker
    Hub页面上找到镜像的参数）。
- en: 'The specific command we need to run RabbitMQ using this image is the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用以下特定命令来运行RabbitMQ使用此镜像：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`docker run` tells Docker to run an image in a container. The image we want
    to run is at the end of the statement: `rabbitmq:3-management`. The `-d` option
    tells Docker to run the container detached, meaning the output of the container
    is not routed to the terminal. This allows us to retain control of the terminal.
    The `-p` option maps a host port to a container port. RabbitMQ uses port 5672
    for actual commands, and port 15672 for the web UI. This maps an identical port
    on your actual operating system to the ports used by the software running in the
    container.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker run`告诉Docker在容器中运行一个镜像。我们要运行的镜像在语句的末尾：`rabbitmq:3-management`。`-d`选项告诉Docker以分离模式运行容器，这意味着容器的输出不会路由到终端。这允许我们保留对终端的控制。`-p`选项将主机端口映射到容器端口。RabbitMQ使用5672端口进行实际命令，15672端口用于Web
    UI。这将在您的实际操作系统上的相同端口映射到容器中运行的软件使用的端口。'
- en: The big hexidecimal value output is an identifier of the container. The first
    portion, 094a13838376, is the container ID created by Docker (this will be different
    for every container that is started).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 大的十六进制值输出是容器的标识符。第一部分，094a13838376，是Docker创建的容器ID（对于每个启动的容器都会有所不同）。
- en: 'We can check which containers are running using docker ps, which gives us the
    process status of each container:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用docker ps来检查正在运行的容器，这会给我们每个容器的进程状态：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We can see the container ID and other information such as which image it is
    based on, how long it has been up, which ports the container exposes, the port
    mappings we defined, and a friendly name made up by Docker for us to refer to
    the container.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到容器ID和其他信息，例如它基于哪个镜像，它已经运行了多长时间，容器暴露了哪些端口，我们定义的端口映射，以及Docker为我们创建的友好名称，以便我们引用容器。
- en: 'The real way to check whether this is running is to open the browser and navigate
    to `localhost:15672`, the RabbitMQ management UI URL:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查是否正在运行的真正方法是打开浏览器，导航到`localhost:15672`，即RabbitMQ管理UI的URL：
- en: '![](assets/d8715fbc-5686-48c9-9f38-16e8c54aa325.png)The RabbitMQ Admin UI login
    page'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/d8715fbc-5686-48c9-9f38-16e8c54aa325.png)RabbitMQ管理UI登录页面'
- en: 'The default username and password for this container is guest:guest. Enter
    those values and you will see the management UI:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该容器的默认用户名和密码是guest:guest。输入这些值，您将看到管理UI：
- en: '![](assets/20179fcc-8e5c-467f-8421-49f1dd7b3e9c.png)The management UI'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/20179fcc-8e5c-467f-8421-49f1dd7b3e9c.png)管理UI'
- en: There's more...
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This is actually as far as we will progress with RabbitMQ. In a later recipe,
    we will use the Nameko Python microservice framework, which will transparently
    use RabbitMQ without our knowledge. We first needed to make sure it was installed
    and running.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是我们将在RabbitMQ中取得的进展。在以后的教程中，我们将使用Nameko Python微服务框架，它将在我们不知情的情况下透明地使用RabbitMQ。我们首先需要确保它已安装并正在运行。
- en: Creating and running an Elasticsearch container
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和运行Elasticsearch容器
- en: While we are looking at pulling container images and starting containers, let's
    go and run an Elasticsearch container.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们正在查看拉取容器镜像和启动容器时，让我们去运行一个Elasticsearch容器。
- en: How to do it
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'Like most things Docker, there are a lot of different versions of Elasticsearch
    containers available. We will use the official Elasticsearch image available in
    Elastic''s own Docker repository:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 像大多数Docker一样，有很多不同版本的Elasticsearch容器可用。我们将使用Elastic自己的Docker存储库中提供的官方Elasticsearch镜像：
- en: 'To install the image, enter the following:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要安装镜像，请输入以下内容：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that we are using another way of specifying the image to pull. Since this
    is on Elastic's Docker repository, we include the qualified name that includes
    the URL to the container image instead of just the image name. The :6.1.1 is the
    tag and specifies a specific version of that image.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们正在使用另一种指定要拉取的镜像的方式。由于这是在Elastic的Docker存储库上，我们包括了包含容器镜像URL的限定名称，而不仅仅是镜像名称。
    :6.1.1是标签，指定了该镜像的特定版本。
- en: 'You will see some output while this is processing, showing the download process.
    When it is complete, you will have a few lines letting you know it is done:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在处理此过程时，您将看到一些输出，显示下载过程。完成后，您将看到几行让您知道已完成：
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now let''s check that the images are available for Docker:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们检查Docker中是否有可用的镜像：
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we can run Elasticsearch with the following Docker command:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用以下Docker命令运行Elasticsearch：
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The environment variable, `ELASTIC_PASSWORD` passes in a password, and the two
    ports map the host ports to the Elasticsearch ports exposed in the container.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 环境变量`ELASTIC_PASSWORD`传递密码，两个端口将主机端口映射到容器中暴露的Elasticsearch端口。
- en: 'Next, check that the container is running in Docker:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，检查容器是否在Docker中运行：
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And finally, perform the following curl. If Elasticsearch is running you will
    get the `You Know, for Search` message:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，执行以下curl。如果Elasticsearch正在运行，您将收到`You Know, for Search`消息：
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Stopping/restarting a container and removing the image
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 停止/重新启动容器并删除镜像
- en: Let's look at how to stop and remove a container, and then also its image.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何停止和删除一个容器，然后也删除它的镜像。
- en: How to do it
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'First query Docker for running containers:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先查询正在运行的Docker容器：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let's  stop the Elasticsearch container. To stop a container, we use `docker
    stop <container-id>`. Elasticsearch has a container ID of 308a02f0e1a5\. The following
    stops the container
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们停止Elasticsearch容器。要停止一个容器，我们使用`docker stop <container-id>`。Elasticsearch的容器ID是`308a02f0e1a5`。以下停止容器
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To acknowledge the container is stopped, Docker will echo the container ID you
    told it to stop
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认容器已停止，Docker将回显您告诉它停止的容器ID
- en: Note that I didn't have to enter the full container ID and only entered 30\.
    You only have to enter the first digits of the container ID until what you have
    entered is unique among all containers. It's a nice shortcut!.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我不必输入完整的容器ID，只输入了30。你只需要输入容器ID的前几位数字，直到你输入的内容在所有容器中是唯一的。这是一个很好的快捷方式！
- en: 'Checking the running container status, Docker only reports the other container:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查运行的容器状态，Docker只报告其他容器：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The container is not running, but it is also not deleted. Let''s look at using
    `docker ps -a` command:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器没有运行，但也没有被删除。让我们来使用`docker ps -a`命令：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This lists all containers currently on the system. I actually truncated my listing
    by quite a bit as I have a lot of these!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这列出了当前系统上的所有容器。实际上，我截断了我的列表，因为我有很多这样的容器！
- en: 'We can restart our Elasticsearch container using `docker restart`:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用`docker restart`来重新启动我们的Elasticsearch容器：
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: If you check `docker ps` you will see the container is operational again.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你检查`docker ps`，你会看到容器再次运行。
- en: This is important as this container is storing the Elasticsearch data within
    the file system of the container. By stopping and restarting, this data is not
    lost. So, you can stop to reclaim the resources (CPU and memory) used by the container,
    and then restart without loss at a later time.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这很重要，因为这个容器在容器的文件系统中存储了Elasticsearch数据。通过停止和重新启动，这些数据不会丢失。因此，您可以停止以回收容器使用的资源（CPU和内存），然后在以后的某个时间重新启动而不会丢失。
- en: 'Running or stopped, a container takes up disk space. A container can be removed
    to reclaim disk space. This can be done using `docker container rm <container-id>`,
    however a container can only be removed if it is not running. Let''s try and remove
    the running container:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无论是运行还是停止，容器都会占用磁盘空间。可以删除容器以回收磁盘空间。这可以使用`docker container rm <container-id>`来完成，但是只有在容器没有运行时才能删除容器。让我们尝试删除正在运行的容器：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We got a warning about the container running. We can force it with a flag,
    but it''s best to stop it first. Stopping ensures the application inside shuts
    down cleanly:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们收到了有关容器运行的警告。我们可以使用一个标志来强制执行，但最好先停止它。停止可以确保容器内的应用程序干净地关闭：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now if you go back to docker `ps -a`, the Elasticsearch container is no longer
    in the list and disk space for the container is reclaimed.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果你回到docker `ps -a`，Elasticsearch容器不再在列表中，容器的磁盘空间被回收。
- en: Note that we have now lost any data that was stored in that container! It's
    beyond the scope of this book, but most containers can be told to store data on
    the host's file system, and therefore we don't lost data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们现在已经丢失了存储在该容器中的任何数据！这超出了本书的范围，但大多数容器可以被告知将数据存储在主机的文件系统上，因此我们不会丢失数据。
- en: 'The disk space for the container has been removed, but the image for the container
    is still on the disk. That''s good if we want to make another container. But if
    you also want to free that space, you can use `docker images rm <image-id>`. 
    Going back to the Docker images result, we can see the image had an ID of `06f0d8328d66`.
    The following deletes that image and we get that space back (in this case 539MB):'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器的磁盘空间已经被删除，但是容器的镜像仍然在磁盘上。如果我们想创建另一个容器，这是很好的。但是如果你也想释放那个空间，你可以使用`docker images
    rm <image-id>`。回到Docker镜像结果，我们可以看到该镜像的ID是`06f0d8328d66`。以下删除该镜像，我们可以获得那个空间（在这种情况下是539MB）：
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: And now the image is gone and we have that space reclaimed also.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在镜像已经消失，我们也已经回收了那个空间。
- en: Note that if there are any containers that have been run off that image that
    still exist, then this will fail and those containers can be either running or
    stopped. Just doing a `docker ps -a` may not show the offending container, so
    you may have to use `docker ps -a` to find the stopped containers and delete them
    first.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果还存在任何使用该镜像运行的容器，那么这将失败，这些容器可能正在运行或已停止。只是做一个`docker ps -a`可能不会显示有问题的容器，所以你可能需要使用`docker
    ps -a`来找到已停止的容器并首先删除它们。
- en: There's more...
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: At this point you know enough about Docker to become very dangerous! So let's
    move on to examining how we can create our own containers with our own applications
    installed. First, let's go and look at making the crawler into a microservice
    that can be run in a container.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你已经了解了足够多关于Docker的知识，可以变得非常危险！所以让我们继续研究如何创建我们自己的容器，并安装我们自己的应用程序。首先，让我们去看看如何将爬虫变成一个可以在容器中运行的微服务。
- en: Creating a generic microservice with Nameko
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Nameko创建通用微服务
- en: In the next few recipes, we are going to create a scraper that can be run as
    a microservice within a Docker container. But before jumping right into the fire,
    let's first look at creating a basic microservice using a Python framework known
    as Nameko.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个步骤中，我们将创建一个可以作为Docker容器内的微服务运行的爬虫。但在直接进入火坑之前，让我们先看看如何使用一个名为Nameko的Python框架创建一个基本的微服务。
- en: Getting ready
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We will use a Python framework known as Nameko (pronounced [nah-meh-koh] to
    implement microservices. As with Flask-RESTful, a microservice implemented with
    Nameko is simply a class. We will instruct Nameko how to run the class as a service,
    and Nameko will wire up a messaging bus implementation to allow clients to communicate
    with the actual microservice.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个名为Nameko的Python框架（发音为[nah-meh-koh]）来实现微服务。与Flask-RESTful一样，使用Nameko实现的微服务只是一个类。我们将指示Nameko如何将该类作为服务运行，并且Nameko将连接一个消息总线实现，以允许客户端与实际的微服务进行通信。
- en: Nameko, by default, uses RabbitMQ as a messaging bus. RabbitMQ is a high-performance
    messaging bus that is great for performing the type of messaging service used
    between microservices. It's a similar model to what we saw earlier with SQS, but
    designed more for services located in the same data center instead of across that
    cloud. That's actually a great use for RabbitMQ, as we tend to cluster/scale microservices
    in the same environment these days, particularly within a containerized cluster
    such as Docker or Kubernetes.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Nameko使用RabbitMQ作为消息总线。RabbitMQ是一个高性能的消息总线，非常适合在微服务之间进行消息传递。它与我们之前在SQS中看到的模型类似，但更适合于位于同一数据中心的服务，而不是跨云。这实际上是RabbitMQ的一个很好的用途，因为我们现在倾向于在相同的环境中集群/扩展微服务，特别是在容器化集群中，比如Docker或Kubernetes。
- en: Therefore, we will need to have a local instance of RabbitMQ running. Make sure
    that you have a RabbitMQ container running as show in the earlier recipe.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要在本地运行一个RabbitMQ实例。确保你有一个RabbitMQ容器运行，就像在之前的示例中展示的那样。
- en: 'Also make sure you have Nameko installed:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 还要确保你已经安装了Nameko：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How to do it
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'We proceed with the recipe as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行操作：
- en: The sample microservice is implemented in `10/01/hello_microservice.py`.  This
    is a very simple service that can be passed a name for which the microservice
    replies `Hello, <name>!`.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 示例微服务实现在`10/01/hello_microservice.py`中。这是一个非常简单的服务，可以传递一个名字，微服务会回复`Hello, <name>!`。
- en: 'To run the microservice, we need to simply execute the following command from
    the terminal (while in the directory for the script):'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要运行微服务，我们只需要从终端执行以下命令（在脚本所在的目录中）：
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Nameko opens the Python file matching the specified microservices name and
    starts up the microservice. When starting, we will see a few lines of output:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nameko打开与指定微服务名称匹配的Python文件，并启动微服务。启动时，我们会看到几行输出：
- en: '[PRE22]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This states that Nameko has found our microservice, and that it has connected
    to an AMQP server (RabbitMQ) on port 5672 (RabbitMQ's default port). The microservice
    is now up and running and awaiting requests.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这表明Nameko已经找到了我们的微服务，并且已经连接到了一个AMQP服务器（RabbitMQ）的5672端口（RabbitMQ的默认端口）。微服务现在已经启动并且正在等待请求。
- en: If you go into the RabbitMQ API and go into the queues tab, you will see that
    Nameko has automatically created a queue for the microservice.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你进入RabbitMQ API并进入队列选项卡，你会看到Nameko已经自动为微服务创建了一个队列。
- en: 'Now we have to do something to make a request of the microservice. We will
    look at two ways of doing this. First, Nameko comes with an interactive shell
    that lets us interactively make requests to Nameko microservices. You can start
    the shell with the following command in a separate terminal window to the one
    running the microservice:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们必须做一些事情来请求微服务。我们将看两种方法来做到这一点。首先，Nameko带有一个交互式shell，让我们可以交互地向Nameko微服务发出请求。你可以在一个单独的终端窗口中使用以下命令启动shell，与运行微服务的窗口分开：
- en: '[PRE23]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You will see an interactive Python session start, with output similar to the
    following:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会看到一个交互式的Python会话开始，输出类似于以下内容：
- en: '[PRE24]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In this shell, we can simply refer to Nameko as ''n''.  To talk to our service
    we issue the following statement:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个shell中，我们可以简单地将Nameko称为'n'。要与我们的服务交谈，我们发出以下声明：
- en: '[PRE25]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This tells Nameko that we want to make an rpc call to the `hello` method of
    `hello_microservice`. When pressing *Enter* you will get the following result
    back:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这告诉Nameko我们想要调用`hello_microservice`的`hello`方法。按下*Enter*后，你会得到以下结果：
- en: '[PRE26]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'If you check in the terminal window running the service you should see an additional
    line of output:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你在运行服务的终端窗口中检查，你应该会看到额外的一行输出：
- en: '[PRE27]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'It is also possible to call the microservice from within Python code. There
    is an implementation of this available in `10/01/say_hi.py`. Executing this script
    with Python has the following output:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 也可以在Python代码中调用微服务。在`10/01/say_hi.py`中有一个实现。用Python执行这个脚本会得到以下输出：
- en: '[PRE28]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: So let's go and see how these are implemented.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们去看看这些是如何实现的。
- en: How it works
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: 'Let''s first look at the implementation of the microservice in `hello_microservice.py`. 
    There really isn''t a lot of code, so here it all is:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看一下`hello_microservice.py`中微服务的实现。实际上并没有太多的代码，所以这里是全部代码：
- en: '[PRE29]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: There are two thing to point out about this class. The first is the declaration
    of `name = "hello_microservice"`.  This is a declaration of the actual name of
    the microservice. This member variable is used instead of the class name.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 有两件事情要指出关于这个类。第一是声明`name = "hello_microservice"`。这是微服务的实际名称声明。这个成员变量被用来代替类名。
- en: The second is the use of the `@rpc` attribute on the `hello` method. This is
    a Nameko attribute that specifies that this method should be exposed as an `rpc`
    style method by the microservice. Hence, the caller is suspended until the reply
    is received from the microservice. There are other implementations, but for our
    purposes this is the only one we will use.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是在`hello`方法上使用`@rpc`属性。这是一个Nameko属性，指定这个方法应该作为`rpc`风格的方法被微服务公开。因此，调用者会一直等待，直到从微服务接收到回复。还有其他实现方式，但是对于我们的目的，这是我们将使用的唯一方式。
- en: When run with the nameko run command, that module will interrogate the file
    for methods with Nameko attributes and wire them up to the underlying bus.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用nameko run命令运行时，该模块将检查文件中带有Nameko属性的方法，并将它们连接到底层总线。
- en: 'The implementation in `say_hi.py` constructs a dynamic proxy that can call
    the service. The code for that is the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`say_hi.py`中的实现构建了一个可以调用服务的动态代理。代码如下：'
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The dynamic proxy is implemented by the `ClusterRpcProxy` class. When creating
    the class, we pass it a configuration object, which in this case specifies the
    address of the AMQP server that the service is located on, and we refer to this
    instance as the variable `rpc`. Nameko then dynamically identifies the next portion,
    `.hello_microservice`, as the name of the microservice (as specified earlier with
    the name field on the microservice class).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 动态代理是由`ClusterRpcProxy`类实现的。创建该类时，我们传递一个配置对象，该对象指定了服务所在的AMQP服务器的地址，在这种情况下，我们将这个实例称为变量`rpc`。然后，Nameko动态识别下一个部分`.hello_microservice`作为微服务的名称（如在微服务类的名称字段中指定的）。
- en: The next section, `.hello` then represents the method to call. Combined together,
    Nameko makes a call to the `hello` method of `hello_microservice`, passing it
    the specified string, and since this is an RPC proxy, waits until the reply is
    received.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分`.hello`代表要调用的方法。结合在一起，Nameko调用`hello_microservice`的`hello`方法，传递指定的字符串，由于这是一个RPC代理，它会等待接收到回复。
- en: Remote procedure calls, RPC for short, block until the result comes back from
    the other system. In contrast with a publish model, where the message is sent
    off and the sending app continues along.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 远程过程调用，简称RPC，会一直阻塞，直到结果从其他系统返回。与发布模型相比，发布模型中消息被发送后发送应用程序继续进行。
- en: There's more...
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: There is quite a lot of good stuff in Nameko that we have not even seen. One
    very useful factor is that Nameko runs listeners for multiple instances of your
    microservice. The default at the time of writing is 10\. Under the covers, Nameko
    sends requests from the clients of the microservice to a RabbitMQ queue, of which
    there will be 10 simultaneous request processors listening to that queue.  If
    there are too many requests to be handled at once, RabbitMQ will hold the message
    until Nameko recycles an existing microservice instance to process the queued
    message. To increase the scalability of the microservice, we can simply increase
    the number of workers through the configuration of the microservice, or run a
    separate Nameko microservice container in another Docker container or on another
    computer system.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在Nameko中有很多好东西，我们甚至还没有看到。一个非常有用的因素是，Nameko运行多个微服务实例的监听器。撰写本文时，默认值为10。在底层，Nameko将来自微服务客户端的请求发送到RabbitMQ队列，其中将有10个同时的请求处理器监听该队列。如果有太多的请求需要同时处理，RabbitMQ将保留消息，直到Nameko回收现有的微服务实例来处理排队的消息。为了增加微服务的可伸缩性，我们可以通过微服务的配置简单地增加工作人员的数量，或者在另一个Docker容器中运行一个单独的Nameko微服务容器，或者在另一台计算机系统上运行。
- en: Creating a scraping microservice
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个抓取微服务
- en: Now let's take our scraper and make it into a Nameko microservice. This scraper
    microservice will be able to be run independently of the implementation of the
    API. This will allow the scraper to be operated, maintained, and scaled independently
    of the API's implementation.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们把我们的抓取器变成一个Nameko微服务。这个抓取微服务将能够独立于API的实现而运行。这将允许抓取器独立于API的实现进行操作、维护和扩展。
- en: How to do it
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'The code for the microservice is straightforward. The code for it is in `10/02/call_scraper_microservice.py`
    and is shown here:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微服务的代码很简单。代码在`10/02/call_scraper_microservice.py`中，如下所示：
- en: '[PRE31]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We have created a class to implement the microservice and given it a single
    method, `get_job_listing_info`.  This method simply wraps the implementation in
    the `sojobs.scraping` module, but gives it an `@rpc` attribute so that Nameko
    exposes that method on the microservice bus. This can be run by opening a terminal
    and running the service with Nameko:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个类来实现微服务，并给它一个单一的方法`get_job_listing_info`。这个方法简单地包装了`sojobs.scraping`模块中的实现，但是给它一个`@rpc`属性，以便Nameko在微服务总线上公开该方法。这可以通过打开终端并使用Nameko运行服务来运行。
- en: '[PRE32]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now we can run the scraper with the code in the `10/02/call_scraper_microservice.py`
    script. The code in the files is the following:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用`10/02/call_scraper_microservice.py`脚本中的代码运行抓取器。文件中的代码如下：
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'It''s basically the same as the code for the client in the previous recipe,
    but changing the microservice and method names, and of course passing the specific
    job listing ID.  When run, you will see the following output (truncated):'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这基本上与上一个教程中客户端的代码相同，但是更改了微服务和方法的名称，并当然传递了特定的工作列表ID。运行时，您将看到以下输出（已截断）：
- en: '[PRE34]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: And just like that, we have created a microservice to get job listings from
    StackOverflow!
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就像这样，我们已经创建了一个从StackOverflow获取工作列表的微服务！
- en: There's more...
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This microservice is only callable using the `ClusterRpcProxy` class and is
    not open to being called by anyone on the internet or even locally using REST.
    We'll solve this issue in an upcoming recipe, where we create a REST API in a
    container that will talk to this microservice, which will be running in another
    container.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这个微服务只能使用`ClusterRpcProxy`类调用，不能被任何人通过互联网甚至本地使用REST调用。我们将在即将到来的教程中解决这个问题，在那里我们将在一个容器中创建一个REST
    API，该API将与另一个运行在另一个容器中的微服务进行通信。
- en: Creating a scraper container
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个抓取容器
- en: Now we create a container for our scraper microservice. We will learn about
    Dockerfiles and how to instruct Docker on how to build a container. We will also
    examine giving our Docker container hostnames so that they can find each other
    through Docker's integrated DNS system. Last but not least, we will learn how
    to configure our Nameko microservice to talk to RabbitMQ in another container
    instead of just on localhost.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们为我们的抓取微服务创建一个容器。我们将学习Dockerfile以及如何指示Docker如何构建容器。我们还将研究如何为我们的Docker容器提供主机名，以便它们可以通过Docker集成的DNS系统相互找到。最后但并非最不重要的是，我们将学习如何配置我们的Nameko微服务，以便与另一个容器中的RabbitMQ通信，而不仅仅是在本地主机上。
- en: Getting ready
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The first thing we want to do is make sure that RabbitMQ is running in a container
    and assigned to a custom Docker network, where various containers connected to
    that network will talk to each other. Among many other features, it also provides
    software defined network (SDN) capabilities to provide various types of integration
    between containers, hosts, and other systems.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是确保RabbitMQ在一个容器中运行，并分配给一个自定义的Docker网络，连接到该网络的各种容器将相互通信。除了许多其他功能外，它还提供了软件定义网络（SDN）功能，以在容器、主机和其他系统之间提供各种类型的集成。
- en: 'Docker comes with several predefined networks built. You can see the networks
    currently installed by using the `docker network ls` command:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Docker自带了几个预定义的网络。您可以使用`docker network ls`命令查看当前安装的网络：
- en: '[PRE35]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: To get our containers to communicate with each other, let's create a new bridge
    network named `scraper-net`.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们的容器相互通信，让我们创建一个名为`scraper-net`的新桥接网络。
- en: '[PRE36]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now when we start a container, we attach it to `scraper-net` using the `--network`
    parameter:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们启动一个容器时，我们使用`--network`参数将其连接到`scraper-net`：
- en: '[PRE37]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This container is now connected to both the scraper-net network and to the host
    network. Because it is also connected to host, it is still possible to connect
    to it from the host system.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这个容器现在连接到`scraper-net`网络和主机网络。因为它也连接到主机，所以仍然可以从主机系统连接到它。
- en: Note also that we used `--name rabbitmq` as an option. This gives this container
    the name, `rabbitmq` , but Docker will also resolve DNS queries from other containers
    attached to `scraper-net` so that they can find this container!
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，我们使用了`--name rabbitmq`作为一个选项。这给了这个容器名字`rabbitmq`，但Docker也会解析来自连接到`scraper-net`的其他容器的DNS查询，以便它们可以找到这个容器！
- en: Now let's go and put the scraper in a container.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们把爬虫放到一个容器中。
- en: How to do it
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'We proceed with the recipe as follows:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行配方：
- en: 'The way that we create a container is by creating a `dockerfile` and then using
    that to tell Docker to create a container.  I''ve included a Dockerfile in the
    `10/03` folder. The contents are the following (we will examine what this means
    in the *How it works* section):'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建容器的方式是创建一个`dockerfile`，然后使用它告诉Docker创建一个容器。我在`10/03`文件夹中包含了一个Dockerfile。内容如下（我们将在*它是如何工作*部分检查这意味着什么）：
- en: '[PRE38]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'To create an image/container from this Dockerfile, from a terminal, and within
    the `10/03` folder, run the following command:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从这个Dockerfile创建一个镜像/容器，在终端中，在`10/03`文件夹中，运行以下命令：
- en: '[PRE39]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This tells Docker that we want to *build* a container based upon the instructions
    in the given Dockerfile (specified with -f).  The image that is created is specified
    by
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这告诉Docker，我们想要根据给定的Dockerfile中的指令*构建*一个容器（用-f指定）。创建的镜像由指定
- en: '`-t scraping-microservice`. The `../..` after build specifies the context of
    the build.  When building, we will copy files into the container. This context
    specifies the home  directory that copies are relative to.  When you run this
    command, you will see output similar to the following:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`-t scraping-microservice`。`build`后面的`../..`指定了构建的上下文。在构建时，我们将文件复制到容器中。这个上下文指定了复制相对于的主目录。当你运行这个命令时，你会看到类似以下的输出：'
- en: '[PRE40]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This will likely take a while as the build process needs to download all of
    the NLTK files into the container. To check that the image is created we can run
    the following command:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这可能需要一些时间，因为构建过程需要将所有的NLTK文件下载到容器中。要检查镜像是否创建，可以运行以下命令：
- en: '[PRE41]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Note that this container is 4.16GB in size. This image is based on the `Python:3`
    container, which can be seen to be `692MB` in size:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，这个容器的大小是4.16GB。这个镜像是基于`Python:3`容器的，可以看到大小为`692MB`：
- en: '[PRE42]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Most of the size of this container is because of the inclusion of the NTLK data
    files.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这个容器的大部分大小是因为包含了NTLK数据文件。
- en: 'We can now run this image as a container using the following command:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用以下命令将这个镜像作为一个容器运行：
- en: '[PRE43]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The scraper that we put together is now running in this container, and this
    output shows that it has connected to an AMQP server located on a system named
    `rabbitmq`.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们组合的爬虫现在在这个容器中运行，这个输出显示它已经连接到一个名为`rabbitmq`的系统上的AMQP服务器。
- en: 'Now let''s test that this is working. In another terminal window run the Nameko
    shell:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们测试一下这是否有效。在另一个终端窗口中运行Nameko shell：
- en: '[PRE44]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, enter the following in the prompt to call the microservice:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在提示符中输入以下内容来调用微服务：
- en: '[PRE45]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You will see quite a bit of output as a result of the scrape (the following
    is truncated):'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于抓取的结果，你会看到相当多的输出（以下是截断的）：
- en: '[PRE46]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Congratulations! We now have successfully called our scraper microservice. Now,
    let's discuss how this works, and how the Dockerfile constructed the Docker image
    for the microservice.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！我们现在已经成功调用了我们的爬虫微服务。现在，让我们讨论这是如何工作的，以及Dockerfile是如何构建微服务的Docker镜像的。
- en: How it works
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: 'Let''s first discuss the Dockerfile by walking through what it told Docker
    to do during the build process. The first line:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先讨论Dockerfile，通过在构建过程中告诉Docker要做什么来逐步了解它的内容。第一行：
- en: '[PRE47]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This informs Docker that we want to build our container image based on the `Python:3`
    image found on Docker Hub. This is a prebuilt Linux image with Python 3 installed.
    The next line informs Docker that we want all of our file operations to be relative
    to the `/usr/src/app` folder.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉Docker，我们想要基于Docker Hub上找到的`Python:3`镜像构建我们的容器镜像。这是一个预先构建的Linux镜像，安装了Python
    3。下一行告诉Docker，我们希望所有的文件操作都是相对于`/usr/src/app`文件夹的。
- en: '[PRE48]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'At this point in building the image we have a base Python 3 install in place.
    We need to then install the various libraries that our scraper uses, so the following
    tells Docker to run pip to install them:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建镜像的这一点上，我们已经安装了一个基本的Python 3。然后我们需要安装我们的爬虫使用的各种库，所以下面告诉Docker运行pip来安装它们：
- en: '[PRE49]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We also need to install the NLTK data files:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要安装NLTK数据文件：
- en: '[PRE50]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Next, we copy in the implementation of our scraper. The following copies the
    `scraper_microservice.py` file from the previous recipe's folder into the container
    image.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将实现我们的爬虫复制进去。以下是将`scraper_microservice.py`文件从上一个配方的文件夹复制到容器镜像中。
- en: '[PRE51]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'This also depends on the `sojobs` module, so we copy that also:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这也取决于`sojobs`模块，因此我们也复制它：
- en: '[PRE52]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The final line informs Docker of the command to run when the container is started:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一行告诉Docker在启动容器时要运行的命令：
- en: '[PRE53]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This tells Nameko to run the microservices in `scraper_microservice.py`, and
    to also talk to the RabbitMQ message broker located on a system with the name,
    `rabbitmq`. Since we attached our scraper container to the scraper-net network,
    and also did the same for the RabbitMQ container, Docker connects these two up
    for us!
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉Nameko在`scraper_microservice.py`中运行微服务，并且还与名为`rabbitmq`的系统上的RabbitMQ消息代理进行通信。由于我们将scraper容器附加到scraper-net网络，并且还对RabbitMQ容器执行了相同操作，Docker为我们连接了这两个容器！
- en: Finally, we ran the Nameko shell from the Docker host system. When it started,
    it reported that it would communicate with the AMQP server (RabbitMQ) at `pyamqp://guest:guest@localhost`.
    When we executed the command in the shell, the Nameko shell sent that message
    to localhost.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们从Docker主机系统中运行了Nameko shell。当它启动时，它报告说它将与AMQP服务器（RabbitMQ）通信`pyamqp://guest:guest@localhost`。当我们在shell中执行命令时，Nameko
    shell将该消息发送到localhost。
- en: So how does it talk to the RabbitMQ instance in that container? When we started
    the RabbitMQ container, we told it to connect to the `scraper-net` network. It
    is still also connected to the host network, so we can still talk to the RabbitMQ
    broker as long as we mapped the `5672` port when we started it.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 那么它如何与容器中的RabbitMQ实例通信呢？当我们启动RabbitMQ容器时，我们告诉它连接到`scraper-net`网络。它仍然连接到主机网络，因此只要我们在启动时映射了`5672`端口，我们仍然可以与RabbitMQ代理进行通信。
- en: Our microservice in the other container is listening for messages in the RabbitMQ
    container, and then responds to that container, which is then picked up by the
    Nameko shell. Isn't that cool?
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在另一个容器中的微服务正在RabbitMQ容器中监听消息，然后响应该容器，然后由Nameko shell接收。这很酷，不是吗？
- en: Creating an API container
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建API容器
- en: At this point, we can only talk to our microservice using AMQP, or by using
    the Nameko shell or a Nameko `ClusterRPCProxy` class.  So let's put our Flask-RESTful
    API into another container, run that alongside the other containers, and make
    REST calls. This will also require that we run an Elasticsearch container, as
    that API code also communicates with Elasticsearch.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们只能使用AMQP或使用Nameko shell或Nameko `ClusterRPCProxy`类与我们的微服务进行通信。因此，让我们将我们的Flask-RESTful
    API放入另一个容器中，与其他容器一起运行，并进行REST调用。这还需要我们运行一个Elasticsearch容器，因为该API代码还与Elasticsearch通信。
- en: Getting ready
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'First let''s start up Elasticsearch in a container that is attached to the
    `scraper-net` network. We can kick that off with the following command:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们在附加到`scraper-net`网络的容器中启动Elasticsearch。我们可以使用以下命令启动它：
- en: '[PRE54]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Elasticsearch is now up and running on our `scarper-net` network. It can be
    reached by apps in other containers using the name elastic. Now let's move onto
    creating the container for the API.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch现在在我们的`scarper-net`网络上运行。其他容器中的应用程序可以使用名称elastic访问它。现在让我们继续创建API的容器。
- en: How to do it
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'In the `10/04` folder is an `api.py` file that implements a modified Flask-RESTful
    API from earlier, but with several  modifications. Let''s examine the code of
    the API:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`10/04`文件夹中有一个`api.py`文件，该文件实现了一个修改后的Flask-RESTful API，但进行了几处修改。让我们检查API的代码：
- en: '[PRE55]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The first change is that there is only one method on the API. We''ll focus
    on the `JobListing` method for now. Within that method, we now make the following
    call to create the Elasticsearch object:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个变化是API上只有一个方法。我们现在将重点放在`JobListing`方法上。在该方法中，我们现在进行以下调用以创建Elasticsearch对象：
- en: '[PRE56]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The default constructor assumes that the Elasticsearch server is on localhost.
    This change now points to the host with the name elastic on our scraper-net network.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认构造函数假定Elasticsearch服务器在localhost上。此更改现在将其指向scraper-net网络上名为elastic的主机。
- en: The second change is the removal of the calls to the functions in the sojobs
    module. Instead, we use a `Nameko ClusterRpcProxy` object to make the call to
    the scraper microservice running within our scraper container. This object is
    passed a configuration that points the RPC proxy to the rabbitmq container.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个变化是删除对sojobs模块中函数的调用。相反，我们使用`Nameko ClusterRpcProxy`对象调用在scraper容器内运行的scraper微服务。该对象传递了一个配置，将RPC代理指向rabbitmq容器。
- en: 'The final change is to the startup of the Flask application:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个变化是Flask应用程序的启动：
- en: '[PRE57]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The default connects to localhost, or 127.0.0.1\. Within a container, this doesn't
    bind to our `scraper-net` network or even on the host network. Using `0.0.0.0`
    binds the service to all network interfaces, and hence we can communicate with
    it via port mapping on the container. The port has also been moved to `8080`,
    a more common port for REST APIs than 5000.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认连接到localhost，或者127.0.0.1。在容器内部，这不会绑定到我们的`scraper-net`网络，甚至不会绑定到主机网络。使用`0.0.0.0`将服务绑定到所有网络接口，因此我们可以通过容器上的端口映射与其通信。端口也已移至`8080`，这是比5000更常见的REST
    API端口。
- en: 'With the API modified to run within a container, and to talk to the scraper
    microservice, we can now construct the container. In the `10/04` folder is a Dockerfile
    to configure the container. Its content is the following:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将API修改为在容器内运行，并与scraper微服务通信后，我们现在可以构建容器。在`10/04`文件夹中有一个Dockerfile来配置容器。其内容如下：
- en: '[PRE58]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: This is simpler than the Dockerfile for the previous container. This container
    doesn't have all the weight of NTLK. Finally, the startup simply executes the
    `api.py` files.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这比以前容器的Dockerfile简单。该容器没有NTLK的所有权重。最后，启动只需执行`api.py`文件。
- en: 'The container is built using the following:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下内容构建容器：
- en: '[PRE59]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'And then we can run the container using the following:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以使用以下命令运行容器：
- en: '[PRE60]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let''s now check that all of our containers are running:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们检查一下我们的所有容器是否都在运行：
- en: '[PRE61]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Now, from the terminal on the host we can issue a curl to the REST endpoint
    (output truncated):'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，从主机终端上，我们可以向REST端点发出curl请求（输出已截断）：
- en: '[PRE62]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: And there we have it. We have containerized the API and the functionality, and
    also run RabbitMQ and Elasticsearch in containers.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们就完成了。我们已经将API和功能容器化，并在容器中运行了RabbitMQ和Elasticsearch。
- en: There's more...
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This type of containerization is a great boon to the design and deployment of
    operations but still, we needed to create a number of Dockerfiles, containers,
    and a network to connect them, and run them all independently. Fortunately, we
    can simplify this with docker-compose. We'll see this in the next recipe.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的容器化对于操作的设计和部署是一个巨大的优势，但是我们仍然需要创建许多Docker文件、容器和网络来连接它们，并独立运行它们。幸运的是，我们可以使用docker-compose来简化这个过程。我们将在下一个步骤中看到这一点。
- en: Composing and running the scraper locally with docker-compose
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用docker-compose在本地组合和运行爬虫
- en: Compose is a tool for defining and running multi-container Docker applications.
    With Compose, you use a YAML file to configure your application’s services. Then,
    with a single command and a simple configuration file, you create and start all
    the services from your configuration.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Compose是一个用于定义和运行多容器Docker应用程序的工具。使用Compose，您可以使用YAML文件配置应用程序的服务。然后，通过一个简单的配置文件和一个命令，您可以从配置中创建和启动所有服务。
- en: Getting ready
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The first thing that needs to be done to use Compose is to make sure it is installed.
    Compose is automatically installed with Docker for macOS. On other platforms,
    it may or not be installed. You can find the instructions at the following URL: [https://docs.docker.com/compose/install/#prerequisites](https://docs.docker.com/compose/install/#prerequisites).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Compose的第一件事是确保已安装。Compose会随Docker for macOS自动安装。在其他平台上，可能已安装或未安装。您可以在以下网址找到说明：[https://docs.docker.com/compose/install/#prerequisites](https://docs.docker.com/compose/install/#prerequisites)。
- en: Also, make sure all of the existing containers that we created earlier are not
    running, as we will create new ones.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请确保我们之前创建的所有现有容器都没有在运行，因为我们将创建新的容器。
- en: How to do it
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'We proceed with the recipe as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'Docker Compose uses a `docker-compose.yml` file that tells Docker how to compose
    containers as `services`.  In the `10/05` folder there is a `docker-compose.yml`
    file to start up all the parts of our scraper as a service.  The following is
    the file''s contents:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Compose使用`docker-compose.yml`文件告诉Docker如何将容器组合为`services`。在`10/05`文件夹中有一个`docker-compose.yml`文件，用于将我们的爬虫的所有部分作为服务启动。以下是文件的内容：
- en: '[PRE63]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: With Docker Compose we move away from thinking in terms of containers and toward
    working with services. In this file, we described four services (api, scraper,
    elastic, and rabbitmq) and how they are created. The image tag for each tells
    Compose which Docker image to use for that service. If we need to map ports, then
    we can use the `ports` tag. The `network` tag specifies a network to connect the
    service to, in this case the network is also declared in the file to be a `bridged`
    network. One last thing to point out is the use of the `depends_on` tag for the
    scraper service. This service requires the `rabbitmq` service to be running beforehand,
    and this tells docker compose to make sure that this happens in the specified
    sequence.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker Compose，我们不再考虑容器，而是转向与服务一起工作。在这个文件中，我们描述了四个服务（api、scraper、elastic和rabbitmq）以及它们的创建方式。每个服务的图像标签告诉Compose要使用哪个Docker图像。如果需要映射端口，那么我们可以使用`ports`标签。`network`标签指定要连接服务的网络，在这种情况下，文件中还声明了一个`bridged`网络。最后要指出的一件事是scraper服务的`depends_on`标签。该服务需要在之前运行`rabbitmq`服务，这告诉docker
    compose确保按指定顺序进行。
- en: 'Now to bring everything up, open a terminal and from that folder run the following
    command:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，要启动所有内容，打开一个终端并从该文件夹运行以下命令：
- en: '[PRE64]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'There will be pause while Compose reads the configuration and figures out what
    to do, and then there will be quite a bit of output as every container''s output
    will be streamed into this one console. At the beginning of the output you will
    see something similar to the following:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Compose在读取配置并弄清楚要做什么时会暂停一会儿，然后会有相当多的输出，因为每个容器的输出都将流式传输到这个控制台。在输出的开头，您将看到类似于以下内容：
- en: '[PRE65]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'In another terminal, you can issue a `docker ps` to see the containers that
    have started:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在另一个终端中，您可以发出`docker ps`命令来查看已启动的容器：
- en: '[PRE66]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Note the names of the service containers. They are wrapped with two different
    identifiers. The prefix is simply the folder that the composition is run from,
    in this case 10 (for a '10_' prefix).  You can change this using the -p option
    to docker-compose up to specify something different. The trailing number is the
    instance number of the container for that service. In this scenario, we only started
    one container per service, so these are all _1 at this point. In a little while,
    we will see this change when we do scaling.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 注意服务容器的名称。它们被两个不同的标识符包裹。前缀只是运行组合的文件夹，本例中为10（用于'10_'前缀）。您可以使用-p选项来更改这个，以指定其他内容。尾随的数字是该服务的容器实例编号。在这种情况下，我们每个服务只启动了一个容器，所以这些都是_1。不久之后，当我们进行扩展时，我们将看到这一点发生变化。
- en: 'You might ask then: if my service is named `rabbitmq`, and Docker creates a
    container with the name `10_rabbitmq_1`, how does the microservice, which uses
    `rabbitmq` as a hostname, still connect to the RabbitMQ instance? Docker Compose
    has you covered in this situation, as it knows that `rabbitmq` needs to be translated
    to `10_rabbitmq_1`. Nice!'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会问：如果我的服务名为`rabbitmq`，而Docker创建了一个名为`10_rabbitmq_1`的容器，那么使用`rabbitmq`作为主机名的微服务如何连接到RabbitMQ实例？在这种情况下，Docker
    Compose已经为您解决了这个问题，因为它知道`rabbitmq`需要被转换为`10_rabbitmq_1`。太棒了！
- en: 'As part of bringing this environment up, Compose has also created the specified
    network:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为启动此环境的一部分，Compose还创建了指定的网络：
- en: '[PRE67]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: If we didn't specify a network, then Compose would have made a default network
    and wired everything to that. In this case that would work fine. But in more complicated
    scenarios this default may not be correct.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有指定网络，那么Compose将创建一个默认网络并将所有内容连接到该网络。在这种情况下，这将正常工作。但在更复杂的情况下，这个默认值可能不正确。
- en: 'Now, at this point everything is up and running. Let''s check things are working
    well by making a call to the REST scraping API:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，此时一切都已经启动并运行。让我们通过调用REST抓取API来检查一切是否正常运行：
- en: '[PRE68]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'And let''s also check that Elasticsearch is running by examining the index
    for the job listings now that we have requested one:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同时，让我们通过检查工作列表的索引来确认Elasticsearch是否正在运行，因为我们已经请求了一个：
- en: '[PRE69]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'We can also use docker-compose to scale the services. If we want to add more
    microservice containers to increase the amount of requests that can be handled,
    we can tell Compose to increase the number of scraper service containers. The
    following increases the number of scraper containers to 3:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用docker-compose来扩展服务。如果我们想要添加更多微服务容器以增加处理请求的数量，我们可以告诉Compose增加scraper服务容器的数量。以下命令将scraper容器的数量增加到3个：
- en: '[PRE70]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Compose will go and think about this request for a bit and then emit the following,
    stating that it is starting up two more scraper service containers (and this will
    be followed with a lot of output from those containers initializing):'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Compose将会考虑一会儿这个请求，然后发出以下消息，说明正在启动另外两个scraper服务容器（随后会有大量输出来自这些容器的初始化）：
- en: '[PRE71]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'A `docker ps` will now show three scraper containers running:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker ps`现在将显示三个正在运行的scraper容器：'
- en: '[PRE72]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Now we can see that we have three containers named `10_scraper_1`, `10_scraper_2`,
    and `10_scraper_3`. Cool!  And if you go into the RabbitMQ admin UI, you can see
    that there are three connections:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以看到我们有三个名为`10_scraper_1`、`10_scraper_2`和`10_scraper_3`的容器。很酷！如果你进入RabbitMQ管理界面，你会看到有三个连接：
- en: '![](assets/79eb12d7-59c6-41d7-be3f-5dd118fdf202.png)The Nameko queues in RabbitMQNote
    that each has a different IP address. On a bridged network like the one we have
    created, Compose allocates the IP addresses on the `172.23.0` network, starting
    at `.2`.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/79eb12d7-59c6-41d7-be3f-5dd118fdf202.png)RabbitMQ中的Nameko队列请注意每个队列都有不同的IP地址。在像我们创建的桥接网络上，Compose会在`172.23.0`网络上分配IP地址，从`.2`开始。'
- en: Operationally, all incoming scraping requests from the API will be routed to
    the rabbitmq container, and the actual RabbitMQ service would then spread the
    messages across all of the active connections and hence across all three containers,
    helping us to scale out processing.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 操作上，所有来自API的抓取请求都将被路由到rabbitmq容器，实际的RabbitMQ服务将把消息传播到所有活动连接，因此传播到所有三个容器，帮助我们扩展处理能力。
- en: Service instances can also be scaled down by issuing a scale value with a smaller
    number of containers, which Compose will respond to by removing containers until
    the value is achieved.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 服务实例也可以通过发出一个较小数量的容器的规模值来缩减，Compose将会响应并删除容器，直到达到指定的值。
- en: 'And when we are all done, we can tell Docker Compose to bring everything down:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 当一切都完成时，我们可以告诉Docker Compose关闭所有内容：
- en: '[PRE73]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Executing a docker ps will now show that all of the containers have been removed.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`docker ps`现在将显示所有容器都已被移除。
- en: There's more...
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We have barely touched many of the capabilities of Docker and Docker Compose,
    and we have not even yet got into looking at using services such as Docker swarm.
    While docker Compose is convenient, it only runs the containers on a single host,
    which ultimately has scalability limitations. Docker swarm will perform similar
    things to Docker Compose, but work that magic across multiple systems within a
    cluster, allowing much greater scalability. But hopefully this has given you a
    feel for the value of Docker and Docker Compose, and how they can be of value
    when creating a flexible scraping service.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎没有涉及Docker和Docker Compose的许多功能，甚至还没有开始研究使用Docker swarm等服务。虽然docker Compose很方便，但它只在单个主机上运行容器，最终会有可扩展性的限制。Docker
    swarm将执行类似于Docker Compose的操作，但是在集群中跨多个系统进行操作，从而实现更大的可扩展性。但希望这让你感受到了Docker和Docker
    Compose的价值，以及在创建灵活的抓取服务时它们的价值。
