- en: Chapter 10. Statistical Programming and Linear Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章。统计编程和线性回归
- en: 'In this chapter, we''ll look at the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究以下内容：
- en: Using the built-in statistics library
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内置的统计库
- en: Average of values in a Counter
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计数器中值的平均值
- en: Computing the coefficient of a correlation
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算相关系数
- en: Computing regression parameters
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算回归参数
- en: Computing an autocorrelation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算自相关
- en: Confirming that the data is random – the null hypothesis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确认数据是随机的-零假设
- en: Locating outliers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定位异常值
- en: Analyzing many variables in one pass
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一次分析多个变量
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Data analysis and statistical processing are very import applications for sophisticated,
    modern programming languages. The subject area is vast. The Python ecosystem includes
    a number of add-on packages that provide sophisticated data exploration, analysis,
    and decision-making features.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析和统计处理是复杂、现代编程语言非常重要的应用。这个领域非常广泛。Python生态系统包括许多附加包，提供了复杂的数据探索、分析和决策功能。
- en: We'll look at some basic statistical calculations that we can do with Python's
    built-in libraries and data structures. We'll look at the question of correlation
    and how to create a regression model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究一些我们可以使用Python内置库和数据结构进行的基本统计计算。我们将研究相关性的问题以及如何创建回归模型。
- en: We'll also look at questions of randomness and the null hypothesis. It's essential
    to be sure that there really is a measurable statistical effect in a set of data.
    We can waste a lot of compute cycles analyzing insignificant noise if we're not
    careful.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论随机性和零假设的问题。确保数据集中确实存在可测量的统计效应是至关重要的。如果不小心的话，我们可能会浪费大量的计算周期来分析无关紧要的噪音。
- en: We'll look at a common optimization technique, as well. It helps to produce
    results quickly. A poorly designed algorithm applied to a very large set of data
    can be an unproductive waste of time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将研究一种常见的优化技术。它有助于快速产生结果。一个设计不良的算法应用于非常大的数据集可能是一种无效的时间浪费。
- en: '![](image/614271.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](image/614271.jpg)'
- en: Using the built-in statistics library
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内置的统计库
- en: 'A great deal of **exploratory data analysis** ( **EDA** ) involves getting
    a summary of the data. There are several kinds of summary that might be interesting:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大量的**探索性数据分析**（**EDA**）涉及到对数据的摘要。有几种可能有趣的摘要：
- en: '**Central Tendency** : Values such as the mean, mode, and median can characterize
    the center of a set of data.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中心趋势**：诸如均值、众数和中位数等值可以描述数据集的中心。'
- en: '**Extrema** : The minimum and maximum are as important as the central measures
    of some data.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**极值**：最小值和最大值和一些数据的中心度量一样重要。'
- en: '**Variance** : The variance and standard deviation are used to describe the
    dispersal of the data. A large variance means the data is widely distributed;
    a small variance means the data clusters tightly around the central value.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差**：方差和标准差用于描述数据的分散程度。大方差意味着数据分布广泛；小方差意味着数据紧密聚集在中心值周围。'
- en: How can we get basic descriptive statistics in Python?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如何在Python中获得基本的描述性统计信息？
- en: Getting ready
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: We'll look at some simple data that can be used for statistical analysis. We've
    been given a file of raw data, called `anscombe.json` . It's a JSON document that
    has four series of ( *x* , *y* ) pairs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究一些可以用于统计分析的简单数据。我们得到了一个原始数据文件，名为`anscombe.json`。它是一个JSON文档，其中包含四个（*x*，*y*）对的系列。
- en: 'We can read this data with the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下方法读取这些数据：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We've defined the `Path` to the data file. We can then use the `Path` object
    to read the text from this file. This text is used by `json.loads()` to build
    a Python object from the JSON data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了数据文件的`Path`。然后我们可以使用`Path`对象来从这个文件中读取文本。`json.loads()`使用这个文本从JSON数据构建Python对象。
- en: We've included an `object_pairs_hook` so that this function will build the JSON
    using the `OrderedDict` class instead of the default `dict` class. This will preserve
    the original order of items in the source document.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经包含了一个`object_pairs_hook`，这样这个函数将使用`OrderedDict`类而不是默认的`dict`类来构建JSON。这将保留源文档中项目的原始顺序。
- en: 'We can examine the data like this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样检查数据：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The overall JSON document is a sequence of subdocuments with keys such as `I`
    and `II` . Each subdocument has two fields—`series` and `data` . Within the `data`
    value, there's a list of observations that we want to characterize. Each observation
    has a pair of values.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 整个JSON文档是一个具有`I`和`II`等键的子文档序列。每个子文档有两个字段-`series`和`data`。在`data`值内，有一个我们想要描述的观察值列表。每个观察值都有一对值。
- en: 'The data looks like this:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据看起来是这样的：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is a list of dict structure, typical of JSON documents. Each dict has a
    series name, with a key `series` , and a sequence of data values, with a key `data`
    . The list within `data` is a sequence of items, and each item has an `x` and
    a `y` value.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个典型的JSON文档的字典列表结构。每个字典都有一个系列名称，带有`series`键，并且一个数据值序列，带有`data`键。`data`中的列表是一系列项目，每个项目都有一个`x`和一个`y`值。
- en: 'To find a specific series in this data structure, we have a number of choices:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要在这个数据结构中找到特定的系列，我们有几种选择：
- en: 'A `for...if...return` statement sequence:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`for...if...return`语句序列：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This `for` statement examines each series in the sequence of values. The series
    is a dictionary with a key of `'series'` that has the series name. The `if` statement
    compares the series name with the target name, and returns the first match. This
    will return `None` for an unknown series name.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`for`语句检查数值序列中的每个系列。系列是一个带有系列名称的键为`'series'`的字典。`if`语句将系列名称与目标名称进行比较，并返回第一个匹配项。对于未知的系列名称，这将返回`None`。
- en: 'We can access the data like this:'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以这样访问数据：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can use a filter that finds all matches, from which the first is selected:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用一个过滤器来找到所有匹配项，然后选择第一个：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This `filter()` function examines each series in the sequence of values. The
    series is a dictionary with a key of `'series'` that has the series name. The
    `name_match` lambda object will compare the name key of the series with the target
    name, and return all of the matches. This is used to build a `list` object. If
    each key is unique, the first item is the only item. This will raise an `IndexError`
    exception for an unknown series name.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`filter（）`函数检查值序列中的每个系列。该系列是一个带有“series”键的字典，其中包含系列名称。`name_match` lambda对象将比较系列的名称键与目标名称，并返回所有匹配项。这用于构建一个`list`对象。如果每个键都是唯一的，第一个项目就是唯一的项目。这将为未知的系列名称引发`IndexError`异常。
- en: 'Now we can access the data like this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以这样访问数据：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can use a generator expression that, similar to the filter, finds all matches.
    We pick the first from the resulting sequence:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用生成器表达式，类似于过滤器，找到所有匹配项。我们从结果序列中选择第一个：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This generator expression examines each series in the sequence of values. The
    series is a dictionary with a key of `'series'` that has the series name. Instead
    of a lambda object, or function, the expression `s['series'] == series_name` will
    compare the name key of the series with the target name, and pass all of the matches.
    This is used to build a `list` object, and the first item from the list is returned.
    This will raise an `IndexError` exception for an unknown series name.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这个生成器表达式检查值序列中的每个系列。该系列是一个带有“series”键的字典，其中包含系列名称。表达式`s['series'] == series_name`将比较系列的名称键与目标名称，并传递所有匹配项。这用于构建一个`list`对象，并返回列表中的第一个项目。这将为未知的系列名称引发`IndexError`异常。
- en: 'Now we can access the data like this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以这样访问数据：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'There are some examples of this kind of processing in the *Implementing "there
    exists" Processing* recipe in [Chapter 8](text00088.html#page "Chapter 8. Functional
    and Reactive Programming Features") , *Functional and Reactive Programming Features*
    Once we''ve picked a series from the data, we''ll also need to pick a variable
    from the series. This can be done with a generator function or a generator expression:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第8章](text00088.html#page "第8章。功能和响应式编程特性")的*实现“存在”处理*配方中有一些这种处理的示例，*功能和响应式编程特性*。一旦我们从数据中选择了一个系列，我们还需要从系列中选择一个变量。这可以通过生成器函数或生成器表达式来完成：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'A series dictionary has a `data` key with the sequence of data values. Each
    data value is a dictionary with two keys, `x` , and `y` . This `data_iter()` function
    will pick one of those variables from each dictionary in the data. This function
    will generate a sequence of values that can be used for detailed analysis:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 系列字典具有带有数据值序列的“data”键。每个数据值都是一个具有两个键“x”和“y”的字典。这个“data_iter（）”函数将从数据中的每个字典中选择其中一个变量。这个函数将生成一系列值，可以用于详细分析：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this case, we picked the series `IV` . From that series, we picked the `x`
    variable from each observation. The length of the resulting list shows us that
    there were 11 observations in this series.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们选择了系列`IV`。从该系列中，我们选择了每个观察的`x`变量。结果列表的长度向我们展示了该系列中有11个观察。
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'To compute the mean and median, use the `statistics` module:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要计算均值和中位数，使用`statistics`模块：
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This uses `get_series()` and `data_iter()` to select sample values from one
    variable of a given series. The `mean()` and `median()` functions handle this
    task nicely. There are several variations on the median calculation that are available.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用`get_series（）`和`data_iter（）`从给定系列的一个变量中选择样本值。`mean（）`和`median（）`函数很好地处理了这个任务。有几种可用的中位数计算变体。
- en: 'To compute `mode` , use the collections module:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要计算`mode`，使用`collections`模块：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This uses `get_series()` and `data_iter()` to select sample values from one
    variable of a given series. The `Counter` object does this job very elegantly.
    We actually get a complete frequency histogram from this operation. The result
    of the `most_common()` method shows both the value and the number of times it
    occurred.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用`get_series（）`和`data_iter（）`从给定系列的一个变量中选择样本值。`Counter`对象非常优雅地完成了这项工作。实际上，我们从这个操作中得到了一个完整的频率直方图。`most_common（）`方法的结果显示了值和它出现的次数。
- en: We can also use the `mode()` function in the `statistics` module. This function
    has the advantage of raising an exception when there is no obvious mode. This
    has the disadvantage of not providing any additional information to help locate
    multimodal data.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`statistics`模块中的`mode（）`函数。该函数的优点是在没有明显模式时引发异常。这的缺点是没有提供任何额外的信息来帮助定位多模态数据。
- en: 'The extrema are computed with the built-in `min()` and `max()` functions:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 极值是用内置的`min（）`和`max（）`函数计算的：
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This uses `get_series()` and `data_iter()` to select sample values from one
    variable of a given series. The built-in `max()` and `min()` functions provide
    the values for the extrema.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用`get_series（）`和`data_iter（）`从给定系列的一个变量中选择样本值。内置的`max（）`和`min（）`函数提供了极值。
- en: 'To compute variance (and standard deviation), we can also use the `statistics`
    module:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要计算方差（和标准差），我们也可以使用`statistics`模块：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This uses `get_series()` and `data_iter()` to select sample values from one
    variable of a given series. The statistics module provides the `variance()` and
    `stdev()` functions that compute the statistical measures of interest.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用`get_series（）`和`data_iter（）`从给定系列的一个变量中选择样本值。统计模块提供了计算感兴趣的统计量的`variance（）`和`stdev（）`函数。
- en: How it works...
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'These functions are generally first class parts of the Python standard library.
    We''ve looked in three places for useful functions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数通常是Python标准库的一等部分。我们已经在三个地方寻找了有用的函数：
- en: The `min()` and `max()` functions are built-in.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min（）`和`max（）`函数是内置的。'
- en: The `collections` module has the `Counter` class, which can create a frequency
    histogram. We can get the mode from this.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collections`模块有`Counter`类，可以创建频率直方图。我们可以从中获取众数。'
- en: The `statistics` module has `mean()` , `median()` , `mode()` , `variance()`
    , and `stdev()` , which provide a variety of statistical measures.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`statistics`模块有`mean()`、`median()`、`mode()`、`variance()`和`stdev()`，提供各种统计量。'
- en: Note that `data_iter()` is a generator function. We can only use the results
    of this generator once. If we only want to compute a single statistical summary
    value, that will work nicely.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`data_iter()`是一个生成器函数。我们只能使用这个生成器的结果一次。如果我们只想计算单个统计摘要值，那将非常有效。
- en: When we want to compute more than one value, we need to capture the result of
    the generator in a collection object. In these examples, we've used `data_iter()`
    to build a `list` object so that we can process it more than once.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要计算多个值时，我们需要将生成器的结果捕获到一个集合对象中。在这些示例中，我们使用`data_iter()`来构建一个`list`对象，以便我们可以多次处理它。
- en: There's more...
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Our original data structure, `data` , is a sequence of mutable dictionaries.
    Each dictionary has two keys—`series` and `data` . We can update this dictionary
    with the statistical summaries. The resulting object can be saved for later analysis
    or display.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的原始数据结构`data`是一系列可变字典。每个字典有两个键——`series`和`data`。我们可以用统计摘要更新这个字典。生成的对象可以保存以供以后分析或显示。
- en: 'Here''s a starting point for this kind of processing:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这种处理的起点：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: For each one one the data series, we've used the `data_iter()` function to extract
    the individual samples. We've applied the `mean()` function to those samples.
    The result is saved back into the `series` object, using a string key made from
    the function name, `mean` , the `_` character, and the `variable_name` .
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个数据系列，我们使用`data_iter()`函数提取单独的样本。我们对这些样本应用`mean()`函数。结果保存回`series`对象，使用由函数名称`mean`、`_`字符和`variable_name`组成的字符串键。
- en: 'Note that a great deal of this function is boilerplate code. The overall structure
    would have to be repeated for median, mode, minimum, maximum, and so on. Looking
    at changing the function from `mean()` to something else shows that there are
    two things that change in this boilerplate code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个函数的大部分内容都是样板代码。整体结构需要重复用于中位数、众数、最小值、最大值等。将函数从`mean()`更改为其他内容时，可以看到这个样板代码中有两个变化的地方：
- en: The key that is used to update the series data
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于更新系列数据的键
- en: The function that's evaluated for the selected sequence of samples
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对所选样本序列进行评估的函数
- en: 'We don''t need to supply the function''s name; we can extract the name from
    a function object as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要提供函数的名称；我们可以从函数对象中提取名称，如下所示：
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This means that we can write a higher-order function that applies a number
    of functions to a set of samples:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以编写一个高阶函数，将一系列函数应用到一组样本中：
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We've replaced the specific function, `mean()` , with a parameter name, `function`
    , that can be bound to any Python function. The processing will apply the given
    function to the results of `data_iter()` . This summary is then used to update
    the series dictionary using the function's name, the `_` character, and the `variable_name`
    .
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用参数名`function`替换了特定的函数`mean()`，这个参数名可以绑定到任何Python函数。处理将应用给定的函数到`data_iter()`的结果。然后使用这个摘要来更新系列字典，使用函数的名称、`_`字符和`variable_name`。
- en: 'This higher-level `set_summary()` function looks like this:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更高级的`set_summary()`函数看起来像这样：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This will update our document with four summaries based on `mean()` , `median()`
    , `max()` , and `min()` . We can use any Python function, so functions such as `sum()`
    can be used in addition to functions like those shown earlier.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这将基于`mean()`、`median()`、`max()`和`min()`更新我们的文档。我们可以使用任何Python函数，因此除了之前显示的函数之外，还可以使用`sum()`等函数。
- en: Because `statistics.mode()` will raise an exception for cases where there's
    no single modal value, this function may need a `try:` block to catch the exception
    and put some useful result into the `series` object. It may also be appropriate
    to allow the exception to propagate to notify the collaborating function that
    the data is suspicious.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因为`statistics.mode()`对于没有单一众数值的情况会引发异常，所以这个函数可能需要一个`try:`块来捕获异常，并将一些有用的结果放入`series`对象中。也可能适当地允许异常传播，以通知协作函数数据是可疑的。
- en: 'Our revised document will look like this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们修改后的文档将如下所示：
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can save this to a file and use it for further analysis. Using `pathlib`
    to work with file names, we might do something like this:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其保存到文件中，并用于进一步分析。使用`pathlib`处理文件名，我们可以做如下操作：
- en: '[PRE20]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This will create a second file adjacent to the source file. The name will have
    the same stem as the source file, but the stem will be extended with the string
    `_stats` and a suffix of `.json` .
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个与源文件相邻的第二个文件。名称将与源文件具有相同的词干，但词干将扩展为字符串`_stats`和后缀`.json`。
- en: Average of values in a Counter
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计数器中值的平均值
- en: The `statistics` module has a number of useful functions. These are based on
    having each individual data sample available for processing. In some cases, however,
    the data has been grouped into bins. We might have a `collections.Counter` object
    instead of a simple list. Rather than values, we now have (value, frequency) pairs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`statistics`模块有许多有用的函数。这些函数是基于每个单独的数据样本可用于处理。然而，在某些情况下，数据已经被分组到箱中。我们可能有一个`collections.Counter`对象，而不是一个简单的列表。现在我们不是值，而是（值，频率）对。'
- en: How can we do statistical processing on (value, frequency) pairs?
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如何对（值，频率）对进行统计处理？
- en: Getting ready
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'The general definition of the mean is the sum of all of the values divided
    by the number of values. It''s often written like this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 均值的一般定义是所有值的总和除以值的数量。通常写成这样：
- en: '![Getting ready](Image00027.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](Image00027.jpg)'
- en: We've defined some set of data, *C* , as a sequence of individual values, *C*
    = { *c* [0] *, c* [1] *, c* [2] *, ... ,c[n]* }, and so on. The mean of this collection,
    μ [*C*] , is the sum of the values over the number of values, *n* .
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将一些数据集*C*定义为一系列单独的值，*C* = {*c*[0], *c*[1], *c*[2], ... ,c[n]},等等。这个集合的平均值，μ[*C*]，是值的总和除以值的数量*n*。
- en: 'There''s a tiny change that helps to generalize this definition:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个微小的变化有助于概括这个定义：
- en: '![Getting ready](Image00028.jpg)![Getting ready](Image00029.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](Image00028.jpg)![准备就绪](Image00029.jpg)'
- en: The value of *S* ( *C* ) is the sum of the values. The value of *n* ( *C* )
    is the sum using one instead of each value. In effect,  *S* ( *C* ) is the sum
    of *c* [*i*] ¹ and  *n* ( *C* ) is the sum of  *c* [*i*] ⁰ . We can easily implement
    these as simple Python generator expressions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*S*（*C*）的值是值的总和。 *n*（*C*）的值是使用每个值的代替的总和。 实际上，*S*（*C*）是*c*[*i*]¹的总和，*n*（*C*）是*c*[*i*]⁰的总和。
    我们可以很容易地将这些实现为简单的Python生成器表达式。'
- en: 'We can reuse these definition in a number of places. Specifically, we can now
    define the mean, μ [*C*] , like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在许多地方重用这些定义。 具体来说，我们现在可以这样定义均值，μ [*C*]：
- en: μ [*C *] = *S* ( *C* )/ *n* ( *C* )
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: μ [*C*] = *S*（*C*）/ *n*（*C*）
- en: 'We will use this general idea to provide statistical calculations on data that''s
    already been collected into bins. When we have a `Counter` object, we have values
    and frequencies. The data structure can be described like this:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个一般想法对已经收集到箱中的数据进行统计计算。 当我们有一个`Counter`对象时，我们有值和频率。 数据结构可以描述如下：
- en: '*F* = { *c* [0] : *f* [0] , *c* [1] : *f* [1] , *c* [2] : *f* [2] , ... *c[m]*
    : *f[m]* }'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*F* = { *c* [0] : *f* [0] , *c* [1] : *f* [1] , *c* [2] : *f* [2] , ... *c[m]*
    : *f[m]* }'
- en: 'The values, *c[i]* , are paired with a frequency, *f[i]* . This makes two small
    changes to perform similar calculations for ![Getting ready](Image00030.jpg)  and
    ![Getting ready](Image00031.jpg)  :'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 值*c[i]*与频率*f[i]*配对。 这对执行类似的计算进行了两个小的更改：
- en: '![Getting ready](Image00032.jpg)![Getting ready](Image00033.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](Image00032.jpg)![准备就绪](Image00033.jpg)'
- en: We've defined ![Getting ready](Image00030.jpg)  to use the product of frequency
    and value. Similarly, we've defined ![Getting ready](Image00031.jpg)  to use the
    frequencies. We've included the hat, ^, on each name to make it clear that these
    functions don't work for simple lists of values; these functions work for lists
    of (value, frequency) pairs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了![准备就绪](Image00030.jpg)使用频率和值的乘积。 类似地，我们已经定义了![准备就绪](Image00031.jpg)使用频率。
    我们在每个名称上都包含了帽子^，以清楚地表明这些函数不适用于简单值列表； 这些函数适用于（值，频率）对的列表。
- en: 'These need to be implemented in Python. As an example, we''ll use the following
    `Counter` object:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这些需要在Python中实现。 例如，我们将使用以下`Counter`对象：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This data is from the *Using the built-in statistics library* recipe. The `Counter`
    object looks like this:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据来自*使用内置统计库*配方。 `Counter`对象如下所示：
- en: '[PRE22]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This shows the various values in a set of samples as well as the frequencies
    for each distinct value.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了样本集中的各个值以及每个不同值的频率。
- en: How to do it...
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Define the sum of a `Counter` :'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`Counter`的总和：
- en: '[PRE23]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can use this as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样使用：
- en: '[PRE24]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Define the total number of values in a `Counter` :'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`Counter`中值的总数：
- en: '[PRE25]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can use this as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样使用：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can now combine these to compute a mean of data that has been put into bins:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以将这些组合起来计算已经放入箱中的数据的均值：
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: A `Counter` is a dictionary. The keys of this dictionary are the actual values
    being counted. The values in the dictionary are the frequencies for each item.
    This means that the `items()` method will produce value and frequency information
    that can be used by our calculations.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`Counter`是一个字典。 此字典的键是实际计数的值。 字典中的值是每个项目的频率。 这意味着`items()`方法将生成可以被我们的计算使用的值和频率信息。'
- en: We've transformed each of the definitions for ![How it works...](Image00030.jpg)  and ![How
    it works...](Image00031.jpg)  into generator expressions. Because Python is designed
    to follow the mathematical formalisms closely, the code follows the math in a
    relatively direct way.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将每个定义![它是如何工作...](Image00030.jpg)和![它是如何工作...](Image00031.jpg)转换为生成器表达式。
    因为Python被设计为紧密遵循数学形式主义，所以代码以相对直接的方式遵循数学。
- en: There's more...
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To compute the variance (and standard deviation) we''ll need two more variations
    on this theme. We can define an overall mean of a frequency distribution, μ [*F*]
    :'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算方差（和标准偏差），我们需要对这个主题进行两个更多的变化。 我们可以定义频率分布的总体均值，μ [*F*]：
- en: '![There''s more...](Image00034.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![更多内容...](Image00034.jpg)'
- en: Where *c[i]* is the key from the `Counter` object, *F* , and *f[i]* is the frequency
    value for the given key from the `Counter` object.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*c[i]*是`Counter`对象*F*的键，*f[i]*是`Counter`对象给定键的频率值。
- en: 'The variance, VAR [*F*] , can be defined in a way that depends on the mean,
    μ [*F*] . The formula is this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 方差，VAR [*F*]，可以以依赖于均值，μ [*F*]的方式定义。 公式如下：
- en: '![There''s more...](Image00035.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![更多内容...](Image00035.jpg)'
- en: This computes the difference between a value, *c* [*i*] , and the mean μ [*F*]
    . This is weighted by the number of times this value occurs, *f[i]* . The sum
    of these weighted differences is divided by the count, ![There's more...](Image00031.jpg)  ,
    minus one.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这计算了值*c*[*i*]与均值μ[*F*]之间的差异。 这是由该值出现的次数*f[i]*加权的。 这些加权差的总和除以计数，![更多内容...](Image00031.jpg)，减去一。
- en: 'The standard deviation, σ [*F*] , is the square root of the variance:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 标准偏差，σ [*F*]，是方差的平方根：
- en: σ [*F*] = √VAR [*F*]
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: σ [*F*] = √VAR [*F*]
- en: This version of the standard deviation is quite stable mathematically, and therefore
    is preferred. It requires two passes through the data, but for some edge cases,
    the cost of making multiple passes is better than an erroneous result.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个标准偏差的版本在数学上非常稳定，因此更受青睐。 它需要对数据进行两次传递，但对于一些边缘情况，进行多次传递的成本要好于错误的结果。
- en: 'Another variation on the calculation does not depend on the mean, μ [*F*] .
    This isn''t as mathematically stable as the previous version. This variation separately
    computes the sum of squares of values, the sum of the values, and the count of
    the values:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 计算的另一个变化不依赖于均值，μ [*F*]。 这不像以前的版本那样在数学上稳定。 这种变化分别计算值的平方和，值的总和以及值的计数：
- en: '![There''s more...](Image00036.jpg)![There''s more...](Image00037.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![更多内容...](Image00036.jpg)![更多内容...](Image00037.jpg)'
- en: 'This requires one extra sum computation. We''ll need to compute the sum of
    the values squared, ![There''s more...](Image00038.jpg)  :'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要额外的一次求和计算。我们需要计算值的平方和，![更多内容...](Image00038.jpg)：
- en: '[PRE28]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Given these three sum functions, ![There''s more...](Image00031.jpg)  , ![There''s
    more...](Image00030.jpg)  , and ![There''s more...](Image00039.jpg)  , we can
    define the variance for a binned summary,  *F*  :'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这三个求和函数，![更多内容...](Image00031.jpg) ，![更多内容...](Image00030.jpg) ，和![更多内容...](Image00039.jpg)
    ，我们可以定义分箱摘要的方差，*F*：
- en: '[PRE29]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The `counter_variance()` function fits the mathematical definition very closely.
    The Python version moves the 1/( *n* - 1) term around as a minor optimization.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`counter_variance()`函数非常接近数学定义。Python版本将1/( *n* - 1)项作为次要优化移动。'
- en: 'Using the `counter_variance()` function, we can compute the standard deviation:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`counter_variance()`函数，我们可以计算标准差：
- en: '[PRE30]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This allows us to see the following:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够看到以下内容：
- en: '[PRE31]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can also make use of the `elements()` method of a `Counter` object. While
    simple, this will create a potentially large intermediate data structure:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以利用`Counter`对象的`elements()`方法。虽然简单，但这将创建一个潜在的大型中间数据结构：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We've used the `elements()` method of a `Counter` object to create an expanded
    list of all of the elements in the counter. We can compute statistical summaries
    of these elements. For a large `Counter` , this can become a very large intermediate
    data structure.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用`Counter`对象的`elements()`方法创建了计数器中所有元素的扩展列表。我们可以计算这些元素的统计摘要。对于一个大的`Counter`，这可能会成为一个非常大的中间数据结构。
- en: See also
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In the  *Designing classes with lots of processing*  recipe in [Chapter 6](text00070.html#page
    "Chapter 6. Basics of Classes and Objects") , *Basics of Classes and Objects,*
    we looked at this from a slightly different perspective. In that recipe, our objective
    was simply to conceal a complex data structure.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第6章](text00070.html#page "第6章. 类和对象的基础")的*设计具有大量处理的类*配方中，我们从略微不同的角度看待了这个问题。在那个配方中，我们的目标只是隐藏一个复杂的数据结构。
- en: The *Analyzing many variables in one pass* recipe, in this chapter will address
    some efficiency considerations. In that recipe, we'll look at ways to compute
    multiple sums in a single pass through the data elements.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的*一次性分析多个变量*配方将解决一些效率方面的考虑。在该配方中，我们将探讨通过数据元素的单次遍历来计算多个求和的方法。
- en: Computing the coefficient of a correlation
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算相关系数
- en: In the  *Using the built-in statistics library* and *Average of values in a
    Counter*  recipes, we looked at ways to summarize data. These recipes showed how
    to compute a central value, as well as variance and extrema.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在*使用内置统计库*和*计数器中的值的平均值*配方中，我们探讨了总结数据的方法。这些配方展示了如何计算中心值，以及方差和极值。
- en: Another common statistical summary involves the degree of correlation between
    two sets of data. This is not directly supported by Python's standard library.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的统计摘要涉及两组数据之间的相关程度。这不是Python标准库直接支持的。
- en: One commonly used metric for correlation is called **Pearson's r** . The *r*
    -value is number between -1 and +1 that expresses the probability that the data
    values will correlate with each other.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性的一个常用度量标准称为**皮尔逊相关系数**。*r* -值是-1到+1之间的数字，表示数据值之间相关的概率。
- en: 'A value of zero says the data is random. A value of *0.95* suggests that 95%
    of the values correlate, and 5% don''t correlate well. A value of *-.95* says
    that 95% of the values have an inverse correlation: when one variable increases,
    the other decreases.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 零值表示数据是随机的。*0.95*的值表示95%的值相关，5%的值不相关。*-.95*的值表示95%的值具有反向相关性：一个变量增加时，另一个变量减少。
- en: How can we determine if two sets of data correlate?
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何确定两组数据是否相关？
- en: Getting ready
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'One expression for Pearson''s *r* is this:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 皮尔逊*r*的一个表达式是这样的：
- en: '![Getting ready](Image00040.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![准备工作](Image00040.jpg)'
- en: This relies on a large number of individual summations of various parts of a
    dataset. Each of the ∑ *z* operators can be implemented via the Python `sum()`
    function.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这依赖于数据集各个部分的大量单独求和。每个∑ *z* 运算符都可以通过Python的`sum()`函数实现。
- en: 'We''ll use data from the *Using the built-in statistics library* recipe. We
    can read this data with the following:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用*使用内置统计库*配方中的数据。我们可以用以下方法读取这些数据：
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We've defined the `Path` to the data file. We can then use the `Path` object
    to read the text from this file. This text is used by `json.loads()` to build
    a Python object from the JSON data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了数据文件的`Path`。然后我们可以使用`Path`对象从该文件中读取文本。这个文本被`json.loads()`用来从JSON数据构建Python对象。
- en: We've included an `object_pairs_hook` so that this function will build the JSON
    using the `OrderedDict` class instead of the default `dict` class. This will preserve
    the original order of items in the source document.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经包含了一个`object_pairs_hook`，这样这个函数将使用`OrderedDict`类构建JSON，而不是默认的`dict`类。这将保留源文档中项目的原始顺序。
- en: 'We can examine the data like this:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样检查数据：
- en: '[PRE34]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The overall JSON document is a sequence of subdocuments with keys like `I` .
    Each subdocument has two fields—`series` and `data` . Within the `data` value
    there's a list of observations that we want to characterize. Each observation
    has a pair of values.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 整个JSON文档是一个具有`I`等键的子文档序列。每个子文档有两个字段—`series`和`data`。在`data`值中有一个我们想要描述的观察值列表。每个观察值都有一对值。
- en: 'The data looks like this:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 数据看起来是这样的：
- en: '[PRE35]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This set of data has four series, each of which is represented as a list-of-dict
    structures. Within each series, the individual items are a dictionary with `x`
    and `y` keys.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这组数据有四个系列，每个系列都表示为字典列表结构。在每个系列中，各个项都是具有`x`和`y`键的字典。
- en: How to do it...
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Identify the various kinds of sums required. For this expression, we see the
    following:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别所需的各种求和。对于这个表达式，我们看到以下内容：
- en: ∑ *x[i] , y[i]*
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ∑ *x[i] , y[i]*
- en: ∑ *x[i]*
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ∑ *x[i]*
- en: ∑ *y[i]*
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ∑ *y[i]*
- en: ∑ *x[i]* ²
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ∑ *x[i]* ²
- en: ∑ *y[i]* ²
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ∑ *y[i]* ²
- en: '![How to do it...](Image00041.jpg)'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![How to do it...](Image00041.jpg)'
- en: The count, *n* , can be defined really as the sum of one for each data in the
    source dataset. This can also be thought of as  *x[i]* ^∘ or *y[i]* ^∘ .
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 计数*n*可以真正定义为源数据集中每个数据的总和。这也可以被认为是*x[i]* ^∘或*y[i]* ^∘。
- en: 'Import the `sqrt()` function from the `math` module:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`math`模块导入`sqrt()`函数：
- en: '[PRE36]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Define a function that wraps the calculation:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个包装计算的函数：
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Write the various sums using the built-in `sum()` function. This is indented
    within the function definition. We''ll use the value of the `data` parameter:
    a sequence of values from a given series. The input data must have two keys, `x`
    and `y` :'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用内置的`sum()`函数编写各种总和。这是在函数定义内缩进的。我们将使用`data`参数的值：给定系列的一系列值。输入数据必须有两个键，`x`和`y`：
- en: '[PRE38]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Write the final calculation of *r* based on the various sums. Be sure the indentation
    matches properly. For more help, see [Chapter 3](text00039.html#page "Chapter 3. Function
    Definitions") , *Function Definitions* :'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据各种总和的最终计算*r*。确保缩进正确匹配。有关更多帮助，请参阅[第3章](text00039.html#page "第3章。函数定义")，*函数定义*：
- en: '[PRE39]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can now use this to determine the degree of correlation between the various
    series:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用这个来确定各个系列之间的相关程度：
- en: '[PRE40]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output looks like this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE41]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: All four series have approximately the same coefficient of correlation. This
    doesn't mean the series are related to each other. It means that within each series,
    82% of the *x* values predict a *y* value. This is almost exactly nine of the
    11 values in each series.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 所有四个系列的相关系数大致相同。这并不意味着这些系列彼此相关。这意味着在每个系列中，82%的*x*值可以预测*y*值。这几乎正好是每个系列中的11个值中的9个。
- en: How it works...
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The overall formula looks rather complex. However, it decomposes into a number
    of separate sums and a final calculation that combines the sums. Each of the sums
    operations can be expressed very succinctly in Python.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 总体公式看起来相当复杂。但是，它可以分解为许多单独的总和和结合这些总和的最终计算。每个总和操作都可以用Python非常简洁地表示。
- en: 'Conventionally, the mathematical notation might look like the following:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，数学表示法可能如下所示：
- en: '![How it works...](Image00042.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![How it works...](Image00042.jpg)'
- en: 'This translates to Python in a very direct way:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这在Python中以非常直接的方式进行翻译：
- en: '[PRE42]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The final correlation ratio can be simplified somewhat. When we replace the
    more complex looking ![How it works...](Image00042.jpg)  with the slightly more
    Pythonic  *S*  ( *x* ), we can better see the overall form of the equation:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的相关系数可以简化一些。当我们用稍微更Pythonic的*S*（*x*）替换更复杂的![How it works...](Image00042.jpg)时，我们可以更好地看到方程的整体形式：
- en: '![How it works...](Image00043.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![How it works...](Image00043.jpg)'
- en: While simple, the implementation shown isn't optimal. It makes six separate
    passes over the data to compute each of the various reductions. As a kind of proof
    of concept this implementation works well. This implementation has the advantage
    of demonstrating that the programming works. It also serves as a starting point
    for creating unit tests and refactoring the algorithm to optimize the processing.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然简单，但所示的实现并不是最佳的。它需要对数据进行六次单独的处理，以计算各种缩减。作为一种概念验证，这种实现效果很好。这种实现的优势在于证明了编程的可行性。它还可以作为创建单元测试和重构算法以优化处理的起点。
- en: There's more...
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The algorithm, while clear, is inefficient. A more efficient version would process
    the data once. To do this, we'll have to write an explicit `for` statement that
    makes a single pass through the data. Within the body of the `for` statement,
    the various sums are computed.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法虽然清晰，但效率低下。更有效的版本将一次处理数据。为此，我们将不得不编写一个明确的`for`语句，通过数据进行一次遍历。在`for`语句的主体内，计算各种总和。
- en: 'An optimized algorithm looks like this:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 优化的算法看起来像这样：
- en: '[PRE43]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We've initialized a number of results to zero, then accumulated values into
    these results from a source of data items, `data` . Since this uses the data value
    once only, this will work with any iterable data source.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将许多结果初始化为零，然后从数据项的源`data`中累积值到这些结果中。由于这只使用了数据值一次，所以这将适用于任何可迭代的数据源。
- en: The calculation of *r* from these sums doesn't change.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些总和计算*r*的算法不会改变。
- en: 'What''s important is the parallel structure between the initial version of
    the algorithm and the revised version that has been optimized to compute all of
    the summaries in one pass. The clear symmetry of the two versions helps validate
    two things:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是初始版本的算法和已经优化为一次性计算所有摘要的修订版本之间的并行结构。两个版本的明显对称性有助于验证两件事：
- en: The initial implementation matches the rather complex formula
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始实现与相当复杂的公式匹配
- en: The optimized implementation matches the initial implementation and the complex
    formula
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化后的实现与初始实现和复杂的公式匹配
- en: This symmetry coupled with proper test cases provides confidence that the implementation
    is correct.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对称性结合适当的测试用例，可以确保实现是正确的。
- en: Computing regression parameters
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算回归参数
- en: Once we've determined that two variables have some kind of relationship, the
    next step is to determine a way to estimate the dependent variable from the value
    of the independent variable. With most real-world data, there are a number of
    small factors that will lead to random variation around a central trend. We'll
    be estimating a relationship that minimizes these errors.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了两个变量之间存在某种关系，下一步就是确定一种估计因变量的方法，以便从自变量的值中估计。对于大多数现实世界的数据，会有许多小因素导致围绕中心趋势的随机变化。我们将估计一种最小化这些误差的关系。
- en: In the simplest cases, the relationship between variables is linear. When we
    plot the data points, they will tend to cluster around a line. In other cases,
    we can adjust one of the variables by computing a logarithm or raising it to a
    power to create a linear model. In more extreme cases, a polynomial is required.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在最简单的情况下，变量之间的关系是线性的。当我们绘制数据点时，它们会倾向于聚集在一条直线周围。在其他情况下，我们可以通过计算对数或将变量提高到幂来调整其中一个变量，从而创建一个线性模型。在更极端的情况下，需要多项式。
- en: How can we compute the linear regression parameters between two variables?
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何计算两个变量之间的线性回归参数？
- en: Getting ready
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The equation for an estimated line is this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 估计线的方程式是这样的：
- en: '![Getting ready](Image00044.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](Image00044.jpg)'
- en: Given the independent variable, *x* , the estimated or predicted value of the
    dependent variable, ![Getting ready](Image00045.jpg)  , is computed from the α
    and β parameters.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 给定自变量*x*，依赖变量*y*的估计或预测值![准备就绪](Image00045.jpg)是通过α和β参数计算得到的。
- en: 'The goal is to find values of α and β that produce the minimal overall error
    between the estimated values, ![Getting ready](Image00045.jpg)  , and the actual
    values for  *y*  . Here''s the computation of β:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是找到α和β的值，使得估计值![准备就绪](Image00045.jpg)和*y*的实际值之间的总体误差最小。这里是β的计算：
- en: β = *r[xy]* (σ [*x*] /σ *[y]* )
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: β = *r[xy]* (σ [*x*] /σ *[y]* )
- en: Where  *r[xy]* is the correlation coefficient. See the *Computing the coefficient
    of correlation* recipe. The definition of σ [*x*] is the standard deviation of
    *x* . This value is given directly by the `statistics` module.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*r[xy]*是相关系数。参见*计算相关系数*配方。σ [*x*]的定义是*x*的标准偏差。这个值可以直接通过`statistics`模块得到。
- en: 'Here''s the computation of α:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是α的计算：
- en: α = μ [*y*] - βμ [*x*]
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: α = μ [*y*] - βμ [*x*]
- en: Where μ [*x*] is the mean of of *x* . This, also, is given directly by the `statistics`
    module.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 其中μ [*x*]是*x*的均值。这也可以直接通过`statistics`模块得到。
- en: 'We''ll use data from the *Using the built-in statistics library* recipe. We
    can read this data with the following:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用*使用内置统计库*配方中的数据。我们可以用以下方法读取这些数据：
- en: '[PRE44]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: We've defined the `Path` to the data file. We can then use the `Path` object
    to read the text from this file. This text is used by `json.loads()` to build
    a Python object from the JSON data.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了数据文件的`Path`。然后我们可以使用`Path`对象从这个文件中读取文本。这个文本被`json.loads()`用来从JSON数据构建一个Python对象。
- en: We've included an `object_pairs_hook` so that this function will build the JSON
    using the `OrderedDict` class instead of the default `dict` class. This will preserve
    the original order of items in the source document.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经包含了一个`object_pairs_hook`，这样这个函数将使用`OrderedDict`类来构建JSON，而不是默认的`dict`类。这将保留源文档中项目的原始顺序。
- en: 'We can examine the data like the following:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像下面这样检查数据：
- en: '[PRE45]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The overall JSON document is a sequence of subdocuments with keys such as `I`
    . Each subdocument has two fields: `series` and `data` . Within the `data` value
    there''s a list of observations that we want to characterize. Each observation
    has a pair of values.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 整个JSON文档是一个具有诸如`I`之类的键的子文档序列。每个子文档有两个字段：`series`和`data`。在`data`值内部有一个我们想要描述的观察值列表。每个观察值都有一对值。
- en: 'The data looks like this:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 数据看起来是这样的：
- en: '[PRE46]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This set of data has four series, each of which is represented as a list-of-dict
    structures. Within each series, the individual items are a dictionary with `x`
    and `y` keys.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这组数据有四个系列，每个系列都表示为一个字典结构的列表。在每个系列中，各个项目都是一个带有`x`和`y`键的字典。
- en: How to do it...
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the `correlation()` function and the `statistics` module:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`correlation()`函数和`statistics`模块：
- en: '[PRE47]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Define a function that will produce the regression model, `regression()` :'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个将产生回归模型的函数，`regression()`：
- en: '[PRE48]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Compute the various values required:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所需的各种值：
- en: '[PRE49]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Compute the β and α values:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算β和α的值：
- en: '[PRE50]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We can use this `regression()` function to compute the regression parameters
    like the following:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个`regression()`函数来计算回归参数，如下所示：
- en: '[PRE51]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output shows the formula that predicts an expected `y` from a given `x`
    value. The output looks like this:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了一个预测给定`x`值的期望`y`的公式。输出如下：
- en: '[PRE52]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: In all cases, the equations are ![How to do it...](Image00046.jpg)  . This estimation
    appears to be a pretty good predictor of the the actual values of  *y*  .
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有情况下，方程式都是![如何做...](Image00046.jpg)。这个估计似乎是实际*y*值的一个相当好的预测器。
- en: How it works...
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The two target formulae for α and β are not complex. The formula for β decomposes
    into the correlation value used with two standard deviations. The formula for α
    uses the β value and two means. Each of these is part of a previous recipe. The
    correlation calculation contains the actual complexity.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: α和β的两个目标公式并不复杂。β的公式分解为使用两个标准偏差的相关值。α的公式使用β值和两个均值。这些都是以前配方的一部分。相关性计算包含了实际的复杂性。
- en: The core design technique is to build new features using as many existing features
    as possible. This spreads the test cases around so that the foundational algorithms
    are used (and tested) widely.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 核心设计技术是使用尽可能多的现有特征构建新特征。这样可以使测试用例分布到基础算法上，从而广泛使用（和测试）基础算法。
- en: The analysis of the performance of *Computing the coefficient of a correlation*
    is important, and applies here, as well. This process makes five separate passes
    over the data to get the correlation as well as the various means and standard
    deviations.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '*计算相关系数*的性能分析很重要，在这里也适用。这个过程对数据进行了五次单独的遍历，以获得相关性以及各种均值和标准偏差。'
- en: As a kind of proof of concept, this implementation demonstrates that the algorithm
    will work. It also serves as a starting point for creating unit tests. Given a
    working algorithm, then, it makes sense to refactor the code to optimize the processing.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 作为概念验证，这个实现证明了算法是有效的。它也作为创建单元测试的起点。有了一个有效的算法，对代码进行重构以优化处理是有意义的。
- en: There's more...
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The algorithm shown earlier, while clear, is inefficient. In order to process
    the data once, we''ll have to write an explicit `for` statement that makes a single
    pass through the data. Within the body of the `for` statement, we''ll need to
    compute the various sums. We''ll also need to compute some values derived from
    the sums, including the mean and standard deviation:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 之前显示的算法虽然清晰，但效率低下。为了处理数据一次，我们将不得不编写一个明确的`for`语句，通过数据进行一次遍历。在`for`语句的主体内，我们需要计算各种和。我们还需要计算一些从总和中派生的值，包括平均值和标准差：
- en: '[PRE53]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We've initialized a number of results to zero, then accumulated values into
    these results from a source of data items, `data` . Since this uses the data value
    once only, this will work with any iterable data source.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将一些结果初始化为零，然后从数据项源`data`中累积值到这些结果中。由于这只使用了数据值一次，因此这将适用于任何可迭代的数据源。
- en: The calculation of `r_xy` from these sums doesn't change from the previous examples.
    Nor does the calculation of the α or β values, `a` and `b` . Since these final
    results are the same as the previous version, we have confidence that this optimization
    will compute the same answer but do it with only one pass over the data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些总和中计算`r_xy`的计算与之前的示例没有变化。`α`或`β`值的计算也没有变化，`a`和`b`。由于这些最终结果与以前版本相同，我们有信心这种优化将计算出相同的答案，但只需对数据进行一次遍历。
- en: Computing an autocorrelation
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算自相关
- en: In many cases, events occur in a repeating cycle. If the data correlates with
    itself, this is called an autocorrelation. With some data, the interval may be
    obvious because there's some visible external influence, such as seasons or tides.
    With some data, the interval may be difficult to discern.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，事件会以重复的周期发生。如果数据与自身相关，这被称为自相关。对于一些数据，间隔可能很明显，因为有一些可见的外部影响，比如季节或潮汐。对于一些数据，间隔可能很难辨别。
- en: In the *Computing the coefficient of a correlation* recipe, we looked at a way
    to measure correlation between two sets of data.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在*计算相关系数*配方中，我们看了一种测量两组数据之间相关性的方法。
- en: If we suspect we have cyclic data, can we leverage the previous correlation
    function to compute an autocorrelation?
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们怀疑我们有循环数据，我们能否利用以前的相关函数来计算自相关？
- en: Getting ready
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The core concept behind autocorrelation is the idea of a correlation through
    a shift in time, T. The measurement for this is sometimes expressed as *r[xx]*
    (T): the correlation between *x* and *x* with a time shift of T.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 自相关的核心概念是通过时间偏移T进行相关性的想法。这种测量有时被表达为*r[xx]*（T）：*x*和具有时间偏移T的*x*之间的相关性。
- en: 'Assume we have a handy correlation function, *R* ( *x* , *y* ). It compares
    two sequences, [ *x* [0] , *x* [1] , *x* [2] , ...] and [ *y* [0] , *y* [1] ,
    *y* [2] , ...], and returns the coefficient of correlation between the two sequences:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个方便的相关函数，*R*（*x*，*y*）。它比较两个序列，[*x*[0]，*x*[1]，*x*[2]，...]和[*y*[0]，*y*[1]，*y*[2]，...]，并返回两个序列之间的相关系数：
- en: '*r[xy]* = *R* ([ *x* [0] , *x* [1] , *x* [2] , ...], [ *y* [0] , *y* [1] ,
    *y* [2] , ...])'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '*r[xy]* = *R*（[*x*[0]，*x*[1]，*x*[2]，...]，[*y*[0]，*y*[1]，*y*[2]，...]）'
- en: 'We can apply this to autocorrelation by using as a time-shift in the index
    values:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用索引值作为时间偏移来将其应用于自相关：
- en: '*r[xx]* (T) = *R* ([ *x* [0] , *x* [1] , *x* [2] , ...], [ *x* [0+T] , *x*
    [1+T] , *x* [2+T] , ...])'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '*r[xx]*（T）= *R*（[*x*[0]，*x*[1]，*x*[2]，...]，[*x*[0+T]，*x*[1+T]，*x*[2+T]，...]）'
- en: We've computed the correlation between values of *x* that are offset from each
    other by T. If T = 0, we're comparing each item with itself, the correlation is
    *r[xx]* (0) = 1.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经计算了相互偏移T的*x*值之间的相关性。如果T = 0，我们将每个项目与自身进行比较，相关性为*r[xx]*（0）= 1。
- en: We'll use some data that we suspect has a seasonal signal in it. This is data
    from [http://www.esrl.noaa.gov/gmd/ccgg/trends/](http://www.esrl.noaa.gov/gmd/ccgg/trends/)
    . We can visit [ftp://ftp.cmdl.noaa.gov/ccg/co2/trends/co2_mm_mlo.txt](ftp://ftp.cmdl.noaa.gov/ccg/co2/trends/co2_mm_mlo.txt)
    to download the file of the raw data.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一些我们怀疑其中有季节信号的数据。这是来自[http://www.esrl.noaa.gov/gmd/ccgg/trends/](http://www.esrl.noaa.gov/gmd/ccgg/trends/)的数据。我们可以访问[ftp://ftp.cmdl.noaa.gov/ccg/co2/trends/co2_mm_mlo.txt](ftp://ftp.cmdl.noaa.gov/ccg/co2/trends/co2_mm_mlo.txt)来下载原始数据文件。
- en: The file has a preamble with lines that start with `#` . These must be filtered
    out of the data. We'll use the  *Picking a subset – three ways to filter*  recipe in
    [Chapter 8](text00088.html#page "Chapter 8. Functional and Reactive Programming
    Features") , *Functional and Reactive Programming Features* , that will remove
    the lines that aren't useful.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 文件有一些以`#`开头的前言行。这些必须从数据中过滤掉。我们将使用[第8章](text00088.html#page "第8章。功能和响应式编程特性")中的
    *Picking a subset – three ways to filter* 配方，*Functional and Reactive Programming
    Features*，它将删除无用的行。
- en: 'The remaining lines are in seven columns with space as the separator between
    values. We''ll use the *Reading delimited files with the CSV module* recipe in
    the [Chapter 9](text00099.html#page "Chapter 9. Input/Output, Physical Format,
    and Logical Layout") , *Input/Output, Physical Format, and Logical Layout*  to
    read CSV data. In this case, the comma in CSV will be a space character. The result
    will be a little awkward to use, so we''ll use the *Upgrading CSV from Dictreader
    to namespace reader* recipe in [Chapter 9](text00099.html#page "Chapter 9. Input/Output,
    Physical Format, and Logical Layout") , *Input/Output, Physical Format, and Logical
    Layout* to create a more useful namespace with properly converted values. In that
    recipe, we imported the `CSV` module:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的行有七列，值之间以空格分隔。我们将使用[第9章](text00099.html#page "第9章。输入/输出、物理格式和逻辑布局")中的 *Reading
    delimited files with the CSV module* 配方，*Input/Output, Physical Format, and Logical
    Layout*，来读取CSV数据。在这种情况下，CSV中的逗号将是一个空格字符。结果将有点尴尬，因此我们将使用[第9章](text00099.html#page
    "第9章。输入/输出、物理格式和逻辑布局")中的 *Upgrading CSV from Dictreader to namespace reader* 配方，*Input/Output,
    Physical Format, and Logical Layout*，创建一个更有用的命名空间，其中值已经正确转换。在该配方中，我们导入了`CSV`模块：
- en: '[PRE54]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Here are two functions to handle the essential aspects of the physical format
    of the file. The first is a filter to reject comment lines; or, viewed the other
    way, pass non-comment lines:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是处理文件物理格式基本方面的两个函数。第一个是一个过滤器，用于拒绝注释行；或者，从另一个角度来看，传递非注释行：
- en: '[PRE55]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The `non_comment_iter()` function will iterate through the given source and
    reject lines that start with `#` . All other lines will be passed untouched.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`non_comment_iter()`函数将遍历给定的源并拒绝以`#`开头的行。所有其他行将原样传递。'
- en: 'The `non_comment_iter()` function can be used to build a CSV reader that handles
    the lines of valid data. The reader needs some additional configuration to define
    the data columns and the details of the CSV dialect involved:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`non_comment_iter()`函数可用于构建处理有效数据行的CSV读取器。读取器需要一些额外的配置来定义数据列和涉及的CSV方言的细节：'
- en: '[PRE56]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The `raw_data_iter()` function defines the seven column headers. It also specifies
    that the column delimiter is a space, and the additional spaces at the front of
    each column of data can be skipped. The input to this function must be stripped
    of comment lines, generally by using a filter function such as `non_comment_iter()`
    .
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`raw_data_iter()`函数定义了七个列标题。它还指定列分隔符是空格，并且可以跳过数据每列前面的额外空格。该函数的输入必须去除注释行，通常是通过使用`non_comment_iter()`等过滤函数。'
- en: 'The results of this function are rows of data in the form of dictionaries with
    seven keys. These rows look like this:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的结果是以字典形式的数据行，具有七个键。这些行看起来像这样：
- en: '[PRE57]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Since the values are all strings, a pass of cleansing and conversion is required.
    Here''s a row cleansing function that can be used in a generator expression. This
    will build a `SimpleNamespace` object, so we''ll need to import that definition:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有的值都是字符串，因此需要进行一次清洗和转换。这是一个可以在生成器表达式中使用的行清洗函数。这将构建一个`SimpleNamespace`对象，因此我们需要导入该定义：
- en: '[PRE58]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: This function will convert each dictionary row to a `SimpleNamespace` by applying
    a conversion function to the values in the dictionary. Most of the items are floating-point
    numbers, so the `float()` function is used. A few of the items are integers, and
    the `int()` function is used for those.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将通过将转换函数应用于字典中的值，将每个字典行转换为`SimpleNamespace`。大多数项目都是浮点数，因此使用`float()`函数。其中一些项目是整数，对于这些项目使用`int()`函数。
- en: 'We can write the following kind of generator expression to apply this cleansing
    function to each row of raw data:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写以下类型的生成器表达式，将此清洗函数应用于原始数据的每一行：
- en: '[PRE59]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: This will apply the `cleanse()` function to each row of data. Generally, the
    expectation is that the rows will come from the `raw_data_iter()` .
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这将对数据的每一行应用`cleanse()`函数。通常，预期是行来自`raw_data_iter()`。
- en: 'Applying the `cleanse()` function to each row will create data that looks like
    this:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 对每一行应用`cleanse()`函数将创建如下所示的数据：
- en: '[PRE60]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: This data is very easy to work with. The individual fields can be identified
    by a simple name, and the data values have been converted to Python internal data
    structures.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据非常容易处理。可以通过简单的名称识别各个字段，并且数据值已转换为Python内部数据结构。
- en: 'These functions can be combined into a stack as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数可以组合成一个堆栈，如下所示：
- en: '[PRE61]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The `get_data()` generator function is a stack of generator functions and generator
    expressions. It returns an iterator which will yield individual rows of the source
    data. The `non_comment_iter()` function will read enough lines to be able to yield
    a single non-comment line. The `raw_data_iter()` function will parse a line of
    CSV and yield a dictionary with a single row of data.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_data()`生成器函数是一组生成器函数和生成器表达式。它返回一个迭代器，该迭代器将产生源数据的单独行。`non_comment_iter()`函数将读取足够的行以便产生单个非注释行。`raw_data_iter()`函数将解析CSV的一行并产生一个包含单行数据的字典。'
- en: The `cleansed_data` generator expression will apply the `cleanse()` function
    to each dictionary of raw data. The individual rows are handy `SimpleNamespace`
    data structures that can be used elsewhere.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '`cleansed_data`生成器表达式将对原始数据的每个字典应用`cleanse()`函数。单独的行是方便的`SimpleNamespace`数据结构，可以在其他地方使用。'
- en: This generator binds all of the individual steps into a transformation pipeline.
    When steps need to be changed, this becomes the focus of the change. We can add
    filters, or replace parsing or cleansing functions here.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 该生成器将所有单独的步骤绑定到一个转换管道中。当需要更改步骤时，这将成为更改的焦点。我们可以在这里添加过滤器，或者替换解析或清洗函数。
- en: 'The context for using the `get_data()` function will look like this:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`get_data()`函数的上下文将如下所示：
- en: '[PRE62]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: We'll need to open a source file. We can provide the file to the `get_data()`
    function. This function will emit each row in a form that can easily be used for
    statistical processing.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要打开一个源文件。我们可以将文件提供给`get_data()`函数。该函数将以易于用于统计处理的形式发出每一行。
- en: How to do it...
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Import the `correlation()` function from the `ch10_r03` module:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`ch10_r03`模块导入`correlation()`函数：
- en: '[PRE63]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Get the relevant time series data item from the source data:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从源数据中获取相关的时间序列数据项：
- en: '[PRE64]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: In this case, we'll use the interpolated data. If we try to use the average
    data, there are reporting gaps that would force us to locate periods without the
    gaps. The interpolated data has values to fill in the gaps.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用插值数据。如果我们尝试使用平均数据，将会有报告间隙，这将迫使我们找到没有间隙的时期。插值数据有值来填补这些间隙。
- en: We've created a `list` object from the generator expression because we'll be
    doing more than one summary operation on it.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从生成器表达式创建了一个`list`对象，因为我们将对其进行多个摘要操作。
- en: 'For a number of time offsets, T, compute the correlation. We''ll use time offsets
    from `1` to `20` periods. Since the data is collected monthly, we suspect that
    T = 12 will have the highest correlation:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于多个时间偏移T，计算相关性。我们将使用从`1`到`20`期的时间偏移。由于数据是每月收集的，我们怀疑T = 12将具有最高的相关性：
- en: '[PRE65]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The `correlation()` function from the *Computing the coefficient of correlation*
    recipe expects a small dictionary with two keys: `x` and `y` . The first step
    is to build an array of these dictionaries. We''ve used the `zip()` function to
    combine two sequences of data:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '*计算相关系数*配方中的`correlation()`函数需要一个具有两个键的小字典：`x`和`y`。第一步是构建这些字典的数组。我们使用`zip()`函数来组合两个数据序列：'
- en: '`co2_ppm[:-tau]`'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`co2_ppm[:-tau]`'
- en: '`co2_ppm[tau:]`'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`co2_ppm[tau:]`'
- en: The `zip()` function will combine values from each slice of the `data` . The
    first slice starts at the beginning. The second starts `tau` positions into the
    sequence. Generally, the second sequence will be shorter, and the `zip()` function
    will stop processing when the sequence is exhausted.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '`zip()`函数将从`data`的每个切片中组合值。第一个切片从开头开始。第二个从序列的`tau`位置开始。通常，第二个序列会更短，`zip()`函数在序列耗尽时停止处理。'
- en: We've used `co2_ppm[:-tau]` as one of the argument values to the `zip()` function
    to make it perfectly clear that we're skipping some items at the end of the sequence.
    We're skipping the same number of items that are omitted from the beginning of
    the second sequence.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`co2_ppm[:-tau]`作为`zip()`函数的一个参数值，以清楚地表明我们跳过了序列末尾的一些项目。我们跳过的项目数量与从第二个序列的开头省略的项目数量相同。
- en: 'We''ve taken just the first 60 values to compute the autocorrelation with various
    time offset values. The data is provided monthly. We can see a very strong annual
    correlation. We''ve highlighted this row of output:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只取了前60个值来计算具有不同时间偏移值的自相关性。数据是按月提供的。我们可以看到非常强烈的年度相关性。我们已经突出显示了输出的这一行：
- en: '[PRE66]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: When the time shift is `12` , the *r[xx]* (12) = .981\. A similarly striking
    autocorrelation is available for almost any subset of the data. This high correlation
    confirms an annual cycle to the data.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 当时间偏移为`12`时，*r[xx]*(12) = .981。几乎任何数据子集都可以获得类似引人注目的自相关性。这种高相关性证实了数据的年度周期。
- en: The overall dataset contains almost 700 samples spanning over 58 years. It turns
    out that the seasonal variation signal is not as clear over the entire span of
    time. This means that there is another, longer period signal that is drowning
    out the annual variation signal.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 整个数据集包含了近58年的将近700个样本。事实证明，季节变化信号在整个时间跨度上并不那么明显。这意味着有另一个更长的周期信号淹没了年度变化信号。
- en: The presence of this other signal suggests that something more complex is going
    on. This effect is on a timescale longer than five years. Further analysis is
    required.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这种其他信号的存在表明正在发生更复杂的事情。这种效应的时间尺度长于五年。需要进一步分析。
- en: How it works...
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: One of the elegant features of Python is the array slicing concept. In the *Slicing
    and dicing a list* recipe in [Chapter 4](text00048.html#page "Chapter 4. Built-in
    Data Structures – list, set, dict") , *Built-in Data Structures – list, set, dict*
    , we looked at the basics of slicing a list. When doing autocorrelation calculations,
    array slicing gives us a wonderful tool for comparing two subsets of the data
    with very little complexity.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: Python的一个优雅特性是数组切片概念。在[第4章](text00048.html#page "第4章。内置数据结构-列表、集合、字典")的*切片和切块列表*配方中，我们看了列表切片的基础知识。在进行自相关计算时，数组切片为我们提供了一个非常简单的工具，用于比较数据的两个子集。
- en: 'The essential elements of the algorithm amounted to this:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的基本要素总结如下：
- en: '[PRE67]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: The pairs are built from `A=a zip()` of two slices of the `co2_ppm` sequence.
    These two slices build the expected (`x` ,`y` ) pairs that are used to create
    a temporary object, `data` . Given this `data` object, an existing `correlation()`
    function computed the correlation metric.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 这些对是从`co2_ppm`序列的两个切片的`a zip()`构建的。这两个切片构建了用于创建临时对象`data`的预期(`x`,`y`)对。有了这个`data`对象，现有的`correlation()`函数计算了相关度量。
- en: There's more...
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We can observe the 12-month seasonal cycle repeatedly throughout the dataset
    using a similar array slicing technique. In the example, we used this:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用类似的数组切片技术在整个数据集中反复观察12个月的季节循环。在这个例子中，我们使用了这个：
- en: '[PRE68]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: The preceding code uses the first `60` samples of the available `699` . We could
    begin the slice at various places and use various sizes of the slice to confirm
    that the cycle is present throughout the data.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码使用了可用的699个样本中的前60个。我们可以从各个地方开始切片，并使用不同大小的切片来确认周期在整个数据中都存在。
- en: 'We can create a model that shows how the 12 months of data behave. Because
    there''s a repeating cycle, the sine function is the most likely candidate for
    a model. We''d be doing a fit using this:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个模型，展示12个月的数据是如何变化的。因为有一个重复的周期，正弦函数是最有可能的模型候选。我们将使用这个进行拟合：
- en: '![There''s more...](Image00047.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![还有更多...](Image00047.jpg)'
- en: The mean of the sine function itself is zero, so the *K* factor is the mean
    of a given 12-month period. The function, *f* ( *x* - φ), will convert month numbers
    to proper values in the range -2π ≤ *f* ( *x* - φ) ≤ 2π. A function such as  *f*
    ( *x* ) = 2π(( *x* -6)/12) might be appropriate. Finally, the scaling factor,
    *A* , scales the data to match the minimum and maximum for a given month.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 正弦函数本身的平均值为零，因此*K*因子是给定12个月周期的平均值。函数*f*(*x* - φ)将月数转换为在-2π ≤ *f*(*x* - φ) ≤
    2π范围内的适当值。例如，*f*(*x*) = 2π(( *x* -6)/12)可能是合适的。最后，缩放因子*A*将数据缩放以匹配给定月份的最小值和最大值。
- en: Long-term model
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 长期模型
- en: While interesting, this analysis doesn't locate the long-term trend that was
    obscuring the annual oscillation. To locate that trend, it is necessary to reduce
    each 12-month sequence of samples to a single, annual, central value. The median
    or the mean will work well for this.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有趣，这种分析并没有找到掩盖年度振荡的长期趋势。为了找到这种趋势，有必要将每个12个月的样本序列减少到一个单一的年度中心值。中位数或平均值对此都很有效。
- en: 'We can create a sequence of monthly average values using the following generator
    expression:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下生成器表达式创建一个月平均值序列：
- en: '[PRE69]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'This generator will build a sequence of dictionaries. Each dictionary has the
    required `x` and `y` items that are used by the regression function. The `x` value
    is a value that is a simple surrogate for the year and month: it''s a number that
    grows from zero to 696\. The `y` value is the average of 12 monthly values.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 该生成器将构建一系列字典。每个字典都有回归函数使用的必需的`x`和`y`项。`x`值是一个简单的代表年份和月份的值：它是一个从零增长到696的数字。`y`值是12个月份值的平均值。
- en: 'The regression calculation is done as follows:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 回归计算如下进行：
- en: '[PRE70]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This shows a pronounced line, with the following equation:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了一个明显的线，方程如下：
- en: '![Long-term model](Image00048.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![长期模型](Image00048.jpg)'
- en: The *x* value is a month number offset from the first month in the dataset,
    which is March, 1958\. For example, March of 1968 would have an *x* value of 120\.
    The yearly average CO[2] parts per million would be *y* = 323.1\. The actual average
    for this year was 323.27\. As you can see, these are very similar values.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '`x`值是与数据集中的第一个月（1958年3月）相偏移的月数。例如，1968年3月的`x`值为120。年均CO[2]浓度为*y*=323.1。该年的实际平均值为323.27。可以看出，这些值非常相似。'
- en: The *r* ² value for this `correlational` model, which shows how the equation
    fits the data, is 0.98\. This rising slope is the signal, which in the long run
    dominates the seasonal fluctuations.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`相关`模型的*r*²值，显示了方程如何拟合数据，为0.98。这个上升的斜率是长期主导季节性波动的信号。
- en: See also
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The *Computing the coefficient of a correlation* recipe shows the core function
    for the computing correlation between a series of values
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算相关系数*配方显示了计算一系列值之间相关性的核心函数'
- en: The *Computing regression parameters* recipe shows additional background for
    determining the detailed regression parameters
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算回归参数*配方显示了确定详细回归参数的额外背景'
- en: Confirming that the data is random – the null hypothesis
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确认数据是随机的-零假设
- en: 'One of the important statistical questions is framed as the null hypothesis
    and an alternate hypothesis about sets of data. Let''s assume we have two sets
    of data, *S1* and *S2* . We can form two kinds of hypothesis about the data:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的统计问题被构建为关于数据集的零假设和备择假设。假设我们有两组数据，*S1*和*S2*。我们可以对数据形成两种假设：
- en: '**Null** : Any differences are minor random effects and there are no significant
    differences.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零假设**：任何差异都是次要的随机效应，没有显著差异。'
- en: '**Alternate** : The differences are statistically significant. Generally, the
    likelihood of this is less than 5%.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备用：这些差异在统计上是显著的。一般来说，这种可能性小于5%。
- en: How can we evaluate data to see if it's truly random of if there's some meaningful
    variation?
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何评估数据，以查看它是否真正随机，还是存在一些有意义的变化？
- en: Getting ready
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: If we have a strong background in statistics, we can leverage statistical theory
    to evaluate the standard deviations of samples and determine if there is a significant
    difference between two distributions. If we are weak in statistics, but have a
    strong background in programming, we can do a little coding and achieve similar
    results without the theory.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在统计学方面有很强的背景，我们可以利用统计理论来评估样本的标准差，并确定两个分布之间是否存在显著差异。如果我们在统计学方面薄弱，但在编程方面有很强的背景，我们可以进行一些编码，达到类似的结果而不需要理论。
- en: There are a variety of ways that we can compare sets of data to see if they're
    significantly different or the differences are random variations. In some cases,
    we might be able to provide a detailed simulation of the phenomena. If we use
    Python's built-in random number generator, we'll get data that's essentially the
    same as truly random real-world events. We can compare a simulation against measured
    data to see if they're the same or not.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过各种方式比较数据集，以查看它们是否存在显著不同或差异是否是随机变化。在某些情况下，我们可能能够对现象进行详细的模拟。如果我们使用Python内置的随机数生成器，我们将得到与真正随机的现实世界事件基本相同的数据。我们可以将模拟与测量数据进行比较，以查看它们是否相同。
- en: The simulation technique only works when a simulation is reasonably complete.
    Discrete events in casino gambling, for example, are easy to simulate. Some kinds
    of discrete events in web transactions, such as the items in a shopping cart,
    are easy to simulate. But some phenomena are hard to simulate precisely.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟技术只有在模拟相对完整时才有效。例如，赌场赌博中的离散事件很容易模拟。但是，网页交易中的某些离散事件，比如购物车中的商品，很难精确模拟。
- en: In the cases where we can't do a simulation, we have a number of resampling
    techniques that are available. We can shuffle the data, use bootstrapping, or
    use cross-validation. In these cases, we'll use the data that's available to look
    for random effects.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们无法进行模拟的情况下，我们有许多可用的重采样技术。我们可以对数据进行洗牌，使用自助法，或者使用交叉验证。在这些情况下，我们将使用可用的数据来寻找随机效应。
- en: 'We''ll compare three subsets of the data in the *Computing an autocorrelation*
    recipe. These are data values from two adjacent years and a third year that is
    widely separated from the other two. Each year has 12 samples, and we can easily
    compute the means of these groups:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*计算自相关*配方中比较数据的三个子集。这些是来自两个相邻年份和一个与其他两个年份相隔很远的第三年的数据值。每年有12个样本，我们可以轻松计算这些组的平均值：
- en: '[PRE71]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'We''ve created three subsets for three of the available years of data. Each
    subset is created with a simple filter that creates a list of values for which
    the year matches a target value. We can compute statistics on these subsets as
    follows:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为三年的可用数据创建了三个子集。每个子集都是使用一个简单的筛选器创建的，该筛选器创建一个数值列表，其中年份与目标值匹配。我们可以按如下方式对这些子集进行统计：
- en: '[PRE72]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: The three averages are different. Our hypothesis is that the differences between
    `1959` and `1960` means are just ordinary random variation with no significance.
    The differences between the `1959` and `2014` means, however, are statistically
    significant.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个平均值是不同的。我们的假设是，`1959`和`1960`之间的差异只是普通的随机变化，没有显著性。然而，`1959`和`2014`之间的差异在统计上是显著的。
- en: 'The permutation or shuffling technique works as follows:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 排列或洗牌技术的工作原理如下：
- en: 'For each permutation of the pooled data:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于汇总数据的每个排列：
- en: The observed difference between the means of `1959` data and `1960` data is
    *316.91-315.97 = 0.94* . We can call this *T[obs]* , the observed test measurement.
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1959年数据和1960年数据之间的平均差异为*316.91-315.97=0.94*。我们可以称之为*T[obs]*，观察到的测试测量。
- en: Create two subsets, *A* , and *B*
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建两个子集，*A*和*B*
- en: Compute the difference between the means, *T*
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算平均值之间的差异，*T*
- en: Count the number of differences, *T* , larger than  *T[obs]* and smaller than 
    *T[obs]*
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算差异的数量，*T*，大于*T[obs]*和小于*T[obs]*的值
- en: 'The two counts show us how our observed difference compares with all possible
    differences. For largish sets of data, there can be a large number of permutations.
    In our case, we know that the number of combinations of 24 samples taken 12 at
    a time is given by this formula:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个计数告诉我们我们观察到的差异如何与所有可能的差异相比。对于大型数据集，可能存在大量的排列组合。在我们的情况下，我们知道24个样本中每次取12个的组合数由以下公式给出：
- en: '![Getting ready](Image00049.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![准备就绪](Image00049.jpg)'
- en: 'We can compute the value for *n* = 24 and *k* = 12:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算*n*=24和*k*=12的值：
- en: '[PRE73]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: There are a hair more than 2.7 million permutations. We can use functions in
    the `itertools` module to generate these. The `combinations()` function will emit
    the various subsets. Processing takes over 5 minutes (320 seconds).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 有略多于2.7百万个排列。我们可以使用`itertools`模块中的函数来生成这些。`combinations()`函数将发出各种子集。处理需要超过5分钟（320秒）。
- en: An alternative plan is to use randomized subsets. Using 270,156 randomized samples
    can be done in about 35 seconds. Using just 10% of the combinations provides an
    answer that's accurate enough to determine if the two samples are statistically
    similar and the null hypothesis is true, or if the two samples are different.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个计划是使用随机子集。使用270,156个随机样本大约需要35秒。使用仅10%的组合提供了足够准确的答案，以确定两个样本是否在统计上相似，并且零假设成立，或者两个样本是否不同。
- en: How to do it...
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We''ll be using the `random` and `statistics` modules. The `shuffle()` function
    is central to randomizing the samples. We''ll also be using the `mean()` function:'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`random`和`statistics`模块。`shuffle()`函数是随机化样本的核心。我们还将使用`mean()`函数：
- en: '[PRE74]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We could simply count values above and below the observed difference between
    the samples. Instead, we''ll create a `Counter` and collect differences in 2,000
    steps from -0.001 to +0.001\. This will provide some confidence that the differences
    are normally distributed:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以简单地计算样本之间观察到的差异以上和以下的值。相反，我们将创建一个`Counter`并在-0.001到+0.001的2,000个步骤中收集差异。这将提供一些信心，表明差异是正态分布的：
- en: '[PRE75]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Define a function that accepts two separate sets of samples. These will be
    combined, and random subsets drawn from the collection:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个接受两组独立样本的函数。这些将被合并，并从集合中随机抽取子集：
- en: '[PRE76]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Compute the observed difference between the means, *T[obs]* :'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算平均值之间的观察到的差异，*T[obs]*：
- en: '[PRE77]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Initialize a `Counter` to collect details:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个`Counter`来收集详细信息：
- en: '[PRE78]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Create the combined universe of samples. We can concatenate the two lists:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建样本的组合宇宙。我们可以连接这两个列表：
- en: '[PRE79]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Use a `for` statement to do a large number of resamples; 270,415 can take 35
    seconds. It''s easy to expand or contract the subset to balance a need for accuracy
    and the speed of calculation. The bulk of the processing will be nested inside
    this loop:'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`for`语句进行大量的重新采样；270,415个样本可能需要35秒。很容易扩展或收缩子集以平衡精度和计算速度的需求。大部分处理将嵌套在这个循环内：
- en: '[PRE80]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Shuffle the data:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 洗牌数据：
- en: '[PRE81]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Pick two subsets that match the original sets of data in size:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择两个与原始数据大小匹配的子集：
- en: '[PRE82]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Because of the way Python list indices work, we are assured that the two lists
    completely separate the values in the universe. Since the ending index value,
    `len(s2)` , is not included in the first list, this kind of slice clearly separates
    all items.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python列表索引的工作方式，我们可以确保两个列表完全分开宇宙中的值。由于第一个列表中不包括结束索引值`len(s2)`，这种切片清楚地分隔了所有项目。
- en: 'Compute the difference between the means. In this case, we''ll scale this by
    `1000` and convert to an integer so that we can accumulate a frequency distribution:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算平均值之间的差异。在这种情况下，我们将通过`1000`进行缩放并转换为整数，以便我们可以累积频率分布：
- en: '[PRE83]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: An alternative to creating a histogram of delta values is to count values above
    and below *T[obs]* . Using the full histogram provides confidence that the data
    is statistically normal.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 创建delta值的直方图的替代方法是计算大于*T[obs]*和小于*T[obs]*的值。使用完整的直方图提供了数据在统计上是正常的信心。
- en: 'After the `for` loop, we can summarize the `counts` showing how many are above
    the observed difference and how many are below. If either value is less than 5%,
    this is a statistically significant difference:'
  id: totrans-405
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`for`循环之后，我们可以总结`counts`，显示有多少个差异大于观察到的差异，有多少个差异小于观察到的差异。如果任一值小于5%，这是一个统计学上显著的差异：
- en: '[PRE84]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'When we run the `randomized()` function for the data from `1959` and `1960`
    , we see the following:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对来自1959年和1960年的数据运行`randomized()`函数时，我们看到以下内容：
- en: '[PRE85]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The output looks like the following:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE86]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: This shows that 11% of the data was above the observed difference and 88% of
    the data was below. This is well within the realm of normal statistical noise.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明11%的数据高于观察到的差异，88%的数据低于观察到的差异。这完全在正常统计噪音的范围内。
- en: 'When we run this for data from `1959` and `2014` , we see the following output:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对来自`1959`和`2014`的数据运行此操作时，我们看到以下输出：
- en: '[PRE87]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: The data involved only one example out of 270,415 that was above the observed
    difference in means, *T[obs]* . The change from `1959` to `2014` is statistically
    significant, with a probability of 3.7 x 10^(-6) .
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及的数据只有270,415个样本中的一个示例高于平均值之间的观察到的差异，*T[obs]*。从1959年到2014年的变化在统计上是显著的，概率为3.7
    x 10^(-6)。
- en: How it works...
  id: totrans-415
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Computing all 2.7 million permutations gives the exact answer. It's faster to
    use randomized subsets instead of computing all possible permutations. The Python
    random number generator is excellent, and it assures us that the randomized subsets
    will be fairly distributed.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 计算所有270万个排列可以得到确切的答案。使用随机子集而不是计算所有可能的排列更快。Python随机数生成器非常出色，它确保随机子集将被公平分布。
- en: 'We''ve used two techniques to compute randomized subsets of the data:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了两种技术来计算数据的随机子集：
- en: Shuffle the entire universe with `random.shuffle(u)`
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用 `random.shuffle(u)` 对整个值域进行洗牌
- en: Partition the universe with code similar to `a, b = u[x:], u[:x]`
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用类似 `a, b = u[x:], u[:x]` 的代码对值域进行分区
- en: Computing means of the two partitions is done with the `statistics` module.
    We could define somewhat more efficient algorithms which did the shuffling, partitioning,
    and mean computation all in a single pass through the data. This more efficient
    algorithm will omit the creation of a complete histogram for the permuted differences.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 两个分区的均值是用 `statistics` 模块完成的。我们可以定义更有效的算法，通过数据的单次遍历来进行洗牌、分区和均值计算。这种更有效的算法将省略创建排列差异的完整直方图。
- en: 'The preceding algorithm turned each difference into a value between -1000 and
    +1000 using this:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的算法将每个差异转换为-1000到+1000之间的值，使用如下：
- en: '[PRE88]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: This allows us to compute a frequency distribution with a `Counter` . This will
    show that most of the differences really are zero; something to be expected for
    normally distributed data. Seeing the distribution assures us that there isn't
    some hidden bias in the random number generation and shuffling algorithm.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够使用 `Counter` 计算频率分布。这将显示大多数差异实际上是零；这是对正态分布数据的预期。看到分布可以确保我们的随机数生成和洗牌算法中没有隐藏的偏差。
- en: 'Instead of populating a `Counter` , we can simply count the above and below
    values. The simplest form of this comparison between a permutation''s difference
    and the observed difference, *T[obs]* , is as follows:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以简单地计算上面和下面的值，而不是填充 `Counter` 。这种比较排列差异和观察差异 *T[obs]* 的最简单形式如下：
- en: '[PRE89]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: This counts the number of resampling differences that are larger than the observed
    difference. From this, we can compute the number below the observation via `below
    = limit-above` . This will give us a simple percentage value.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 这计算了大于观察差异的重采样差异的数量。从中，我们可以通过 `below = limit-above` 计算出低于观察值的数量。这将给我们一个简单的百分比值。
- en: There's more...
  id: totrans-427
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We can speed processing up a tiny bit more by changing the way we compute the
    mean of each random subset.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过改变计算每个随机子集的均值的方式来进一步加快处理速度。
- en: 'Given a pool of numbers, *P* , we''re creating two disjoint subsets, *A* ,
    and *B* , such that:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个数字池 *P* ，我们创建两个不相交的子集 *A* 和 *B* ，使得：
- en: '*A* ∪ *B* = *P* ∧ *A* ∩ *B* = ∅'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '*A* ∪ *B* = *P* ∧ *A* ∩ *B* = ∅'
- en: The union of the *A* and *B* subsets covers the entire universe, *P* . There
    are no missing values because the intersection between *A* and *B* is an empty
    set.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '*A* 和 *B* 子集的并集覆盖了整个值域 *P* 。没有缺失值，因为 *A* 和 *B* 之间的交集是一个空集。'
- en: 'The overall sum, *S[p]* , can be computed just once:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 整体总和 *S[p]* 只需计算一次：
- en: '*S[P]* = ∑ *P*'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '*S[P]* = ∑ *P*'
- en: 'We only need to compute a sum for one subset, *S[A]* :'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要计算一个子集 *S[A]* 的总和：
- en: '*S[A] = ∑ A*'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: '*S[A] = ∑ A*'
- en: This means that the other subset sum is simply a subtraction. We don't need
    a costly process to compute a second sum.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着另一个子集的总和只是一个减法。我们不需要一个昂贵的过程来计算第二个总和。
- en: 'The sizes of the sets, *N[A]* , and *N[B]* , similarly, are constant. The means,
    μ [*A*] and μ [*B*] , can be calculated quickly:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 集合的大小，*N[A]* 和 *N[B]* ，同样是恒定的。均值，μ [*A*] 和 μ [*B*] ，可以快速计算：
- en: μ [*A*] = ( *S[A]* / *N[A]* )
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: μ [*A*] = ( *S[A]* / *N[A]* )
- en: μ [*B*] = ( *S[P]* - *S[A]* )/ *N[B]*
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: μ [*B*] = ( *S[P]* - *S[A]* )/ *N[B]*
- en: 'This leads to a slight change in the resample loop:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了重采样循环的轻微变化：
- en: '[PRE90]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: By computing just one sum, `s_a` , we shave processing time off of the random
    resampling procedure. We don't need to compute the sum of the other subset, since
    we can compute this as a difference between the sum of the entire universe of
    values. We can then avoid using the `mean()` function, and compute the means directly
    from the sums and the fixed counts.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仅计算一个总和 `s_a` ，我们可以节省随机重采样过程的处理时间。我们不需要计算另一个子集的总和，因为我们可以将其计算为整个值域的总和之间的差异。然后我们可以避免使用
    `mean()` 函数，并直接从总和和固定计数计算均值。
- en: This kind of optimization makes it quite easy to reach a statistical decision
    quickly. Using resampling means that we don't need to rely on a complex theoretical
    knowledge of statistics; we can resample the existing data to show that a given
    sample meets the null hypothesis or is outside of the expectations, and some alternative
    hypothesis is called for.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 这种优化使得很容易迅速做出统计决策。使用重采样意味着我们不需要依赖于复杂的统计理论知识；我们可以重采样现有数据以表明给定样本符合零假设或超出预期，并需要提出一些替代假设。
- en: See also
  id: totrans-444
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: This process can be applied to other statistical decision procedures. This includes
    the *Computing regression parameters* and *Computing an autocorrelation* recipes.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个过程可以应用于其他统计决策程序。这包括 *计算回归参数* 和 *计算自相关* 配方。
- en: Locating outliers
  id: totrans-446
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查找异常值
- en: When we have statistical data, we often find data points which can be described
    as outliers. An outlier deviates from other samples, and may indicate bad data
    or a new discovery. Outliers are, by definition, rare events.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有统计数据时，我们经常发现可以描述为异常值的数据点。异常值偏离其他样本，可能表明坏数据或新发现。异常值根据定义是罕见事件。
- en: Outliers may be simple mistakes in data gathering. They might represent a software
    bug, or perhaps a measuring device that isn't calibrated properly. Perhaps a log
    entry is unreadable because a server crashed or a timestamp is wrong because a
    user entered data improperly.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值可能是数据收集中的简单错误。它们可能代表软件错误，或者可能是测量设备未正确校准。也许日志条目无法读取是因为服务器崩溃或时间戳错误是因为用户错误输入了数据。
- en: Outliers may also be of interest because there is some other signal that is
    difficult to detect. It might be novel, or rare, or outside the accurate calibration
    of our devices. In a web log it might suggest a new use case for an application
    or signal the start of a new kind of hacking attempt.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值也可能是有趣的，因为存在一些难以检测的其他信号。它可能是新颖的，或者罕见的，或者超出了我们设备的准确校准。在Web日志中，它可能暗示了应用程序的新用例，或者标志着新类型的黑客攻击的开始。
- en: How do we locate and label potential outliers?
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何定位和标记潜在的异常值？
- en: Getting ready
  id: totrans-451
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'An easy way to locate outliers is to normalize the values to make them Z-scores.
    A Z- score converts the measured value to a ratio between the measured value and
    the mean measured in units of standard deviation:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 定位异常值的一种简单方法是将值标准化以使它们成为Z分数。Z分数将测量值转换为测量值与均值之间的比率，以标准差为单位：
- en: '*Z[i]* = ( *x[i]* - μ [*x*] )/σ [*x*]'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '*Z[i]* = ( *x[i]* - μ [*x*] )/σ [*x*]'
- en: Where μ [*x*] is the mean of a given variable, *x* , and σ [*x*] is the standard
    deviation of that variable. We can compute these values using the `statistics`
    module.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 其中μ [*x*]是给定变量*x*的均值，σ [*x*]是该变量的标准差。我们可以使用`statistics`模块计算这些值。
- en: 'This, however, can be somewhat misleading because the Z-scores are limited
    by the number of samples involved. Consequently, the *NIST Engineering and Statistics
    Handbook* , *section 1.3.5.17* , suggests using the following rule for detecting
    outliers:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这可能有些误导，因为Z分数受涉及的样本数量限制。因此，*NIST工程和统计手册*，*1.3.5.17节*，建议使用以下规则来检测异常值：
- en: '![Getting ready](Image00050.jpg)'
  id: totrans-456
  prefs: []
  type: TYPE_IMG
  zh: 准备工作
- en: '**MAD** ( **Median Absolute Deviation** ) is used instead of the standard deviation.
    The MAD is the median of the absolute values of the deviations between each sample,
    *x[i]* , and the population median, *x* :'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: '**MAD**（**中位数绝对偏差**）代替标准差。MAD是每个样本*x[i]*与总体中位数*x*之间的偏差的绝对值的中位数：'
- en: '![Getting ready](Image00051.jpg)'
  id: totrans-458
  prefs: []
  type: TYPE_IMG
  zh: 准备工作
- en: The scaling factor of *0.6745* is used to scale these scores so that a *M[i]*
    value greater than 3.5 can be identified as an outlier. Note that this is parallel
    to the calculation of the sample variance. The variance measure uses a mean, this
    measure uses a median. The value, 0.6745, is widely-used in the literature as
    the appropriate value to locate outliers.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 使用缩放因子*0.6745*来缩放这些分数，以便可以将大于3.5的*M[i]*值识别为异常值。请注意，这与计算样本方差是平行的。方差测量使用均值，而这个测量使用中位数。值0.6745在文献中被广泛用作定位异常值的适当值。
- en: We'll use some data from the *Using the built-in statistics library* recipe
    that includes some relatively smooth datasets and some datasets that have egregious
    outliers. The data is in a JSON document that has four series of ( *x* , *y* )
    pairs.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一些来自*使用内置统计库*配方的数据，其中包括一些相对平滑的数据集和一些具有严重异常值的数据集。数据位于一个JSON文档中，其中包含四个( *x*
    , *y* )对的系列。
- en: 'We can read this data with the following:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下方法读取这些数据：
- en: '[PRE91]'
  id: totrans-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: We've defined the `Path` to the data file. We can then use the `Path` object
    to read the text from this file. This text is used by `json.loads()` to build
    a Python object from the JSON data.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了数据文件的`Path`。然后，我们可以使用`Path`对象从该文件中读取文本。`json.loads()`使用这些文本从JSON数据构建Python对象。
- en: We've included an `object_pairs_hook` so that this function will build the JSON
    using the `OrderedDict` class instead of the default `dict` class. This will preserve
    the original order of items in the source document.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经包含了一个`object_pairs_hook`，以便该函数将使用`OrderedDict`类构建JSON，而不是默认的`dict`类。这将保留源文档中项目的原始顺序。
- en: 'We can examine the data such as following:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查以下数据：
- en: '[PRE92]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'The overall JSON document is a sequence of subdocuments with keys such as `I`
     and `II` . Each subdocument has two fields: `series`  and `data` . The `data`
     value is a list of observations that we want to characterize. Each observation
    is a pairs measurements.'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 整个JSON文档是具有诸如`I`和`II`等键的子文档序列。每个子文档有两个字段：`series`和`data`。`data`值是我们想要描述的观测值列表。每个观测值都是一对测量值。
- en: How to do it...
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: Import the `statistics` module. We'll be doing a number of median calculations.
    In addition, we can use some of the features of `itertools` , such as `compress()`
    and `filterfalse()` .
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`statistics`模块。我们将进行许多中位数计算。此外，我们可以使用`itertools`的一些功能，如`compress()`和`filterfalse()`。
- en: '[PRE93]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Define the `absdev()` mapping. This will either use a given median or compute
    the actual median of the samples. It will then return a generator that provides
    all of the absolute deviations from the median:'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`absdev()`映射。这将使用给定的中位数或计算样本的实际中位数。然后返回一个生成器，提供所有相对于中位数的绝对偏差：
- en: '[PRE94]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Define the `median_absdev()` reduction. This will locate the median of a sequence
    of absolute deviation values. This computes the MAD value used to detect outliers.
    This can compute a median or it can be given a median already computed:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`median_absdev()`缩减。这将定位绝对偏差值序列的中位数。这计算用于检测异常值的MAD值。这可以计算中位数，也可以给定已计算的中位数：
- en: '[PRE95]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Define the modified Z-score mapping, `z_mod()` . This will compute the median
    for the dataset, and use this to compute the MAD. The deviation value is then
    used to compute modified Z-scores based on this deviation value. The returned
    value is an iterator over the modified Z-scores. Because multiple passes are made
    over the data, the input can''t be an iterable collection, so it must be a sequence
    object:'
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义修改后的Z分数映射，`z_mod()`。这将计算数据集的中位数，并使用它来计算MAD。然后使用偏差值来计算基于该偏差值的修改后的Z分数。返回的值是修改后的Z分数的迭代器。由于数据需要多次通过，输入不能是可迭代集合，因此必须是序列对象：
- en: '[PRE96]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: In this implementation, we've used a constant, `0.6745` . In some vases, we
    might want to make this a parameter. We might use `def z_mod(data, threshold=0.6745)`
    to allow changing this value.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实现中，我们使用了一个常数`0.6745`。在某些情况下，我们可能希望将其作为参数。我们可以使用`def z_mod(data, threshold=0.6745)`来允许更改这个值。
- en: Interestingly, there's a possibility that the MAD value is zero. This can happen
    when the majority of the values don't deviate from the median. When more than
    half of the points have the same value, the median absolute deviation will be
    zero.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，MAD值为零的可能性。当大多数值不偏离中位数时，这种情况可能发生。当超过一半的点具有相同的值时，中位绝对偏差将为零。
- en: 'Define the outlier filter based on the modified Z mapping, `z_mod()` . Any
    value over 3.5 can be labeled as an outlier. The statistical summaries can then
    be computed with and without the outlier values. The `itertools` module has a
    `compress()` function which can use a sequence of Boolean selector values to choose
    items from the original data sequence based on the results of the `z_mod()` computation:'
  id: totrans-479
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于修改后的Z映射`z_mod()`定义异常值过滤器。任何值超过3.5都可以被标记为异常值。然后可以计算包括和不包括异常值的统计摘要。`itertools`模块有一个`compress()`函数，可以使用布尔选择器值的序列根据`z_mod()`计算的结果从原始数据序列中选择项目：
- en: '[PRE97]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: The `pass_outliers()` function passes only the outliers. The `reject_outliers()`
    function passes the non-outlier values. Often, we'll display two results—the whole
    set of data, and the whole set with outliers rejected.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '`pass_outliers()`函数仅传递异常值。`reject_outliers()`函数传递非异常值。通常，我们会显示两个结果——整个数据集和拒绝异常值的整个数据集。'
- en: Most of these functions make multiple references to the input data parameter—an
    iterable cannot be used. These functions must be given a `Sequence` object. A
    `list` or a `tuple` are examples of a `Sequence` .
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数这些函数都多次引用输入数据参数，不能使用可迭代对象。这些函数必须给定一个`Sequence`对象。`list`或`tuple`是`Sequence`的例子。
- en: We can use the `pass_outliers()` to locate the outlier values. This can be handy
    to identify the suspicious data values. We can use the `reject_outliers()` to
    provide data with the outliers removed from consideration.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`pass_outliers()`来定位异常值。这对于识别可疑的数据值很有用。我们可以使用`reject_outliers()`来提供已从考虑中移除异常值的数据。
- en: How it works...
  id: totrans-484
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'The stack of transformations can be summarized like this:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 转换堆栈可以总结如下：
- en: Reduce the population to compute a population median.
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少总体以计算总体中位数。
- en: Map each value to an absolute deviation from the population median.
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个值映射到与总体中位数的绝对偏差。
- en: Reduce the absolute deviations to create a median absolute deviation, MAD.
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 减少绝对偏差以创建中位绝对偏差MAD。
- en: Map each value to the modified Z-score using the population median and the MAD.
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个值映射到使用总体中位数和MAD的修改Z得分。
- en: Filter the results based on the modified Z-scores.
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据修改后的Z得分过滤结果。
- en: We've defined each transformation function in this stack separately. We can
    use recipes from [Chapter 8](text00088.html#page "Chapter 8. Functional and Reactive
    Programming Features") , *Functional and Reactive Programming Features* , to create
    smaller functions and use the built-in `map()` and `filter()` functions to implement
    this process.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分别定义了这个堆栈中的每个转换函数。我们可以使用[第8章](text00088.html#page "第8章。功能和响应式编程特性")中的示例，*功能和响应式编程特性*，创建更小的函数，并使用内置的`map()`和`filter()`函数来实现这个过程。
- en: We can't easily use the built-in `reduce()` function to define a median computation.
    To compute a median, we have to use a recursive median finding algorithm that
    partitions the data into smaller and smaller subsets, one of which has the median
    value.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能轻松地使用内置的`reduce()`函数来定义中位数计算。为了计算中位数，我们必须使用递归中位数查找算法，将数据分成越来越小的子集，其中一个子集具有中位数值。
- en: 'Here''s how we can apply this to the given sample data:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们如何将其应用于给定的样本数据：
- en: '[PRE98]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: We've iterated through each of the series in the source data. The computation
    of `series_data` extracts one of the series from the source data. Each of the
    series has two variables, `x` and `y` . Within the set of samples, we can use
    the `pass_outliers()` function to locate outliers in the data.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历了源数据中的每个系列。`series_data`的计算从源数据中提取了一个系列。每个系列都有两个变量`x`和`y`。在样本集中，我们可以使用`pass_outliers()`函数来定位数据中的异常值。
- en: 'The `except` clause handles a `ZeroDivisionError` exception. This exception
    is raised by the `z_mod()` function for a particularly pathological set of data.
    Here''s the line of output that shows this odd-looking data:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '`except`子句处理`ZeroDivisionError`异常。这个异常是由`z_mod()`函数对一组特别病态的数据引发的。以下是显示这些奇怪数据的输出行：'
- en: '[PRE99]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: In this case, at least half the values are the same. That single majority value
    will be taken as the median. The absolute deviations from the median will be zero
    for this subset. Consequently, the MAD will be zero. In this case, the idea of
    outliers is suspicious because the data don't seem to reflect ordinary statistical
    noise, either.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，至少一半的值是相同的。这个单一的多数值将被视为中位数。对于这个子集，与中位数的绝对偏差将为零。因此，MAD将为零。在这种情况下，异常值的概念是可疑的，因为数据似乎不反映普通的统计噪声。
- en: This data does not fit the general model, and a different kind of analysis must
    be applied to this variable. The very idea of outliers may have to be rejected
    because of the peculiar nature of the data.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据不符合一般模型，必须对这个变量应用不同类型的分析。由于数据的特殊性，可能必须拒绝异常值的概念。
- en: There's more...
  id: totrans-500
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We've used `itertools.compress()` to pass or reject outliers. We can also use
    the `filter()` and `itertools.filterfalse()` functions in a similar way. We'll
    look at some optimizations of `compress()` as well as ways to use `filter()` instead
    of `compress()` .
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`itertools.compress()`来传递或拒绝异常值。我们还可以以类似的方式使用`filter()`和`itertools.filterfalse()`函数。我们将研究一些`compress()`的优化以及使用`filter()`代替`compress()`的方法。
- en: 'We used two similar looking function definitions to `pass_outliers` and `reject_outliers`
    . This design suffers from an unpleasant duplication of critical program logic;
    it breaks the DRY principle. Here are the two functions:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了两个看起来相似的函数定义`pass_outliers`和`reject_outliers`。这种设计存在对关键程序逻辑的不必要重复，违反了DRY原则。以下是这两个函数：
- en: '[PRE100]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: The difference between `pass_outliers()` and `reject_outliers()` is tiny, and
    amounts to a logical negation of an expression. We have `>=` in one version and
    `<` in another. This kind of code difference is is not always trivial to validate.
    If the logic was more complex, performing the logical negation is a place where
    a design error can creep into the code.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '`pass_outliers()`和`reject_outliers()`之间的区别很小，只是表达式的逻辑否定。一个版本中有`>=`，另一个版本中有`<`。这种代码差异并不总是容易验证。如果逻辑更复杂，执行逻辑否定是设计错误可能渗入代码的地方。'
- en: 'We can extract one version of the filter rule to create something like the
    following:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以提取过滤规则的一个版本，创建类似以下内容：
- en: '[PRE101]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'We can then modify the two uses of the `compress()` function to make the logical
    negation explicit:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以修改`compress()`函数的两个用法，使逻辑否定明确：
- en: '[PRE102]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: Exposing the filter rule as a separate lambda object or function definition
    helps reduce the code duplication. The negation is made more obvious. Now the
    two versions can be compared easily to be sure that they have appropriate semantics.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 将过滤规则公开为单独的lambda对象或函数定义有助于减少代码重复。否定更加明显。现在可以轻松比较这两个版本，以确保它们具有适当的语义。
- en: 'If we want to use the `filter()` function, we have to make a radical transformation
    to the processing pipeline. The `filter()` higher-order function requires a decision
    function that creates a true/false result for each raw value. Processing this
    will combine a modified Z-score calculation with the decision threshold. The decision
    function must compute this:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要使用`filter()`函数，我们必须对处理流水线进行根本性的转换。`filter()`高阶函数需要一个决策函数，为每个原始值创建一个真/假结果。处理这个将结合修改后的Z得分计算和决策阈值。决策函数必须计算这个：
- en: '![There''s more...](Image00052.jpg)'
  id: totrans-511
  prefs: []
  type: TYPE_IMG
  zh: '![更多内容...](Image00052.jpg)'
- en: 'It must compute this in order to determine the outlier status for each *x[i]*
    value. This decision function requires two additional inputs—the population median,
    ![There''s more...](Image00053.jpg)  , and the MAD value. This makes the filter
    decision function rather complex. It would look like this:'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 它必须计算这个，以确定每个*x[i]*值的异常值状态。这个决策函数需要两个额外的输入——总体中位数，![更多内容...](Image00053.jpg)，和MAD值。这使得过滤决策函数相当复杂。它会看起来像这样：
- en: '[PRE103]'
  id: totrans-513
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: This `outlier()` function can be used with the `filter()` to pass outliers.
    It can be used with `itertools.filterfalse()` to reject outliers and create a
    subset that is free from erroneous values.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`outlier()`函数可以与`filter()`一起用于传递异常值。它可以与`itertools.filterfalse()`一起用于拒绝异常值并创建一个没有错误值的子集。
- en: 'In order to use this `outlier()` function, we''ll need to create a function
    like this:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用这个`outlier()`函数，我们需要创建一个类似这样的函数：
- en: '[PRE104]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'This computes the two overall reductions: `population_median` , and `mad` .
    Given these two values, we can create a partial function, `outlier_partial()`
    . This function has values bound for the the first two positional parameter values,
    `mad` , and `population_median` . The resulting partial function requires only
    the individual data value for processing.'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 这计算了两个总体减少：`population_median`和`mad`。有了这两个值，我们可以创建一个偏函数`outlier_partial()`。这个函数将为前两个位置参数值`mad`和`population_median`绑定值。结果的偏函数只需要单独的数据值进行处理。
- en: 'The `outlier_partial()` and `filter()` processing are equivalent to this generator
    expression:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: '`outlier_partial()`和`filter()`处理等同于这个生成器表达式：'
- en: '[PRE105]'
  id: totrans-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: It's not clear that this expression has a distinct advantage over using the
    `compress()` function in the `itertools` module. It can, however, be somewhat
    more clear for programmers who are more comfortable with `filter()` .
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 目前尚不清楚这个表达式是否比`itertools`模块中的`compress()`函数具有明显优势。但是，对于更熟悉`filter()`的程序员来说，它可能会更清晰一些。
- en: See also
  id: totrans-521
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: See [http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm](http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm)
    for detection of outliers
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关异常值检测，请参见[http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm](http://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm)
- en: Analyzing many variables in one pass
  id: totrans-523
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一次分析多个变量
- en: In many cases, we'll have data with multiple variables that we'd like to analyze.
    The data can be visualized as filling in a grid, with each row containing a specific
    outcome. Each outcome row has multiple variables in columns.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们会有多个变量的数据需要分析。数据可以可视化为填充网格，每一行包含特定的结果。每个结果行在列中有多个变量。
- en: We can follow the pattern of column-major order and process each variable (from
    a column of data) independently. This will lead to visiting each row of data multiple
    times. Or, we can use the pattern of row-major order and process all the variables
    at once for each row of data.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以遵循列主序的模式，并独立处理每个变量（从数据列中）。这将导致多次访问每一行数据。或者，我们可以使用行主序的模式，并一次处理所有变量的每一行数据。
- en: The advantage of a focus on each variable is that we can write a relatively
    simple processing stack. We'll have multiple stacks, one per variable, but each
    stack can reuse common functions from the `statistics` module.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 关注每个变量的优势在于，我们可以编写一个相对简单的处理堆栈。我们将有多个堆栈，每个变量一个，但每个堆栈可以重用`statistics`模块中的公共函数。
- en: The disadvantage of this kind of focus is that processing each variable for
    a very large dataset requires reading the raw data from OS files. This part of
    the process can be the most time-consuming. Indeed, the time required to read
    the data often dominates the time required to do statistical analyses. The I/O
    cost is so high that specialized systems such as Hadoop have been invented to
    try and speed up access to extremely large datasets.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关注的缺点是，处理非常大数据集的每个变量需要从操作系统文件中读取原始数据。这个过程的这一部分可能是最耗时的。事实上，读取数据所需的时间通常主导了进行统计分析所需的时间。I/O成本如此之高，以至于专门的系统，如Hadoop，已被发明用来尝试加速对极大数据集的访问。
- en: How can we make one pass through a set of data and collect a number of descriptive
    statistics?
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何通过一组数据进行一次遍历并收集一些描述性统计信息？
- en: Getting ready
  id: totrans-529
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The variables that we might want to analyze will fall into a number of categories.
    For example, statisticians often segregate variables into categories such as the
    following:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能想要分析的变量将分为多个类别。例如，统计学家经常将变量分成以下类别：
- en: '**Continuous real-valued data** : These variables are often measured by floating-point
    values, they have a well defined unit of measure, and they can take on values
    with a precision limited by the accuracy of the measurement.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连续实值数据**：这些变量通常由浮点值测量，它们有一个明确定义的测量单位，并且它们可以取得由测量精度限制的值。'
- en: '**Discrete or categorical data** : These variables take on a value selected
    from a finite domain. In some cases, we can enumerate the domain in advance. In
    other cases, the domain''s values must be discovered.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离散或分类数据**：这些变量取自有限域中选择的值。在某些情况下，我们可以预先枚举域。在其他情况下，必须发现域的值。'
- en: '**Ordinal data** : This provides a ranking or ordering. Generally, the ordinal
    value is a number, but no other statistical summaries apply to this number, since
    it''s not really a measurement; it has no units.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序数数据**：这提供了一个排名或顺序。通常，序数值是一个数字，但除此数字外，没有其他统计摘要适用于此数字，因为它实际上不是一个测量；它没有单位。'
- en: '**Count data** : This variable is a summary of individual discrete outcomes.
    It can be treated as if it were continuous by computing a real-valued mean of
    an otherwise discrete count.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数数据**：这个变量是个别离散结果的摘要。通过计算一个实值均值，它可以被视为连续的。'
- en: Variables may be independent of each other or they may depend on other variables.
    In the initial phases of a study, the dependence may not be known. In later phases,
    one objective of the software is to discover the dependencies. Later, software
    may be used to model the dependencies.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 变量可能彼此独立，也可能依赖于其他变量。在研究的初期阶段，可能不知道依赖关系。在后期阶段，软件的一个目标是发现这些依赖关系。之后，软件可以用来建模这些依赖关系。
- en: Because of the varieties of data, we need to treat each variable as a distinct
    item. We can't treat them all as simple floating-point values. Properly acknowledging
    the differences will lead to a hierarchy of class definitions. Each subclass will
    contain the unique features for a variable.
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据的多样性，我们需要将每个变量视为一个独立的项目。我们不能将它们都视为简单的浮点值。适当地承认这些差异将导致一系列类定义的层次结构。每个子类将包含变量的独特特征。
- en: 'We have two overall design patterns:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两种总体设计模式：
- en: '**Eager** : We can compute the various summaries as early as possible. In some
    cases, we don''t have to accumulate very much data for this.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**急切**：我们可以尽早计算各种摘要。在某些情况下，我们不必为此积累太多数据。'
- en: '**Lazy** : We compute the summaries as late as possible. This means we''ll
    be accumulating data, and using properties to compute the summaries.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**懒惰**：我们尽可能晚地计算摘要。这意味着我们将积累数据，并使用属性来计算摘要。'
- en: For very large sets of data, we want to have a hybrid solution. We'll compute
    some summaries eagerly, and also use properties to compute the final results from
    those summaries.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非常大的数据集，我们希望有一个混合解决方案。我们将急切地计算一些摘要，并且还使用属性从这些摘要中计算最终结果。
- en: We'll use some data from the *Using the built-in statistics library* recipe
    that includes just two variables in a number of similar data series. The variables
    are named *x* and *y* and are both real-valued variables. The *y* variable should
    depend on the *x* variable, so correlation and regression models apply there.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用*使用内置统计库*食谱中的一些数据，其中包括一系列相似数据系列中的两个变量。这些变量被命名为*x*和*y*，都是实值变量。*y*变量应该依赖于*x*变量，因此相关性和回归模型适用于这里。
- en: 'We can read this data with the following commands:'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下命令读取这些数据：
- en: '[PRE106]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: We've defined the `Path` to the data file. We can then use the `Path` object
    to read the text from this file. This text is used by `json.loads()` to build
    a Python object from the JSON data.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了数据文件的路径。然后我们可以使用`Path`对象从该文件中读取文本。这些文本将被`json.loads()`使用，以从JSON数据构建Python对象。
- en: We've included an `object_pairs_hook` so that this function will build the JSON
    using the `OrderedDict` class instead of the default `dict` class. This will preserve
    the original order of items in the source document.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经包含了一个`object_pairs_hook`，以便该函数将使用`OrderedDict`类构建JSON，而不是默认的`dict`类。这将保留源文档中项目的原始顺序。
- en: 'We can examine the data as follows:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式检查数据：
- en: '[PRE107]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'The overall JSON document is a sequence of subdocuments with keys such as `''I''`
    . Each subdocument has two fields: `"series"` and `"data"` . Within the `"data"`
    array there''s a list of observations that we want to characterize. Each observation
    has a pair of values.'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 整个JSON文档是一个具有诸如`'I'`之类的键的子文档序列。每个子文档有两个字段："series"和"data"。在"data"数组中，有一个我们想要描述的观察值列表。每个观察值都有一对值。
- en: How to do it...
  id: totrans-549
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Define a class to handle the analysis of the variable. This should handle all
    conversions and cleansing. We''ll use the hybrid process approach: we''ll update
    the sums and counts as each data element arrives. We won''t compute the final
    mean or standard deviation until these attributes are requested:'
  id: totrans-550
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个类来处理变量的分析。这应该处理所有的转换和清洗。我们将使用混合处理方法：我们将在每个数据元素到达时更新总和和计数。直到请求这些属性时，我们才会计算最终的均值或标准差：
- en: '[PRE108]'
  id: totrans-551
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: In this example, we've defined summaries for `count` , `sum` , and sum of squares.
    We can extend this class to add more computations. For the median or mode, we
    will have to accumulate the individual values, and change the design to be entirely
    lazy.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们已经为`count`、`sum`和平方和定义了摘要。我们可以扩展这个类以添加更多的计算。对于中位数或模式，我们将不得不积累个体值，并改变设计以完全懒惰。
- en: 'Define instances to handle the input columns. We''ll create two instances of
    our `SimpleStats` class. In this recipe, we''ve chosen two variables that are
    so much alike that a single class covers both cases:'
  id: totrans-553
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义实例来处理输入列。我们将创建我们的`SimpleStats`类的两个实例。在这个示例中，我们选择了两个非常相似的变量，一个类就可以涵盖这两种情况：
- en: '[PRE109]'
  id: totrans-554
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'Define a mapping from actual column titles to the statistics-computing objects.
    In some cases, the columns may not be identified by names: we might be using column
    indexes. In this case, a sequence of objects will match the sequence of columns
    in each row:'
  id: totrans-555
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义实际列标题到统计计算对象的映射。在某些情况下，列可能不是通过名称标识的：我们可能使用列索引。在这种情况下，对象序列将与每行中的列序列匹配：
- en: '[PRE110]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Define a function to process all rows, using the statistics-computing objects
    for each column within each row:'
  id: totrans-557
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来处理所有行，使用每列的统计计算对象在每行内：
- en: '[PRE111]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: The outer `for` statement processes each row of data. The inner `for` statement
    processes each column of each row. The processing is clearly in row-major order.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 外部`for`语句处理每一行数据。内部`for`语句处理每一行的每一列。处理显然是按行主要顺序进行的。
- en: 'Display results or summaries from the various objects:'
  id: totrans-560
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示来自各个对象的结果或摘要：
- en: '[PRE112]'
  id: totrans-561
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: We can apply the analysis function to a series of data values. This will return
    the dictionary that has the statistical summaries.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将分析函数应用于一系列数据值。这将返回具有统计摘要的字典。
- en: How it works...
  id: totrans-563
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: We've created a class that handles cleansing, filtering, and statistics processing
    for a specific kind of column. When confronted with various kinds of columns,
    we'll need multiple class definitions. The idea is to be able to easily create
    a hierarchy of related classes.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个处理特定类型列的清洁、过滤和统计处理的类。当面对各种类型的列时，我们将需要多个类定义。其思想是能够轻松创建相关类的层次结构。
- en: We create an instance of this class for each specific column that we're going
    to analyze. In this example, the `SimpleStats` was designed for a column of simple
    floating-point values. Other designs would be appropriate for discrete or ordinal
    data.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为要分析的每个特定列创建了这个类的一个实例。在这个例子中，`SimpleStats`是为一个简单浮点值列设计的。其他设计可能适用于离散或有序数据。
- en: The externally-facing features of this class are an `add()` method. Each individual
    data value is provided to this method. The `mean` and `stdev` properties compute
    summary statistics.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 该类的外部特性是`add()`方法。每个单独的数据值都提供给这个方法。`mean`和`stdev`属性计算摘要统计信息。
- en: The class also defines a `cleanse()` method that handles the data conversion
    needs. This can be extended to handle the possibility of invalid data. It might
    filter the values instead of raising an exception. This method must be overridden
    to handle more complex data conversions.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 该类还定义了一个`cleanse()`方法，用于处理数据转换需求。这可以扩展到处理无效数据的可能性。它可能会过滤值，而不是引发异常。必须重写此方法以处理更复杂的数据转换。
- en: We've created a collection of individual statistics-processing objects. In this
    example, both items in the collection are instances of `SimpleStats` . In most
    cases, there will be multiple classes involved, and the collection of statistics
    processing objects might be rather complex.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一组单独的统计处理对象。在这个例子中，集合中的两个项目都是`SimpleStats`的实例。在大多数情况下，将涉及多个类，并且统计处理对象的集合可能会相当复杂。
- en: This collection of `SimpleStats` objects is applied to each row of data. A `for`
    statement uses the keys of the mapping, which are also column names to associate
    each column's data with the appropriate statistics-processing object.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 这些`SimpleStats`对象的集合应用于每行数据。`for`语句使用映射的键，这些键也是列名，将每列的数据与适当的统计处理对象相关联。
- en: In some cases, the statistical summaries must be computed lazily. To spot outliers,
    for instance, we need all of the data. One common approach to locating outliers
    required computing a median, computing the absolute deviations from the median,
    and then a median of these absolute deviations. See the *Locating outliers* recipe.
    To compute the mode, we would accumulate all of the data values into a `Counter`
    object.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，统计摘要必须以惰性方式计算。例如，要发现异常值，我们需要所有数据。定位异常值的一种常见方法是计算中位数，计算与中位数的绝对偏差，然后计算这些绝对偏差的中位数。参见*定位异常值*配方。要计算模式，我们将所有数据值累积到`Counter`对象中。
- en: There's more...
  id: totrans-571
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In this design, we've tacitly assumed that all columns are completely independent.
    In some cases, we'll need to combine columns to derive additional data items.
    This will lead to a more complex class definition that may include a reference
    to other instances of `SimpleStats` . This can become rather involved to be sure
    that columns are handled in dependency order.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种设计中，我们默认假设所有列都是完全独立的。在某些情况下，我们需要组合列来推导出额外的数据项。这将导致更复杂的类定义，可能包括对`SimpleStats`的其他实例的引用。确保按照依赖顺序处理列可能会变得相当复杂。
- en: As we saw in the  *Using stacked generator expressions* recipe in [Chapter 8](text00088.html#page
    "Chapter 8. Functional and Reactive Programming Features") , *Functional And Reactive
    Programming Features* , we may have a multistage processing that involves enrichment
    and computing derived values. This further constrains the ordering among the column
    processing rules. One way to handle this is to provide each analyzer with a reference
    to the relevant other analyzers. We might have something like the following rather
    complex set of class definitions.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第8章](text00088.html#page "第8章。功能和响应式编程特性")的*使用堆叠的生成器表达式*配方中看到的，*功能和响应式编程特性*，我们可能会有一个涉及增强和计算派生值的多阶段处理。这进一步限制了列处理规则之间的顺序。处理这种情况的一种方法是为每个分析器提供与相关其他分析器的引用。我们可能会有以下相当复杂的一组类定义。
- en: First, we'll define two classes to handle date columns and time columns in isolation.
    Then we'll combine these to create a timestamp column based on the two input columns.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将定义两个类来分别处理日期列和时间列。然后我们将结合这些类来创建基于两个输入列的时间戳列。
- en: 'Here''s the class to handle a date column in isolation:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是处理日期列的类：
- en: '[PRE113]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'The `DateStats` class only implements the `add()` method. It cleanses the data
    and retains a current value. We can define something similar for processing the
    time column:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: '`DateStats`类只实现了`add()`方法。它清洗数据并保留当前值。我们可以为处理时间列定义类似的东西：'
- en: '[PRE114]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: The `TimeStats` class is similar to `DateStats` ; it only implements the `add()`
    method. Both classes focus on cleaning the source data and retaining the current
    value.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: “TimeStats”类类似于“DateStats”；它只实现了“add()”方法。这两个类都专注于清洗源数据并保留当前值。
- en: 'Here''s a class that depends on the results of the previous two classes. This
    will use the `current` attribute of the `DateStats` and `TimeStats` objects to
    get the currently available value from each of these:'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个依赖于前两个类的类。这将使用“DateStats”和“TimeStats”对象的“current”属性来获取每个对象当前可用的值：
- en: '[PRE115]'
  id: totrans-581
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: The `DateTimeStats` class combines the results of two objects. It requires an
    instance of the `DateStats` class and an instance of the `TimeStats` class. From
    these other two objects, the current cleansed value is available as the `current`
    attribute.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: “DateTimeStats”类结合了两个对象的结果。它需要一个“DateStats”类的实例和一个“TimeStats”类的实例。从这两个对象中，当前的清洗值作为“current”属性是可用的。
- en: Note that the `value` parameter is not used for the `DateTimeStats` implementation
    of the `add()` method. Instead of accepting `value` as an argument, a value is
    collected from the two other cleansing objects. This requires that the other two
    columns were processed before this derived column is processed.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，“value”参数在“DateTimeStats”实现的“add()”方法中未被使用。与接受“value”作为参数不同，值是从另外两个清洗对象中收集的。这要求在处理派生列之前，其他两列必须被处理。
- en: 'In order to be sure that the values are available, some additional processing
    is required for each row. The basic date and time processing maps to specific
    columns:'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保值是可用的，需要对每一行进行一些额外的处理。基本的日期和时间处理映射到特定的列：
- en: '[PRE116]'
  id: totrans-585
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: This `column_stats` mapping can be used to apply two foundational data cleansing
    operations against each row of data. However, we also have derived data that must
    be computed after the foundational data is done.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 这个“column_stats”映射可以用来对每行数据应用两个基础数据清洗操作。然而，我们还有派生数据，必须在基础数据完成后计算。
- en: 'We might have something like this:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会有这样的情况：
- en: '[PRE117]'
  id: totrans-588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'We''ve built an instance of `DateTimeStats` that depends on two other statistical
    process objects: `date_stats` and `time_stats` . The `add()` method of this object
    will fetch the current values from each of the other two objects. If we had other
    derived columns, we could collect them into this mapping.'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建立了一个依赖于另外两个统计处理对象“date_stats”和“time_stats”的“DateTimeStats”实例。这个对象的“add()”方法将从另外两个对象中获取当前值。如果我们有其他派生列，我们可以将它们收集到这个映射中。
- en: 'This `derived_stats` mapping can be used to apply statistical processing operations
    to create and analyze derived data. The overall processing loop now has two phases:'
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 这个“derived_stats”映射可以用来应用统计处理操作，以创建和分析派生数据。整体处理循环现在有两个阶段：
- en: '[PRE118]'
  id: totrans-591
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: We've computed statistics for the columns that are present in the source data.
    Then we computed statistics for the derived columns. This has the pleasant feature
    of being configured using just two mappings. We can change the classes that are
    used by updating the `column_stats` and `derived_stats` mappings.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为源数据中存在的列计算了统计数据。然后我们为派生列计算了统计数据。这个方法的一个令人愉快的特点是只使用了两个映射进行配置。我们可以通过更新“column_stats”和“derived_stats”映射来更改所使用的类。
- en: Using map()
  id: totrans-593
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用map()
- en: We've used explicit `for` statements to apply each statistics object to the
    appropriate column data. We can also use a generator expression. We can even try
    to use the `map()` function. See the *Combining map and reduce transformations*
    recipe in [Chapter 8](text00088.html#page "Chapter 8. Functional and Reactive
    Programming Features") , *Functional and Reactive Programming Features* , for
    some additional background on this technique.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用显式的“for”语句将每个统计对象应用于相应的列数据。我们也可以使用一个生成器表达式。我们甚至可以尝试使用“map()”函数。在[第8章](text00088.html#page
    "第8章. 函数式和响应式编程特性")的*组合map和reduce转换*一节中，可以了解到有关这种技术的一些额外背景。
- en: 'An alternative data gathering collection could look like this:'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个数据收集集合可能如下所示：
- en: '[PRE119]'
  id: totrans-596
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: Instead of the object, we've provided a function that applies the object's `add()`
    method to the given data value.
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个应用对象的“add()”方法到给定数据值的函数，而不是对象本身。
- en: 'With this collection, we can use a generator expression:'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个集合，我们可以使用一个生成器表达式：
- en: '[PRE120]'
  id: totrans-599
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: This will apply the `data_gathering[k]` function to each value, `k` , that's
    available in the row.
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 这将对每个值“k”在行中可用的“data_gathering[k]”函数进行应用。
- en: See also
  id: totrans-601
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: See the *Designing classes with lots of processing* and *Using properties for
    lazy attributes* recipes in [Chapter 6](text00070.html#page "Chapter 6. Basics
    of Classes and Objects") , *Basics of Classes and Objects,* for some additional
    design alternatives that fit into this overall approach
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第6章](text00070.html#page "第6章. 类和对象的基础知识")的*类的设计与大量处理*和*使用惰性属性*一节中，还可以了解到一些适合这种整体方法的其他设计选择。
