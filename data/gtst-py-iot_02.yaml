- en: Dividing Text Data and Building Text Classifiers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 划分文本数据和构建文本分类器
- en: 'This chapter presents the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了以下主题：
- en: Building a text classifier
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建文本分类器
- en: Preprocessing data using tokenization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用标记化预处理数据
- en: Stemming text data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词干化文本数据
- en: Dividing text using chunking
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分块划分文本
- en: Building a bag-of-words model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建词袋模型
- en: Applications of text classifiers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本分类器的应用
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: This chapter presents recipes to build text classifiers. This includes extracting
    vital features from the database, training, testing, and validating the text classifier.
    Initially, a text classifier is trained using commonly used words. Later, the
    trained text classifier is used for prediction. Building a text classifier includes
    preprocessing the data using tokenization, stemming text data, dividing text using
    chunking, and building a bag-of-words model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了构建文本分类器的方法。这包括从数据库中提取重要特征、训练、测试和验证文本分类器。最初，使用常用词训练文本分类器。后来，训练好的文本分类器用于预测。构建文本分类器包括使用标记化预处理数据、词干化文本数据、使用分块划分文本和构建词袋模型。
- en: Building a text classifier
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建文本分类器
- en: Classifier units are normally considered to separate a database into various
    classes. The Naive Bayes classifier scheme is widely considered in literature
    to segregate the texts based on the trained model. This section of the chapter
    initially considers a text database with keywords; feature extraction extracts
    the key phrases from the text and trains the classifier system. Then, **term frequency-inverse
    document frequency** (**tf-idf**) transformation is implemented to specify the
    importance of the word. Finally, the output is predicted and printed using the
    classifier system.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器单元通常被认为是将数据库分成各种类别的。朴素贝叶斯分类器方案被广泛认为是根据训练模型将文本分隔的文献。本章的这一部分最初考虑了一个带有关键词的文本数据库；特征提取从文本中提取关键短语并训练分类器系统。然后，实施**词频-逆文档频率**（**tf-idf**）转换以指定单词的重要性。最后，使用分类器系统预测并打印输出。
- en: How to do it...
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Include the following lines in a new Python file to add datasets:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新的Python文件中包含以下行以添加数据集：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Perform feature extraction to extract the main words from the text:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行特征提取以从文本中提取主要单词：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Train the classifier:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练分类器：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Implement the Multinomial Naive Bayes classifier:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现多项式朴素贝叶斯分类器：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Predict the output categories:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测输出类别：
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Print the output:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印输出：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following screenshot provides examples of predicting the object based on
    the input from the database:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图提供了根据数据库输入预测对象的示例：
- en: '![](Images/14d70abf-d300-4e88-9ece-6318c2e1abb0.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/14d70abf-d300-4e88-9ece-6318c2e1abb0.png)'
- en: How it works...
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The previous section of this chapter provided insight regarding the implemented
    classifier section and some sample results. The classifier section works based
    on a comparison between the previous text in the trained Naive Bayes with the
    key test in the test sequence*.*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的前一部分提供了有关实施分类器部分和一些样本结果的见解。分类器部分是基于训练好的朴素贝叶斯中的先前文本与测试序列中的关键测试之间的比较工作的。
- en: See also
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'Please refer to the following articles:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅以下文章：
- en: '*Sentiment analysis algorithms and applications: A survey *at [https://www.sciencedirect.com/science/article/pii/S2090447914000550](https://www.sciencedirect.com/science/article/pii/S2090447914000550).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感分析算法和应用：调查*在[https://www.sciencedirect.com/science/article/pii/S2090447914000550](https://www.sciencedirect.com/science/article/pii/S2090447914000550)。'
- en: 'S*entiment classification of online reviews: using sentence-based language
    model* to learn how sentiment prediction works at [https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20](https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在线评论的情感分类：使用基于句子的语言模型*来学习情感预测的工作方式[https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20](https://www.tandfonline.com/doi/abs/10.1080/0952813X.2013.782352?src=recsys&journalCode=teta20)。'
- en: '*Sentiment analysis using product review data* and *Sentence-level sentiment
    analysis in the presence of modalities* to learn more about various metrics used
    in recommendation systems at [https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2)
    and ;[https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1](https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用产品评论数据进行情感分析*和*在存在情感的情况下进行句子级情感分析*，以了解推荐系统中使用的各种指标[https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0015-2)和[https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1](https://link.springer.com/chapter/10.1007/978-3-642-54903-8_1)。'
- en: Pre-processing data using tokenization
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用标记化预处理数据
- en: The pre-processing of data involves converting the existing text into acceptable
    information for the learning algorithm.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的预处理涉及将现有文本转换为学习算法的可接受信息。
- en: Tokenization is the process of dividing text into a set of meaningful pieces.
    These pieces are called tokens.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化是将文本分成一组有意义的片段的过程。这些片段被称为标记。
- en: How to do it...
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Introduce sentence tokenization:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍句子标记化：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Form a new text tokenizer:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 形成一个新的文本标记器：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Form a new word tokenizer:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 形成一个新的单词标记器：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Introduce a new WordPunct tokenizer:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 引入一个新的WordPunct标记器：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result obtained by the tokenizer is shown here. It divides a sentence into
    word groups:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 标记器得到的结果如下所示。它将一个句子分成单词组：
- en: '![](Images/fb4eb393-47a2-496c-a3cb-a2f99a36dfa6.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/fb4eb393-47a2-496c-a3cb-a2f99a36dfa6.png)'
- en: Stemming text data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词干化文本数据
- en: The stemming procedure involves creating a suitable word with reduced letters
    for the words of the tokenizer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 词干处理过程涉及为标记器的单词创建适当的缩写单词。
- en: How to do it...
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Initialize the stemming process with a new Python file:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用新的Python文件初始化词干处理过程：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s describe some words to consider, as follows:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们描述一些要考虑的词，如下所示：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Identify a group of `stemmers` to be used:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定要使用的一组`词干处理器`：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Initialize the necessary tasks for the chosen `stemmers`:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为所选的“词干处理器”初始化必要的任务：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Format a table to print the results:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 格式化表格以打印结果：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Repeatedly check the list of words and arrange them using chosen `stemmers`:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反复检查单词列表，并使用选择的“词干处理器”对它们进行排列：
- en: '[PRE15]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The result obtained from the stemming process is shown in the following screenshot:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 词干处理过程得到的结果如下截图所示：
- en: '![](Images/c6b683e2-a8d2-4273-89f8-7b841628e28b.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/c6b683e2-a8d2-4273-89f8-7b841628e28b.png)'
- en: Dividing text using chunking
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分块分割文本
- en: The chunking procedure can be used to divide the large text into small, meaningful
    words.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 分块过程可用于将大文本分成小的、有意义的单词。
- en: How to do it...
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Develop and import the following packages using Python:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python开发并导入以下包：
- en: '[PRE16]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Describe a function that divides text into chunks:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述将文本分成块的函数：
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Initialize the following programming lines to get the assigned variables:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化以下编程行以获取分配的变量：
- en: '[PRE18]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Start the iteration using words:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始使用单词进行迭代：
- en: '[PRE19]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After getting the essential amount of words, reorganize the variables:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取必要数量的单词后，重新组织变量：
- en: '[PRE20]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Attach the chunks to the output variable:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将块附加到输出变量：
- en: '[PRE21]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Import the data of `Brown corpus` and consider the first `10000` words:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入“布朗语料库”的数据，并考虑前10000个单词：
- en: '[PRE22]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Describe the word size in every chunk:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述每个块中的字大小：
- en: '[PRE23]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Initiate a pair of significant variables:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一对重要的变量：
- en: '[PRE24]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Print the result by calling the `splitter` function:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用“分割器”函数打印结果：
- en: '[PRE25]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The result obtained after chunking is shown in the following screenshot:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分块后得到的结果如下截图所示：
- en: '![](Images/e33566a4-1380-4420-91db-00b582161836.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/e33566a4-1380-4420-91db-00b582161836.png)'
- en: Building a bag-of-words model
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建词袋模型
- en: When working with text documents that include large words, we need to switch
    them to several types of arithmetic depictions. We need to formulate them to be
    suitable for machine learning algorithms. These algorithms require arithmetical
    information so that they can examine the data and provide significant details.
    The bag-of-words procedure helps us to achieve this. Bag-of-words creates a text
    model that discovers vocabulary using all the words in the document. Later, it
    creates the models for every text by constructing a histogram of all the words
    in the text.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理包含大单词的文本文档时，我们需要将它们转换为几种类型的算术表示。我们需要将它们制定为适合机器学习算法的形式。这些算法需要算术信息，以便它们可以检查数据并提供重要的细节。词袋程序帮助我们实现这一点。词袋创建一个文本模型，使用文档中的所有单词来发现词汇。随后，它通过构建文本中所有单词的直方图来为每个文本创建模型。
- en: How to do it...
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Initialize a new Python file by importing the following file:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过导入以下文件初始化一个新的Python文件：
- en: '[PRE26]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Define the `main` function and read the input data from `Brown corpus`:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义“main”函数并从“布朗语料库”中读取输入数据：
- en: '[PRE27]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Split the text content into chunks:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本内容分成块：
- en: '[PRE28]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Build a vocabulary based on these `text` chunks:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于这些“文本”块构建词汇表：
- en: '[PRE29]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Extract a document word matrix, which effectively counts the amount of incidences
    of each word in the document:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取文档词矩阵，有效地计算文档中每个单词的出现次数：
- en: '[PRE30]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Extract the document term `matrix:`
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取文档术语“矩阵”：
- en: '[PRE31]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Extract the vocabulary and print it:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取词汇并打印它：
- en: '[PRE32]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Print the document term `matrix`:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印文档术语“矩阵”：
- en: '[PRE33]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Iterate throughout the words, and print the reappearance of every word in various
    chunks:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代单词，并打印每个单词在不同块中的重现：
- en: '[PRE34]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The result obtained after executing the bag-of-words model is shown as follows:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行词袋模型后获得的结果如下所示：
- en: '![](Images/be04e751-2b4b-4148-a279-59415d35db0a.png)![](Images/c0088dd1-48ad-4485-b29b-14b920f4998e.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/be04e751-2b4b-4148-a279-59415d35db0a.png)![](Images/c0088dd1-48ad-4485-b29b-14b920f4998e.png)'
- en: 'In order to understand how it works on a given sentence, refer to the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解它在给定句子上的工作原理，请参考以下内容：
- en: '*Introduction to Sentiment Analysis*, explained here: [https://blog.algorithmia.com/introduction-sentiment-analysis/](https://blog.algorithmia.com/introduction-sentiment-analysis/)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感分析简介*，在这里解释：[https://blog.algorithmia.com/introduction-sentiment-analysis/](https://blog.algorithmia.com/introduction-sentiment-analysis/)'
- en: Applications of text classifiers
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本分类器的应用
- en: Text classifiers are used to analyze customer sentiments, in product reviews,
    when searching queries on the internet, in social tags, to predict the novelty
    of research articles, and so on.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类器用于分析客户情绪，在产品评论中，当在互联网上搜索查询时，在社交标签中，预测研究文章的新颖性等等。
