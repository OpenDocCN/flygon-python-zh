- en: Data Acquisition and Extraction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据获取和提取
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: How to parse websites and navigate the DOM using BeautifulSoup
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用BeautifulSoup解析网站和导航DOM
- en: Searching the DOM with Beautiful Soup's find methods
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Beautiful Soup的查找方法搜索DOM
- en: Querying the DOM with XPath and lxml
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用XPath和lxml查询DOM
- en: Querying data with XPath and CSS Selectors
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用XPath和CSS选择器查询数据
- en: Using Scrapy selectors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Scrapy选择器
- en: Loading data in Unicode / UTF-8 format
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以Unicode / UTF-8格式加载数据
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: The key aspects for effective scraping are understanding how content and data
    are stored on web servers, identifying the data you want to retrieve, and understanding
    how the tools support this extraction. In this chapter, we will discuss website
    structures and the DOM, introduce techniques to parse, and query websites with
    lxml, XPath, and CSS. We will also look at how to work with websites developed
    in other languages and different encoding types such as Unicode.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有效抓取的关键方面是理解内容和数据如何存储在Web服务器上，识别要检索的数据，并理解工具如何支持此提取。在本章中，我们将讨论网站结构和DOM，介绍使用lxml、XPath和CSS解析和查询网站的技术。我们还将看看如何处理其他语言和不同编码类型（如Unicode）开发的网站。
- en: Ultimately, understanding how to find and extract data within an HTML document
    comes down to understanding the structure of the HTML page, its representation
    in the DOM, the process of querying the DOM for specific elements, and how to
    specify which elements you want to retrieve based upon how the data is represented.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，理解如何在HTML文档中查找和提取数据归结为理解HTML页面的结构，它在DOM中的表示，查询DOM以查找特定元素的过程，以及如何根据数据的表示方式指定要检索的元素。
- en: How to parse websites and navigate the DOM using BeautifulSoup
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用BeautifulSoup解析网站和导航DOM
- en: When the browser displays a web page it builds a model of the content of the
    page in a representation known as the **document object model** (**DOM**). The
    DOM is a hierarchical representation of the page's entire content, as well as
    structural information, style information, scripts, and links to other content.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当浏览器显示网页时，它会在一种称为**文档对象模型**（**DOM**）的表示中构建页面内容的模型。DOM是页面整个内容的分层表示，以及结构信息、样式信息、脚本和其他内容的链接。
- en: It is critical to understand this structure to be able to effectively scrape
    data from web pages. We will look at an example web page, its DOM, and examine
    how to navigate the DOM with Beautiful Soup.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这种结构对于能够有效地从网页上抓取数据至关重要。我们将看一个示例网页，它的DOM，并且检查如何使用Beautiful Soup导航DOM。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'We will use a small web site that is included in the `www` folder of the sample
    code.  To follow along, start a web server from within the `www` folder.  This
    can be done with Python 3 as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用示例代码的`www`文件夹中包含的一个小型网站。要跟着做，请从`www`文件夹内启动一个Web服务器。可以使用Python 3来完成这个操作：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The DOM of a web page can be examined in Chrome by right-clicking the page and
    selecting Inspect. This opens the Chrome Developer Tools. Open a browser page
    to `http://localhost:8080/planets.html`. Within chrome you can right click and
    select 'inspect' to open developer tools (other browsers have similar tools).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过右键单击页面并选择检查来检查Chrome中的网页DOM。这将打开Chrome开发者工具。在浏览器中打开`http://localhost:8080/planets.html`。在Chrome中，您可以右键单击并选择“检查”以打开开发者工具（其他浏览器也有类似的工具）。
- en: '![](assets/414227f7-dd30-4c7e-8bab-7fc02e136fcd.png) Selecting Inspect on the
    Page'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/414227f7-dd30-4c7e-8bab-7fc02e136fcd.png)在页面上选择检查'
- en: This opens the developer tools and the inspector. The DOM can be examined in
    the Elements tab.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开开发者工具和检查器。DOM可以在元素选项卡中检查。
- en: 'The following shows the selection of the first row in the table:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下显示了表中第一行的选择：
- en: '![](assets/f3dd4285-7e9b-4b96-a3c5-3f31e318b983.png)Inspecting the First Row'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/f3dd4285-7e9b-4b96-a3c5-3f31e318b983.png)检查第一行'
- en: Each row of planets is within a `<tr>` element.  There are several characteristics
    of this element and its neighboring elements that we will examine because they
    are designed to model common web pages.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行行星都在一个`<tr>`元素内。这个元素及其相邻元素有几个特征，我们将检查它们，因为它们被设计为模拟常见的网页。
- en: 'Firstly, this element has three attributes: `id`, `planet`, and `name`. Attributes
    are often important in scraping as they are commonly used to identify and locate
    data embedded in the HTML.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这个元素有三个属性：`id`，`planet`和`name`。属性在抓取中通常很重要，因为它们通常用于识别和定位嵌入在HTML中的数据。
- en: Secondly, the `<tr>` element has children, and in this case, five `<td>` elements.
    We will often need to look into the children of a specific element to find the
    actual data that is desired.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，`<tr>`元素有子元素，在这种情况下是五个`<td>`元素。我们经常需要查看特定元素的子元素，以找到所需的实际数据。
- en: This element also has a parent element, `<tbody>`. There are also sibling elements,
    and the a set of `<tr>`  child elements.  From any planet, we can go up to the
    parent and find the other planets. And as we will see, we can use various constructs
    in the various tools, such as the **find** family of functions in Beautiful Soup,
    and also  `XPath` queries, to easily navigate these relationships.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个元素还有一个父元素`<tbody>`。还有兄弟元素，以及一组`<tr>`子元素。从任何行星，我们可以向上到父元素并找到其他行星。正如我们将看到的，我们可以使用各种工具中的各种构造，比如Beautiful
    Soup中的**find**函数系列，以及`XPath`查询，轻松地导航这些关系。
- en: How to do it...
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This recipe, and most of the others in this chapter, will be presented with
    iPython in an interactive manner.  But all of the code for each is available in
    a script file.  The code for this recipe is in `02/01_parsing_html_wtih_bs.py`.
    You can type the following in, or cut and paste from the script file.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方以及本章中的大多数其他配方都将以iPython的交互方式呈现。但是每个配方的代码都可以在脚本文件中找到。这个配方的代码在`02/01_parsing_html_wtih_bs.py`中。您可以输入以下内容，或者从脚本文件中复制粘贴。
- en: Now let's walk through parsing HTML with Beautiful Soup. We start by loading
    this page into a `BeautifulSoup` object using the following code, which creates
    a BeautifulSoup object, loads the content of the page using with requests.get,
    and loads it into a variable named soup.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过Beautiful Soup解析HTML。我们首先通过以下代码将此页面加载到`BeautifulSoup`对象中，该代码创建一个BeautifulSoup对象，使用requests.get加载页面内容，并将其加载到名为soup的变量中。
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The HTML in the `soup` object can be retrieved by converting it to a string
    (most BeautifulSoup objects have this characteristic).  This following shows the
    first 1000 characters of the HTML in the document:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将其转换为字符串，可以检索`soup`对象中的HTML（大多数BeautifulSoup对象都具有此特性）。以下显示了文档中HTML的前1000个字符：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can navigate the elements in the DOM using properties of `soup`. `soup`
    represents the overall document and we can drill into the document by chaining
    the tag names. The following navigates to the `<table>` containing the data:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`soup`的属性来导航DOM中的元素。`soup`代表整个文档，我们可以通过链接标签名称来深入文档。以下导航到包含数据的`<table>`：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following retrieves the the first child `<tr>` of the table:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是获取表格的第一个子`<tr>`：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note this type of notation retrieves only the first child of that type.  Finding
    more requires iterations of all the children, which we will do next, or using
    the find methods (the next recipe).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此类表示法仅检索该类型的第一个子节点。要找到更多，需要迭代所有子节点，我们将在下一步中进行，或者使用查找方法（下一个示例）。
- en: 'Each node has both children and descendants. Descendants are all the nodes
    underneath a given node (event at further levels than the immediate children),
    while children are those that are a first level descendant. The following retrieves
    the children of the table, which is actually a `list_iterator` object:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点都有子节点和后代。后代是给定节点下面的所有节点（甚至比直接子节点更深层次的节点），而子节点是第一级后代。以下是获取表格的子节点，实际上是一个`list_iterator`对象：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can examine each child element in the iterator using a `for` loop or a Python
    generator. The following uses a generator to get all the children of the and return
    the first few characters of their constituent HTML as a list:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`for`循环或Python生成器来检查迭代器中的每个子元素。以下使用生成器来获取所有子节点，并将它们的HTML组成的前几个字符作为列表返回：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Last but not least, the parent of a node can be found using the `.parent` property:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，节点的父节点可以使用`.parent`属性找到：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: Beautiful Soup converts the HTML from the page into its own internal representation.
    This model has an identical representation to the DOM that would be created by
    a browser. But Beautiful Soup also provides many powerful capabilities for navigating
    the elements in the DOM, such as what we have seen when using the tag names as
    properties.  These are great for finding things when we know a fixed path through
    the HTML with the tag names.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Beautiful Soup将页面的HTML转换为其自己的内部表示。这个模型与浏览器创建的DOM具有相同的表示。但是Beautiful Soup还提供了许多强大的功能，用于导航DOM中的元素，例如我们在使用标签名称作为属性时所看到的。当我们知道HTML中的标签名称的固定路径时，这些功能非常适合查找东西。
- en: There's more...
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: This manner of navigating the DOM is relatively inflexible and is highly dependent
    upon the structure. It is possible that this structure can change over time as
    web pages are updated by their creator(s). The pages could even look identical,
    but have a completely different structure that breaks your scraping code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种导航DOM的方式相对不灵活，并且高度依赖于结构。可能随着网页由其创建者更新，结构会随时间改变。页面甚至可能看起来相同，但具有完全不同的结构，从而破坏您的抓取代码。
- en: So how can we deal with this? As we will see, there are several ways of searching
    for elements that are much better than defining explicit paths. In general, we
    can do this using XPath and by using the find methods of beautiful soup. We will
    examine both in recipes later in this chapter.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们该如何处理呢？正如我们将看到的，有几种搜索元素的方法比定义显式路径要好得多。一般来说，我们可以使用XPath和Beautiful Soup的查找方法来做到这一点。我们将在本章后面的示例中检查这两种方法。
- en: Searching the DOM with Beautiful Soup's find methods
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Beautiful Soup的查找方法搜索DOM
- en: We can perform simple searches of the DOM using Beautiful Soup's find methods.
    These methods give us a much more flexible and powerful construct for finding
    elements that are not dependent upon the hierarchy of those elements.  In this
    recipe we will examine  several common uses of these functions to locate various
    elements in the DOM.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Beautiful Soup的查找方法对DOM进行简单搜索。这些方法为我们提供了一个更灵活和强大的构造，用于查找不依赖于这些元素的层次结构的元素。在本示例中，我们将检查这些函数的几种常见用法，以定位DOM中的各种元素。
- en: Getting ready
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: ff you want to cut and paste the following into ipython, you can find the samples
    in `02/02_bs4_find.py`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想将以下内容剪切并粘贴到ipython中，您可以在`02/02_bs4_find.py`中找到示例。
- en: How to do it...
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We will start with a fresh iPython session and start by loading the planets
    page:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个新的iPython会话开始，并首先加载行星页面：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the previous recipe, to access all of the `<tr>` in the table, we used a
    chained property syntax to get the table, and then needed to get the children
    and iterator over them.  This does have a problem as the children could be elements
    other than `<tr>`.  A more preferred method of getting just the `<tr>` child elements
    is to use `findAll`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，为了访问表格中的所有`<tr>`，我们使用了链式属性语法来获取表格，然后需要获取子节点并对其进行迭代。这会有一个问题，因为子节点可能是除了`<tr>`之外的其他元素。获取`<tr>`子元素的更优选方法是使用`findAll`。
- en: 'Lets start by first finding the `<table>`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先找到`<table>`：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This tells the soup object to find the first `<table>` element in the document. 
    From this element we can find all of the `<tr>` elements that are descendants
    of the table with `findAll`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉soup对象在文档中查找第一个`<table>`元素。从这个元素中，我们可以使用`findAll`找到所有属于该表格的`<tr>`元素的后代：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note that these are the descendants and not immediate children.  Change the
    query to `"td"` to see the difference.  The are no direct children that are `<td>`,
    but each row has multiple <td> elements.  In all, there would be 54 `<td>` elements
    found.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意这些是后代而不是直接的子代。将查询更改为`"td"`以查看区别。没有直接的子代是`<td>`，但每行都有多个`<td>`元素。总共会找到54个`<td>`元素。
- en: There is a small issue here if we want only rows that contain data for planets.
    The table header is also included.  We can fix this by utilizing the `id` attribute
    of the target rows.  The following finds the row where the value of `id` is `"planet3"`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只想要包含行星数据的行，这里有一个小问题。表头也被包括在内。我们可以通过利用目标行的`id`属性来解决这个问题。以下代码找到了`id`值为`"planet3"`的行。
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Awesome! We used the fact that this page uses this attribute to represent table
    rows with actual data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们利用了这个页面使用这个属性来表示具有实际数据的表行。
- en: 'Now let''s go one step further and collect the masses for each planet and put
    the name and mass in a dictionary:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们再进一步，收集每个行星的质量，并将名称和质量放入字典中：
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: And just like that we have made a nice data structure from the content embedded
    within the page.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 就像这样，我们已经从页面中嵌入的内容中制作了一个很好的数据结构。
- en: Querying the DOM with XPath and lxml
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用XPath和lxml查询DOM
- en: 'XPath is a query language for selecting nodes from an XML document and is a
    must-learn query language for anyone performing web scraping. XPath offers a number
    of benefits to its user over other model-based tools:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: XPath是一种用于从XML文档中选择节点的查询语言，对于进行网页抓取的任何人来说，它是必须学习的查询语言。XPath相对于其他基于模型的工具，为其用户提供了许多好处：
- en: Can easily navigate through the DOM tree
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以轻松地浏览DOM树
- en: More sophisticated and powerful than other selectors like CSS selectors and
    regular expressions
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比CSS选择器和正则表达式等其他选择器更复杂和强大
- en: It has a great set (200+) of built-in functions and is extensible with custom
    functions
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有一个很棒的（200+）内置函数集，并且可以通过自定义函数进行扩展
- en: It is widely supported by parsing libraries and scraping platforms
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它得到了解析库和抓取平台的广泛支持
- en: 'XPath contains seven data models (we have seen some of them previously):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: XPath包含七种数据模型（我们之前已经看到了其中一些）：
- en: root node (top level parent node)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根节点（顶级父节点）
- en: element nodes (`<a>`..`</a>`)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素节点（`<a>`..`</a>`）
- en: attribute nodes (`href="example.html"`)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 属性节点（`href="example.html"`）
- en: text nodes (`"this is a text"`)
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本节点（`"this is a text"`）
- en: comment nodes (`<!-- a comment -->`)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注释节点（`<!-- a comment -->`）
- en: namespace nodes
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名空间节点
- en: processing instruction nodes
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理指令节点
- en: 'XPath expressions can return different data types:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: XPath表达式可以返回不同的数据类型：
- en: strings
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串
- en: booleans
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔值
- en: numbers
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字
- en: node-sets (probably the most common case)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点集（可能是最常见的情况）
- en: An (XPath) **axis** defines a node-set relative to the current node. A total
    of 13 axes are defined in XPath to enable easy searching for different node parts,
    from the current context node, or the root node.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: （XPath）**轴**定义了相对于当前节点的节点集。XPath中定义了总共13个轴，以便轻松搜索不同的节点部分，从当前上下文节点或根节点。
- en: '**lxml** is a Python wrapper on top of the libxml2 XML parsing library, which
    is written in C.  The implementation in C helps make it faster than Beautiful
    Soup, but also harder to install on some computers. The latest installation instructions
    are available at: [http://lxml.de/installation.html](http://lxml.de/installation.html).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**lxml**是一个Python包装器，位于libxml2 XML解析库之上，后者是用C编写的。C中的实现有助于使其比Beautiful Soup更快，但在某些计算机上安装起来也更困难。最新的安装说明可在以下网址找到：[http://lxml.de/installation.html](http://lxml.de/installation.html)。'
- en: lxml supports XPath, which makes it considerably easy to manage complex XML
    and HTML documents. We will examine several techniques of using lxml and XPath
    together, and how to use lxml and XPath to navigate the DOM and access data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: lxml支持XPath，这使得管理复杂的XML和HTML文档变得相当容易。我们将研究使用lxml和XPath一起的几种技术，以及如何使用lxml和XPath来导航DOM并访问数据。
- en: Getting ready
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The code for these snippets is in `02/03_lxml_and_xpath.py` in case you want
    to save some typing.  We will start by importing `html` from `lxml`, as well as
    `requests`, and then load the page.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这些片段的代码在`02/03_lxml_and_xpath.py`中，如果你想节省一些输入。我们将首先从`lxml`中导入`html`，以及`requests`，然后加载页面。
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: By this point, lxml should be installed as a dependency of other installs. 
    If you get errors, install it with `pip install lxml`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一点，lxml应该已经作为其他安装的依赖项安装了。如果出现错误，请使用`pip install lxml`进行安装。
- en: How to do it...
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: The first thing that we do is to load the HTML into an lxml "etree".  This is
    lxml's representation of the DOM.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是将HTML加载到lxml的“etree”中。这是lxml对DOM的表示。
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `tree` variable is now an lxml representation of the DOM which models the
    HTML content. Let's now examine how to use it and XPath to select various elements
    from the document.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`tree`变量现在是DOM的lxml表示，它对HTML内容进行了建模。现在让我们来看看如何使用它和XPath从文档中选择各种元素。'
- en: Out first XPath example will be to find all the the `<tr>` elements below the
    `<table>` element.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个XPath示例将是查找所有在`<table>`元素下的`<tr>`元素。
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This XPath navigates by tag name from the root of the document down to the `<tr>`
    element.  This example looks similar to the property notation from Beautiful Soup,
    but ultimately it is significantly more expressive.  And notice one difference
    in the result.  All the the `<tr>` elements were returned and not just the first. 
    As a matter of fact, the tags at each level of this path with return multiple
    items if they are available.  If there was multiple `<div>` elements just below
    `<body>`, then the search for `table/tr` would be executed on all of those `<div>`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个XPath从文档的根部通过标签名称进行导航，直到`<tr>`元素。这个例子看起来类似于Beautiful Soup中的属性表示法，但最终它更加具有表现力。请注意结果中的一个区别。所有的`<tr>`元素都被返回了，而不仅仅是第一个。事实上，如果每个级别的标签都有多个项目可用，那么这个路径的搜索将在所有这些`<div>`上执行。
- en: 'The actual result was an `lxml` element object.  The following gets the HTML
    associated with the elements but using `etree.tostring()` (albeit they have encoding
    applied):'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 实际结果是一个`lxml`元素对象。以下使用`etree.tostring()`获取与元素相关的HTML（尽管它们已经应用了编码）：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now let's look at using XPath to select only the `<tr>` elements that are planets.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用XPath来选择只有行星的`<tr>`元素。
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The use of the `[]` next to a tag states that we want to do a selection based
    on some criteria upon the current element.  The `@` states that we want to examine
    an attribute of the tag, and in this cast we want to select tags where the attribute
    is equal to `"planet"`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在标签旁边使用`[]`表示我们要根据当前元素的某些条件进行选择。`@`表示我们要检查标签的属性，在这种情况下，我们要选择属性等于"planet"的标签。
- en: There is also another point to be made out of the query that had 11 `<tr>` rows. 
    As stated earlier, the XPath runs the navigation on all the nodes found at each
    level.  There are two tables in this document, both children of a different `<div>`
    that are both a child or the `<body>` element.  The row with `id="planetHeader"`
    came from our desired target table, the other, with `id="footerRow"`, came from
    the second table.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一个要指出的是查询中有11个`<tr>`行。如前所述，XPath在每个级别上对所有找到的节点进行导航。这个文档中有两个表，都是不同`<div>`的子元素，都是`<body>`元素的子元素。具有`id="planetHeader"`的行来自我们想要的目标表，另一个具有`id="footerRow"`的行来自第二个表。
- en: 'Previously we solved this by selecting `<tr>` with `class="row"`, but there
    are also other ways worth a brief mention.  The first is that we can also use
    `[]` to specify a specific element at each section of the XPath like they are
    arrays.  Take the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以前我们通过选择`class="row"`的`<tr>`来解决了这个问题，但还有其他值得简要提及的方法。首先，我们还可以使用`[]`来指定XPath的每个部分中的特定元素，就像它们是数组一样。看下面的例子：
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Arrays in XPath start at 1 instead of 0 (a common source of error).  This selected
    the first `<div>`.  A change to `[2]` selects the second `<div>` and hence only
    the second `<table>`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: XPath中的数组从1开始而不是0（一个常见的错误来源）。这选择了第一个`<div>`。更改为`[2]`选择了第二个`<div>`，因此只选择了第二个`<table>`。
- en: '[PRE19]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The first `<div>` in this document also has an id attribute:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文档中的第一个`<div>`也有一个id属性：
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This can be used to select this `<div>`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以用来选择这个`<div>`：
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Earlier we selected the planet rows based upon the value of the class attribute. 
    We can also exclude rows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们根据class属性的值选择了行星行。我们也可以排除行：
- en: '[PRE22]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Suppose that the planet rows did not have attributes (nor the header row),
    then we could do this by position, skipping the first row:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 假设行星行没有属性（也没有标题行），那么我们可以通过位置来做到这一点，跳过第一行：
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'It is possible to navigate to the parent of a node using `parent::*`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`parent::*`来导航到节点的父级：
- en: '[PRE24]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This returned two parents as, remember, this XPath returns the rows from two
    tables, so the parents of all those rows are found. The `*` is a wild card that
    represents any parent tags with any name. In this case, the two parents are both
    tables, but in general the result can be any number of HTML element types.  The
    following has the same result, but if the two parents where different HTML tags
    then it would only return the `<table>` elements.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了两个父级，因为这个XPath返回了两个表的行，所以找到了所有这些行的父级。`*`是一个通配符，代表任何名称的任何父级标签。在这种情况下，这两个父级都是表，但通常结果可以是任意数量的HTML元素类型。下面的结果相同，但如果两个父级是不同的HTML标签，那么它只会返回`<table>`元素。
- en: '[PRE25]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'It is also possible to specify a specific parent by position or attribute.
    The following selects the parent with `id="footerTable"`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以通过位置或属性指定特定的父级。以下选择具有`id="footerTable"`的父级：
- en: '[PRE26]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'A shortcut for parent is `..` (and `.` also represents the current node):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 父级的快捷方式是`..`（`.`也表示当前节点）：
- en: '[PRE27]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'And the last example finds the mass of Earth:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个示例找到了地球的质量：
- en: '[PRE28]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The trailing portion of this XPath,`/td[3]/text()[1]`, selects the third `<td>`
    element in the row, then the text of that element (which is an array of all the
    text in the element), and the first of those which is the mass.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这个XPath的尾部`/td[3]/text()[1]`选择了行中的第三个`<td>`元素，然后选择了该元素的文本（这是元素中所有文本的数组），并选择了其中的第一个质量。
- en: How it works
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: XPath is a element of the **XSLT** (**eXtensible Stylesheet Language Transformation**)
    standard and provides the ability to select nodes in an XML document. HTML is
    a variant of XML, and hence XPath can work on on HTML document (although HTML
    can be improperly formed and mess up XPath parsing in those cases).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: XPath是**XSLT**（可扩展样式表语言转换）标准的一部分，提供了在XML文档中选择节点的能力。HTML是XML的一种变体，因此XPath可以在HTML文档上工作（尽管HTML可能格式不正确，在这种情况下会破坏XPath解析）。
- en: XPath itself is designed to model the structure of XML nodes, attributes, and
    properties. The syntax provides means of finding items in the XML that match the
    expression. This can include matching or logical comparison of any of the nodes,
    attributes, values, or text in the XML document.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: XPath本身旨在模拟XML节点、属性和属性的结构。该语法提供了查找与表达式匹配的XML中的项目的方法。这可以包括匹配或逻辑比较XML文档中任何节点、属性、值或文本的任何部分。
- en: XPath expressions can be combined to form very complex paths within the document.
    It is also possible to navigate the document based upon relative positions, which
    helps greatly in finding data based upon relative positions instead of absolute
    positions within the DOM.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: XPath表达式可以组合成非常复杂的路径在文档中。还可以根据相对位置导航文档，这在根据相对位置而不是DOM中的绝对位置找到数据时非常有帮助。
- en: Understanding XPath is essential for knowing how to parse HTML and perform web
    scraping. And as we will see, it underlies, and provides an implementation for,
    many of the higher level libraries such as lxml.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 理解XPath对于知道如何解析HTML和执行网页抓取是至关重要的。正如我们将看到的，它是许多高级库的基础，并为其提供了实现，比如lxml。
- en: There's more...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: XPath is actually an amazing tool for working with XML and HTML documents. It
    is quite rich in its capabilities, and we have barely touched the surface of its
    capabilities for demonstrating a few examples that are common to scraping data
    in HTML documents.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: XPath实际上是处理XML和HTML文档的一个了不起的工具。它在功能上非常丰富，我们仅仅触及了它在演示HTML文档中常见的一些示例的表面。
- en: 'To learn much more, please visit the following links:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多，请访问以下链接：
- en: '[https://www.w3schools.com/xml/xml_xpath.asp](https://www.w3schools.com/xml/xml_xpath.asp)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.w3schools.com/xml/xml_xpath.asp](https://www.w3schools.com/xml/xml_xpath.asp)'
- en: '[https://www.w3.org/TR/xpath/](https://www.w3.org/TR/xpath/)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.w3.org/TR/xpath/](https://www.w3.org/TR/xpath/)'
- en: Querying data with XPath and CSS selectors
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用XPath和CSS选择器查询数据
- en: 'CSS selectors are patterns used for selecting elements and are often used to
    define the elements that styles should be applied to. They can also be used with
    lxml to select nodes in the DOM. CSS selectors are commonly used as they are more
    compact than XPath and generally can be more reusable in code. Examples of common
    selectors which may be used are as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: CSS选择器是用于选择元素的模式，通常用于定义应该应用样式的元素。它们也可以与lxml一起用于选择DOM中的节点。CSS选择器通常被广泛使用，因为它们比XPath更紧凑，并且通常在代码中更可重用。以下是可能使用的常见选择器的示例：
- en: '| **What you are looking for** | **Example** |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| **您要寻找的内容** | **示例** |'
- en: '| All tags | `*` |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 所有标签 | `*` |'
- en: '| A specific tag (that is, `tr`) | `.planet` |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: 特定标签（即`tr`）| `.planet` |
- en: '| A class name (that is, `"planet"`) | `tr.planet` |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 类名（即`"planet"`） | `tr.planet` |'
- en: '| A tag with an `ID "planet3"` | `tr#planet3` |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 具有`ID "planet3"`的标签 | `tr#planet3` |'
- en: '| A child `tr` of a table | `table tr` |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 表的子`tr` | `table tr` |'
- en: '| A descendant `tr` of a table | `table tr` |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 表的后代`tr` | `table tr` |'
- en: '| A tag with an attribute (that is, `tr` with `id="planet4"`) | `a[id=Mars]`
    |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: 带有属性的标签（即带有`id="planet4"`的`tr`）| `a[id=Mars]` |
- en: Getting ready
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Let's start examining CSS selectors using the same start up code we used in
    the last recipe.  These code snippets are also in the `02/04_css_selectors.py`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始使用与上一个示例中使用的相同的启动代码来检查CSS选择器。这些代码片段也在`02/04_css_selectors.py`中。
- en: '[PRE29]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: How to do it...
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Now let''s start playing with XPath and CSS selectors.  The following selects
    all `<tr>` elements with a class equal to `"planet"`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始使用XPath和CSS选择器。以下选择所有具有等于`"planet"`的类的`<tr>`元素：
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Data for the Earth can be found in several ways. The following gets the row
    based on `id`:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过多种方式找到地球的数据。以下是基于`id`获取行的方法：
- en: '[PRE31]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following uses an attribute with a specific value:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例使用具有特定值的属性：
- en: '[PRE32]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note that unlike XPath, the `@` symbol need not be used to specify an attribute.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，与XPath不同，不需要使用`@`符号来指定属性。
- en: How it works
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理
- en: lxml converts the CSS selector you provide to XPath, and then performs that
    XPath expression against the underlying document. In essence, CSS selectors in
    lxml provide a shorthand to XPath, which makes finding nodes that fit certain
    patterns simpler than with XPath.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: lxml将您提供的CSS选择器转换为XPath，然后针对底层文档执行该XPath表达式。实质上，lxml中的CSS选择器提供了一种简写XPath的方法，使得查找符合某些模式的节点比使用XPath更简单。
- en: There's more...
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Because CSS selectors utilize XPath under the covers, there is overhead to its
    use as compared to using XPath directly. This difference is, however, almost a
    non-issue, and hence in certain scenarios it is easier to just use cssselect.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CSS选择器在底层使用XPath，因此与直接使用XPath相比，使用它会增加一些开销。然而，这种差异几乎不成问题，因此在某些情况下，更容易只使用cssselect。
- en: A full description of CSS selectors can be found at: [https://www.w3.org/TR/2011/REC-css3-selectors-20110929/](https://www.w3.org/TR/2011/REC-css3-selectors-20110929/)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在以下位置找到CSS选择器的完整描述：[https://www.w3.org/TR/2011/REC-css3-selectors-20110929/](https://www.w3.org/TR/2011/REC-css3-selectors-20110929/)
- en: Using Scrapy selectors
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Scrapy选择器
- en: Scrapy is a Python web spider framework that is used to extract data from websites.
    It provides many powerful features for navigating entire websites, such as the
    ability to follow links. One feature it provides is the ability to find data within
    a document using the DOM, and using the now, quite familiar, XPath.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Scrapy是一个用于从网站提取数据的Python网络爬虫框架。它提供了许多强大的功能，用于浏览整个网站，例如跟踪链接的能力。它提供的一个功能是使用DOM在文档中查找数据，并且现在，相当熟悉的XPath。
- en: In this recipe we will load the list of current questions on StackOverflow,
    and then parse this using a scrapy selector. Using that selector, we will extract
    the text of each question.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将加载StackOverflow上当前问题的列表，然后使用scrapy选择器解析它。使用该选择器，我们将提取每个问题的文本。
- en: Getting ready
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The code for this recipe is in `02/05_scrapy_selectors.py`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的代码位于`02/05_scrapy_selectors.py`中。
- en: How to do it...
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We start by importing `Selector` from `scrapy`, and also `requests` so that
    we can retrieve the page:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从`scrapy`中导入`Selector`，还有`requests`，以便我们可以检索页面：
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next we load the page.  For this example we are going to retrieve the most
    recent questions on StackOverflow and extract their titles.  We can make this
    query with the the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来加载页面。在此示例中，我们将检索StackOverflow上最近的问题并提取它们的标题。我们可以使用以下查询来实现：
- en: '[PRE34]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now create a `Selector` and pass it the response object:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在创建一个`Selector`并将其传递给响应对象：
- en: '[PRE35]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Examining the content of this page we can see that questions have the following
    structure to their HTML:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 检查此页面的内容，我们可以看到问题的HTML具有以下结构：
- en: '![](assets/d72e8df6-61f1-4395-a003-009279e30ddb.png)The HTML of a StackOverflow
    Question'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/d72e8df6-61f1-4395-a003-009279e30ddb.png)StackOverflow问题的HTML'
- en: 'With the selector we can find these using XPath:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用选择器，我们可以使用XPath找到这些：
- en: '[PRE36]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: And now we drill a little further into each to get the title of the question.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们进一步深入每个问题的标题。
- en: '[PRE37]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How it works
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理
- en: Underneath the covers, Scrapy builds its selectors on top of lxml. It offers
    a smaller and slightly simpler API, which is similar in performance to lxml.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，Scrapy构建其选择器基于lxml。它提供了一个较小且略微简单的API，性能与lxml相似。
- en: There's more...
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To learn more about Scrapy Selectors see: [https://doc.scrapy.org/en/latest/topics/selectors.html](https://doc.scrapy.org/en/latest/topics/selectors.html).'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关Scrapy选择器的更多信息，请参见：[https://doc.scrapy.org/en/latest/topics/selectors.html](https://doc.scrapy.org/en/latest/topics/selectors.html)。
- en: Loading data in unicode / UTF-8
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以unicode / UTF-8加载数据
- en: A document's encoding tells an application how the characters in the document
    are represented as bytes in the file. Essentially, the encoding specifies how
    many bits there are per character. In a standard ASCII document, all characters
    are 8 bits. HTML files are often encoded as 8 bits per character, but with the
    globalization of the internet, this is not always the case. Many HTML documents
    are encoded as 16-bit characters, or use a combination of 8- and 16-bit characters.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 文档的编码告诉应用程序如何将文档中的字符表示为文件中的字节。基本上，编码指定每个字符有多少位。在标准ASCII文档中，所有字符都是8位。HTML文件通常以每个字符8位编码，但随着互联网的全球化，情况并非总是如此。许多HTML文档以16位字符编码，或者使用8位和16位字符的组合。
- en: A particularly common form HTML document encoding is referred to as UTF-8\.
    This is the encoding form that we will examine.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特别常见的HTML文档编码形式被称为UTF-8。这是我们将要研究的编码形式。
- en: Getting ready
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will read a file named `unicode.html` from our local web server, located
    at `http://localhost:8080/unicode.html`.  This file is UTF-8 encoded and contains
    several sets of characters in different parts of the encoding space. For example,
    the page looks as follows in your browser:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从位于`http://localhost:8080/unicode.html`的本地Web服务器中读取名为`unicode.html`的文件。该文件采用UTF-8编码，并包含编码空间不同部分的几组字符。例如，页面在浏览器中如下所示：
- en: '![](assets/89c7b066-5d99-4dff-a318-3d97e1d6be0a.png)The Page in the Browser'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 浏览器中的页面
- en: 'Using an editor that supports UTF-8, we can see how the Cyrillic characters
    are rendered in the editor:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 使用支持UTF-8的编辑器，我们可以看到西里尔字母在编辑器中是如何呈现的：
- en: '![](assets/afdf6e7f-3bbb-4226-bc69-356d01a27d5a.png)The HTML in an Editor'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑器中的HTML
- en: Code for the sample is in `02/06_unicode.py`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 示例的代码位于`02/06_unicode.py`中。
- en: How to do it...
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: We will look at using `urlopen` and `requests` to handle HTML in UTF-8\. These
    two libraries handle this differently, so let's examine this.  Let's start importing
    `urllib`, loading the page, and examining some of the content.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究如何使用`urlopen`和`requests`来处理UTF-8中的HTML。这两个库处理方式不同，让我们来看看。让我们开始导入`urllib`，加载页面并检查一些内容。
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Note how the Cyrillic characters were read in as multi-byte codes using \ notation,
    such as `\xd0\x89`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，西里尔字母是以多字节代码的形式读入的，使用\符号，例如`\xd0\x89`。
- en: 'To rectify this, we can convert the content to UTF-8 format using the Python
    `str` statement:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了纠正这一点，我们可以使用Python的`str`语句将内容转换为UTF-8格式：
- en: '[PRE39]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note that the output now has the characters encoded properly.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，输出现在已经正确编码了字符。
- en: We can exclude this extra step by using `requests`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`requests`来排除这一额外步骤。
- en: '[PRE40]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: How it works
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: 'In the case of using `urlopen`, the conversion was explicitly performed by
    using the str statement and specifying that the content should be converted to
    UTF-8\. For `requests`, the library was able to determine from the content within
    the HTML that it was in UTF-8 format by seeing the following tag in the document:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`urlopen`时，通过使用str语句并指定应将内容转换为UTF-8来明确执行了转换。对于`requests`，该库能够通过在文档中看到以下标记来确定HTML中的内容是以UTF-8格式编码的：
- en: '[PRE41]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: There's more...
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: There are a number of resources available on the internet for learning about
    Unicode and UTF-8 encoding techniques. Perhaps the best is the following Wikipedia
    article, which has an excellent summary and a great table describing the encoding
    technique: [https://en.wikipedia.org/wiki/UTF-8](https://en.wikipedia.org/wiki/UTF-8)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网上有许多关于Unicode和UTF-8编码技术的资源。也许最好的是以下维基百科文章，其中有一个很好的摘要和描述编码技术的表格：[https://en.wikipedia.org/wiki/UTF-8](https://en.wikipedia.org/wiki/UTF-8)
