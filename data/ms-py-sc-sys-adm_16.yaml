- en: Web Scraping - Extracting Useful Data from Websites
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络爬虫-从网站提取有用的数据
- en: In this chapter, you will learn about web scraping. You will also learn about
    the `beautifulsoup` library in Python, which is used for extracting information
    from websites.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习有关网络爬虫的知识。您还将学习Python中的`beautifulsoup`库，该库用于从网站提取信息。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: What is web scraping?
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是网络爬虫？
- en: Data extraction
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据提取
- en: Extracting information from Wikipedia
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从维基百科提取信息
- en: What is web scraping?
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是网络爬虫？
- en: Web scraping is the technique used to extract information from websites. This
    technique is used to transform unstructured data into structured data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 网络爬虫是从网站提取信息的技术。这种技术用于将非结构化数据转换为结构化数据。
- en: The use of web scraping is to extract the data from the websites. The extracted
    information is saved as a local file on your system, and you can store it to database
    in a table format as well. The web scraping software accesses the **World Wide
    Web** (**WWW**) directly using HTTP or a web browser. This is an automated process
    implemented using a web crawler or a bot.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 网络爬虫的用途是从网站提取数据。提取的信息以本地文件的形式保存在您的系统上，您也可以以表格格式将其存储到数据库中。网络爬虫软件直接使用HTTP或Web浏览器访问**万维网**（**WWW**）。这是使用网络爬虫或机器人实施的自动化过程。
- en: Scraping a web page involves fetching the page and then extracting the data.
    A web crawler fetches a web page. A web crawler is a mandatory component in web
    scraping. After fetching, extraction takes place. You can search, parse, save
    the data into tables, and reformat the page.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 爬取网页涉及获取页面，然后提取数据。网络爬虫获取网页。网络爬虫是网络爬取中的一个必不可少的组件。获取后，进行提取。您可以搜索、解析、将数据保存到表中，并重新格式化页面。
- en: Data extraction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据提取
- en: In this section, we are going to see the actual data extraction process. Python
    has the `beautifulsoup` library to perform the data extraction task. We are also
    going to use the requests library of Python.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到实际的数据提取过程。Python具有`beautifulsoup`库来执行数据提取任务。我们还将使用Python的requests库。
- en: 'First, we must install these two libraries. Run the following commands to install
    the `requests` and `beautifulsoup` libraries:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须安装这两个库。运行以下命令以安装`requests`和`beautifulsoup`库：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The requests library
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: requests库
- en: 'The use of the `requests` library is to use HTTP within our Python script in
    human-readable format. We can download the pages using the `requests` library
    in Python. The `requests` library has different types of requests. Here, we are
    going to learn about the `GET` request. The `GET` request is used to retrieve
    information from a web server. The `GET` request downloads the HTML content of
    a specified web page. Every request has a status code. The status codes return
    with every request we made to the server. These status codes give us the information
    about what happened with the request we made. The types of status code are listed
    here:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`requests`库是在我们的Python脚本中以人类可读的格式使用HTTP。我们可以使用Python中的`requests`库下载页面。`requests`库有不同类型的请求。在这里，我们将学习`GET`请求。`GET`请求用于从Web服务器检索信息。`GET`请求下载指定网页的HTML内容。每个请求都有一个状态代码。状态代码与我们向服务器发出的每个请求一起返回。这些状态代码为我们提供了关于请求发生了什么的信息。状态代码的类型在此列出：
- en: '`200`: Indicates everything went OK and returns the result, if any'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`200`：表示一切正常，并返回结果（如果有的话）'
- en: '`301`: Indicates that the server is redirecting to a different endpoint if
    it has switched the domain name or the endpoint name must be changed'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`301`：表示服务器正在重定向到不同的端点，如果已经切换了域名或端点名称必须更改'
- en: '`400`: Indicates that you made a bad request'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`400`：表示您发出了一个错误的请求'
- en: '`401`: Indicates when we are not authenticated'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`401`：表示我们未经授权'
- en: '`403`: Indicated that you are trying to access forbidden resources'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`403`：表示您正在尝试访问被禁止的资源'
- en: '`404`: Indicates that the resource you are trying to access is not available
    on the server'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`404`：表示您正在尝试访问的资源在服务器上不可用'
- en: The beautifulsoup library
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: beautifulsoup库
- en: '`beautifulsoup` is a library in Python, used for web scraping. It has simple
    methods for searching, navigating, and modifying. It is simply a toolkit used
    for extracting the data you needed from a web page.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`beautifulsoup`是Python中用于网络爬虫的库。它具有用于搜索、导航和修改的简单方法。它只是一个工具包，用于从网页中提取所需的数据。'
- en: 'Now, to use the `requests` and `beautifulsoup` functionality in your scripts
    you must import these two libraries using the `import` statement. Now, we are
    going to see an example of parsing a web page. Here, we are going to parse a web
    page, which is a top news page from the IMDb website. For that purpose, create
    a `parse_web_page.py` script and write the following content in it:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要在脚本中使用`requests`和`beautifulsoup`功能，您必须使用`import`语句导入这两个库。现在，我们将看一个解析网页的例子。在这里，我们将解析一个网页，这是来自IMDb网站的头条新闻页面。为此，请创建一个`parse_web_page.py`脚本，并在其中编写以下内容：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Run the script and you will get the output as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本，您将获得以下输出：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the preceding example, we collected a page and parsed it using `beautifulsoup`.
    First, we imported the `requests` and `beautifulsoup` modules. Then, we collected
    the URL using the `GET` request and assigned that URL to the `page_result` variable.
    Next, we created a `beautifulsoup` object `parse_obj`. This object will take `page_result`.content
    as its argument from requests and then the page parsed using `html.parser`.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们收集了一个页面并使用`beautifulsoup`解析了它。首先，我们导入了`requests`和`beautifulsoup`模块。然后，我们使用`GET`请求收集了URL，并将该URL分配给`page_result`变量。接下来，我们创建了一个`beautifulsoup`对象`parse_obj`。这个对象将使用来自requests的`page_result`.content作为参数，然后使用`html.parser`解析页面。
- en: 'Now, we are going to extract the content from a class and a tag. To perform
    this operation, go to your web browser and right-click on the content, that you
    want to extract and scroll down so you can see the **Inspect** option. Click on
    that and you will get the class name. Mention it in your program and run your
    script. For that, create a `extract_from_class.py` script and write the following
    content in it:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将从一个类和一个标签中提取内容。要执行此操作，请转到您的网络浏览器，右键单击要提取的内容，然后向下滚动，直到您看到**检查**选项。单击它，您将获得类名。在程序中提到它并运行您的脚本。为此，请创建一个`extract_from_class.py`脚本，并在其中编写以下内容：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Run the script and you will get the following output:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本，您将获得以下输出：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the preceding example, we first imported the requests and `beautifulsoup`
    modules. Then, we created a request object and assigned an URL to it. Next, we
    created a `beautifulsoup` object `parse_obj`. This object takes `page_result.content`
    as its argument from requests and then the page was parsed using `html.parser`.
    Next, we used beautifulsoup's `find()` method to get the content from the `'news-article__content'`
    class.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，我们首先导入了requests和`beautifulsoup`模块。然后，我们创建了一个请求对象并为其分配了一个URL。接下来，我们创建了一个`beautifulsoup`对象`parse_obj`。这个对象以requests的`page_result.content`作为参数，然后使用`html.parser`解析页面。接下来，我们使用beautifulsoup的`find()`方法从`'news-article__content'`类中获取内容。
- en: 'Now, we are going to see an example of extracting content from a particular
    tag. In this example, we are going to extract the content from the `<a>` tag.
    Create an `extract_from_tag.py` script and write the following content in it:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将看到从特定标签中提取内容的示例。在这个例子中，我们将从`<a>`标签中提取内容。创建一个`extract_from_tag.py`脚本，并在其中编写以下内容：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Run the script and you will get the output as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本，您将获得以下输出：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the preceding example, we are extracting contents from the `<a>` tag. We
    used the `find_all()` method to extract all `<a>` tag contents from the `'news-article__content'`
    class.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，我们正在从`<a>`标签中提取内容。我们使用`find_all()`方法从`'news-article__content'`类中提取所有`<a>`标签内容。
- en: Extracting information from Wikipedia
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从维基百科中提取信息
- en: 'In this section, we are going to see an example of a list of dance forms from
    Wikipedia. We are going to list all classical Indian dances. For that, create
    a `extract_from_wikipedia.py` script and write the following content in it:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到维基百科上興舞形式列表的一个示例。我们将列出所有古典印度舞蹈。为此，请创建一个`extract_from_wikipedia.py`脚本，并在其中编写以下内容：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run the script and you will get the following output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本，您将获得以下输出：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Summary
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about what web scraping is. We learned about two
    libraries that are used in extracting the data from a web page. We also extracted
    information from Wikipedia.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了网络爬取的内容。我们了解了用于从网页中提取数据的两个库。我们还从维基百科中提取了信息。
- en: In the next chapter, you will learn about statistics gathering and reporting.
    You will learn about the NumPy module, data visualization, and displaying data
    using plots, graphs, and charts.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习有关统计数据收集和报告的内容。您将学习有关NumPy模块、数据可视化以及使用图表、图形和图表显示数据的内容。
- en: Questions
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is web scrapping?
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是网络爬虫？
- en: What are the web crawlers?
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是网络爬虫？
- en: Can you scrape data behind a login page?
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您能够在登录页面后面抓取数据吗？
- en: Can you crawl Twitter?
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能爬Twitter吗？
- en: Is it possible to scrap the Java script pages? If yes, how?
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否可能抓取JavaScript页面？如果是，如何？
- en: Further reading
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Urllib documentation: [https://docs.python.org/3/library/urllib.html](https://docs.python.org/3/library/urllib.html)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Urllib文档：[https://docs.python.org/3/library/urllib.html](https://docs.python.org/3/library/urllib.html)
- en: Mechanize: [https://mechanize.readthedocs.io/en/latest/](https://mechanize.readthedocs.io/en/latest/)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mechanize：[https://mechanize.readthedocs.io/en/latest/](https://mechanize.readthedocs.io/en/latest/)
- en: Scrapemark: [https://pypi.org/project/scrape/](https://pypi.org/project/scrape/)
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scrapemark：[https://pypi.org/project/scrape/](https://pypi.org/project/scrape/)
- en: Scrapy: [https://doc.scrapy.org/en/latest/index.html](https://doc.scrapy.org/en/latest/index.html)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scrapy：[https://doc.scrapy.org/en/latest/index.html](https://doc.scrapy.org/en/latest/index.html)
