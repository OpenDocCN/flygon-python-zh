- en: Traditional Supervised Learning Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统监督学习算法
- en: In this chapter, we will focus on supervised machine learning algorithms, which
    are one of the most important types of modern algorithms. The distinguishing characteristic
    of a supervised machine learning algorithm is the use of labeled data to train
    a model. In this book, supervised machine learning algorithms are divided into
    two chapters. In this chapter, we will present all the traditional supervised
    machine learning algorithms, excluding neural networks. The next chapter is all
    about implementing supervised machine learning algorithms using neural networks.
    The truth is that with so much ongoing development in this field, neural networks
    are a comprehensive topic that deserves a separate chapter in this book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点介绍监督式机器学习算法，这是现代算法中最重要的类型之一。监督式机器学习算法的显著特征是使用带标签的数据来训练模型。在本书中，监督式机器学习算法分为两章。在本章中，我们将介绍所有传统的监督式机器学习算法，不包括神经网络。下一章将全面介绍使用神经网络实现监督式机器学习算法。事实上，在这一领域有如此多的持续发展，神经网络是一个值得在本书中单独章节讨论的综合性主题。
- en: So, this chapter is the first of two parts about supervised machine learning
    algorithms. First, we will introduce the fundamental concepts of supervised machine
    learning. Next, we will present two types of supervised machine models—classifiers
    and regressors. In order to demonstrate the abilities of classifiers, we will
    first present a real-world problem as a challenge. Then, we will present six different
    classification algorithms that are used to solve the problem. Then, we will focus
    on regression algorithms, first by presenting a similar problem to be solved for
    the regressors. Next, we will present three regression algorithms and use them
    to solve the problem. Finally, we will compare the results to help us summarize
    the concepts presented in this chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这一章是关于监督式机器学习算法的两个部分中的第一部分。首先，我们将介绍监督式机器学习的基本概念。接下来，我们将介绍两种监督式机器模型——分类器和回归器。为了展示分类器的能力，我们将首先提出一个真实世界的问题作为挑战。然后，我们将介绍六种不同的分类算法，用于解决这个问题。然后，我们将专注于回归算法，首先提出一个类似的问题，以便为回归器解决问题。接下来，我们将介绍三种回归算法，并使用它们来解决问题。最后，我们将比较结果，以帮助我们总结本章介绍的概念。
- en: The overall objective of this chapter is for you to understand the different
    types of supervised machine learning techniques and know what the best supervised
    machine learning techniques are for certain classes of problems.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的总体目标是让您了解不同类型的监督式机器学习技术，并了解对于某些类别的问题，最佳的监督式机器学习技术是什么。
- en: 'The following concepts are discussed in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了以下概念：
- en: Understanding supervised machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解监督式机器学习
- en: Understanding classification algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解分类算法
- en: The methods for evaluating the performance of classifiers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估分类器性能的方法
- en: Understanding regression algorithms
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解回归算法
- en: The methods for evaluating the performance of regression algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估回归算法性能的方法
- en: Let's start by looking at the basic concepts behind supervised machine learning.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从理解监督式机器学习背后的基本概念开始。
- en: Understanding supervised machine learning
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解监督式机器学习
- en: Machine learning focuses on using data-driven approaches to create autonomous
    systems that can help us to make decisions with or without human supervision.
    In order to create these autonomous systems, machine learning uses a group of
    algorithms and methodologies to discover and formulate repeatable patterns in
    data. One of the most popular and powerful methodologies used in machine learning
    is the supervised machine learning approach. In supervised machine learning, an
    algorithm is given a set of inputs, called **features**, and their corresponding
    outputs, called **target** **variables**. Using a given dataset, a supervised
    machine learning algorithm is used to train a model that captures the complex
    relationship between the features and target variables represented by a mathematical
    formula. This trained model is the basic vehicle that is used for predictions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习专注于使用数据驱动的方法来创建可以帮助我们做出决策的自主系统，无论是否有人类监督。为了创建这些自主系统，机器学习使用一组算法和方法来发现和制定数据中可重复的模式。在机器学习中最流行和强大的方法之一是监督式机器学习方法。在监督式机器学习中，算法被给定一组输入，称为**特征**，以及它们对应的输出，称为**目标**
    **变量**。使用给定的数据集，监督式机器学习算法用于训练一个捕捉特征和目标变量之间复杂关系的模型，该关系由数学公式表示。这个训练好的模型是用于预测的基本工具。
- en: Predictions are made by generating the target variable of an unfamiliar set
    of features through the trained model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过训练模型，通过生成未知特征集的目标变量来进行预测。
- en: The ability to learn from existing data in supervised learning is similar to
    the ability of the human brain to learn from experience. This learning ability
    in supervised learning uses one of the attributes of the human brain and is a
    fundamental way of opening the gates to bring decision-making power and intelligence
    to machines.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中从现有数据中学习的能力类似于人脑从经验中学习的能力。监督学习中的这种学习能力使用了人脑的一个属性，是将决策能力和智能引入机器的基本途径。
- en: Let's consider an example where we want to use supervised machine learning techniques
    to train a model that can categorize a set of emails into legitimate ones (called
    **legit**) and unwanted ones (called **spam**). First of all, in order to get
    started, we need examples from the past so that the machine can learn what sort
    of content of emails should be classified as spam. This content-based learning
    task for text data is a complex process and is achieved through one of the supervised
    machine learning algorithms. Some examples of supervised machine learning algorithms
    that can be used to train the model in this example include decision trees and
    naive Bayes classifiers, which we will discuss later in this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个例子，我们想要使用监督式机器学习技术训练一个模型，可以将一组电子邮件分类为合法邮件（称为**合法**）和不需要的邮件（称为**垃圾邮件**）。首先，为了开始，我们需要过去的例子，这样机器才能学习应该将什么样的电子邮件内容分类为垃圾邮件。这种基于内容的文本数据学习任务是一个复杂的过程，可以通过监督式机器学习算法之一来实现。在这个例子中，可以用来训练模型的一些监督式机器学习算法包括决策树和朴素贝叶斯分类器，我们将在本章后面讨论。
- en: Formulating supervised machine learning
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 制定监督式机器学习
- en: 'Before going deeper into the details of supervised machine learning algorithms,
    let''s define some of the basic supervised machine learning terminologies:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究监督式机器学习算法的细节之前，让我们定义一些基本的监督式机器学习术语：
- en: '| **Terminology** | **Explanation** |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **术语** | **解释** |'
- en: '| Target variable | The target variable is the variable that we want our model
    to predict. There can be only one target variable in a supervised machine learning
    model. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 目标变量 | 目标变量是我们希望模型预测的变量。在监督式机器学习模型中只能有一个目标变量。 |'
- en: '| Label | If the target variable we want to predict is a category variable,
    it is called a label. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 如果我们想要预测的目标变量是一个类别变量，那么它被称为标签。 |'
- en: '| Features | The set of input variables used to predict the label is called
    the features. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 特征 | 用于预测标签的一组输入变量称为特征。 |'
- en: '| Feature engineering | Transforming features to prepare them for the chosen
    supervised machine learning algorithm is called feature engineering. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 特征工程 | 将特征转换为所选监督式机器学习算法准备的过程称为特征工程。 |'
- en: '| Feature vector | Before providing an input to a supervised machine learning
    algorithm, all the features are combined in a data structure called a feature
    vector. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 特征向量 | 在将输入提供给监督式机器学习算法之前，所有特征都被组合在一个称为特征向量的数据结构中。 |'
- en: '| Historical data | The data from the past that is used to formulate the relationship
    between the target variable and the features is called historical data. Historical
    data comes with examples. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 历史数据 | 用于制定目标变量和特征之间关系的过去数据称为历史数据。历史数据带有示例。 |'
- en: '| Training/testing data | Historical data with examples is divided into two
    parts—a larger dataset called the training data and a smaller dataset called the
    testing data. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 训练/测试数据 | 历史数据与示例被分成两部分——一个更大的数据集称为训练数据，一个较小的数据集称为测试数据。 |'
- en: '| Model | A mathematical formulation of the patterns that best capture the
    relationship between the target variable and the features. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 目标变量和特征之间关系的最佳捕捉模式的数学表达。 |'
- en: '| Training | Creating a model using training data. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 训练 | 使用训练数据创建模型。 |'
- en: '| Testing | Evaluating the quality of the trained model using testing data.
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 测试 | 使用测试数据评估训练模型的质量。 |'
- en: '| Prediction | Using a model to predict the target variable. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 预测 | 使用模型预测目标变量。 |'
- en: A trained supervised machine learning model is capable of making predictions
    by estimating the target variable based on the features.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 经过训练的监督式机器学习模型能够通过估计特征来预测目标变量。
- en: 'Let''s introduce the notation that we will be using in this chapter to discuss
    the machine learning techniques:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们介绍一下本章中将使用的符号，讨论机器学习技术：
- en: '| **Variable** | **Meaning** |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **变量** | **含义** |'
- en: '| *y* | Actual label |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| *y* | 实际标签 |'
- en: '| *ý* | Predicted label |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| *ý* | 预测标签 |'
- en: '| *d* | Total number of examples |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| *d* | 总示例数量 |'
- en: '| *b* | Number of training examples |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| *b* | 训练示例的数量 |'
- en: '| *c* | Number of testing examples |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| *c* | 测试示例的数量 |'
- en: Now, let's see how some of these terminologies are formulated practically.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一些这些术语如何在实际中被制定。
- en: As we discussed, a feature vector is defined as a data structure that has all
    the features stored in it.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的，特征向量被定义为一个包含所有特征的数据结构。
- en: If the number of features is *n* and the number of training examples is *b*,
    then `X_train` represents the training feature vector. Each example is a row in
    the feature vector.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果特征的数量是*n*，训练示例的数量是*b*，那么`X_train`表示训练特征向量。每个示例都是特征向量中的一行。
- en: 'For the training dataset, the feature vector is represented by `X_train`. If
    there are *b* examples in the training dataset, then `X_train` will have *b* rows.
    If there are *n* variables in the training dataset, then it will have *n* columns.
    So, the training dataset will have a dimension of *n* x *b*, as represented in
    the following diagram:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练数据集，特征向量由`X_train`表示。如果训练数据集中有*b*个示例，那么`X_train`将有*b*行。如果训练数据集中有*n*个变量，那么它将有*n*列。因此，训练数据集将具有*n*
    x *b*的维度，如下图所示：
- en: '![](assets/83067a86-5ff3-4854-a16f-5415111cc00d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/83067a86-5ff3-4854-a16f-5415111cc00d.png)'
- en: Now, let's assume that there are *b* training examples and *c* testing examples.
    A particular training example is represented by (*X*, *y*).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们假设有*b*个训练示例和*c*个测试示例。一个特定的训练示例由(*X*, *y*)表示。
- en: We use superscript to indicate which training example is which within the training
    set.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上标来指示训练集中的每个训练示例。
- en: So, our labeled dataset is represented by D = {X^((1)),y^((1))), (X^((2)),y^((2))),
    ..... , (X^((d)),y^((d)))}.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的标记数据集由D = {X^((1)),y^((1))), (X^((2)),y^((2))), ..... , (X^((d)),y^((d)))}表示。
- en: We divide that into two parts—D[train]and D[test].
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其分为两部分——D[train]和D[test]。
- en: So, our training set can be represented by D[train]  = {X^((1)),y^((1))), (X^((2)),y^((2))),
    ..... , (X^((b)),y^((b)))}.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的训练集可以用D[train] = {X^((1)),y^((1))), (X^((2)),y^((2))), ..... , (X^((b)),y^((b)))}来表示。
- en: The objective of training a model is that for any *i*^(th) example in the training
    set, the predicted value of the target value should be as close to the actual
    value in the examples as possible. In other words, ![](assets/191e0803-78b6-4df4-b1a4-54ac88b95d3f.png).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型的目标是对于训练集中的任何第i个示例，目标值的预测值应尽可能接近示例中的实际值。换句话说，![](assets/191e0803-78b6-4df4-b1a4-54ac88b95d3f.png)。
- en: So, our testing set can be represented by D[test] = {X^((1)),y^((1))), (X^((2)),y^((2))),
    ..... , (X^((c)),y^((c)))}.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的测试集可以用D[test] = {X^((1)),y^((1))), (X^((2)),y^((2))), ..... , (X^((c)),y^((c)))}来表示。
- en: 'The values of the target variable are represented by a vector, *Y*:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 目标变量的值由向量*Y*表示：
- en: Y ={ y^((1)), y^((2)), ....., y^((m))}
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Y = {y^((1)), y^((2)), ....., y^((m))}
- en: Understanding enabling conditions
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解启用条件
- en: 'Supervised machine learning is based on the ability of an algorithm to train
    a model using examples. A supervised machine learning algorithm needs certain
    enabling conditions to be met in order to perform. These enabling conditions are
    as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 监督式机器学习是基于算法使用示例来训练模型的能力。监督式机器学习算法需要满足一定的启用条件才能执行。这些启用条件如下：
- en: '**Enough examples**:Supervised machine learning algorithms need enough examples
    to train a model.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**足够的示例**：监督式机器学习算法需要足够的示例来训练模型。'
- en: '**Patterns in historical data**: The examples used to train a model need to
    have patterns in it. The likelihood of the occurrence of our event of interest
    should be dependent on a combination of patterns, trends, and events. Without
    these, we are dealing with random data that cannot be used to train a model.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**历史数据中的模式**：用于训练模型的示例需要具有其中的模式。我们感兴趣事件的发生可能性应取决于模式、趋势和事件的组合。如果没有这些，我们处理的是无法用于训练模型的随机数据。'
- en: '**Valid assumptions**:When we train a supervised machine learning model using
    examples, we expect that the assumptions that apply to the examples will also
    be valid in the future. Let''s look at an actual example. If we want to train
    a machine learning model for the government that can predict the likelihood of
    whether a visa will be granted to a student, the understanding is that the laws
    and policies will not change when the model is used for predictions. If new policies
    or laws are enforced after training the model, the model may need to be retrained
    to incorporate this new information.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效的假设**：当我们使用示例训练监督式机器学习模型时，我们期望适用于示例的假设在未来也是有效的。让我们看一个实际的例子。如果我们想要为政府训练一个可以预测学生是否会获得签证的机器学习模型，那么理解是在模型用于预测时，法律和政策不会发生变化。如果在训练模型后实施了新的政策或法律，可能需要重新训练模型以纳入这些新信息。'
- en: Differentiating between classifiers and regressors
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区分分类器和回归器
- en: 'In a machine learning model, the target variable can be a category variable
    or a continuous variable. The type of target variable determines what type of
    supervised machine learning model we have. Fundamentally, we have two types of
    supervised machine learning models:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习模型中，目标变量可以是类别变量或连续变量。目标变量的类型决定了我们拥有的监督式机器学习模型的类型。基本上，我们有两种类型的监督式机器学习模型：
- en: '**Classifiers**: If the target variable is a category variable, the machine
    learning model is called a classifier. Classifiers can be used to answer the following
    type of business questions:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类器**：如果目标变量是类别变量，则机器学习模型称为分类器。分类器可用于回答以下类型的业务问题：'
- en: Is this abnormal tissue growth a malignant tumor?
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种异常组织生长是否是恶性肿瘤？
- en: Based on the current weather conditions, will it rain tomorrow?
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据当前的天气条件，明天会下雨吗？
- en: Based on the profile of a particular applicant, should their mortgage application
    be approved?
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于特定申请人的资料，他们的抵押贷款申请是否应该被批准？
- en: '**Regressors**: If the target variable is a continuous variable, we train a
    regressor. Regressors can be used to answer the following types of business questions:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归器**：如果目标变量是连续变量，我们训练一个回归器。回归器可用于回答以下类型的业务问题：'
- en: Based on the current weather condition, how much will it rain tomorrow?
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据当前的天气条件，明天会下多少雨？
- en: What will the price of a particular home be with given characteristics?
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有给定特征的特定房屋的价格将是多少？
- en: Let's look at both classifiers and regressors in more detail.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看分类器和回归器。
- en: Understanding classification algorithms
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解分类算法
- en: 'In supervised machine learning, if the target variable is a category variable,
    the model is categorized as a classifier:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督式机器学习中，如果目标变量是类别变量，则模型被归类为分类器：
- en: The target variable is called a  **label**.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标变量称为**标签**。
- en: The historical data is called  **labeled data**.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 历史数据称为**标记数据**。
- en: The production data, which the label needs to be predicted for, is called  **unlabeled
    data**.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要预测标签的生产数据称为**未标记数据**。
- en: The ability to accurately label unlabeled data using a trained model is the
    real power of classification algorithms. Classifiers predict labels for unlabeled
    data to answer a particular business question.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用训练模型准确标记未标记数据的能力是分类算法的真正力量。分类器预测未标记数据的标签以回答特定的业务问题。
- en: Before we present the details of classification algorithms, let's first present
    a business problem that we will use as a challenge for classifiers. We will then
    use six different algorithms to answer the same challenge, which will help us
    compare their methodology, approach, and performance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们介绍分类算法的细节之前，让我们首先提出一个业务问题，作为分类器的挑战。然后我们将使用六种不同的算法来回答相同的挑战，这将帮助我们比较它们的方法、途径和性能。
- en: Presenting the classifiers challenge
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提出分类器挑战
- en: 'We will first present a common problem, which we will use as a challenge to
    test six different classification algorithms. This common problem is referred
    to as the classifier challenge in this chapter. Using all the six classifiers
    to solve the same problem will help us in two ways:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先提出一个常见的问题，我们将使用它作为测试六种不同分类算法的挑战。这个常见的问题在本章中被称为分类器挑战。使用所有六种分类器来解决同一个问题将帮助我们以两种方式：
- en: All the input variables need to be processed and assembled as a complex data
    structure, called a feature vector. Using the same feature vector helps us avoid
    repeating data preparation for all six algorithms.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有输入变量都需要被处理和组装成一个复杂的数据结构，称为特征向量。使用相同的特征向量可以帮助我们避免为所有六个算法重复数据准备。
- en: We can compare the performance of various algorithms as we are using the same
    feature vector for input.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过使用相同的特征向量作为输入来比较各种算法的性能。
- en: The classifiers challenge is about predicting the likelihood of a person making
    a purchase. In the retail industry, one of the things that can help maximize sales
    is better understanding the behavior of the customers. This can be done by analyzing
    the patterns found in historical data. Let's state the problem, first.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器挑战是关于预测一个人购买的可能性。在零售行业，可以帮助最大化销售的一件事是更好地了解客户的行为。这可以通过分析历史数据中发现的模式来实现。让我们先阐述问题。
- en: The problem statement
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题陈述
- en: Given the historical data, can we train a binary classifier that can predict
    whether a particular user will eventually buy a product based on their profile?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 根据历史数据，我们能否训练一个二元分类器，可以预测特定用户最终是否会购买产品？
- en: 'First, let''s explore the historical labeled data set available to solve this
    problem:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们探索可用于解决这个问题的历史标记数据集：
- en: x € ℜ^b, y € {0,1}
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: x € ℜ^b, y € {0,1}
- en: For a particular example, when *y* = 1, we call it a positive class and when
    *y* = 0, we call it a negative class.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定示例，当*y* = 1时，我们称之为正类，当*y* = 0时，我们称之为负类。
- en: Although the level of the positive and negative class can be chosen arbitrarily,
    it is good practice to define the positive class as the event of interest. If
    we are trying to flag the fraudulent transaction for a bank, then the positive
    class (that is, *y* = 1 ) should be the fraudulent transaction, not the other
    way around.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管正类和负类的级别可以任意选择，但定义正类为感兴趣的事件是一个好的做法。如果我们试图为银行标记欺诈交易，那么正类（即*y* = 1）应该是欺诈交易，而不是相反。
- en: 'Now, let''s look at the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下以下内容：
- en: The actual label, denoted by *y*
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际标签，用*y*表示
- en: The predicted label, denoted by *y`*
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的标签，用*y`*表示
- en: Note that for our classifiers challenge, the actual value of the label found
    in examples is represented by *y*. If, in our example, someone has purchased an
    item, we say *y* =1\. The predicted values are represented by *y`*. The input
    feature vector, *x*, has a dimension of 4\. We want to determine what the probability
    is that a user will make a purchase, given a particular input.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，对于我们的分类器挑战，示例中找到的标签的实际值由*y*表示。如果在我们的示例中，有人购买了一个物品，我们说*y* = 1。预测值由*y`*表示。输入特征向量*x*的维度为4。我们想确定用户在给定特定输入时购买的概率是多少。
- en: 'So, we want to determine the probability that *y* = 1 is, given a particular
    value of feature vector *x*. Mathematically, we can represent this as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们希望确定在给定特征向量*x*的特定值时*y* = 1的概率。从数学上讲，我们可以表示如下：
- en: '![](assets/64b062ae-9b4e-4cb4-b2f0-608d0ba569e0.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/64b062ae-9b4e-4cb4-b2f0-608d0ba569e0.png)'
- en: Now, let's look at how we can process and assemble different input variables
    in the feature vector, *x*. The methodology to assemble different parts of *x*
    using the processing pipeline is discussed in more detail in the following section.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何处理和组装特征向量*x*中的不同输入变量。在下一节中，将更详细地讨论使用处理管道组装*x*的不同部分的方法。
- en: Feature engineering using a data processing pipeline
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据处理管道进行特征工程
- en: Preparing data for a chosen machine learning algorithm is called **feature engineering**
    and is a crucial part of the machine learning life cycle. Feature engineering
    is done in different stages or phases. The multi-stage processing code used to
    process data is collectively known as a **data pipeline**. Making a data pipeline
    using standard processing steps, wherever possible, makes it reusable and decreases
    the effort needed to train the models. By using more well-tested software modules,
    the quality of the code is also enhanced.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择一个特定的机器学习算法的数据准备被称为**特征工程**，它是机器学习生命周期的一个关键部分。特征工程在不同的阶段或阶段进行。用于处理数据的多阶段处理代码被统称为**数据管道**。在可能的情况下使用标准处理步骤制作数据管道，使其可重用并减少训练模型所需的工作量。通过使用更多经过测试的软件模块，代码的质量也得到了提高。
- en: Let's see design a reusable processing pipeline for the classifiers challenge.
    As mentioned, we will prepare data once and then use it for all the classifiers.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为分类器挑战设计一个可重用的处理管道。如前所述，我们将准备数据一次，然后将其用于所有分类器。
- en: Importing data
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入数据
- en: 'The historical data for this problem is stored in a file called `dataset` in
    `.csv` format. We will use the `pd.read_csv` function from pandas to import the
    data as a data frame:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的历史数据存储在一个名为`dataset`的文件中，格式为`.csv`。我们将使用pandas的`pd.read_csv`函数将数据导入为数据框：
- en: '[PRE0]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Feature selection
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择
- en: The process of selecting features that are relevant to the context of the problem
    that we want to solve is called **feature selection**. It is an essential part
    of feature engineering.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 选择与我们想要解决的问题相关的特征的过程称为**特征选择**。这是特征工程的一个重要部分。
- en: 'Once the file is imported, we drop the `User ID` column, which is used to identify
    a person and should be excluded when training a model:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文件被导入，我们删除`User ID`列，该列用于识别一个人，并且在训练模型时应该被排除：
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let''s preview the dataset:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们预览数据集：
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The dataset looks like this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集如下：
- en: '![](assets/b0a76952-07bb-4025-9614-1e7e6d683bf0.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b0a76952-07bb-4025-9614-1e7e6d683bf0.png)'
- en: Now, let's look at how we can further process the input dataset.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何进一步处理输入数据集。
- en: One-hot encoding
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 独热编码
- en: 'Many machine learning algorithms require all the features to be continuous
    variables. It means that if some of the features are category variables, we need
    to find a strategy to convert them into continuous variables. One-hot encoding
    is one of the most effective ways of performing this transformation. For this
    particular problem, the only category variable we have is `Gender`. Let''s convert
    that into a continuous variable using one-hot encoding:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法要求所有特征都是连续变量。这意味着如果一些特征是类别变量，我们需要找到一种策略将它们转换为连续变量。独热编码是执行这种转换的最有效方式之一。对于这个特定的问题，我们唯一的类别变量是`Gender`。让我们使用独热编码将其转换为连续变量：
- en: '[PRE3]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once it''s converted, let''s look at the dataset again:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦转换完成，让我们再次查看数据集：
- en: '![](assets/6a3f7425-0e6d-444f-914c-7c12b15ada54.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6a3f7425-0e6d-444f-914c-7c12b15ada54.png)'
- en: Notice that in order to convert a variable from a category variable into a continuous
    variable, one-hot encoding has converted `Gender` into two separate columns—`Male`
    and `Female`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了将变量从类别变量转换为连续变量，独热编码已将`Gender`转换为两个单独的列——`Male`和`Female`。
- en: Specifying the features and label
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定特征和标签
- en: 'Let''s specify the features and labels. We will use `y` through this book to
    represent the label and `X` to represent the feature set:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们指定特征和标签。我们将使用`y`来代表标签，`X`代表特征集：
- en: '[PRE4]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`X` represents the feature vector and contains all the input variables that
    we need to use to train the model.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`X`代表特征向量，包含我们需要用来训练模型的所有输入变量。'
- en: Dividing the dataset into testing and training portions
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据集分为测试和训练部分
- en: 'Now, let''s divide the training dataset into 25% testing and 75% training portions
    using `sklearn.model_selection import train_test_split`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`sklearn.model_selection import train_test_split`将训练数据集分为25%的测试部分和75%的训练部分：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This has created the following four data structures:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经创建了以下四个数据结构：
- en: '`X_train`: A data structure containing the features of the training data'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_train`：包含训练数据特征的数据结构'
- en: '`X_test`: A data structure containing the features of the training test'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_test`：包含训练测试特征的数据结构'
- en: '`y_train`: A vector containing the values of the label in the training dataset'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_train`：包含训练数据集中标签值的向量'
- en: '`y_test`: A vector containing the values of the label in the testing dataset'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_test`：包含测试数据集中标签值的向量'
- en: Scaling the features
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩放特征
- en: 'For many machine learning algorithms, it''s good practice to scale the variables
    from `0` to `1`. This is also called **feature normalization**. Let''s apply the
    scaling transformation to achieve this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多机器学习算法，将变量从`0`到`1`进行缩放是一个好的做法。这也被称为**特征归一化**。让我们应用缩放转换来实现这一点：
- en: '[PRE6]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After we scale the data, it is ready to be used as input to the different classifiers
    that we will present in the subsequent sections.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们缩放数据之后，它准备好作为输入用于我们将在后续部分中介绍的不同分类器。
- en: Evaluating the classifiers
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估分类器
- en: 'Once the model is trained, we need to evaluate its performance. To do that,
    we will use the following process:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，我们需要评估其性能。为此，我们将使用以下过程：
- en: We will divide the labeling dataset into two parts—a training partition and
    a testing partition. We will use the testing partition to evaluate the trained
    model.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将标签数据集分为两部分——训练部分和测试部分。我们将使用测试部分来评估训练好的模型。
- en: We will use the features of our testing partition to generate labels for each
    row. This is our set of predicted labels.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用测试部分的特征来为每一行生成标签。这是我们的预测标签集。
- en: We will compare the set of predicted labels with the actual labels to evaluate
    the model.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将比较预测标签集与实际标签以评估模型。
- en: Unless we are trying to solve something quite trivial, there will be some misclassifications
    when we evaluate the model. How we interpret these misclassifications to determine
    the quality of the model depends on which performance metrics we choose to use.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 除非我们试图解决的问题非常琐碎，否则在评估模型时会有一些错误分类。我们如何解释这些错误分类以确定模型的质量取决于我们选择使用的性能指标。
- en: Once we have both the set of actual labels and the predicted labels, a bunch
    of performance metrics can be used to evaluate the models. The best metric to
    quantify the model will depend on the requirements of the business problem that
    we want to solve, as well as the characteristics of the training dataset.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了实际标签集和预测标签集，就可以使用一系列性能指标来评估模型。用于量化模型的最佳指标将取决于我们想要解决的业务问题的要求，以及训练数据集的特征。
- en: Confusion matrix
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'A confusion matrix is used to summarize the results of the evaluation of a
    classifier. The confusion matrix for a binary classifier looks as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵用于总结对分类器的评估结果。二元分类器的混淆矩阵如下所示：
- en: '![](assets/ca9d79e4-5e30-4bf9-b81f-d0aee047b206.png)If the label of the classifier
    we are training has two levels, it is called a **binary classifier**. The first
    critical use case of supervised machine learning—specifically, a binary classifier—was
    during the First World War to differentiate between an aircraft and flying birds.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/ca9d79e4-5e30-4bf9-b81f-d0aee047b206.png)如果我们正在训练的分类器的标签有两个级别，则称为**二元分类器**。监督机器学习的第一个关键用例，特别是二元分类器，是在第一次世界大战期间用于区分飞机和飞行鸟。'
- en: 'The classification can be divided into the following four categories:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 分类可以分为以下四类：
- en: '**True positives** (**TP**): The positive classifications that were correctly
    classified'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例**（**TP**）：正确分类的正分类'
- en: '**True Negatives** (**TN**): The negative classifications that were correctly
    classified'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真负例**（**TN**）：正确分类的负分类'
- en: '**False Positives** (**FP**): The positive classifications  that were actually
    negative'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假正例**（**FP**）：实际上是负分类的正分类'
- en: '**False Negatives** (**FN**): The negative classifications that were actually
    positive'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性**（**FN**）：实际上是积极的负面分类'
- en: Let's see how we can use these four categories to create various performance
    metrics.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用这四个类别来创建各种性能指标。
- en: Performance metrics
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'Performance metrics are used to quantify the performance of the trained models.
    Based on this, let''s define the following four metrics:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 性能指标用于量化训练模型的性能。基于此，让我们定义以下四个指标：
- en: '| **Metric** | **Formula** |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| **指标** | **公式** |'
- en: '| Accuracy | ![](assets/6732024e-647e-40b8-8965-e0e10573db8d.png) |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | ![](assets/6732024e-647e-40b8-8965-e0e10573db8d.png) |'
- en: '| Recall | ![](assets/52d52b33-c954-4bc6-ac31-325849e8a6e7.png) |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 召回率 | ![](assets/52d52b33-c954-4bc6-ac31-325849e8a6e7.png) |'
- en: '| Precision | ![](assets/985538cb-41f1-4fcf-93a4-8da6a3fecf13.png) |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 精度 | ![](assets/985538cb-41f1-4fcf-93a4-8da6a3fecf13.png) |'
- en: '| F1 score | ![](assets/e50cf3cc-6542-4e86-82dc-39e65afcba92.png) |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| F1分数 | ![](assets/e50cf3cc-6542-4e86-82dc-39e65afcba92.png) |'
- en: Accuracy is the proportion of correction classifications among all predictions.
    While calculating accuracy, we do not differentiate between TP and TN. Evaluating
    a model through accuracy is straightforward, but in certain situations, it will
    not work.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是所有预测中正确分类的比例。在计算准确率时，我们不区分TP和TN。通过准确率评估模型是直接的，但在某些情况下，它不起作用。
- en: 'Let''s look at the situations where we need more than accuracy to quantify
    the performance of a model. One of these situations is when we use a model to
    predict a rare event, such as in the following examples:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们需要更多的东西来量化模型的性能的情况。其中之一是当我们使用模型来预测罕见事件时，比如以下的例子：
- en: A model to predict the fraudulent transactions in a banks transactional database
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于预测银行交易数据库中欺诈交易的模型
- en: A model to predict the likelihood of mechanical failure of an engine part of
    an aircraft
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于预测飞机发动机零部件机械故障可能性的模型
- en: 'In both of these examples, we are trying to predict a rare event. Two additional
    measures become more important than accuracy in these situations—recall and precision.
    Let''s look at them one by one:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个例子中，我们试图预测罕见事件。在这种情况下，比准确率更重要的是召回率和精度。让我们逐个来看：
- en: '**Recall**: This calculates the hit rate. In the first of the preceding examples,
    it is the proportion of fraudulent documents successfully flagged by the model
    out of all the fraudulent documents. If, in our testing dataset, we had 1 million
    transactions, out of which 100 were known to be fraudulent, the model was able
    to identify 78 of them. In this case, the recall value would be 78/100.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**：这计算了命中率。在前面的例子中，它是模型成功标记的欺诈文件占所有欺诈文件的比例。如果在我们的测试数据集中有100万笔交易，其中有100笔被确认为欺诈交易，模型能够识别出78笔。在这种情况下，召回率值将是78/100。'
- en: '**Precision**: The precision measures how many of the transactions flagged
    by the model were actually bad. Instead of focusing on the bad transactions that
    the model failed to flag, we want to determine how precise the bad bins flagged
    by the model really is.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精度**：精度衡量了模型标记的交易中实际上是坏的交易有多少。我们不是专注于模型未能标记的坏交易，而是想确定模型标记的坏交易有多精确。'
- en: Note that the F1 score brings both the recall and precision together. If a model
    has perfect scores for both precision and recall, then its F1 score will be perfect.
    A high F1 score means that we have trained a high-quality model that has high
    recall and precision.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，F1分数将召回率和精度结合在一起。如果一个模型的精度和召回率都是完美的，那么它的F1分数将是完美的。高F1分数意味着我们训练了一个高质量的模型，具有高召回率和精度。
- en: Understanding overfitting
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解过拟合
- en: If a machine learning model performs great in a development environment but
    degrades noticeably in a production environment, we say the model is overfitted.
    This means the trained model too closely follows the training dataset. It is an
    indication there are too many details in the rules created by the model. The trade-off
    between model variance and bias best captures the idea. Let's look at these concepts
    one by one.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个机器学习模型在开发环境中表现出色，但在生产环境中明显下降，我们说这个模型是过拟合的。这意味着训练模型过于密切地遵循训练数据集。这表明模型创建的规则中有太多细节。模型方差和偏差之间的权衡最能捕捉到这个概念。让我们逐个来看这些概念。
- en: Bias
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差
- en: Any machine learning model is trained based on certain assumptions. In general,
    these assumptions are the simplistic approximations of some real-world phenomena.
    These assumptions simplify the actual relationships between features and their
    characteristics and make a model easier to train. More assumptions means more
    bias. So, while training a model, more simplistic assumptions = high bias, and
    realistic assumptions that are more representative of actual phenomena = low bias.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习模型都是基于某些假设进行训练的。一般来说，这些假设是对一些真实世界现象的简化近似。这些假设简化了特征和特征特性之间的实际关系，并使模型更容易训练。更多的假设意味着更多的偏差。因此，在训练模型时，更简化的假设=高偏差，更符合实际现象的现实假设=低偏差。
- en: In linear regression, the non-linearity of the features is ignored and they
    are approximated as linear variables. So, linear regression models are inherently
    vulnerable to exhibiting high bias.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，忽略了特征的非线性，并将它们近似为线性变量。因此，线性回归模型天生容易表现出高偏差。
- en: Variance
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方差
- en: Variance quantifies how accurately a model estimates the target variable if
    a different dataset is used to train the model. It quantifies whether the mathematical
    formulation of our model is a good generalization of the underlying patterns.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 方差量化了模型在使用不同数据集训练时对目标变量的估计准确性。它量化了我们的模型的数学公式是否是底层模式的良好概括。
- en: Specific overfitted rules based on specific scenarios and situations = high
    variance, and rules that are generalized and applicable to a variety of scenarios
    and situations = low variance.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 基于特定情景和情况的特定过拟合规则=高方差，而基于广泛情景和情况的泛化规则=低方差。
- en: Our goal in machine learning is to train models that exhibit low bias and low
    variance. Achieving this goal is not always easy and usually keeps data scientists
    awake at night.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在机器学习中的目标是训练表现出低偏差和低方差的模型。实现这一目标并不总是容易的，通常会让数据科学家夜不能寐。
- en: Bias-variance trade-off
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差-方差权衡
- en: When training a particular machine learning model, it is tricky to decide the
    right level of generalization for the rules that comprise a trained model. The
    struggle to come up with the right level of generalization is captured by the
    bias-variance trade-off.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练特定的机器学习模型时，很难确定训练模型所包含的规则的正确泛化级别。为了找到正确的泛化级别而进行的挣扎被称为偏差-方差权衡。
- en: Note that more simplistic assumptions = more generalization = low variance =
    high variance.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，更简化的假设=更泛化=低方差=高方差。
- en: This trade-off between bias and variance is determined by the choice of algorithm,
    the characteristics of the data, and various hyperparameters. It is important
    to achieve the right compromise between the bias and variance based on the requirements
    of the specific problem you are trying to solve.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差和方差之间的权衡是由算法的选择、数据的特征和各种超参数决定的。根据您尝试解决的具体问题的要求，重要的是在偏差和方差之间取得正确的折衷。
- en: Specifying the phases of classifiers
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定分类器的阶段
- en: Once the labeled data is prepared, the development of the classifiers involves
    training, evaluation, and deployment. These three phases of implementing a classifier
    are shown in the **CRISP-DM**  (**Cross-Industry Standard Process for Data Mining**)
    life cycle in the following diagram (the CRISP-DM life cycle was explained in
    more detail in [Chapter 5](051e9b32-f15f-4e88-a63a-ae3c14696492.xhtml)*, Graph
    Algorithms*)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦标记的数据准备好，分类器的开发包括训练、评估和部署。在以下图表中，CRISP-DM（数据挖掘的跨行业标准流程）生命周期展示了实施分类器的这三个阶段（CRISP-DM生命周期在[第5章](051e9b32-f15f-4e88-a63a-ae3c14696492.xhtml)*，图形算法中有更详细的解释）
- en: '![](assets/0d74d428-cad1-4af4-bf70-f6eecb3aba00.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/0d74d428-cad1-4af4-bf70-f6eecb3aba00.png)'
- en: In the first two phases of implementing a classifier—the testing and training
    phases—we use labeled data. The labeled data is divided into two partitions—a
    larger partition called the training data and a smaller partition called the testing
    data. A random sampling technique is used to divide the input labeled data into
    training and testing partitions to make sure that both partitions contain consistent
    patterns. Note that, as the preceding diagram shows, first, there is a training
    phase, where training data is used to train a model. Once the training phase is
    over, the trained model is evaluated using the testing data. Different performance
    matrices are used to quantify the performance of the trained model. Once the model
    is evaluated, we have the model deployment phase, where the trained model is deployed
    and used for inference to solve real-world problems by labeling unlabeled data.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施分类器的前两个阶段——测试和训练阶段，我们使用标记的数据。标记的数据被分成两个分区——一个更大的分区称为训练数据，一个更小的分区称为测试数据。使用随机抽样技术将输入的标记数据分成训练和测试分区，以确保两个分区都包含一致的模式。请注意，如前图所示，首先是训练阶段，使用训练数据来训练模型。训练阶段结束后，使用测试数据评估训练模型。不同的性能指标用于量化训练模型的性能。评估模型后，我们有模型部署阶段，其中训练好的模型被部署并用于推理，通过标记未标记的数据解决现实世界的问题。
- en: Now, let's look at some classification algorithms.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一些分类算法。
- en: 'We will look at the following classification algorithms in the subsequent sections:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分中看到以下分类算法：
- en: The decision tree algorithm
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树算法
- en: The XGBoost algorithm
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost算法
- en: The random forest algorithm
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林算法
- en: The logistic regression algorithm
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归算法
- en: The **Support Vector Machine** (**SVM**) algorithm
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）算法
- en: The naive Bayes algorithm
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法
- en: Let's start with the decision tree algorithm.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从决策树算法开始。
- en: Decision tree classification algorithm
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树分类算法
- en: A decision tree is based on the recursive partitioning approach (divide and
    conquer), which generates a set of rules that can be used to predict a label.
    It starts with a root node and splits into multiple branches. Internal nodes represent
    a test on a certain attribute and the result of the test is represented by a branch
    to the next level. The decision tree ends in leaf nodes that contain the decisions.
    The process stops when partitioning no longer improves the outcome.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树基于递归分区方法（分而治之），生成一组规则，可用于预测标签。它从根节点开始，分成多个分支。内部节点表示对某个属性的测试，测试的结果由分支到下一级表示。决策树以包含决策的叶节点结束。当分区不再改善结果时，过程停止。
- en: Understanding the decision tree classification algorithm
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解决策树分类算法
- en: 'The distinguishing feature of decision tree classification is the generation
    of the human-interpretable hierarchy of rules that are used to predict the label
    at runtime. The algorithm is recursive in nature. Creating this hierarchy of rules
    involves the following steps:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树分类的显著特点是生成可解释的层次规则，用于在运行时预测标签。该算法具有递归性质。创建这些规则层次涉及以下步骤：
- en: '**Find the most important feature**:  Out of all of the features, the algorithm
    identifies the feature that best differentiates between the data points in the
    training dataset with respect to the label. The calculation is based on metrics
    such as information gain or Gini impurity.'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**找到最重要的特征**：在所有特征中，算法确定了最能区分训练数据集中数据点的特征。计算基于信息增益或基尼不纯度等指标。'
- en: '**Bifurcate**: Using the most identified important feature, the algorithm creates
    a criterion that is used to divide the training dataset into two branches:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分叉**：使用最重要的特征，算法创建一个标准，用于将训练数据集分成两个分支：'
- en: Data points that pass the criterion
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过满足标准的数据点
- en: Data points that fail the criterion
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未通过标准的数据点
- en: '**Check for leaf nodes**:  If any resultant branch mostly contains labels of
    one class, the branch is made final, resulting in a leaf node.'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检查叶节点**：如果任何结果分支大多包含一个类的标签，则该分支被确定为最终分支，形成一个叶节点。'
- en: '**Check the stopping conditions and repeat**: If the provided stopping conditions
    are not met, then the algorithm will go back to *step 1* for the next iteration.
    Otherwise, the model is marked as trained and each node of the resultant decision
    tree at the lowest level is labeled as a leaf node. The stopping condition can
    be as simple as defining the number of iterations, or the default stopping condition
    can be used, where the algorithm stops as soon it reaches a certain homogeneity
    level for each of the leaf nodes.'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检查停止条件并重复**：如果未满足提供的停止条件，则算法将返回到*步骤1*进行下一次迭代。否则，模型被标记为已训练，并且结果决策树的每个最低级节点都被标记为叶节点。停止条件可以简单地定义为迭代次数，或者可以使用默认的停止条件，即一旦每个叶节点达到一定的同质性水平，算法就会停止。'
- en: 'The decision tree algorithm can be explained by the following diagram:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树算法可以用以下图解释：
- en: '![](assets/53f88b67-009e-48f6-9389-b487fe7c0388.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/53f88b67-009e-48f6-9389-b487fe7c0388.png)'
- en: In the preceding diagram, the root contains a bunch of circles and crosses.
    The algorithm creates a criterion that tries to separate the circles from the
    crosses. At each level, the decision tree creates partitions of the data, which
    are expected to be more and more homogeneous from level 1 upward. A perfect classifier
    has leaf nodes that only contain circles or crosses. Training perfect classifiers
    is usually difficult due to the inherent randomness of the training dataset.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，根节点包含一堆圆圈和十字。该算法创建了一个标准，试图将圆圈与十字分开。在每个级别，决策树创建数据的分区，预期从第1级开始越来越同质。完美的分类器只包含只包含圆圈或十字的叶节点。由于训练数据集固有的随机性，训练完美的分类器通常很困难。
- en: Using the decision tree classification algorithm for the classifiers challenge
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用决策树分类算法进行分类器挑战
- en: 'Now, let''s use the decision tree classification algorithm for the common problem
    that we previously defined to predict whether a customer ends up purchasing a
    product:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用决策树分类算法来解决我们之前定义的常见问题，预测客户最终是否购买产品：
- en: 'To do, first, let''s instantiate the decision tree classification algorithm
    and train a model using the training portion of the data that we prepared for
    our classifiers:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们实例化决策树分类算法，并使用我们为分类器准备的训练部分数据来训练模型：
- en: '[PRE7]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, let''s use our trained model to predict the labels for the testing portion
    of our labeled data. Let''s generate a confusion matrix that can summarize the
    performance of our trained model:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用我们训练好的模型来预测我们标记数据的测试部分的标签。让我们生成一个可以总结我们训练好的模型性能的混淆矩阵：
- en: '[PRE8]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This gives the following output:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '![](assets/7588760f-69c4-4470-ade7-85255d5e67f7.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7588760f-69c4-4470-ade7-85255d5e67f7.png)'
- en: 'Now, let''s calculate the `accuracy`, `recall`, and `precision` values for
    the created classifier by using the decision tree classification algorithm:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们通过使用决策树分类算法来计算所创建分类器的`准确率`、`召回率`和`精确度`值：
- en: '[PRE9]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Running the preceding code will produce the following output:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行上述代码将产生以下输出：
- en: '![](assets/a7a7e80c-e144-4e7c-8c1b-98cc1cec5fef.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a7a7e80c-e144-4e7c-8c1b-98cc1cec5fef.png)'
- en: The performance measures help us compare different training modeling techniques
    with each other.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 性能指标帮助我们比较不同的训练建模技术。
- en: The strengths and weaknesses of decision tree classifiers
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树分类器的优势和劣势
- en: In this section, let's look at the strengths and weaknesses of using the decision
    tree classification algorithm.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们看看使用决策树分类算法的优势和劣势。
- en: Strengths
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优势
- en: 'The following are the strengths of decision tree classifiers:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是决策树分类器的优势：
- en: The rules of the models created by using a decision tree algorithm are interpretable
    by humans. Models such as this are called **whitebox models**. Whitebox models
    are a requirement whenever transparency is needed to trace the details and reasons
    for decisions that are made by the model. This transparency is essential in applications
    where we want to prevent bias and protect vulnerable communities. For example,
    a whitebox model is generally a requirement for critical use cases in government
    and insurance industries.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用决策树算法创建的模型的规则可被人类解释。这样的模型被称为**白盒模型**。白盒模型是在需要追踪决策的细节和原因时的必要条件。这种透明性在我们想要防止偏见和保护脆弱社区的应用中至关重要。例如，在政府和保险行业的关键用例中，通常需要白盒模型。
- en: Decision tree classifiers are designed to extract information from discrete
    problem space. This means that most of the features are category variables, so
    using a decision tree to train the model is a good choice.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树分类器旨在从离散问题空间中提取信息。这意味着大多数特征都是类别变量，因此使用决策树来训练模型是一个不错的选择。
- en: Weaknesses
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 劣势
- en: 'The following are the weaknesses of decision tree classifiers:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是决策树分类器的弱点：
- en: If the tree generated by the decision tree classifier goes too deep, the rules
    capture too many details, resulting in an overfitted model. While using a decision
    tree algorithm, we need to be aware that decision trees are vulnerable to overfitting
    and so we need to prune the tree, whenever necessary, to prevent this.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果决策树分类器生成的树太深，规则会捕捉太多细节，导致过拟合的模型。在使用决策树算法时，我们需要意识到决策树容易过拟合，因此我们需要及时修剪树以防止这种情况。
- en: A weakness of decision tree classifiers is their inability to capture non-linear
    relationships in the rules that they create.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树分类器的一个弱点是它们无法捕捉规则中的非线性关系。
- en: Use cases
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例
- en: In this section, let's look at the use cases that the decision tree algorithm
    is used for.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们看看决策树算法用于哪些用例。
- en: Classifying records
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类记录
- en: 'Decision trees classifiers can be used to classify data points, such as in
    the following examples:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树分类器可用于对数据点进行分类，例如以下示例：
- en: '**Mortgage applications**: To train a binary classifier to determine whether
    an applicant is likely to default.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**抵押贷款申请**：训练一个二元分类器，以确定申请人是否可能违约。'
- en: '**Customer segmentation**: To categorize customers into high-worth, medium-worth,
    and low-worth customers so that marketing strategies can be customized for each
    category.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户细分**：将客户分类为高价值、中价值和低价值客户，以便为每个类别定制营销策略。'
- en: '**Medical diagnosis**: To train a classifier that can categorize a benign or
    malignant growth.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学诊断**：训练一个分类器，可以对良性或恶性生长进行分类。'
- en: '**Treatment-effectiveness analysis**: To train a classifier that can flag patients
    that have reacted positively to a particular treatment.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**治疗效果分析**：训练一个分类器，可以标记对特定治疗产生积极反应的患者。'
- en: Feature selection
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择
- en: The decision tree classification algorithm selects a small subset of features
    to create rules for. That feature selection can be used to select the features
    for another machine learning algorithm when you have a large number of features.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树分类算法选择一小部分特征来创建规则。当特征数量很大时，可以使用该特征选择来选择另一个机器学习算法的特征。
- en: Understanding the ensemble methods
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解集成方法
- en: An ensemble is a method, in machine learning, of creating more than one slightly
    different model using different parameters and then combining them into an aggregate
    model. In order to create effective ensembles, we need to find what our aggregation
    criterion is to generate the resultant model. Let's look at some ensemble algorithms.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 集成是一种机器学习方法，通过使用不同的参数创建多个略有不同的模型，然后将它们组合成一个聚合模型。为了创建有效的集成，我们需要找到我们的聚合标准，以生成最终模型。让我们看看一些集成算法。
- en: Implementing gradient boosting with the XGBoost algorithm
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用XGBoost算法实现梯度提升
- en: XGBoost was created in 2014 and is based on gradient-boosting principles. It
    has become one of the most popular ensemble classification algorithms. It generates
    a bunch of interrelated trees and uses gradient descent to minimize the residual
    error. This makes it a perfect fit for distributed infrastructures, such as Apache
    Spark, or for cloud computing, such as Google Cloud or  **Amazon Web Services**(**AWS**)**.**
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost于2014年创建，基于梯度提升原理。它已成为最受欢迎的集成分类算法之一。它生成一堆相互关联的树，并使用梯度下降来最小化残差误差。这使其非常适合分布式基础设施，如Apache
    Spark，或云计算，如Google Cloud或**亚马逊网络服务（AWS）**。
- en: 'Let''s now see how we can implement gradient boosting with the XGBoost algorithm:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用XGBoost算法实现梯度提升：
- en: 'First, we will instantiate the XGBClassfier classifier and train the model
    using the training portion of the data:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将实例化XGBClassfier分类器，并使用数据的训练部分来训练模型：
- en: '![](assets/27a8fe49-3854-4c12-84f2-e71c0f64e430.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/27a8fe49-3854-4c12-84f2-e71c0f64e430.png)'
- en: 'Then, we will generate predictions based on the newly trained model:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将基于新训练的模型生成预测：
- en: '[PRE10]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The produces the following output :'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 产生以下输出：
- en: '![](assets/3d7d4afa-c3ae-4ae3-a2d2-7ab69b67dcdd.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3d7d4afa-c3ae-4ae3-a2d2-7ab69b67dcdd.png)'
- en: 'Finally, we will quantify the performance of the model:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将量化模型的性能：
- en: '[PRE11]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This gives us the following output:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '![](assets/beaac243-597f-4f5d-b1ec-022f89f01584.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/beaac243-597f-4f5d-b1ec-022f89f01584.png)'
- en: Next, let's look at the random forest algorithm.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看随机森林算法。
- en: Using the random forest algorithm
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用随机森林算法
- en: Random forest is a type of ensemble method that works by combining several decision
    trees to decrease both the bias and the variance.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是一种集成方法，通过组合多个决策树来减少偏差和方差。
- en: Training a random forest algorithm
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练随机森林算法
- en: In training, this algorithm takes *N* samples from the training data and creates
    *m* subsets of our overall data. These subsets are created by randomly selecting
    some of the rows and columns of the input data. The algorithm builds *m* independent
    decision trees. These classification trees are represented by `C[1]` to `C[m]`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练中，该算法从训练数据中获取*N*个样本，并创建我们整体数据的*m*个子集。这些子集是通过随机选择输入数据的一些行和列来创建的。该算法构建*m*个独立的决策树。这些分类树由`C[1]`到`C[m]`表示。
- en: Using random forest for predictions
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用随机森林进行预测
- en: 'Once the model is trained, it can be used to label new data. Each of the individual
    trees generates a label. The final prediction is determined by voting these individual
    predictions, as shown:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，可以用于标记新数据。每个个体树生成一个标签。最终预测由这些个体预测的投票决定，如下所示：
- en: '![](assets/89d3a5b6-24cc-4fbd-b922-90865ca6b739.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/89d3a5b6-24cc-4fbd-b922-90865ca6b739.png)'
- en: Note that in the preceding diagram, *m* trees are trained, which is represented
    by `C[1]` to `C[m]`. That is Trees = {C[1],..,C[m]}
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在上图中，训练了*m*棵树，表示为`C[1]`到`C[m]`。即树 = {C[1],..,C[m]}
- en: 'Each of the trees generates a prediction that is represented by a set:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 每棵树生成一个由一组表示的预测：
- en: Individual predictions = P= {P[1],..., P[m]}
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 个体预测 = P= {P[1],..., P[m]}
- en: 'The final prediction is represented by `P[f]`. It is determined by the majority
    of the individual predictions. The `mode` function can be used to find the majority
    decision (`mode` is the number that repeats most often and is in the majority).
    The individual prediction and the final prediction are linked, as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 最终预测由`P[f]`表示。它由个体预测的大多数决定。`mode`函数可用于找到多数决定（`mode`是最常重复且处于多数的数字）。个体预测和最终预测如下所示：
- en: P[f] = mode (P)
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: P[f] = mode (P)
- en: Differentiating the random forest algorithm from ensemble boosting
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区分随机森林算法和集成提升
- en: Each of the trees generated by the random forest algorithm is totally independent
    of each other. It is not aware of any of the details of the other trees in the
    ensemble. This differentiates it from other techniques, such as ensemble boosting.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林算法生成的每棵树都是完全独立的。它不知道集成中其他树的任何细节。这使它与其他技术有所不同，如集成增强。
- en: Using the random forest algorithm for the classifiers challenge
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用随机森林算法进行分类器挑战
- en: Let's instantiate the random forest algorithm and use it to train our model
    using the training data.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实例化随机森林算法，并使用它来训练我们的模型使用训练数据。
- en: 'There are two key hyperparameters that we''ll be looking at here:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个关键的超参数：
- en: '`n_estimators`'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_estimators`'
- en: '`max_depth`'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`'
- en: The `n_estimators` hyperparameter controls how many individual decision trees
    are built and the `max_depth` hyperparameter controls how deep each of these individual
    decision trees can go.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_estimators`超参数控制构建多少个独立的决策树，`max_depth`超参数控制每个独立决策树可以有多深。'
- en: 'So, in other words, a decision tree can keep splitting and splitting until
    it has a node that represents every given example in the training set. By setting
    `max_depth`, we constrain how many levels of splits it can make. This controls
    the complexity of the model and determines how closely it fits the training data.
    If we refer to the following output, `n_estimators` controls the width of the
    random forest model and `max_depth` controls the depth of the model:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，决策树可以不断分裂，直到它有一个节点代表训练集中的每个给定示例。通过设置`max_depth`，我们限制了它可以进行多少级别的分裂。这控制了模型的复杂性，并确定了它与训练数据的拟合程度。如果我们参考以下输出，`n_estimators`控制了随机森林模型的宽度，`max_depth`控制了模型的深度：
- en: '![](assets/d4ee0995-7c13-4508-bf5c-5fa23929a1be.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d4ee0995-7c13-4508-bf5c-5fa23929a1be.png)'
- en: 'Once the random forest model is trained, let''s use it for predictions:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦随机森林模型训练好了，让我们用它进行预测：
- en: '[PRE12]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Which gives the output as:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 它的输出是：
- en: '![](assets/374d8a18-c24f-44c3-a475-e19c54bc4329.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/374d8a18-c24f-44c3-a475-e19c54bc4329.png)'
- en: 'Now, let''s quantify how good our model is:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们量化我们的模型有多好：
- en: '[PRE13]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We will observe the following output:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将观察以下输出：
- en: '![](assets/ac3d4ce9-a599-4064-a93f-4742874af7b4.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ac3d4ce9-a599-4064-a93f-4742874af7b4.png)'
- en: Next, let's look into logistic regression.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们来看看逻辑回归。
- en: Logistic regression
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Logistic regression is a classification algorithm used for binary classification.
    It uses a logistic function to formulate the interaction between the input features
    and the target variable. It is one of the simplest classification techniques that
    is used to model a binary dependent variable.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是一种用于二元分类的分类算法。它使用逻辑函数来制定输入特征和目标变量之间的交互。它是用于建模二元因变量的最简单的分类技术之一。
- en: Assumptions
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假设
- en: 'Logistic regression assumes the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归假设以下内容：
- en: The training dataset does not have a missing value.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据集没有缺失值。
- en: The label is a binary category variable.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签是一个二进制类别变量。
- en: The label is ordinal—in other words, a categorical variable with ordered values.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签是有序的，换句话说，是一个具有有序值的分类变量。
- en: All features or input variables are independent of each other.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有特征或输入变量彼此独立。
- en: Establishing the relationship
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立关系
- en: 'For logistic regression, the predicted value is calculated as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于逻辑回归，预测值计算如下：
- en: '![](assets/57472f0a-fed2-46a3-8f85-82a58abe001c.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/57472f0a-fed2-46a3-8f85-82a58abe001c.png)'
- en: Let's suppose that ![](assets/57ba1e44-a466-4007-99ec-5e7c03a7d299.png).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 假设![](assets/57ba1e44-a466-4007-99ec-5e7c03a7d299.png)。
- en: 'So now:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 所以现在：
- en: '![](assets/5a9b351d-1683-44cf-8324-c8897ee20680.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5a9b351d-1683-44cf-8324-c8897ee20680.png)'
- en: 'The preceding relationship can be graphically shown as follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 上述关系可以用图形表示如下：
- en: '![](assets/c4c1e51c-a610-4fb4-8c21-ba38fed82d20.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c4c1e51c-a610-4fb4-8c21-ba38fed82d20.png)'
- en: Note that if *z* is large, σ (*z*) will equal `1`. If *z* is very small or a
    large negative number, σ (z) will equal `0`. So, the objective of logistic regression
    is to find the correct values for *w* and *j*.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果*z*很大，σ (*z*)将等于`1`。如果*z*非常小或非常负，σ (*z*)将等于`0`。因此，逻辑回归的目标是找到*W*和*j*的正确值。
- en: Logistic regression is named after the function that is used to formulate it,
    called the **logistic** or **sigmoid function**.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是根据用于制定它的函数命名的，称为**逻辑**或**Sigmoid函数**。
- en: The loss and cost functions
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 损失和成本函数
- en: The `loss` function defines how we want to quantify an error for a particular
    example in our training data. The `cost` function defines how we want to minimize
    an error in our entire training dataset. So, the `loss` function is used for one
    of the examples in the training dataset and the `cost` function is used for the
    overall cost that quantifies the overall deviation of the actual and predicted
    values. It is dependent on the choice of *w* and *h*.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '`loss`函数定义了我们想要量化训练数据中特定示例的错误的方式。`cost`函数定义了我们想要最小化整个训练数据集中的错误的方式。因此，`loss`函数用于训练数据集中的一个示例，`cost`函数用于量化实际值和预测值的整体偏差。它取决于*w*和*h*的选择。'
- en: 'The `loss` function used in logistic regression is as follows:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归中使用的`loss`函数如下：
- en: '*Loss (ý^((i)), y^((i))) = - (y^((i))log ý^((i))+(1-y^((i)) ) log (1-ý^((i)))*'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '*Loss (ý^((i)), y^((i))) = - (y^((i))log ý^((i))+(1-y^((i)) ) log (1-ý^((i)))*'
- en: Note that when  *y^((i))  = 1, Loss(ý^((i)), y^((i))**) = - logý^((i))*.Minimizing
    the loss will result in a large value of ý^((i)) . Being a sigmoid function, the
    maximum value will be `1`.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 注意当*y^((i))  = 1, Loss(ý^((i)), y^((i))**) = - logý^((i))*.最小化损失将导致ý^((i))的值很大。作为Sigmoid函数，最大值将是`1`。
- en: If *y^((i)) = 0, Loss (ý^((i)), y^((i))) = - log (1-ý^((i))**)*. Minimizing
    the loss will result in *ý^((i))* being as small as possible, which is `0`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*y^((i)) = 0, Loss (ý^((i)), y^((i))) = - log (1-ý^((i))**)*。最小化损失将导致*ý^((i))*尽可能小，即`0`。
- en: 'The cost function of logistic regression is as follows:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的成本函数如下：
- en: '![](assets/41a6378a-1b02-4912-8fcd-0279b7e7fc45.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/41a6378a-1b02-4912-8fcd-0279b7e7fc45.png)'
- en: When to use logistic regression
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用逻辑回归
- en: Logistic regression works great for binary classifiers. Logistic regression
    doesn't do very well when the data is huge but the quality of the data is not
    great. It can capture relationships that aren't too complex. While it doesn't
    usually generate the greatest performance, it does set a very nice benchmark to
    start.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归在二元分类器方面表现出色。当数据量很大但数据质量不佳时，逻辑回归效果不佳。它可以捕捉不太复杂的关系。虽然它通常不会产生最佳性能，但它确实为起步设定了一个很好的基准。
- en: Using the logistic regression algorithm for the classifiers challenge
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用逻辑回归算法进行分类器挑战
- en: 'In this section, we will see how we can use the logistic regression algorithm
    for the classifiers challenge:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何使用逻辑回归算法进行分类器挑战：
- en: 'First, let''s instantiate a logistic regression model and train it using the
    training data:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们实例化一个逻辑回归模型，并使用训练数据对其进行训练：
- en: '[PRE14]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s predict the values of the `test` data and create a confusion matrix:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们预测`test`数据的值并创建一个混淆矩阵：
- en: '[PRE15]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We get the following output upon running the preceding code:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码后，我们得到以下输出：
- en: '![](assets/e6d66de7-957c-43d0-83a6-bc2b2f334b6d.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e6d66de7-957c-43d0-83a6-bc2b2f334b6d.png)'
- en: 'Now, let''s look at the performance metrics:'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看性能指标：
- en: '[PRE16]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We get the following output upon running the preceding code:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行上述代码后，我们得到以下输出：
- en: '![](assets/31737825-b84d-423e-8416-c6885f175eb1.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/31737825-b84d-423e-8416-c6885f175eb1.png)'
- en: Next, let's look at **SVM**.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看**SVM**。
- en: The SVM algorithm
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SVM算法
- en: 'Now, let''s look at SVM. SVM is a classifier that finds an optimal hyperplane
    that maximizes the margin between two classes. In SVMs, our optimization objective
    is to maximize the margin. The margin is defined as the distance between the separating
    hyperplane (the decision boundary) and the training samples that are closest to
    this hyperplane, called the **support vectors***.* So, let''s start with a very
    basic example with only two dimensions, *X1* and *X2*. We want a line to separate
    the circles from the crosses. This is shown in the following diagram:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看SVM。SVM是一种找到最大化两个类之间间隔的最优超平面的分类器。在SVM中，我们的优化目标是最大化间隔。间隔被定义为分隔超平面（决策边界）与最靠近该超平面的训练样本之间的距离，称为**支持向量**。因此，让我们从一个只有两个维度*X1*和*X2*的非常基本的例子开始。我们希望有一条线将圆圈与十字分开。如下图所示：
- en: '![](assets/9830448e-e681-400a-9017-57888b5df6da.png)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9830448e-e681-400a-9017-57888b5df6da.png)'
- en: 'We have drawn two lines and both perfectly separate the crosses from the circles.
    However, there has to be an optimal line, or decision boundary, that gives us
    the best chance to correctly classify most of the additional examples. A reasonable
    choice may be a line that is evenly spaced between these two classes to give a
    little bit of a buffer for each class, as shown:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们画了两条线，都完美地将十字与圆圈分开。然而，必须有一个最佳线或决策边界，使我们有最佳机会正确分类大多数额外的例子。一个合理的选择可能是一条均匀分布在这两个类之间的线，为每个类提供一点缓冲，如下所示：
- en: '![](assets/710cb98c-c09e-42bb-a173-1e392b0f8d5b.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/710cb98c-c09e-42bb-a173-1e392b0f8d5b.png)'
- en: Now, let's see how we can use SVM to train a classifier for our challenge.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用SVM来训练我们挑战的分类器。
- en: Using the SVM algorithm for the classifiers challenge
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SVM算法进行分类器挑战
- en: 'First, let''s instantiate the SVM classifier and then use the training portion
    of the labeled data to train it. The `kernel` hyperparameter determines the type
    of transformation that is applied to the input data in order to make it linearly
    separable.:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们实例化SVM分类器，然后使用标记数据的训练部分对其进行训练。`kernel`超参数确定应用于输入数据的转换类型，以使其线性可分。
- en: '[PRE17]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Once trained, let''s generate some predictions and look at the confusion matrix:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练完成后，让我们生成一些预测并查看混淆矩阵：
- en: '[PRE18]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Observe the following output:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察以下输出：
- en: '![](assets/9e0d3b4b-2ba9-48ee-8999-692c32d334b5.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9e0d3b4b-2ba9-48ee-8999-692c32d334b5.png)'
- en: 'Now, let''s look at the various performance metrics:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们来看看各种性能指标：
- en: '[PRE19]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After running the preceding code, we get the following values as our output:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码后，我们得到以下值作为输出：
- en: '![](assets/64c827cb-bf53-453d-96f1-cb1d34c01db9.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/64c827cb-bf53-453d-96f1-cb1d34c01db9.png)'
- en: Understanding the naive Bayes algorithm
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解朴素贝叶斯算法
- en: 'Based on probability theory, naive Bayes is one of the simplest classification
    algorithms. If used properly, it can come up with accurate predictions. The Naive
    Bayes Algorithm is s0-named for two reasons:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 基于概率论，朴素贝叶斯是最简单的分类算法之一。如果使用正确，它可以得出准确的预测。朴素贝叶斯算法之所以被如此命名有两个原因：
- en: It is based on a naive assumption that there is independence between the features
    and the input variable.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它基于一个天真的假设，即特征和输入变量之间是独立的。
- en: It is based on Bayes, theorem.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它基于贝叶斯定理。
- en: This algorithm tries to classify instances based on the probabilities of the
    preceding attributes/instances, assuming complete attribute independence.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法试图基于先前属性/实例的概率对实例进行分类，假设属性完全独立。
- en: 'There are three types of events:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种类型的事件：
- en: '**Independent** events do not affect the probability of another event occurring
    (for example, receiving an email offering you free entry to a tech event *and*
    a re-organization occurring in your company).'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**独立**事件不会影响另一个事件发生的概率（例如，收到一封电子邮件提供免费参加科技活动的机会*和*公司进行重新组织）。'
- en: '**Dependent** events affect the probability of another event occurring; that
    is, they are linked in some way (for example, the probability of you getting to
    a conference on time could be affected by an airline staff strike or flights that
    may not run on time).'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖**事件会影响另一个事件发生的概率；也就是说，它们在某种程度上是相关的（例如，你准时参加会议的概率可能会受到航空公司员工罢工或航班不准时的影响）。'
- en: '**Mutually exclusive** events cannot occur simultaneously (for example, the
    probability of rolling a three and a six on a single dice roll is 0—these two
    outcomes are mutually exclusive).'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**互斥**事件不能同时发生（例如，单次掷骰子得到三和六的概率为0——这两个结果是互斥的）。'
- en: Bayes, theorem
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 贝叶斯定理
- en: 'Bayes, theorem is used to calculate the conditional probability between two
    independent events, *A* and *B*. The probability of events *A* and *B* happening  is
    represented by P(*A*) and P(*B*). The conditional probability is represented by
    P(*B*|*A*), which is the conditional probability that event *B* will happen given
    that event *A* has occurred:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理用于计算两个独立事件*A*和*B*之间的条件概率。事件*A*和*B*发生的概率由P（*A*）和P（*B*）表示。条件概率由P（*B*|*A*）表示，这是事件*A*发生的条件概率，假设事件*B*已经发生：
- en: '![](assets/c3857335-8ad7-48cb-bc9d-d0a1a132aebf.png)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c3857335-8ad7-48cb-bc9d-d0a1a132aebf.png)'
- en: Calculating probabilities
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算概率
- en: 'Naive Bayes is based on probability fundamentals. The probability of a single
    event occurring (the observational probability) is calculated by taking the number
    of times the event occurred and dividing it by the total number of processes that
    could have led to that event. For example, a call center receives over 100 support
    calls per day, 50 times over the course of a month. You want to know the probability
    that a call is responded to in under 3 minutes based on the previous times it
    was responded to. If the call center manages to match this time record on 27 occasions,
    then the observational probability of 100 calls being answered in under 3 minutes
    is as follows:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯基于概率基本原理。单个事件发生的概率（观察概率）是通过将事件发生的次数除以可能导致该事件发生的总进程次数来计算的。例如，呼叫中心每天接到100多个支持电话，一个月内有50次。您想知道基于以前的响应时间，呼叫在3分钟内得到响应的概率。如果呼叫中心在27次匹配这个时间记录，那么100次呼叫在3分钟内得到响应的观察概率如下：
- en: '*P(100 support calls in under 3 mins) = (27 / 50) = 0.54 (54%)*'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '* P（3分钟内100个支持电话）=（27/50）= 0.54（54％）*'
- en: 100 calls can be responded to in under 3 minutes in about half the time, based
    on records of the 50 times it occurred in the past.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 根据过去的50次记录，100次呼叫大约有一半的时间可以在3分钟内得到响应。
- en: Multiplication rules for AND events
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AND事件的乘法规则
- en: 'To calculate the probability of two or more events occurring simultaneously,
    consider whether events are independent or dependent. If they are independent,
    the simple multiplication rule is used:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算两个或更多事件同时发生的概率，请考虑事件是独立还是相关的。如果它们是独立的，则使用简单的乘法规则：
- en: '*P(outcome 1 AND outcome 2) = P(outcome 1) * P(outcome 2)*'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '* P（结果1和结果2）= P（结果1）* P（结果2）*'
- en: For example, to calculate the probability of receiving an email with free entry
    to a tech event  *and* re-organization occurring in your workplace, this simple
    multiplication rule would be used. The two events are independent as the occurrence
    of one does not affect the chance of the other occurring
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要计算收到免费参加技术活动的电子邮件的概率*和*工作场所发生重新组织的概率，将使用这个简单的乘法规则。这两个事件是独立的，因为其中一个发生并不影响另一个发生的机会
- en: 'If receiving the tech event email has a probability of 31% and the probability
    of staff re-organization is 82%, then the probability of both occurring is calculated
    as follows:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 如果收到技术活动的电子邮件的概率为31％，并且员工重新组织的概率为82％，则同时发生的概率如下计算：
- en: P(email AND re-organization) = P(email) * P(re-organization) = (0.31) * (0.82)
    = 0.2542 (25%)
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: P（电子邮件和重新组织）= P（电子邮件）* P（重新组织）=（0.31）*（0.82）= 0.2542（25％）
- en: The general multiplication rule
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一般乘法规则
- en: 'If two or more events are dependent, the general multiplication rule is used.
    This formula is actually valid in both cases of independent and dependent events:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个或更多事件是相关的，则使用一般乘法规则。这个公式实际上在独立和相关事件的情况下都是有效的：
- en: '*P(outcome 1 AND outcome 2)=P(outcome 1)*P(outcome 2 | outcome 1)*'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '* P（结果1和结果2）= P（结果1）* P（结果2 | 结果1）*'
- en: Note that `P(outcome 2 | outcome 1)` refers to the conditional probability of
    `outcome 2` occurring given `outcome 1` has already occurred. The formula incorporates
    the dependence between the events. If the events are independent, then the conditional
    probability is irrelevant as one outcome does not influence the chance of the
    other occurring, and `P(outcome 2 | outcome 1)` is simply `P(outcome 2)`. Note
    that the formula in this case just becomes the simple multiplication rule.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`P（结果2 | 结果1）`指的是`结果1`已经发生的情况下`结果2`发生的条件概率。该公式包含了事件之间的依赖关系。如果事件是独立的，那么条件概率是无关紧要的，因为一个结果不会影响另一个发生的机会，`P（结果2
    | 结果1）`就是`P（结果2）`。请注意，在这种情况下，该公式变成了简单的乘法规则。
- en: Addition rules for OR events
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OR事件的加法规则
- en: 'When calculating the probability of either one event or the other occurring
    (mutually exclusive), the following simple addition rule is used:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算两个事件中的一个或另一个发生的概率（互斥）时，使用以下简单的加法规则：
- en: '*P(outcome 1 OR outcome 2) = P(outcome 1) + P(outcome 2)*'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '* P（结果1或结果2）= P（结果1）+ P（结果2）*'
- en: 'For example, what is the probability of rolling a 6 or a 3? To answer this
    question, first, note that both outcomes cannot occur simultaneously. The probability
    of rolling a 6 is (1 / 6) and the same can be said for rolling a 3:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，掷出6或3的概率是多少？要回答这个问题，首先注意到两个结果不能同时发生。掷出6的概率是（1/6），掷出3的概率也是如此：
- en: '*P(6 OR 3) = (1 / 6) + (1 / 6) = 0.33 (33%)*'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '* P（6或3）=（1/6）+（1/6）= 0.33（33％）*'
- en: 'If the events are not mutually exclusive and can occur simultaneously, use
    the following general addition formula, which is always valid in both cases of
    mutual exclusiveness and of non-mutual exclusiveness:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 如果事件不是互斥的并且可以同时发生，请使用以下一般加法公式，这在互斥和非互斥的情况下都是有效的：
- en: '*P(outcome 1 OR outcome 2) = P(outcome 1) + P(outcome 2) P(outcome 1 AND outcome
    2)*'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '* P（结果1或结果2）= P（结果1）+ P（结果2）P（结果1和结果2）*'
- en: Using the naive Bayes algorithm for the classifiers challenge
  id: totrans-370
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯算法进行分类器挑战
- en: 'Now, let''s use the naive Bayes algorithm to solve the classifiers challenge:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用朴素贝叶斯算法来解决分类器挑战：
- en: 'First, we import the `GaussianNB()` function and use it to train the model:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入`GaussianNB（）`函数并用它来训练模型：
- en: '[PRE20]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, let''s use the trained model to predict the results. We will use it to
    predict the labels for our test partition, which is `X_test`:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用训练好的模型来预测结果。我们将用它来预测我们的测试分区`X_test`的标签：
- en: '[PRE21]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, let''s print the confusion matrix:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们打印混淆矩阵：
- en: '![](assets/61ad873a-a502-41be-8d3b-433d21072c96.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/61ad873a-a502-41be-8d3b-433d21072c96.png)'
- en: 'Now, let''s print the performance matrices to quantify the quality of our trained
    model:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们打印性能矩阵来量化我们训练模型的质量：
- en: '[PRE22]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Which gives the output as:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](assets/7cc3ecd6-99b2-426d-9e47-d434e60e3d13.png)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7cc3ecd6-99b2-426d-9e47-d434e60e3d13.png)'
- en: For classification algorithms, the winner is...
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对于分类算法，获胜者是...
- en: 'Let''s look at the performance metrics of the various algorithms we have presented.
    This is summarized in the following table:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下我们提出的各种算法的性能指标。这在下表中总结如下：
- en: '| **Algorithm** | **Accuracy** | **Recall** | **Precision** |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| **算法** | **准确度** | **召回率** | **精确度** |'
- en: '| Decision tree | 0.94 | 0.93 | 0.88 |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 决策树 | 0.94 | 0.93 | 0.88 |'
- en: '| XGBoost | 0.93 | 0.90 | 0.87 |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| XGBoost | 0.93 | 0.90 | 0.87 |'
- en: '| Random forest | 0.93 | 0.90 | 0.87 |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | 0.93 | 0.90 | 0.87 |'
- en: '| Logistic regression | 0.91 | 0.81 | 0.89 |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑回归 | 0.91 | 0.81 | 0.89 |'
- en: '| SVM | 0.89 | 0.71 | 0.92 |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 支持向量机 | 0.89 | 0.71 | 0.92 |'
- en: '| Naive Bayes | 0.92 | 0.81 | 0.92 |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| 朴素贝叶斯 | 0.92 | 0.81 | 0.92 |'
- en: Looking at the preceding table, we can observe that the decision tree classifier
    performs the best in terms of accuracy and recall. If we are looking for precision,
    then there is a tie between SVM and naive Bayes, so either one will work for us.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的表中可以看出，决策树分类器在准确性和召回率方面表现最佳。如果我们寻求精确度，那么支持向量机和朴素贝叶斯之间存在平局，因此任何一个都适用于我们。
- en: Understanding regression algorithms
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解回归算法
- en: The supervised machine learning model uses one of the regression algorithms
    if the target variable is a continuous variable. In this case, the machine learning
    model is called a regressor.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习模型使用回归算法之一，如果目标变量是连续变量。在这种情况下，机器学习模型被称为回归器。
- en: In this section, we will present various algorithms that can be used to train
    a supervised machine learning regression model—or simply, regressors. Before we
    go into the details of the algorithms, let's first create a challenge for these
    algorithms to test their performance, abilities, and effectiveness on.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍各种可用于训练监督机器学习回归模型的算法，或者简单地说，回归器。在我们深入了解算法的细节之前，让我们首先为这些算法创建一个挑战，以测试它们的性能、能力和有效性。
- en: Presenting the regressors challenge
  id: totrans-395
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 呈现回归器挑战
- en: 'Similar to the approach that we used with the classification algorithms, we
    will first present a problem to be solved as a challenge for all regression algorithms.
    We will call this common problem as the regressors challenge. Then, we will use
    three different regression algorithms to address the challenge. This approach
    of using a common challenge for different regression algorithms has two benefits:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 与分类算法使用的方法类似，我们将首先提出一个问题，作为所有回归算法的挑战来解决。我们将把这个共同的问题称为回归器挑战。然后，我们将使用三种不同的回归算法来解决这个挑战。使用一个共同的挑战来测试不同的回归算法有两个好处：
- en: We can prepare the data once and used the prepared data on all three regression
    algorithms.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以准备一次数据，然后在所有三个回归算法上使用准备好的数据。
- en: We can compare the performance of three regression algorithms in a meaningful
    way as we will use them to solve the same problem.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以以有意义的方式比较三种回归算法的性能，因为我们将使用它们来解决同一个问题。
- en: Let's look at the problem statement of the challenge.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下挑战的问题陈述。
- en: The problem statement of the regressors challenge
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归器挑战的问题陈述
- en: Predicting the mileage of different vehicles is important these days. An efficient
    vehicle is good for the environment and is also cost-effective. The mileage can
    be estimated from the power of the engine and the characteristics of the vehicle.
    Let's create a challenge for regressors to train a model that can predict the
    **Miles Per Gallon** (**MPG**) of a vehicle based on its characteristics.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 预测不同车辆的里程数在当今是很重要的。高效的车辆对环境有益，也具有成本效益。里程数可以根据发动机功率和车辆特性来估算。让我们为回归器创建一个挑战，训练一个能够根据车辆特性预测车辆的**每加仑英里数**（**MPG**）的模型。
- en: Let's look at the historical dataset that we will use to train the regressors.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们将用来训练回归器的历史数据集。
- en: Exploring the historical dataset
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索历史数据集
- en: 'The following are the features of the historical dataset data that we have:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们拥有的历史数据集数据的特征：
- en: '| **Name** | **Type** | **Description** |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **类型** | **描述** |'
- en: '| `NAME` | Category | Identifies a particular vehicle |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| `名称` | 类别 | 标识特定车辆 |'
- en: '| `CYLINDERS` | Continuous | The number of cylinders (between 4 and 8) |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| `CYLINDERS` | 连续 | 气缸数量（4至8之间）|'
- en: '| `DISPLACEMENT` | Continuous | The displacement of the engine in cubic.inches
    |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| `DISPLACEMENT` | 连续 | 发动机排量（立方英寸）|'
- en: '| `HORSEPOWER` | Continuous | The horsepower of the engine |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| `HORSEPOWER` | 连续 | 发动机马力 |'
- en: '| `ACCELERATION` | Continuous | The time it takes to accelerate from 0 to 60
    mph (in seconds) |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| `ACCELERATION` | 连续 | 从0到60英里/小时的加速时间（秒）|'
- en: The target variable for this problem is a continuous variable, `MPG`, that specifies
    the mpg for each of the vehicles.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的目标变量是一个连续变量，`MPG`，它指定了每辆车的英里数。
- en: Let's first design the data processing pipeline for this problem.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先为这个问题设计数据处理管道。
- en: Feature engineering using a data processing pipeline
  id: totrans-413
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用数据处理管道进行特征工程
- en: 'Let''s see how we can design a reusable processing pipeline to address the
    regressors challenge. As mentioned, we will prepare the data once and then use
    it in all the regression algorithms. Let''s follow these steps:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何设计一个可重复使用的处理管道来解决回归器挑战。如前所述，我们将一次准备数据，然后在所有回归算法中使用它。让我们按照以下步骤进行：
- en: 'We start by importing the dataset, as follows:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入数据集，如下所示：
- en: '[PRE23]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let''s now preview the dataset:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们预览数据集：
- en: '[PRE24]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This is how the dataset will look:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集将如下所示：
- en: '![](assets/c62f1a01-274e-4d93-b005-cd688ca4d630.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c62f1a01-274e-4d93-b005-cd688ca4d630.png)'
- en: 'Now, let''s proceed on to feature selection. Let''s drop the `NAME` column
    as it is only an identifier that is needed for cars. Columns that are used to
    identify the rows in our dataset are not relevant for training the model. Let''s
    drop this column:'
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们继续进行特征选择。让我们删除 `NAME` 列，因为它只是一个用于汽车的标识符。用于识别数据集中行的列对于训练模型是不相关的。让我们删除这一列：
- en: '[PRE25]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s convert all of the input variables and impute all the null values:'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们转换所有的输入变量并填充所有的空值：
- en: '[PRE26]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Imputation improves the quality of the data and prepares it to be used to train
    the model. Now, let''s see the final step:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 填充提高了数据的质量，并准备好用于训练模型。现在，让我们看最后一步：
- en: 'Let''s divide the data into testing and training partitions:'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据分成测试和训练分区：
- en: '[PRE27]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This has created the following four data structures:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了以下四个数据结构：
- en: '`X_train`: A data structure containing the features of the training data'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_train`：包含训练数据的特征的数据结构'
- en: '`X_test`: A data structure containing the features of the training test'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_test`：包含训练测试的特征的数据结构'
- en: '`y_train`: A vector containing the values of the label in the training dataset'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_train`：包含训练数据集中标签的值的向量'
- en: '`y_test`: A vector containing the values of the label in the testing dataset'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_test`：包含测试数据集中标签的值的向量'
- en: Now, let's use the prepared data on three different regressors so that we can
    compare their performance.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用准备好的数据在三个不同的回归器上，以便比较它们的性能。
- en: Linear regression
  id: totrans-434
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归
- en: Of all the supervised machine learning techniques, the linear regression algorithm
    is the easiest one to understand. We will first look at simple linear regression
    and then we will expand the concept to multiple linear regression.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有监督学习技术中，线性回归算法是最容易理解的。我们首先看一下简单线性回归，然后将概念扩展到多元线性回归。
- en: Simple linear regression
  id: totrans-436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单线性回归
- en: 'In its simplest form, linear regression formulates the relationship between
    a single continuous independent variable and a single continuous independent variable.
    A (simple) regression is used to show the extent that changes in a dependent variable
    (shown on the *y*-axis) can be attributed to changes in an explanatory variable
    (shown on the *x*-axis). It can be represented as follows:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最简单的形式中，线性回归阐述了单个连续自变量和单个连续自变量之间的关系。回归用于显示因变量（显示在 *y* 轴上）的变化程度可以归因于解释变量（显示在
    *x* 轴上）的变化程度。它可以表示如下：
- en: '![](assets/a1ca60f3-867b-410e-b01f-f8f00c083695.png)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a1ca60f3-867b-410e-b01f-f8f00c083695.png)'
- en: 'This formula can be explained as follows:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式可以解释如下：
- en: '*y* is the dependent variable.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y* 是因变量。'
- en: '*X* is the independent variable.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X* 是自变量。'
- en: '![](assets/4dc02d52-61ac-4dc5-ade3-3868a299cd92.png) is the slope that indicates
    how much the line rises for each increase in *X*.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](assets/4dc02d52-61ac-4dc5-ade3-3868a299cd92.png) 是斜率，表示每增加一个 *X*，线就上升多少。'
- en: '*α* is the intercept that indicates the value of *y* when *X* = 0.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*α* 是截距，表示 *X* = 0 时 *y* 的值。'
- en: 'Some examples of relationships between a single continuous dependent variable
    and a single continuous independent variable are as follows:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 单个连续因变量和单个连续自变量之间关系的一些例子如下：
- en: A person's weight and their calories intake
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个人的体重和他们的卡路里摄入量
- en: The price of a house and its area in square feet in a particular neighborhood
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特定社区房屋价格和面积
- en: The humidity in the air and the likelihood of rain
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空气中的湿度和下雨的可能性
- en: For linear regression, both the input (independent) variable and the target
    (dependent) variable must be numeric. The best relationship is found by minimizing
    the sum of the squares of the vertical distances of each point from a line drawn
    through all the points. It is assumed that the relationship is linear between
    the predictor variable and the target variable. For example, the more money invested
    in research and development, the higher the sales.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归，输入（自变量）和目标（因变量）变量都必须是数值型的。最佳关系是通过最小化每个点到通过所有点的线的垂直距离的平方和来找到的。假设预测变量和目标变量之间是线性关系。例如，投入研发的资金越多，销售额就越高。
- en: 'Let''s look at a specific example. Let''s try to formulate the relationship
    between marketing expenditures and sales for a particular product. They are found
    to be directly relational to each other. The marketing expenditures and sales
    are drawn on a two-dimensional graph and are shown as blue diamonds. The relationship
    can best be approximated by drawing a straight line, as in the following graph:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个具体的例子。让我们尝试阐明特定产品的营销支出和销售之间的关系。它们被发现直接相关。营销支出和销售在二维图上绘制，并显示为蓝色的钻石。这种关系最好通过绘制一条直线来近似，如下图所示：
- en: '![](assets/4308ca96-fec7-4de9-96f0-f700a67e5f77.png)'
  id: totrans-450
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4308ca96-fec7-4de9-96f0-f700a67e5f77.png)'
- en: Once the linear line is drawn, we can see the mathematical relationship between
    the marketing expenditure and sales.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦画出线性线，我们就可以看到营销支出和销售之间的数学关系。
- en: Evaluating the regressors
  id: totrans-452
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估回归器
- en: 'The linear line that we drew is an approximation of the relationship between
    the dependent and independent variables. Even the best line will have some deviation
    from the actual values, as shown:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 我们画的线性线是因变量和自变量之间关系的近似值。即使最佳线也会与实际值有一些偏差，如下所示：
- en: '![](assets/71d38f55-1568-4a86-ba02-4681a035c983.png)'
  id: totrans-454
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/71d38f55-1568-4a86-ba02-4681a035c983.png)'
- en: 'A typical way of quantifying the performance of linear regression models is
    by using **Root Mean Square Error** (**RMSE**). This calculates the standard deviation
    of the errors made by the trained model mathematically. For a certain example
    in the training dataset, the `loss` function is calculated as follows:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 评估线性回归模型性能的一种典型方法是使用**均方根误差**（**RMSE**）。这通过数学计算训练模型产生的误差的标准偏差。对于训练数据集中的某个示例，`loss`
    函数计算如下：
- en: Loss (ý^((i)), y^((i))) = 1/2(ý^((i)-) y^((i)))²
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 损失（ý^((i)), y^((i))) = 1/2(ý^((i)-) y^((i)))²
- en: 'This leads to the following `cost` function, which minimizes the loss of all
    of the examples in the training set:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下`cost`函数，最小化训练集中所有示例的损失：
- en: '![](assets/25cd8116-2626-4182-a7c5-fb22681dd6b4.png)'
  id: totrans-458
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/25cd8116-2626-4182-a7c5-fb22681dd6b4.png)'
- en: Let's try to interpret RMSE. If RMSE is $50 for our example model that predicts
    the price of a product, this means that around 68.2% of the predictions will fall
    within $50 of the true value (that is, *α*). It also means that 95% of the predictions
    will fall within $100 (that is, 2*α*) of the actual value. Finally, 99.7% of the
    predictions will fall within $150 of the actual value.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试解释RMSE。如果我们的示例模型的RMSE为$50，这意味着大约68.2%的预测值将在真实值（即*α*）的$50范围内。这也意味着95%的预测值将在实际值的$100（即2*α*）范围内。最后，99.7%的预测值将在实际值的$150范围内。
- en: Multiple regression
  id: totrans-460
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多元回归
- en: The fact is that most real-world analyses have more than one independent variable.  Multiple
    regression is an extension of simple linear regression. The key difference is
    that there are additional beta coefficients for the additional predictor variables.
    When training a model, the goal is to find the beta coefficients that minimize
    the errors of the linear equation. Let's try to mathematically formulate the relationship
    between the dependent variable and the set of independent variables (features).
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，大多数现实世界的分析都有多个自变量。多元回归是简单线性回归的扩展。关键区别在于额外的预测变量有额外的beta系数。在训练模型时，目标是找到最小化线性方程误差的beta系数。让我们尝试数学上阐述因变量和一组自变量（特征）之间的关系。
- en: 'Similar to a simple linear equation, the dependent variable, *y*, is quantified
    as the sum of an intercept term plus the product of the *β* coefficients multiplied
    by the *x* value for each of the *i* features:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 与简单线性方程类似，因变量*y*被量化为截距项的总和，加上*β*系数乘以每个*i*特征的*x*值：
- en: y = α + β  [1]  x  [1]  + β  [2]  x 2 +...+ β  [i]  x  [i]  + ε
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: y = α + β  [1]  x  [1]  + β  [2]  x 2 +...+ β  [i]  x  [i]  + ε
- en: The error is represented by *ε* and indicates that the predictions are not perfect.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 误差用*ε*表示，表明预测并不完美。
- en: The *β* coefficients allow each feature to have a separate estimated effect
    on the value of *y* because of  *y* changes by an amount of *β  [i]*  for each
    unit increase in *x*[*i*.] Moreover, the intercept (*α*) indicates the expected
    value of *y* when the independent variables are all 0.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '*β*系数允许每个特征对*y*的值有单独的估计影响，因为*y*每增加一个单位的*x*[*i*]，*y*的变化量为*β  [i]*。此外，截距（*α*）表示当独立变量都为0时*y*的期望值。'
- en: Note that all the variables in the preceding equation can be represented by
    a bunch of vectors. The target and predictor variables are now vectors with a
    row and the regression coefficients, *β*, and errors, *ε*, are also vectors.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前述方程中的所有变量都可以用一堆向量表示。目标和预测变量现在是带有行的向量，而回归系数*β*和误差*ε*也是向量。
- en: Using the linear regression algorithm for the regressors challenge
  id: totrans-467
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线性回归算法进行回归挑战
- en: 'Now, let''s train the model using the training portion of the dataset:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用数据集的训练部分来训练模型：
- en: 'Let''s start by importing the linear regression package:'
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入线性回归包开始：
- en: '[PRE28]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Then, let''s instantiate the linear regression model and train it using the
    training dataset:'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，让我们实例化线性回归模型，并使用训练数据集对其进行训练：
- en: '[PRE29]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, let''s predict the results using the test portion of the dataset:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用数据集的测试部分来预测结果：
- en: '[PRE30]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output generated by running the preceding code will generate the following:'
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行上述代码生成的输出将生成以下内容：
- en: '![](assets/10b80cc4-475a-4fc7-9c53-ab9cad02c6e7.png)'
  id: totrans-476
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/10b80cc4-475a-4fc7-9c53-ab9cad02c6e7.png)'
- en: As discussed in the preceding section, RMSE is the standard deviation of the
    error. It indicates that 68.2% of predictions will fall within `4.36` of the value
    of the target variable.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节所讨论的，RMSE是误差的标准差。它表明68.2%的预测值将在目标变量值的`4.36`范围内。
- en: When is linear regression used?
  id: totrans-478
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用线性回归？
- en: 'Linear regression is used to solve many real-world problems, including the
    following:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归用于解决许多现实世界的问题，包括以下内容：
- en: Sales forecasting
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 销售预测
- en: Predicting optimum product prices
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测最佳产品价格
- en: Quantifying the causal relationship between an event and the response, such
    as in clinical drug trials, engineering safety tests, or marketing research
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量化事件和响应之间的因果关系，例如临床药物试验、工程安全测试或市场研究
- en: Identifying patterns that can be used to forecast future behavior, given known
    criteria—for example, predicting insurance claims, natural disaster damage, election
    results, and crime rates
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别可用于预测未来行为的模式，给定已知条件，例如预测保险索赔、自然灾害损失、选举结果和犯罪率
- en: The weaknesses of linear regression
  id: totrans-484
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归的弱点
- en: 'The weaknesses of linear regression are as follows:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的弱点如下：
- en: It only works with numerical features.
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它只适用于数值特征。
- en: Categorical data needs to be preprocessed.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类数据需要进行预处理。
- en: It does not cope well with missing data.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它无法很好地处理缺失数据。
- en: It makes assumptions about the data.
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它对数据做出假设。
- en: The regression tree algorithm
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归树算法
- en: The regression tree algorithm is similar to the classification tree algorithm,
    except the target variable is a continuous variable, not a category variable.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 回归树算法类似于分类树算法，只是目标变量是连续变量，而不是类别变量。
- en: Using the regression tree algorithm for the regressors challenge
  id: totrans-492
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回归树算法进行回归挑战
- en: 'In this section, we will see how a regression tree algorithm can be used for
    the regressors challenge:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何使用回归树算法进行回归挑战：
- en: 'First, we train the model using a regression tree algorithm:'
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们使用回归树算法训练模型：
- en: '![](assets/2e89f7e5-0fd7-4b78-82ee-d60ba4e2b15d.png)'
  id: totrans-495
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2e89f7e5-0fd7-4b78-82ee-d60ba4e2b15d.png)'
- en: 'Once the regression tree model is trained, we use the trained model to predict
    the values:'
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦回归树模型训练完成，我们就可以使用训练好的模型来预测值：
- en: '[PRE31]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then, we calculate RMSE to quantify the performance of the model:'
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们计算RMSE来量化模型的性能：
- en: '[PRE32]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We get the following output:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](assets/c5716e34-aa3b-4b39-b5b2-88b8ab4419c0.png)'
  id: totrans-501
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c5716e34-aa3b-4b39-b5b2-88b8ab4419c0.png)'
- en: The gradient boost regression algorithm
  id: totrans-502
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升回归算法
- en: Let's now look at the gradient boost regression algorithm. It uses an ensemble
    of decision trees in an effort to better formulate the underlying patterns in
    data.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看梯度提升回归算法。它使用一组决策树来更好地表达数据中的潜在模式。
- en: Using gradient boost regression algorithm for the regressors challenge
  id: totrans-504
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用梯度提升回归算法来解决回归问题
- en: 'In this section, we will see how we can use the gradient boost regression algorithm
    for the regressors challenge:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将看到如何使用梯度提升回归算法来解决回归问题：
- en: 'First, we train the model using the gradient boost regression algorithm:'
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们使用梯度提升回归算法来训练模型：
- en: '![](assets/c59155c9-6344-4272-b33e-826d814ed78f.png)'
  id: totrans-507
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c59155c9-6344-4272-b33e-826d814ed78f.png)'
- en: 'Once the gradient regression algorithm model is trained, we use it to predict
    the values:'
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦梯度回归算法模型被训练，我们就可以用它来预测数值：
- en: '[PRE33]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Finally, we calculate RMSE to quantify the performance of the model:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们计算RMSE来量化模型的性能：
- en: '[PRE34]'
  id: totrans-511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Running this will give us the output value, as follows:'
  id: totrans-512
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行这个将给我们输出值，如下所示：
- en: '![](assets/bd5c2be4-d453-4b08-90be-dbe55b9e1dc9.png)'
  id: totrans-513
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bd5c2be4-d453-4b08-90be-dbe55b9e1dc9.png)'
- en: For regression algorithms, the winner is...
  id: totrans-514
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对于回归算法，获胜者是...
- en: 'Let''s look at the performance of the three regression algorithms that we used
    on the same data and exactly the same use case:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们在相同数据和完全相同用例上使用的三种回归算法的表现：
- en: '| **Algorithm** | **RMSE** |'
  id: totrans-516
  prefs: []
  type: TYPE_TB
  zh: '|**算法**|**RMSE**|'
- en: '| Linear regression | 4.36214129677179 |'
  id: totrans-517
  prefs: []
  type: TYPE_TB
  zh: '|线性回归|4.36214129677179|'
- en: '| Regression tree | 5.2771702288377 |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
  zh: '|回归树|5.2771702288377|'
- en: '| Gradient boost regression | 4.034836373089085 |'
  id: totrans-519
  prefs: []
  type: TYPE_TB
  zh: '|梯度提升回归|4.034836373089085|'
- en: Looking at the performance of all the regression algorithms, it is obvious that
    the performance of gradient boost regression is the best as it has the lowest
    RMSE. This is followed by linear regression. The regression tree algorithm performed
    the worst for this problem.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 从所有回归算法的表现来看，很明显梯度提升回归的表现最好，因为它具有最低的RMSE。其次是线性回归。对于这个问题，回归树算法的表现最差。
- en: Practical example – how to predict the weather
  id: totrans-521
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际例子 - 如何预测天气
- en: Let's see how we can use the concepts developed in this chapter to predict the
    weather. Let's assume that we want to predict whether it will rain tomorrow based
    on the data collected over a year for a particular city.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用本章中开发的概念来预测天气。假设我们想根据一年内针对特定城市收集的数据来预测明天是否会下雨。
- en: 'The data available to train this model is in the CSV file called `weather.csv`:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练该模型的数据在名为`weather.csv`的CSV文件中：
- en: 'Let''s import the data as a pandas data frame:'
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将数据导入为一个pandas数据框：
- en: '[PRE35]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s look at the columns of the data frame:'
  id: totrans-526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来看看数据框的列：
- en: '![](assets/cc8c37ff-f4b0-42ab-8a02-2d6901bbd040.png)'
  id: totrans-527
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/cc8c37ff-f4b0-42ab-8a02-2d6901bbd040.png)'
- en: 'Next, let''s look at the header of the first 13 columns of the `weather.csv`
    data:'
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们来看一下`weather.csv`数据的前13列的标题：
- en: '![](assets/5c5f2025-72f7-413f-b7a2-42b3fcfa249b.png)'
  id: totrans-529
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5c5f2025-72f7-413f-b7a2-42b3fcfa249b.png)'
- en: 'Now, let''s look at the last 10 columns of the `weather.csv` data:'
  id: totrans-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下`weather.csv`数据的最后10列：
- en: '![](assets/825cb777-bb57-4caf-ab05-15d8ab625241.png)'
  id: totrans-531
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/825cb777-bb57-4caf-ab05-15d8ab625241.png)'
- en: 'Let''s use `x` to represent the input features. We will drop the `Date` field
    for the feature list as it is not useful in the context of predictions. We will
    also drop the `RainTomorrow` label:'
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们用`x`来代表输入特征。我们将在特征列表中删除`Date`字段，因为在预测的情境下它没有用处。我们还将删除`RainTomorrow`标签：
- en: '[PRE36]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let''s use `y` to represent the label:'
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们用`y`来代表标签：
- en: '[PRE37]'
  id: totrans-535
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, let''s divide the data into `train_test_split`:'
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将数据分成`train_test_split`：
- en: '[PRE38]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As the label is a binary variable, we are training a classifier. So, logistic
    regression will be a good choice here. First, let''s instantiate the logistic
    regression model:'
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于标签是一个二元变量，我们正在训练一个分类器。因此，在这里逻辑回归将是一个不错的选择。首先，让我们实例化逻辑回归模型：
- en: '[PRE39]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, we can use `train_x` and `test_x` to train the model:'
  id: totrans-540
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`train_x`和`test_x`来训练模型：
- en: '[PRE40]'
  id: totrans-541
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Once the model is trained, let''s use it for predictions:'
  id: totrans-542
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型被训练，让我们用它进行预测：
- en: '[PRE41]'
  id: totrans-543
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, let''s find the accuracy of our trained model:'
  id: totrans-544
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们找出我们训练模型的准确性：
- en: '![](assets/baa59ee9-e705-4a2c-9824-b92d37b0b333.png)'
  id: totrans-545
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/baa59ee9-e705-4a2c-9824-b92d37b0b333.png)'
- en: Now, this binary classifier can be used to predict whether it will rain tomorrow.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个二元分类器可以用来预测明天是否会下雨。
- en: Summary
  id: totrans-547
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we started by looking at the basics of supervised machine learning.
    Then, we looked at various classification algorithms  in more detail. Next, we
    looked at different methods to evaluate the performance of classifiers and studied
    various regression algorithms. We also looked at the different methods that can
    be used to evaluate the performance of the algorithms that we studied.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先了解了监督式机器学习的基础知识。然后，我们更详细地了解了各种分类算法。接下来，我们研究了评估分类器性能的不同方法，并研究了各种回归算法。我们还研究了用于评估我们研究的算法性能的不同方法。
- en: In the next chapter, we will look at neural networks and deep learning algorithms.
    We will look at the methods used to train a neural network and we will also look
    at the various tools and frameworks available for evaluating and deploying a neural
    network.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究神经网络和深度学习算法。我们将研究训练神经网络所使用的方法，还将研究用于评估和部署神经网络的各种工具和框架。
