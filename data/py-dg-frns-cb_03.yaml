- en: A Deep Dive into Mobile Forensic Recipes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入移动取证食谱
- en: 'The following recipes are covered in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下食谱：
- en: Parsing PLIST files
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析PLIST文件
- en: Handling SQLite databases
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理SQLite数据库
- en: Identifying gaps in SQLite databases
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别SQLite数据库中的间隙
- en: Processing iTunes backups
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理iTunes备份
- en: Putting Wi-Fi on the map
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Wi-Fi标记在地图上
- en: Digging deep to recover messages
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入挖掘以恢复消息
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Perhaps it is becoming a bit of a cliché, but it remains true that as technology
    evolves it continues to become more integrated with our lives. Never has this
    been so apparent as with the development of the first smartphone. These precious
    devices seemingly never leave the possession of their owners and often receive
    more interaction than human companions. It should be no surprise then that a smartphone
    can supply investigators with lots of insight into their owner. For example, messages
    may provide insight into the state of mind of the owner or knowledge of particular
    facts. They may even shed light on previously unknown information. Location history
    is another useful artifact we can extract from these devices and can be helpful
    to validate an individual's alibi. We will learn to extract this information and
    more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 也许这已经成为陈词滥调，但事实仍然如此，随着技术的发展，它继续与我们的生活更加紧密地融合。这从未如此明显，如第一部智能手机的发展。这些宝贵的设备似乎永远不会离开其所有者，并且通常比人类伴侣更多地接触。因此，毫不奇怪，智能手机可以为调查人员提供大量关于其所有者的见解。例如，消息可能提供有关所有者心态或特定事实的见解。它们甚至可能揭示以前未知的信息。位置历史是我们可以从这些设备中提取的另一个有用的证据，可以帮助验证个人的不在场证明。我们将学习提取这些信息以及更多内容。
- en: 'A common source of evidentiary value on smartphones are SQLite databases. These
    databases serve as the de facto storage for applications in most smartphone operating
    systems. For this reason, many scripts in this chapter will focus on teasing out
    data and drawing inferences from these databases. In addition to that, we will
    also learn how to process PLIST files, commonly used with Apple operating systems,
    including iOS, and extract relevant data. The scripts in this chapter focus on
    solving specific problems and are ordered by complexity:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 智能手机上证据价值的常见来源是SQLite数据库。这些数据库在大多数智能手机操作系统中作为应用程序的事实存储。因此，本章中的许多脚本将专注于从这些数据库中提取数据并推断。除此之外，我们还将学习如何处理PLIST文件，这些文件通常与苹果操作系统一起使用，包括iOS，并提取相关数据。本章中的脚本专注于解决特定问题，并按复杂性排序：
- en: Learning to process XML and binary PLIST files
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习处理XML和二进制PLIST文件
- en: Using Python to interact with SQLite databases
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python与SQLite数据库交互
- en: Identifying missing gaps in SQLite databases
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别SQLite数据库中的缺失间隙
- en: Converting an iOS backup into a human-readable format
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将iOS备份转换为人类可读格式
- en: Processing output from Cellebrite and performing Wi-Fi MAC address geolocation
    lookups with WiGLE
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理Cellebrite的输出并执行Wi-Fi MAC地址地理位置查找
- en: Identifying potentially intact deleted content from SQLite databases
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从SQLite数据库中识别潜在完整的已删除内容
- en: Visit [www.packtpub.com/books/content/support](http://www.packtpub.com/books/content/support)
    to download the code bundle for this chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 访问[www.packtpub.com/books/content/support](http://www.packtpub.com/books/content/support)下载本章的代码包。
- en: Parsing PLIST files
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析PLIST文件
- en: 'Recipe Difficulty: Easy'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 食谱难度：简单
- en: 'Python Version: 2.7 or 3.5'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Python版本：2.7或3.5
- en: 'Operating System: Any'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统：任何
- en: 'This recipe will process the `Info.plist` file present in every iOS backup
    and extract device-specific information such as the device name, IMEI, serial
    number, product make, model, and iOS version, and the last backup date. Property
    lists, or PLISTs, come in two different formats: XML or binary. Typically, when
    dealing with binary PLISTs, one will need to use the plutil utility on a macOS
    platform to convert it to a readable XML format. However, we will introduce a
    Python library that handles both types readily and easily. Once we extract the
    relevant data elements from the `Info.plist` file, we will print this data to
    the console.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱将处理每个iOS备份中存在的`Info.plist`文件，并提取设备特定信息，如设备名称、IMEI、序列号、产品制造、型号和iOS版本，以及最后备份日期。属性列表，或PLIST，有两种不同的格式：XML或二进制。通常，在处理二进制PLIST时，需要在macOS平台上使用plutil实用程序将其转换为可读的XML格式。然而，我们将介绍一个处理两种类型的Python库，即可轻松处理。一旦我们从`Info.plist`文件中提取相关数据元素，我们将把这些数据打印到控制台上。
- en: Getting started
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: This recipe requires the installation of the third-party library `biplist`.
    All other libraries used in this script are present in Python's standard library.
    The `biplist` module provides a means of processing both XML and binary PLIST
    files.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此食谱需要安装第三方库`biplist`。此脚本中使用的所有其他库都包含在Python的标准库中。`biplist`模块提供了处理XML和二进制PLIST文件的方法。
- en: To learn more about the `biplist` library, visit [https://github.com/wooster/biplist](https://github.com/wooster/biplist).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`biplist`库的信息，请访问[https://github.com/wooster/biplist](https://github.com/wooster/biplist)。
- en: Python has a built-in PLIST library, `plistlib`; however, this library was found
    to not support binary PLIST files as extensively as `biplist` does.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Python有一个内置的PLIST库，`plistlib`；然而，发现这个库不像`biplist`那样广泛支持二进制PLIST文件。
- en: To learn more about the `plistlib` library, visit [https://docs.python.org/3/library/plistlib.html](https://docs.python.org/3/library/plistlib.html).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`plistlib`库的信息，请访问[https://docs.python.org/3/library/plistlib.html](https://docs.python.org/3/library/plistlib.html)。
- en: 'Installing `biplist` can be accomplished using `pip`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pip`可以完成安装`biplist`：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Be sure to grab your own `Info.plist` file to process with this script. If you
    cannot find an `Info.plist` file, any PLIST file should be suitable. Our script
    is not so specific and should technically work with any PLIST file.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 确保获取自己的`Info.plist`文件以便使用此脚本进行处理。如果找不到`Info.plist`文件，任何PLIST文件都应该合适。我们的脚本并不那么具体，理论上应该适用于任何PLIST文件。
- en: How to do it...
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'We will employ the following steps to process the PLIST file:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采用以下步骤处理PLIST文件：
- en: Open the input PLIST file.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开输入的PLIST文件。
- en: Read PLIST data into a variable.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将PLIST数据读入变量。
- en: Print formatted PLIST data to the console.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将格式化的PLIST数据打印到控制台。
- en: How it works...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'First, we import the required libraries to handle argument parsing and processing
    PLISTs:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入所需的库来处理参数解析和处理PLIST文件：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This recipe''s command-line handler accepts one positional argument, `PLIST_FILE`,
    which represents the path to the PLIST file we will process:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该配方的命令行处理程序接受一个位置参数`PLIST_FILE`，表示我们将处理的PLIST文件的路径：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We use the `os.exists()` and `os.path.isfile()` functions to validate that
    the input file exists and is a file, as opposed to a directory. We do not perform
    any further validation on this file, such as confirming whether it is a PLIST
    file rather than a text file and instead rely on the `biplist` library (and common
    sense) to catch such errors. If the input file passes our tests, we call the `main()`
    function and pass it the PLIST file path:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`os.exists()`和`os.path.isfile()`函数来验证输入文件是否存在并且是一个文件，而不是一个目录。我们不对这个文件进行进一步的验证，比如确认它是一个PLIST文件而不是一个文本文件，而是依赖于`biplist`库（和常识）来捕捉这样的错误。如果输入文件通过了我们的测试，我们调用`main()`函数并将PLIST文件路径传递给它：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `main()` function is relatively straightforward and accomplishes the goal
    of reading the PLIST file and then printing the data to the console. First, we
    print an update to the console that we are attempting to open the file. Then,
    we use the `biplist.readPlist()` method to open and read the PLIST into our `plist_data`
    variable. If the PLIST is corrupt or otherwise inaccessible, `biplist` will raise
    an `InvalidPlistException` or `NotBinaryPlistException` error. We catch both of
    these in a `try` and `except` block and `exit` the script accordingly:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`main()`函数相对简单，实现了读取PLIST文件然后将数据打印到控制台的目标。首先，我们在控制台上打印一个更新，表示我们正在尝试打开文件。然后，我们使用`biplist.readPlist()`方法打开并读取PLIST到我们的`plist_data`变量中。如果PLIST文件损坏或无法访问，`biplist`会引发`InvalidPlistException`或`NotBinaryPlistException`错误。我们在`try`和`except`块中捕获这两种错误，并相应地`exit`脚本：'
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once we have successfully read in the PLIST data, we iterate through the keys
    in the resulting `plist_data` dictionary and print them to the console. Notice
    that we print all keys in the `Info.plist` file with the exception of the `Applications`
    and `iTunes Files` keys. Both of these keys contain a great deal of data that
    floods the console and therefore are not desirable for this type of output. We
    use the format method to help create legible console output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们成功读取了PLIST数据，我们遍历结果中的`plist_data`字典中的键，并将它们打印到控制台上。请注意，我们打印`Info.plist`文件中除了`Applications`和`iTunes
    Files`键之外的所有键。这两个键包含大量数据，会淹没控制台，因此不适合这种类型的输出。我们使用format方法来帮助创建可读的控制台输出：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Notice the additional formatting characters in the first curly brackets. We
    are specifying here to left-align the input string with a static width of 25 characters.
    As you can see in the following screenshot, this ensures the data is presented
    in an orderly and structured format:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意第一个花括号中的额外格式化字符。我们在这里指定左对齐输入字符串，并且宽度为25个字符。正如你在下面的截图中所看到的，这确保了数据以有序和结构化的格式呈现：
- en: '![](../images/00022.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00022.jpeg)'
- en: There's more…
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'This script can be further improved. We have provided a couple of recommendations
    here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本可以进一步改进。我们在这里提供了一些建议：
- en: Rather than printing data to the console, add a CSV function to write the data
    to a CSV file
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 而不是将数据打印到控制台，添加一个CSV函数将数据写入CSV文件
- en: Add support for processing a directory full of PLIST files
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加支持处理一个目录中的所有PLIST文件
- en: Handling SQLite databases
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理SQLite数据库
- en: 'Recipe Difficulty: Easy'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 配方难度：简单
- en: 'Python Version: 3.5'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Python版本：3.5
- en: 'Operating System: Any'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统：任何
- en: As discussed, SQLite databases serve as the primary data repository on mobile
    devices. Python has a built-in library, `sqlite3`, which can be used to interface
    with these databases. In this script, we will interact with the iPhone `sms.db`
    file and extract data from the `message` table. We will also use this script as
    an opportunity to introduce the `csv` library and write the message data to a
    spreadsheet.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，SQLite数据库是移动设备上的主要数据存储库。Python有一个内置的`sqlite3`库，可以用来与这些数据库进行交互。在这个脚本中，我们将与iPhone的`sms.db`文件交互，并从`message`表中提取数据。我们还将利用这个脚本的机会介绍`csv`库，并将消息数据写入电子表格。
- en: To learn more about the `sqlite3` library, visit [https://docs.python.org/3/library/sqlite3.html](https://docs.python.org/3/library/sqlite3.html).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`sqlite3`库的信息，请访问[https://docs.python.org/3/library/sqlite3.html](https://docs.python.org/3/library/sqlite3.html)。
- en: Getting started
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: All libraries used in this script are present in Python's standard library.
    For this script, make sure to have an `sms.db` file from which to query. With
    some minor modification, you can use this script with any database; however, we
    will specifically be talking about it with respect to the iPhone SMS database
    from an iOS 10.0.1 device.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本中使用的所有库都包含在Python的标准库中。对于这个脚本，请确保有一个`sms.db`文件可以进行查询。通过一些小的修改，你可以使用这个脚本与任何数据库；然而，我们将特别讨论它与iOS
    10.0.1设备的iPhone短信数据库相关。
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'The recipe follows these basic principles:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该配方遵循以下基本原则：
- en: Connect to the input database.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接到输入数据库。
- en: Query table PRAGMA to extract column names.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询表PRAGMA以提取列名。
- en: Fetch all table content.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取所有表内容。
- en: Write all table content to CSV.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有表内容写入CSV。
- en: How it works...
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'First, we import the required libraries to handle argument parsing, writing
    spreadsheets, and interacting with SQLite databases:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入所需的库来处理参数解析、写入电子表格和与SQLite数据库交互：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This recipe''s command-line handler accepts two positional arguments, `SQLITE_DATABASE`
    and `OUTPUT_CSV`, which represent the file paths for the input database and the
    desired CSV output, respectively:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 该配方的命令行处理程序接受两个位置参数`SQLITE_DATABASE`和`OUTPUT_CSV`，分别表示输入数据库和期望的CSV输出的文件路径：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we use the `os.dirname()` method to extract just the directory path of
    the output file. We do this to check if the output directory already exists. If
    it does not, we use the `os.makedirs()` method to create each directory in the
    output path that does not already exist. This avoids issues later on if we were
    to try to write the output CSV to a directory that does not exist:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`os.dirname()`方法仅提取输出文件的目录路径。我们这样做是为了检查输出目录是否已经存在。如果不存在，我们使用`os.makedirs()`方法创建输出路径中尚不存在的每个目录。这样可以避免以后尝试将输出CSV写入不存在的目录时出现问题：
- en: '[PRE8]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once we have verified that the output directory exists, we pass the supplied
    arguments to the `main()` function:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们验证了输出目录存在，我们将提供的参数传递给`main()`函数：
- en: '[PRE9]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `main()` function prints a status update for the user to the console and
    then checks if the input file exists and is a file. If it does not exist, we use
    the `sys.exit()` method to exit the script using a value greater than 0 to indicate
    the script exited due to an error:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`main()`函数向用户的控制台打印状态更新，然后检查输入文件是否存在且是否为文件。如果不存在，我们使用`sys.exit()`方法退出脚本，使用大于0的值指示脚本由于错误退出：'
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we use the `sqlite3.conn()` method to connect to the input database.
    It is important to note that the `sqlite3.conn()` method opens a database of the
    supplied name regardless of whether it exists or not. Therefore, it is vital to
    check that the file exists before trying to open a connection to it. Otherwise,
    we could create an empty database, which would likely cause issues in the script
    when we interact with it. Once we have a connection, we need to create a `Cursor`
    object to interact with the database:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`sqlite3.conn()`方法连接到输入数据库。重要的是要注意，`sqlite3.conn()`方法会打开所提供名称的数据库，无论它是否存在。因此，重要的是在尝试打开连接之前检查文件是否存在。否则，我们可能会创建一个空数据库，在与其交互时可能会导致脚本出现问题。一旦建立了连接，我们需要创建一个`Cursor`对象来与数据库交互：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can now perform queries against the database using the `Cursor` object''s
    `execute()` command. At this point, the strings we pass into the execute function
    are just standard SQLlite queries. For the most part, you can run any query that
    you normally would when interacting with an SQLite database. The results returned
    from a given command are stored in the `Cursor` object. We need to use the `fetchall()`
    method to dump the results into a variable we can manipulate:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`Cursor`对象的`execute()`命令对数据库执行查询。此时，我们传递给execute函数的字符串只是标准的SQLlite查询。在大多数情况下，您可以运行与与SQLite数据库交互时通常运行的任何查询。从给定命令返回的结果存储在`Cursor`对象中。我们需要使用`fetchall()`方法将结果转储到我们可以操作的变量中：
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `fetchall()` method returns a tuple of results. Each column''s name is
    stored in the first index of each tuple. By using list comprehension, we store
    the column names for the `message` table into a list. This comes into play later
    when we write the results of the data to a CSV file. After we obtain the column
    names for the `message` table, we directly query that table for all of its data
    and store it in the `message_data` variable:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`fetchall()`方法返回一组结果的元组。每个元组的第一个索引中存储了每列的名称。通过使用列表推导，我们将`message`表的列名存储到列表中。这在稍后将数据结果写入CSV文件时会发挥作用。在获取了`message`表的列名后，我们直接查询该表的所有数据，并将其存储在`message_data`变量中：'
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'With the data extracted, we print a status message to the console and pass
    the output CSV and the message table columns and data to the `write_csv()` method:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 提取数据后，我们向控制台打印状态消息，并将输出的CSV和消息表列和数据传递给`write_csv()`方法：
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You'll find that most of the scripts end with writing data to a CSV file. There
    are a few reasons for that. Writing CSVs in Python is very straightforward and
    can be accomplished in a few lines of code for most datasets. Additionally, having
    data in a spreadsheet allows one to sort and filter on columns to help summarize
    and understand large datasets.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您会发现大多数脚本最终都会将数据写入CSV文件。这样做有几个原因。在Python中编写CSV非常简单，对于大多数数据集，可以用几行代码完成。此外，将数据放入电子表格中可以根据列进行排序和过滤，以帮助总结和理解大型数据集。
- en: Before we begin to write to the CSV file, we use the `open()` method to create
    a file object and its alias, `csvfile`. The way in which you open this file changes
    depending on if you are using Python 2.x or Python 3.x. For Python 2.x, you open
    the file in `wb` mode and without the newline keyword argument. With Python 3.x,
    you instead open the file in `w` mode and with the newline keyword set to an empty
    string. Where possible the code is written for Python 3.x, so we use the latter.
    Failing to open the file object in this manner results in the output CSV file
    containing an empty row between each row that is written.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始写入CSV文件之前，我们使用`open()`方法创建文件对象及其别名`csvfile`。打开此文件的方式取决于您是否使用Python 2.x或Python
    3.x。对于Python 2.x，您以`wb`模式打开文件，而不使用newline关键字参数。对于Python 3.x，您可以以`w`模式打开文件，并将newline关键字设置为空字符串。在可能的情况下，代码是针对Python
    3.x编写的，因此我们使用后者。未以这种方式打开文件对象会导致输出的CSV文件在每行之间包含一个空行。
- en: 'After opening the file object, we pass it to the `csv.writer()` method. We
    can use the `writerow()` and `writerows()` methods from this object to write the
    column header list and the list of tuples, respectively. As an aside, we could
    iterate through each tuple in the `msgs` list and call `writerow()` for each tuple.
    The `writerows()` method eliminates the need for the unnecessary loop and is used
    here:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 打开文件对象后，我们将其传递给`csv.writer()`方法。我们可以使用该对象的`writerow()`和`writerows()`方法分别写入列标题列表和元组列表。顺便说一句，我们可以遍历`msgs`列表中的每个元组，并为每个元组调用`writerow()`。`writerows()`方法消除了不必要的循环，并在这里使用：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'When we run this script, we see the following console message. Within the CSV
    we can gather in-depth details about the messages sent and received, along with
    interesting metadata including dates, errors, the source, and so on:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行此脚本时，会看到以下控制台消息。在CSV中，我们可以收集有关发送和接收的消息的详细信息，以及包括日期、错误、来源等在内的有趣的元数据：
- en: '![](../images/00023.jpeg)![](../images/00024.jpeg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00023.jpeg)![](../images/00024.jpeg)'
- en: Identifying gaps in SQLite databases
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别 SQLite 数据库中的间隙
- en: 'Recipe Difficulty: Easy'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 食谱难度：简单
- en: 'Python Version: 2.7 or 3.5'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Python 版本：2.7 或 3.5
- en: 'Operating System: Any'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统：任意
- en: This recipe will demonstrate how to programmatically identify missing entries
    for a given table by using its primary key. This technique allows us to identify
    records that are no longer active in the database. We will use this to identify
    which and how many messages have been deleted from an iPhone SMS database. This,
    however, will work with any table that uses an auto-incrementing primary key.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱将演示如何通过编程方式使用主键来识别给定表中的缺失条目。这种技术允许我们识别数据库中不再有效的记录。我们将使用这个方法来识别从 iPhone 短信数据库中删除了哪些消息以及删除了多少条消息。然而，这也适用于使用自增主键的任何表。
- en: To learn more about SQLite tables and primary keys, visit [https://www.sqlite.org/lang_createtable.html](https://www.sqlite.org/lang_createtable.html).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 SQLite 表和主键的信息，请访问 [https://www.sqlite.org/lang_createtable.html](https://www.sqlite.org/lang_createtable.html)。
- en: One fundamental idea governing SQLite databases and their tables are primary
    keys. A primary key is typically a column that serves as a unique integer for
    a particular row in the table. A common implementation is the auto-incrementing
    primary key, starting typically at `1` for the first row, and incrementing by
    `1` for each successive row. When rows are removed from the table, the primary
    key does not change to account for that or reorder the table.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 管理 SQLite 数据库及其表的一个基本概念是主键。主键通常是表中特定行的唯一整数列。常见的实现是自增主键，通常从第一行开始为 `1`，每一行递增 `1`。当从表中删除行时，主键不会改变以适应或重新排序表。
- en: For example, if we had a database with 10 messages and deleted messages `4`
    through `6`, we would have a gap in the primary key column from `3` to `7`. With
    our understanding of auto-incrementing primary keys, we can make the inference
    that messages `4` through `6`, at one point present, are no longer active entries
    in the database. In this manner, we can quantify the number of messages no longer
    active in the database and the primary key value associated with them. We will
    use this in a later recipe, *Digging deep to recover messages*, to then go hunt
    for those entries in an effort to determine if they are intact and recoverable.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们有一个包含 10 条消息的数据库，并删除了消息 `4` 到 `6`，那么主键列中将会有一个从 `3` 到 `7` 的间隙。通过我们对自增主键的理解，我们可以推断消息
    `4` 到 `6` 曾经存在，但现在不再是数据库中的有效条目。通过这种方式，我们可以量化数据库中不再有效的消息数量以及与之相关的主键值。我们将在后续的食谱
    *深入挖掘以恢复消息* 中使用这个信息，然后去寻找这些条目，以确定它们是否完整且可恢复。
- en: Getting started
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: All libraries used in this script are present in Python's standard library.
    This recipe does require a database to run against. For this example, we will
    use the iPhone `sms.db` database.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本中使用的所有库都包含在 Python 的标准库中。这个食谱需要一个数据库来运行。在这个例子中，我们将使用 iPhone `sms.db` 数据库。
- en: How to do it...
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We will perform the following steps in this recipe:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将执行以下步骤：
- en: Connect to the input database.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接到输入数据库。
- en: Query table PRAGMA to identify a table's primary key(s).
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询表 PRAGMA 以识别表的主键。
- en: Fetch all primary key values.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取所有主键值。
- en: Calculate and display gaps in the table to the console.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算并在控制台上显示表中的间隙。
- en: How it works...
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'First, we import the required libraries to handle argument parsing and interacting
    with SQLite databases:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入所需的库来处理参数解析和与 SQLite 数据库交互：
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This recipe''s command-line handler accepts two positional arguments, `SQLITE_DATABASE`
    and `TABLE`, which represents the path of the input database and the name of the
    table to review, respectively. An optional argument, `column`, indicated by the
    dash, can be used to manually supply the primary key column if it is known:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱的命令行处理程序接受两个位置参数，`SQLITE_DATABASE` 和 `TABLE`，分别表示输入数据库的路径和要查看的表的名称。一个可选参数
    `column`，由破折号表示，可以用来手动提供主键列（如果已知）：
- en: '[PRE17]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If the optional column argument is supplied, we pass it to the `main()` function
    as a keyword argument along with the database and table name. Otherwise, we just
    pass the database and table name to the `main()` function without the `col` keyword
    argument:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提供了可选的列参数，我们将它作为关键字参数与数据库和表名一起传递给 `main()` 函数。否则，我们只将数据库和表名传递给 `main()` 函数，而不包括
    `col` 关键字参数：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `main()` function, like the previous recipe, first performs some validation
    that the input database exists and is a file. Because we are using keyword arguments
    with this function, we must indicate this with the `**kwargs` argument in the
    function definition. This argument serves as a dictionary that stores all provided
    keyword arguments. In this case, if the optional column argument were supplied,
    this dictionary would contain a `col` key/value pair:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`main()` 函数，与前一个食谱一样，首先执行一些验证，验证输入数据库是否存在且是一个文件。因为我们在这个函数中使用了关键字参数，所以我们必须在函数定义中使用
    `**kwargs` 参数来指示这一点。这个参数充当一个字典，存储所有提供的关键字参数。在这种情况下，如果提供了可选的列参数，这个字典将包含一个 `col`
    键值对：'
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After validating the input file, we use `sqlite3` to connect to this database
    and create the `Cursor` object we use to interact with it:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证输入文件后，我们使用 `sqlite3` 连接到这个数据库，并创建我们用来与之交互的 `Cursor` 对象：
- en: '[PRE20]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In order to identify the primary key for the desired table, we run the `pragma
    table_info` command with the table name inserted in parentheses. We use the `format()`
    method to dynamically insert the name of the table into the otherwise static string.
    After we store the command''s results in the `table_data` variable, we perform
    validation on the table name input. If the user supplied a table name that does
    not exist, we will have an empty list as the result. We check for this and exit
    the script if the table does not exist:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确定所需表的主键，我们使用带有插入括号的表名的`pragma table_info`命令。我们使用`format()`方法动态地将表的名称插入到否则静态的字符串中。在我们将命令的结果存储在`table_data`变量中后，我们对表名输入进行验证。如果用户提供了一个不存在的表名，我们将得到一个空列表作为结果。我们检查这一点，如果表不存在，就退出脚本。
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: At this point, we create an `if-else` statement for the remainder of the script,
    depending on whether the optional column argument was supplied by the user. If
    `col` is a key in the `kwargs` dictionary, we immediately call the `find_gaps()`
    function and pass it the `Cursor` object, `c`, the table name, and the user-specified
    primary key column name. Otherwise, we try to identify the primary key(s) in the
    `table_data` variable.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们为脚本的其余部分创建了一个`if-else`语句，具体取决于用户是否提供了可选的列参数。如果`col`是`kwargs`字典中的一个键，我们立即调用`find_gaps()`函数，并将`Cursor`对象`c`、表名和用户指定的主键列名传递给它。否则，我们尝试在`table_data`变量中识别主键。
- en: 'The command previously executed and stored in the `table_data` variable returns
    a tuple for each column in the given table. The last element of each tuple is
    a binary option between `1` or `0`, where `1` indicates that the column is a primary
    key. We iterate through each of the last elements in the returned tuples and,
    if they are equal to `1`, the column name, stored in index one of the tuple, is
    appended to the `potential_pks` list:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 先前在`table_data`变量中执行并存储的命令为给定表中的每一列返回一个元组。每个元组的最后一个元素是`1`或`0`之间的二进制选项，其中`1`表示该列是主键。我们遍历返回的元组中的每个最后一个元素，如果它们等于`1`，则将元组的索引一中存储的列名附加到`potential_pks`列表中。
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Once we have identified all primary keys, we check the list to determine if
    there are zero or more than one keys present. If either of these cases exists,
    we alert the user and exit the script. In these scenarios, the user would need
    to specify which column should be treated as the primary key column. If the list
    contains a single primary key, we pass the name of that column along with the
    database cursor and table name to the `find_gaps()` function:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了所有的主键，我们检查列表以确定是否存在零个或多个键。如果存在这些情况中的任何一种，我们会提醒用户并退出脚本。在这些情况下，用户需要指定哪一列应被视为主键列。如果列表包含单个主键，我们将该列的名称与数据库游标和表名一起传递给`find_gaps()`函数。
- en: '[PRE23]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `find_gaps()` method starts by displaying a message to the console, alerting
    the user of the current execution status of the script. We attempt the database
    query in a `try` and `except` block. If the user-specified column does not exist
    or was misspelled, we will receive an `OperationalError` from the `sqlite3` library.
    This is the last validation step of user-supplied arguments and will exit the
    script if the except block is triggered. If the query executes successfully, we
    fetch all of the data and store it in the `results` variable:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`find_gaps()`方法首先通过在控制台显示一条消息来提醒用户脚本的当前执行状态。我们尝试在`try`和`except`块中进行数据库查询。如果用户指定的列不存在或拼写错误，我们将从`sqlite3`库接收到`OperationalError`。这是用户提供的参数的最后验证步骤，如果触发了except块，脚本将退出。如果查询成功执行，我们获取所有数据并将其存储在`results`变量中。'
- en: '[PRE24]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We use list comprehension and the built-in `sorted()` function to create a list
    of sorted primary keys. The `results` list contains tuples with one element at
    index `0`, the primary key, which for the `sms.db` `message` table is the column
    named ROWID. With the sorted list of ROWIDs, we can quickly calculate the number
    of entries missing from the table. This would be the most recent ROWID minus the
    number of ROWIDs present in the list. If all entries were active in the database,
    this value would be zero.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用列表推导和内置的`sorted()`函数来创建排序后的主键列表。`results`列表包含索引`0`处的一个元素的元组，即主键，对于`sms.db`的`message`表来说，就是名为ROWID的列。有了排序后的ROWID列表，我们可以快速计算表中缺少的条目数。这将是最近的ROWID减去列表中存在的ROWID数。如果数据库中的所有条目都是活动的，这个值将为零。
- en: We are working under the assumption that the most recent ROWID is the actual
    most recent ROWID. It is possible that one could delete the last few entries and
    the recipe would only detect the most recent active entry as the highest ROWID.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设最近的ROWID是实际最近的ROWID。有可能删除最后几个条目，而配方只会将最近的活动条目检测为最高的ROWID。
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If we are not missing any values from the list, we print this fortuitous message
    to the console and exit with `0`, indicating a successful termination. On the
    other hand, if we are missing entries, we print that to the console along with
    the count of the missing entries:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果列表中没有缺少任何值，我们将这一幸运的消息打印到控制台，并以`0`退出，表示成功终止。另一方面，如果我们缺少条目，我们将其打印到控制台，并显示缺少条目的计数。
- en: '[PRE26]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To calculate the missing gaps, we generate a set of all ROWIDs between the
    first ROWID and the last using the `range()` method and then compare that against
    the sorted list that we have. The `difference()` function can be used with a set
    to return a new set with elements in the first set that are not present in the
    object in parentheses. We then print the identified gaps to the console, which
    completes the execution of the script:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算缺失的间隙，我们使用`range()`方法生成从第一个ROWID到最后一个ROWID的所有ROWIDs的集合，然后将其与我们拥有的排序列表进行比较。`difference()`函数可以与集合一起使用，返回一个新的集合，其中包含第一个集合中不在括号中的对象中的元素。然后我们将识别的间隙打印到控制台，这样脚本的执行就完成了。
- en: '[PRE27]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'An example of the output of this script may look like the following screenshot.
    Note how quickly the console can become cluttered based on the number of deleted
    messages. This, however, is not the intended end of this recipe. We will use the
    logic from this script in a more advanced recipe, *Digging deep to recover messages*,
    later in the chapter to identify and then attempt to locate potentially recoverable
    messages:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本的输出示例可能如下截图所示。请注意，控制台可以根据已删除消息的数量迅速变得混乱。然而，这并不是此脚本的预期结束。我们将在本章后面的更高级的食谱“深入挖掘以恢复消息”中使用此脚本的逻辑，来识别并尝试定位潜在可恢复的消息：
- en: '![](../images/00025.jpeg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00025.jpeg)'
- en: See also
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: For more on SQLite database structure and primary keys, refer to their extensive
    documentation at [https://www.sqlite.org/](https://www.sqlite.org/).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 有关SQLite数据库结构和主键的更多信息，请参阅其广泛的文档[https://www.sqlite.org/](https://www.sqlite.org/)。
- en: Processing iTunes backups
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理iTunes备份
- en: 'Recipe Difficulty: Easy'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 食谱难度：简单
- en: 'Python Version: 2.7 or 3.5'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Python版本：2.7或3.5
- en: 'Operating System: Any'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统：任何
- en: In this recipe, we will convert unencrypted iTunes backups into a human-readable
    format, allowing us to easily explore its contents without any third-party tools.
    Backups can be found in the `MobileSync\Backup` folder on the host computer.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将把未加密的iTunes备份转换成人类可读的格式，这样我们就可以轻松地探索其内容，而无需任何第三方工具。备份文件可以在主机计算机的`MobileSync\Backup`文件夹中找到。
- en: For details on default iTunes backup locations for Windows and OS X, visit [https://support.apple.com/en-us/HT204215](https://support.apple.com/en-us/HT204215).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Windows和OS X默认iTunes备份位置的详细信息，请访问[https://support.apple.com/en-us/HT204215](https://support.apple.com/en-us/HT204215)。
- en: If an Apple product has been backed up to the machine, there will be a number
    of folders whose name is a GUID representing a specific device within the backup
    folder. These folders contain differential backups for each device over a period
    of time.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果苹果产品已备份到计算机上，将会有许多文件夹，其名称是表示备份文件夹中特定设备的GUID。这些文件夹包含了一段时间内每个设备的差异备份。
- en: With the new backup format introduced in iOS 10, files are stored in subfolders
    containing the first two hexadecimal characters of the file name. Each file's
    name is a `SHA-1` hash of its path on the device. In the root of the device's
    backup folder, there are a few files of interest, such as the `Info.plist` file
    we discussed earlier and the `Manifest.db` database. This database stores details
    on each backed up file, including its `SHA-1` hash, file path, and name. We will
    use this information to recreate the native backup folder structure with human-friendly
    names.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在iOS 10中引入的新备份格式中，文件存储在包含文件名前两个十六进制字符的子文件夹中。每个文件的名称都是设备上路径的`SHA-1`哈希。在设备的备份文件夹的根目录中，有一些感兴趣的文件，例如我们之前讨论过的`Info.plist`文件和`Manifest.db`数据库。此数据库存储了每个备份文件的详细信息，包括其`SHA-1`哈希、文件路径和名称。我们将使用这些信息来使用人类友好的名称重新创建本机备份文件夹结构。
- en: Getting started
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: All libraries used in this script are present in Python's standard library.
    To follow along, you will need to procure an unencrypted iTunes backup to work
    with. Make sure the backup is of the newer iTunes backup format (iOS 10+) matching
    what was described previously.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本中使用的所有库都包含在Python的标准库中。要跟随操作，您需要获取一个未加密的iTunes备份文件进行操作。确保备份文件是较新的iTunes备份格式（iOS
    10+），与之前描述的内容相匹配。
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'We will use these steps to process the iTunes backup in this recipe:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下步骤来处理此食谱中的iTunes备份：
- en: Identify all backups in the `MobileSync\Backup folder`.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别`MobileSync\Backup`文件夹中的所有备份。
- en: Iterate through each backup.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历每个备份。
- en: Read the Manifest.db file and associate `SHA-1` hash names with filenames.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取Manifest.db文件，并将`SHA-1`哈希名称与文件名关联起来。
- en: Copy and rename backed-up files to the output folder with the appropriate file
    path and name.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将备份文件复制并重命名到输出文件夹，使用适当的文件路径和名称。
- en: How it works...
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'First, we import the required libraries to handle argument parsing, logging,
    copying files, and interacting with SQLite databases. We also set up a variable
    used to later construct the recipe''s logging component:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入所需的库来处理参数解析、日志记录、文件复制和与SQLite数据库交互。我们还设置了一个变量，用于稍后构建食谱的日志记录组件：
- en: '[PRE28]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This recipe''s command-line handler accepts two positional arguments, `INPUT_DIR`
    and `OUTPUT_DIR`, which represent the iTunes backup folder and the desired output
    folder, respectively. An optional argument can be supplied to specify the location
    of the log file and the verbosity for the log messages:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 此食谱的命令行处理程序接受两个位置参数，`INPUT_DIR`和`OUTPUT_DIR`，分别表示iTunes备份文件夹和所需的输出文件夹。可以提供一个可选参数来指定日志文件的位置和日志消息的冗长程度。
- en: '[PRE29]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we begin to set up the log for this recipe. We check if the optional
    verbosity argument was supplied by the user, and if it has been, we increase the
    level from `INFO` to `DEBUG`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们开始为此食谱设置日志。我们检查用户是否提供了可选的冗长参数，如果有，我们将将级别从“INFO”增加到“DEBUG”：
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'For this log, we set up the message format and configure handlers for the console
    and file output, attaching them to our defined `logger`:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此日志，我们设置消息格式并为控制台和文件输出配置处理程序，并将它们附加到我们定义的`logger`：
- en: '[PRE31]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'With the log file set up, we log a few debug details to the log, including
    the arguments supplied to this script and details about the host and Python version.
    We exclude the first element of the `sys.argv` list, which is the name of the
    script and not one of the supplied arguments:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 设置好日志文件后，我们向日志记录一些调试详细信息，包括提供给此脚本的参数以及有关主机和Python版本的详细信息。我们排除了`sys.argv`列表的第一个元素，这是脚本的名称，而不是提供的参数之一：
- en: '[PRE32]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Using the `os.makedirs()` function, we create any necessary folders for the
    desired output directory if they do not already exist:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`os.makedirs()`函数，如果必要，我们将为所需的输出目录创建任何必要的文件夹，如果它们尚不存在：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Lastly, if the input directory exists and is actually a directory, we pass
    the supplied input and output directories to the `main()` function. If the input
    directory fails validation, we print an error to the console and log before exiting
    the script:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果输入目录存在并且确实是一个目录，我们将提供的输入和输出目录传递给`main()`函数。如果输入目录未通过验证，我们将在退出脚本之前向控制台打印错误并记录：
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The `main()` function starts by calling the `backup_summary()` function to
    identify all backups present in the input folder. Let''s first look at the `backup_summary()`
    function and understand what it does before continuing on with the `main()` function:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`main()`函数首先调用`backup_summary()`函数来识别输入文件夹中存在的所有备份。在继续`main()`函数之前，让我们先看看`backup_summary()`函数并了解它的作用：'
- en: '[PRE35]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `backup_summary()` function uses the `os.listdir()` method to list the
    contents of the input directory. We also instantiate the `backups` dictionary,
    which stores details for each discovered backup:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`backup_summary()`函数使用`os.listdir()`方法列出输入目录的内容。我们还实例化`backups`字典，用于存储每个发现的备份的详细信息：'
- en: '[PRE36]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'For each item in the input directory, we use the `os.path.join()` method with
    the input directory and item. We then check if this is a directory, rather than
    a file and if the name of the directory is 40 characters long. If the directory
    passes these checks, this is likely a backup directory and so we instantiate two
    variables to keep track of the number of files within the backup and the total
    size of those files:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 对于输入目录中的每个项目，我们使用`os.path.join()`方法与输入目录和项目。然后我们检查这是否是一个目录，而不是一个文件，以及目录的名称是否为40个字符长。如果目录通过了这些检查，这很可能是一个备份目录，因此我们实例化两个变量来跟踪备份中文件的数量和这些文件的总大小：
- en: '[PRE37]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We use the `os.walk()` method discussed in [Chapter 1](part0029.html#RL0A0-260f9401d2714cb9ab693c4692308abe),
    *Essential Scripting and File Information Recipes,* and create lists for the root,
    subdirectories, and files under the backup folder. We can, therefore, use the
    length of the files list and continue to add it to the `num_files` variable as
    we iterate through the backup folder. In a similar manner, we use a nifty one-liner
    to add each file''s size to the `size` variable:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用[第1章](part0029.html#RL0A0-260f9401d2714cb9ab693c4692308abe)中讨论的`os.walk()`方法，并为备份文件夹下的根目录、子目录和文件创建列表。因此，我们可以使用文件列表的长度，并在迭代备份文件夹时继续将其添加到`num_files`变量中。类似地，我们使用一个巧妙的一行代码将每个文件的大小添加到`size`变量中：
- en: '[PRE38]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'After we finish iterating through the backup, we add the backup to the `backups`
    dictionary using its name as the key and store the backup folder path, file count,
    and size as values. Once we complete iteration of all backups, we return this
    dictionary to the `main()` function. Let''s pick it back up there:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成对备份的迭代之后，我们使用备份的名称作为键将备份添加到`backups`字典中，并将备份文件夹路径、文件计数和大小作为值存储。一旦我们完成了所有备份的迭代，我们将这个字典返回给`main()`函数。让我们接着来看：
- en: '[PRE39]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Back in the `main()` function, we print a summary of each backup to the console
    if any were found. For each backup, we print an arbitrary number identifying the
    backup, the name of the backup, the number of files, and the size. We use the
    `format()` method and manually specify newlines (`\n`) to ensure the console remains
    legible:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main()`函数中，如果找到了任何备份，我们将每个备份的摘要打印到控制台。对于每个备份，我们打印一个任意的标识备份的数字，备份的名称，文件数量和大小。我们使用`format()`方法并手动指定换行符(`\n`)来确保控制台保持可读性：
- en: '[PRE40]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Next, we use a `try-except` block to dump the contents of the `Manifest.db`
    file to the `db_items` variable. If the `Manifest.db` file is not found, the identified
    backup folder is either of an older format or invalid and so we skip it with the
    `continue` command. Let''s briefly discuss the `process_manifest()` function,
    which uses `sqlite3` to connect to and extract all data in the `Manifest.db` files
    table:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`try-except`块将`Manifest.db`文件的内容转储到`db_items`变量中。如果找不到`Manifest.db`文件，则识别的备份文件夹可能是旧格式或无效的，因此我们使用`continue`命令跳过它。让我们简要讨论一下`process_manifest()`函数，它使用`sqlite3`连接到并提取`Manifest.db`文件表中的所有数据：
- en: '[PRE41]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The `process_manifest()` method takes the directory path of the backup as its
    only input. To this input, we join the `Manifest.db` string, to represent the
    location where this database should exist in a valid backup. If it is found that
    this file does not exist, we log that error and raise an `IOError` to the `main()`
    function, which as we just discussed will cause a message to be printed to the
    console and continue on to the next backup:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`process_manifest()` 方法以备份的目录路径作为唯一输入。对于这个输入，我们连接`Manifest.db`字符串，表示这个数据库应该存在在一个有效的备份中的位置。如果发现这个文件不存在，我们记录这个错误并向`main()`函数抛出一个`IOError`，正如我们刚才讨论的那样，这将导致在控制台上打印一条消息，并继续下一个备份：'
- en: '[PRE42]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'If the file does exist, we connect to it and create the `Cursor` object using
    `sqlite3`. The `items` dictionary stores each entry in the `Files` table using
    the item''s `SHA-1` hash as the key and storing all other data as values in a
    list. Notice here an alternative method of accessing the results of the query
    rather than the `fetchall()` function used in previous recipes. After we have
    extracted all of the data from the `Files` table, we return the dictionary back
    to the `main()` function:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果文件确实存在，我们连接到它，并使用`sqlite3`创建`Cursor`对象。`items`字典使用每个条目在`Files`表中的`SHA-1`哈希作为键，并将所有其他数据存储为列表中的值。请注意，这里有一种替代方法来访问查询结果，而不是在以前的示例中使用的`fetchall()`函数。在我们从`Files`表中提取了所有数据之后，我们将字典返回给`main()`函数：
- en: '[PRE43]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Back in the `main()` function, we immediately pass the returned dictionary,
    now referred to as `db_items`, to the `create_files()` method. The dictionary
    we just created is going to be used by the next function to perform lookups on
    the file `SHA-1` hash and determine its real filename, extension, and native file
    path. The `create_files()` function performs these lookups and copies the backed-up
    file to the output folder with the appropriate path, name, and extension.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 回到`main()`函数，我们立即将返回的字典，现在称为`db_items`，传递给`create_files()`方法。我们刚刚创建的字典将被下一个函数用来执行对文件`SHA-1`哈希的查找，并确定其真实文件名、扩展名和本地文件路径。`create_files()`函数执行这些查找，并将备份文件复制到输出文件夹，并使用适当的路径、名称和扩展名。
- en: 'The `else` statement handles situations where there were no backups found by
    the `backup_summary()` function. We remind the user of what the appropriate input
    folder should be and exit the script. This completes the `main()` function; now
    let''s move onto the `create_files()` method:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`else`语句处理了`backup_summary()`函数未找到备份的情况。我们提醒用户应该是适当的输入文件夹，并退出脚本。这完成了`main()`函数；现在让我们继续进行`create_files()`方法：'
- en: '[PRE44]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We start the `create_files()` method by printing a status message to the log:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过在日志中打印状态消息来启动`create_files()`方法：
- en: '[PRE45]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Next, we create a counter to track the number of files found in the manifest
    but not within the backup. We then iterate through each key in the `db_items`
    dictionary generated from the `process_manifest()` function. We first check if
    the associated file name is `None` or an empty string and continue onto the next
    `SHA-1` hash item otherwise:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个计数器来跟踪在清单中找到但在备份中找不到的文件数量。然后，我们遍历从`process_manifest()`函数生成的`db_items`字典中的每个键。我们首先检查关联的文件名是否为`None`或空字符串，否则继续到下一个`SHA-1`哈希项：
- en: '[PRE46]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If the associated file name is present, we create a few variables representing
    the output directory path and the output file path. Notice the output path is
    appended to the name of the backup, `b`, to mimic the backup folder structure
    in the input directory. We use the output directory path, `dirpath`, to first
    check if it exists and create it otherwise:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果关联的文件名存在，我们创建几个表示输出目录路径和输出文件路径的变量。请注意，输出路径被附加到备份名称`b`的名称上，以模仿输入目录中备份文件夹的结构。我们使用输出目录路径`dirpath`首先检查它是否存在，否则创建它：
- en: '[PRE47]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We create a few more path variables, including the location of the backed-up
    file in the input directory. We do this by creating a string with the backup name,
    the first two characters of the `SHA-1` hash key, and the `SHA-1` key itself separated
    by forward slashes. We then join this to the input directory:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一些路径变量，包括输入目录中备份文件的位置。我们通过创建一个字符串，其中包括备份名称、`SHA-1`哈希键的前两个字符和`SHA-1`键本身，它们之间用斜杠分隔来实现这一点。然后将其连接到输入目录中：
- en: '[PRE48]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'With all of these paths created, we can now begin to perform a few more validation
    steps and then copy files over to the new output destination. First, we check
    if the output file already exists in the output folder. During development of
    this script, we noticed some files had the same name and were stored in the same
    folder in the output. This caused data to be overwritten and file counts to not
    match up between the backup folder and the output folder. To remedy this, if the
    file already exists in the backup, we append an underscore and an integer, `x`,
    which represents the loop iteration number, which serves as a unique value for
    our purposes:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 有了所有这些路径创建好后，我们现在可以开始执行一些验证步骤，然后将文件复制到新的输出目的地。首先，我们检查输出文件是否已经存在于输出文件夹中。在开发这个脚本的过程中，我们注意到一些文件具有相同的名称，并存储在输出文件夹中的同一文件夹中。这导致数据被覆盖，并且备份文件夹和输出文件夹之间的文件计数不匹配。为了解决这个问题，如果文件已经存在于备份中，我们会附加一个下划线和一个整数`x`，表示循环迭代次数，这对我们来说是一个唯一的值：
- en: '[PRE49]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'With filename collisions sorted out, we use the `shutil.copyfile()` method
    to copy the backed-up file, represented by the path variable, and rename it and
    store it in the output folder, represented by the `filepath` variable. If the
    path variable refers to a file that is not in the backup folder, it will raise
    an `IOError`, which we catch and log to the log file and add to our counter:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 解决了文件名冲突后，我们使用`shutil.copyfile()`方法来复制由路径变量表示的备份文件，并将其重命名并存储在输出文件夹中，由`filepath`变量表示。如果路径变量指的是不在备份文件夹中的文件，它将引发`IOError`，我们会捕获并记录到日志文件中，并添加到我们的计数器中：
- en: '[PRE50]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We then provide a warning to the user about the number of files that were not
    found in the `Manifest.db`, just in case the user did not enable verbose logging.
    Once we have copied all files in the backup directory, we use the `shutil.copyfile()`
    method to individually copy the non-obfuscated PLIST and database files present
    in the backup folder to the output folder:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们向用户提供一个警告，告知在`Manifest.db`中未找到的文件数量，以防用户未启用详细日志记录。一旦我们将备份目录中的所有文件复制完毕，我们就使用`shutil.copyfile()`方法逐个复制备份文件夹中存在的非混淆的PLIST和数据库文件到输出文件夹中：
- en: '[PRE51]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'When we run this code, we can see the following updated file structure in our
    output:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这段代码时，我们可以在输出中看到以下更新后的文件结构：
- en: '![](../images/00026.jpeg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00026.jpeg)'
- en: There's more...
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'This script can be further improved. We have provided a recommendation here:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本可以进一步改进。我们在这里提供了一个建议：
- en: Add functionality to convert encrypted iTunes backups. Using a third-party library,
    such as `pycrypto`, one can decrypt the backups by supplying the correct password.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加功能以转换加密的iTunes备份。使用第三方库，如`pycrypto`，可以通过提供正确的密码来解密备份。
- en: Putting Wi-Fi on the map
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Wi-Fi标记在地图上
- en: 'Recipe Difficulty: Medium'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 食谱难度：中等
- en: 'Python Version: 3.5'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Python版本：3.5
- en: 'Operating System: Any'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统：任意
- en: Without a connection to the outside world, mobile devices are little more than
    an expensive paperweight. Fortunately, open Wi-Fi networks are everywhere, and
    sometimes a mobile device will connect to them automatically. On the iPhone, a
    list of Wi-Fi networks the device has connected to is stored in a binary PLIST
    named `com.apple.wifi.plist`. This PLIST records, among other things, the Wi-Fi
    SSID, BSSID, and connection time. In this recipe, we will show how to extract
    Wi-Fi details from a standard Cellebrite XML report or supply Wi-Fi MAC addresses
    in a newline-delimited file. As the Cellebrite report formats may evolve over
    time, we are basing our XML parsing on a report generated with UFED Physical Analyzer
    version 6.1.6.19.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 没有与外部世界的连接，移动设备只不过是一块昂贵的纸砖。幸运的是，开放的Wi-Fi网络随处可见，有时移动设备会自动连接到它们。在iPhone上，设备连接过的Wi-Fi网络列表存储在一个名为`com.apple.wifi.plist`的二进制PLIST文件中。这个PLIST记录了Wi-Fi的SSID、BSSID和连接时间等信息。在这个教程中，我们将展示如何从标准的Cellebrite
    XML报告中提取Wi-Fi详细信息，或者提供Wi-Fi MAC地址的逐行分隔文件。由于Cellebrite报告格式可能随时间而变化，我们基于使用UFED Physical
    Analyzer版本6.1.6.19生成的报告进行XML解析。
- en: 'WiGLE is an online searchable repository of, at the time of writing, over 300
    million Wi-Fi networks. We will use the Python `requests` library to access the
    API for WiGLE, to perform automated searches based on Wi-Fi MAC addresses. To
    install the `requests` library, we can use `pip`, as shown here:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: WiGLE是一个在线可搜索的存储库，截至撰写时，拥有超过3亿个Wi-Fi网络。我们将使用Python的`requests`库访问WiGLE的API，以基于Wi-Fi
    MAC地址执行自动搜索。要安装`requests`库，我们可以使用`pip`，如下所示：
- en: '[PRE52]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: If a network is found in the WiGLE repository, we can obtain a great deal of
    data about it, including its latitude and longitude coordinates. With this information,
    we can understand where a user's device, and presumably the user itself, has been
    and when that connection was made.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在WiGLE存储库中找到网络，我们可以获取关于它的大量数据，包括其纬度和经度坐标。有了这些信息，我们可以了解用户设备所在的位置，以及可能的用户本身，以及连接的时间。
- en: To learn more about and use WiGLE, visit the website [https://wigle.net/.](https://wigle.net/)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于WiGLE并使用WiGLE，请访问网站[https://wigle.net/.](https://wigle.net/)
- en: Getting started
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: This recipe requires an API key from the WiGLE website. To register for a free
    API key, visit [https://wigle.net/account](https://wigle.net/account) and follow
    the instructions to display your API key. There are two API values, the name and
    key. For this recipe, please create a file with a single line where the API name
    value is first, followed by a colon (no spaces), and then the API key. This format
    will be read by the script to authenticate you to the WiGLE API.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程需要从WiGLE网站获取API密钥。要注册免费的API密钥，请访问[https://wigle.net/account](https://wigle.net/account)并按照说明显示您的API密钥。有两个API值，名称和密钥。对于这个教程，请创建一个文件，其中API名称值在前，后跟一个冒号（没有空格），然后是API密钥。脚本将读取此格式以对您进行WiGLE
    API身份验证。
- en: At the time of writing, in order to query the WiGLE API you must contribute
    data to the service. This is because the whole site is built on community sourced
    data and this encourages users to share information with others. There are many
    ways to contribute data, as documented on [https://wigle.net](https://wigle.net).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写时，为了查询WiGLE API，您必须向服务贡献数据。这是因为整个网站都是建立在社区共享数据的基础上的，这鼓励用户与他人分享信息。有许多贡献数据的方式，如[https://wigle.net](https://wigle.net)上所记录的那样。
- en: How to do it...
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'This recipe follows the following steps to accomplish the goal:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程遵循以下步骤来实现目标：
- en: Identify input as either a Cellebrite XML report or a line-separated text file
    of MAC addresses.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入标识为Cellebrite XML报告或MAC地址的逐行文本文件。
- en: Process either type of input into a Python dataset.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将任一类型的输入处理为Python数据集。
- en: Query the WiGLE API using `requests`.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`requests`查询WiGLE API。
- en: Optimize the returned WiGLE results into a more convenient format.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将返回的WiGLE结果优化为更方便的格式。
- en: Write the processed output to a CSV file.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将处理后的输出写入CSV文件。
- en: How it works...
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'First, we import the required libraries to handle argument parsing, writing
    spreadsheets, processing XML data, and interacting with the WiGLE API:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入所需的库来处理参数解析、编写电子表格、处理XML数据以及与WiGLE API交互：
- en: '[PRE53]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This recipe's command-line handler accepts two positional arguments, `INPUT_FILE`
    and `OUTPUT_CSV`, representing the input file with Wi-Fi MAC addresses and the
    desired output CSV, respectively. By default, the script assumes the input file
    is a Cellebrite XML report. The user can specify the type of the input file using
    the optional `-t` flag and choose between `xml` or `txt`. Additionally, we can
    set the path of the file containing our API key. By default, this is set in the
    base of the user's directory and named `.wigle_api`, though you can update this
    value to reflect what is easiest in your environment.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程的命令行处理程序接受两个位置参数，`INPUT_FILE`和`OUTPUT_CSV`，分别表示带有Wi-Fi MAC地址的输入文件和期望的输出CSV。默认情况下，脚本假定输入文件是Cellebrite
    XML报告。用户可以使用可选的`-t`标志指定输入文件的类型，并在`xml`或`txt`之间进行选择。此外，我们可以设置包含我们API密钥的文件的路径。默认情况下，这在用户目录的基础上设置，并命名为`.wigle_api`，但您可以更新此值以反映您的环境中最容易的内容。
- en: This file holding your API key should have additional protections, through file
    permissions or otherwise, to prevent theft of your key.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 保存您的API密钥的文件应具有额外的保护措施，通过文件权限或其他方式，以防止您的密钥被盗。
- en: '[PRE54]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We perform the standard data validation steps and check that the input file
    exists and is a file, exiting the script otherwise. We use `os.path.dirname()`
    to extract the directory path and check if it exists. If it does not already exist,
    we use the `os.makedirs()` function to create the directory. We also read in and
    split the API name and key before calling the `main()` function:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行标准的数据验证步骤，并检查输入文件是否存在且为文件，否则退出脚本。我们使用`os.path.dirname（）`来提取目录路径并检查其是否存在。如果目录不存在，我们使用`os.makedirs（）`函数来创建目录。在调用`main（）`函数之前，我们还读取并拆分API名称和密钥：
- en: '[PRE55]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'After we perform argument validation, we pass all arguments to the `main()`
    function:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们执行参数验证之后，我们将所有参数传递给`main（）`函数：
- en: '[PRE56]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'In the `main()` function, we first determine the type of input we are working
    with. By default, the `type` variable is `"xml"` unless otherwise specified by
    the user. Depending on the file type, we send it to the appropriate parser, which
    returns the extracted Wi-Fi data elements in a dictionary. This dictionary is
    then passed, along with the output CSV, to the `query_wigle()` function. This
    function is responsible for querying, processing, and writing the query results
    to a CSV file. First, let''s take a look at the parsers, starting with the `parse_xml()`
    function:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main()`函数中，我们首先确定我们正在处理的输入类型。默认情况下，`type`变量是`"xml"`，除非用户另有指定。根据文件类型，我们将其发送到适当的解析器，该解析器将以字典形式返回提取的Wi-Fi数据元素。然后将此字典与输出CSV一起传递给`query_wigle()`函数。此函数负责查询、处理并将查询结果写入CSV文件。首先，让我们来看看解析器，从`parse_xml()`函数开始：
- en: '[PRE57]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: We parse the Cellebrite XML report using `xml.etree.ElementTree`, which we have
    imported as `ET`.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`xml.etree.ElementTree`解析Cellebrite XML报告，我们已将其导入为`ET`。
- en: "To learn more about the `xml` library, visit [https://docs.python.org/3/library/xml.etree.elementtree.html](https://docs.python.org/3/library/xml.etree.elementtree.html).[\uFEFF\
    ](https://docs.python.org/3/library/xml.etree.elementtree.html)"
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关`xml`库的更多信息，请访问[https://docs.python.org/3/library/xml.etree.elementtree.html](https://docs.python.org/3/library/xml.etree.elementtree.html)。
- en: Parsing a report generated by a forensic tool can be tricky business. These
    reports may change in format and break your script. Therefore, we cannot assume
    that this script will continue to function with future iterations of Cellebrite's
    Physical Analyzer software. And it is for that reason that we've included an option
    to use this script with a text file containing MAC addresses instead.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 解析由取证工具生成的报告可能是棘手的。这些报告的格式可能会发生变化，并破坏您的脚本。因此，我们不能假设此脚本将继续在未来的Cellebrite Physical
    Analyzer软件版本中运行。正因为如此，我们已包含了一个选项，可以使用此脚本与包含MAC地址的文本文件一起使用。
- en: 'As with any XML file, we need to first access the file and parse it using the
    `ET.parse()` function. We then use the `getroot()` method to return the root element
    of the XML file. We use this root as the initial foothold in the file as we search
    for the Wi-Fi data tags within the report:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何XML文件一样，我们需要首先访问文件并使用`ET.parse()`函数对其进行解析。然后我们使用`getroot()`方法返回XML文件的根元素。我们将此根元素作为文件中搜索报告中的Wi-Fi数据标记的初始立足点：
- en: '[PRE58]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We use the `iter()` method to iterate through the child elements of the root.
    We check the tag for each child looking for the model tag. If found, we check
    if it has a location type attribute:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`iter()`方法来迭代根元素的子元素。我们检查每个子元素的标记，寻找模型标记。如果找到，我们检查它是否具有位置类型属性：
- en: '[PRE59]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'For each location model found, we iterate through each of its field elements
    using the `findall()` method. This element contains metadata about the location
    artifact, such as the timestamp, BSSID, and SSID, of the network. We can check
    if the field has a name attribute with the value of `"Timestamp"` and store its
    value in the `ts` variable. If the value does not have any text content, we continue
    on to the next field:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对于找到的每个位置模型，我们使用`findall()`方法迭代其每个字段元素。此元素包含有关位置工件的元数据，例如网络的时间戳、BSSID和SSID。我们可以检查字段是否具有名称属性，其值为`"Timestamp"`，并将其值存储在`ts`变量中。如果值没有任何文本内容，我们继续下一个字段：
- en: '[PRE60]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'In a similar fashion, we check if the field''s name matches `"Description"`.
    This field contains the BSSID and SSID of the Wi-Fi network in a tab-delimited
    string. We attempt to access the text of this value and except an `AttributeError`
    if there is no text:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们检查字段的名称是否与`"Description"`匹配。此字段包含Wi-Fi网络的BSSID和SSID，以制表符分隔的字符串。我们尝试访问此值的文本，并在没有文本时引发`AttributeError`：
- en: '[PRE61]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Because there may be other types of `"Location"` artifacts in the Cellebrite
    report, we check that the string `"SSID"` is present in the value''s text. If
    so, we split the string using the tab special character into two variables. These
    strings we extracted from the value''s text contain some unnecessary characters,
    which we remove from the string using string slicing:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Cellebrite报告中可能存在其他类型的`"Location"`工件，我们检查值的文本中是否存在字符串`"SSID"`。如果是，我们使用制表符特殊字符将字符串拆分为两个变量。我们从值的文本中提取的这些字符串包含一些不必要的字符，我们使用字符串切片将其从字符串中删除：
- en: '[PRE62]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'After we extract the timestamp, BSSID, and SSID from the report, we can add
    them to the `wifi` dictionary. If the Wi-Fi BSSID is already stored as one of
    the keys, we append the timestamp and SSID to the list. This is so that we can
    capture all historical connections to this Wi-Fi network and any changes to the
    name of the network. If we have not yet added this MAC address to the `wifi` dictionary,
    we create the key/value pairs including the WiGLE dictionary that stores API call
    results. After we have parsed all Location model artifacts, we return the `wifi`
    dictionary to the `main()` function:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在从报告中提取时间戳、BSSID和SSID之后，我们可以将它们添加到`wifi`字典中。如果Wi-Fi的BSSID已经存储为其中一个键，我们将时间戳和SSID附加到列表中。这样我们就可以捕获到这个Wi-Fi网络的所有历史连接以及网络名称的任何更改。如果我们还没有将此MAC地址添加到`wifi`字典中，我们将创建键/值对，包括存储API调用结果的WiGLE字典。在解析所有位置模型工件之后，我们将`wifi`字典返回给`main()`函数：
- en: '[PRE63]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'In contrast to the XML parser, the TXT parser is much more straightforward.
    We iterate through each line of the text file and set up each line, which should
    be one MAC address, as a key to an empty dictionary. After we have processed all
    lines in the file, we return the dictionary to the `main()` function:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 与XML解析器相比，TXT解析器要简单得多。我们遍历文本文件的每一行，并将每一行设置为一个MAC地址，作为一个空字典的键。在处理文件中的所有行之后，我们将字典返回给`main()`函数：
- en: '[PRE64]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'With the dictionary of MAC addresses, we can now move onto the `query_wigle()`
    function and use `requests` to make WiGLE API calls. First, we print a message
    to the console informing the user of the current execution status. Next, we iterate
    through each MAC address in the dictionary and use the `query_mac_addr()` function
    to query the site for the BSSID:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 有了MAC地址的字典，我们现在可以转到`query_wigle()`函数，并使用`requests`进行WiGLE API调用。首先，我们在控制台打印一条消息，通知用户当前的执行状态。接下来，我们遍历字典中的每个MAC地址，并使用`query_mac_addr()`函数查询BSSID的站点：
- en: '[PRE65]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The `query_mac_addr()` function takes our MAC address and API key and constructs
    the URL for the request. We use the base URL for the API and insert the MAC address
    at the end of it. This URL is then provided to the `requests.get()` method, along
    with an `auth kwarg` to provide the API name and key. The `requests` library handles
    forming and sending the packet to the API with the correct HTTP basic authentication.
    The `req` object is now ready for us to interpret, so we can call the `json()`
    method to return the data as a dictionary:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`query_mac_addr()`函数接受我们的MAC地址和API密钥，并构造请求的URL。我们使用API的基本URL，并在其末尾插入MAC地址。然后将此URL提供给`requests.get()`方法，以及`auth
    kwarg`来提供API名称和密钥。`requests`库处理形成并发送带有正确HTTP基本身份验证的数据包到API。`req`对象现在已准备好供我们解释，因此我们可以调用`json()`方法将数据返回为字典：'
- en: '[PRE66]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'With the returned `wigle_results` dictionary, we check the `resultCount` key
    to determine how many results were found in the `Wigle` database. If there are
    no results, we append an empty list to the results key in the `Wigle` dictionary.
    Likewise, if there are results, we directly append the returned `wigle_results`
    dictionary to the dataset. The API does have limits to a number of calls you can
    execute per day. When you reach that limit, a `KeyError` will be generated, which
    we catch and print to the console. We also provide reporting for other errors
    identified in a run, as the API may grow to expand the error reporting. After
    searching for each address and adding the results to the dictionary, we pass it,
    along with the output CSV, to the `prep_output()` method:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 使用返回的`wigle_results`字典，我们检查`resultCount`键，以确定在`Wigle`数据库中找到了多少结果。如果没有结果，我们将一个空列表附加到`Wigle`字典中的结果键。同样，如果有结果，我们直接将返回的`wigle_results`字典附加到数据集中。API确实对每天可以执行的调用次数有限制。当达到限制时，将生成`KeyError`，我们捕获并打印到控制台。我们还提供其他错误的报告，因为API可能会扩展错误报告。在搜索每个地址并将结果添加到字典后，我们将其与输出CSV一起传递给`prep_output()`方法：
- en: '[PRE67]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: If you haven't noticed, the data is becoming increasingly complicated, which
    makes writing it and working with it a bit more complicated. The `prep_output()`
    method essentially flattens the dictionary into easily writable chunks. The other
    reason we need this function is that we need to create separate rows for each
    instance a particular Wi-Fi network was connected to. While the WiGLE results
    for that network will be the same, the connection timestamp and the network SSID
    may be different.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有注意到，数据变得越来越复杂，这使得编写和处理它变得更加复杂。`prep_output()`方法基本上将字典展平为易于编写的块。我们需要这个函数的另一个原因是，我们需要为每个特定Wi-Fi网络连接的实例创建单独的行。虽然该网络的WiGLE结果将是相同的，但连接时间戳和网络SSID可能是不同的。
- en: 'To accomplish this, we start by creating a dictionary for the final processed
    results and a Google Maps-related string. We use this string to create a query
    with the latitude and longitude so the user can easily paste the URL into their
    browser to view geolocation details in Google Maps:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们首先为最终处理的结果和与Google Maps相关的字符串创建一个字典。我们使用这个字符串来创建一个查询，其中包含纬度和经度，以便用户可以轻松地将URL粘贴到其浏览器中，以在Google
    Maps中查看地理位置详细信息：
- en: '[PRE68]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: We iterate through each MAC address in the dictionary and create two additional
    loops to iterate through all timestamps and all WiGLE results for the MAC address.
    With these loops, we can now access all of the data we have collected thus far
    and begin to add the data to the new output dictionary.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遍历字典中的每个MAC地址，并创建两个额外的循环，以遍历MAC地址的所有时间戳和所有WiGLE结果。通过这些循环，我们现在可以访问到目前为止收集的所有数据，并开始将数据添加到新的输出字典中。
- en: 'Due to the complexity of the initial dictionary, we create a variable called
    `shortres` to act as a shortcut to a deeper part of the output dictionary. This
    prevents us from unnecessarily writing the entire directory structure each and
    every time we need to access that part of the dictionary. The first use of the
    `shortres` variable can be seen as we extract the latitude and longitude of this
    network from the WiGLE results and append it to the Google Maps query:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 由于初始字典的复杂性，我们创建了一个名为`shortres`的变量，用作输出字典的更深部分的快捷方式。这样可以防止我们在每次需要访问字典的那部分时不必要地写入整个目录结构。`shortres`变量的第一个用法可以看作是我们从WiGLE结果中提取此网络的纬度和经度，并将其附加到Google
    Maps查询中：
- en: '[PRE69]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: In one (rather complicated) line, we add a key and value pair where the key
    is unique based on loop iteration counters and the value is the flattened dictionary.
    We do this by first creating a new dictionary containing the BSSID, SSID, timestamp,
    and the newly created Google Maps URL. Because we want to simplify the output,
    we need to merge the new dictionary and the WiGLE results, stored in the `shortres`
    variable, together.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在一行中（相当复杂），我们添加一个键值对，其中键是基于循环迭代计数器的唯一键，值是展平的字典。我们首先创建一个新字典，其中包含BSSID、SSID、时间戳和新创建的Google
    Maps URL。因为我们想简化输出，我们需要合并新字典和存储在`shortres`变量中的WiGLE结果。
- en: We could iterate through each key in the second dictionary and add its key and
    value pairs one by one. However, it is much quicker to use a feature introduced
    in Python 3.5 whereby we can merge the two dictionaries by placing two `*` symbols
    before each dictionary. This will combine both dictionaries and, if there are
    any keys with the same name, overwrite data from the first dictionary with the
    second one. In this case, we do not have any key overlap, so this will simply
    combine the dictionaries as desired.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以遍历第二个字典中的每个键，并逐个添加其键值对。但是，使用Python 3.5中引入的一个特性会更快，我们可以通过在每个字典之前放置两个`*`符号来合并这两个字典。这将合并两个字典，并且如果有任何重名的键，它将用第二个字典中的数据覆盖第一个字典中的数据。在这种情况下，我们没有任何键重叠，所以这将简单地合并字典。
- en: 'See the following StackOverflow post to learn more about dictionary merging:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅以下StackOverflow帖子以了解更多关于字典合并的信息：
- en: '[https://stackoverflow.com/questions/38987/how-to-merge-two-python-dictionaries-in-a-single-expression](https://stackoverflow.com/questions/38987/how-to-merge-two-python-dictionaries-in-a-single-expression).'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://stackoverflow.com/questions/38987/how-to-merge-two-python-dictionaries-in-a-single-expression](https://stackoverflow.com/questions/38987/how-to-merge-two-python-dictionaries-in-a-single-expression)。'
- en: 'After all of the dictionaries have been merged, we proceed to the `write_csv()`
    function to finally write the output:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在合并了所有字典之后，我们继续使用`write_csv()`函数最终写入输出：
- en: '[PRE70]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'In this recipe, we reintroduce the `csv.DictWriter` class, which allows us
    to easily write dictionaries to a CSV file. This is preferable over the `csv.writer`
    class we have used previously as it provides us a few benefits, including ordering
    the columns. To take advantage of that, we need to know all of the fields we use.
    Because WiGLE is dynamic and the reported results may change, we elected to dynamically
    find the names of all keys in the output dictionary. By adding them to a set,
    we ensure we only have unique keys:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们重新介绍了`csv.DictWriter`类，它允许我们轻松地将字典写入CSV文件。这比我们之前使用的`csv.writer`类更可取，因为它为我们提供了一些好处，包括对列进行排序。为了利用这一点，我们需要知道我们使用的所有字段。由于WiGLE是动态的，报告的结果可能会改变，我们选择动态查找输出字典中所有键的名称。通过将它们添加到一个集合中，我们确保只有唯一的键：
- en: '[PRE71]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Once we have identified all of the keys we have in the output, we can create
    the CSV object. Notice how with the `csv.DictWriter` object we use two keyword
    arguments. The first, as mentioned previously, is a list of all the keys in the
    dictionary that we have sorted. This sorted list is the order of the columns in
    the resulting CSV. If the `csv.DictWriter` encounters a key that is not in the
    supplied `field_list`, which shouldn''t happen in this case due to our precautions,
    it will ignore the error rather than raise an exception due to the configuration
    in the `extrasaction kwarg`:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了输出中所有的键，我们就可以创建CSV对象。请注意，使用`csv.DictWriter`对象时，我们使用了两个关键字参数。如前所述，第一个是字典中所有键的列表，我们已经对其进行了排序。这个排序后的列表就是结果CSV中列的顺序。如果`csv.DictWriter`遇到一个不在提供的`field_list`中的键，由于我们的预防措施，它会忽略错误而不是引发异常，这是由`extrasaction
    kwarg`中的配置决定的：
- en: '[PRE72]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Once we have the writer set up, we can use the `writeheader()` method to automatically
    write the columns based on the supplied field names. After that, it''s a simple
    matter of iterating through each dictionary in the data and writing it to the
    CSV file with the `writerow()` function. While this function is simple, imagine
    the headache we would have if we did not simplify the original data structure
    first:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们设置好写入器，我们可以使用`writeheader()`方法根据提供的字段名称自动写入列。之后，只需简单地遍历数据中的每个字典，并使用`writerow()`函数将其写入CSV文件。虽然这个函数很简单，但想象一下，如果我们没有先简化原始数据结构，我们会有多大的麻烦：
- en: '[PRE73]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'After running this script, we can see all sorts of useful information in our
    CSV report. The first few columns include the BSSID, Google Maps URL, City and
    County:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此脚本后，我们可以在CSV报告中看到各种有用的信息。前几列包括BSSID、Google地图URL、城市和县：
- en: '![](../images/00027.jpeg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00027.jpeg)'
- en: 'We then see several timestamps such as the first time seen, most recent time
    seen, and more specific locations such as the region and road:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们会看到一些时间戳，比如第一次出现的时间、最近出现的时间，以及更具体的位置，比如地区和道路：
- en: '![](../images/00028.jpeg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00028.jpeg)'
- en: 'And finally, we can learn the SSID, coordinates, and type of network and authentication
    used:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以了解到SSID、坐标、网络类型和使用的认证方式：
- en: '![](../images/00029.jpeg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00029.jpeg)'
- en: Digging deep to recover messages
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入挖掘以恢复消息
- en: 'Recipe Difficulty: Hard'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 示例难度：困难
- en: 'Python Version: 3.5'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: Python版本：3.5
- en: 'Operating System: Any'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统：任意
- en: Earlier in this chapter, we developed a recipe to identify missing records from
    a database. In this recipe, we will leverage the output from that recipe and identify
    recoverable records and their offset within a database. This is accomplished by
    understanding some internals of SQLite databases and leveraging that understanding
    to our advantage.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的前面，我们开发了一个从数据库中识别缺失记录的示例。在这个示例中，我们将利用该示例的输出，识别可恢复的记录及其在数据库中的偏移量。这是通过了解SQLite数据库的一些内部机制，并利用这种理解来实现的。
- en: For a detailed description of the SQLite file internals, review [https://www.sqlite.org/fileformat.html](https://www.sqlite.org/fileformat.html).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 有关SQLite文件内部的详细描述，请查看[https://www.sqlite.org/fileformat.html](https://www.sqlite.org/fileformat.html)。
- en: With this technique, we will be able to quickly triage a database and identify
    recoverable messages.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种技术，我们将能够快速审查数据库并识别可恢复的消息。
- en: When a row from a database is deleted, similar to a file, the entry is not necessarily
    overwritten. This entry can still persist for some time based on database activity
    and its allocation algorithms. Our chances for data recovery decrease when, for
    example, a `vacuum` command is triggered.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当从数据库中删除一行时，类似于文件，条目不一定会被覆盖。根据数据库活动和其分配算法，这个条目可能会持续一段时间。例如，当触发`vacuum`命令时，我们恢复数据的机会会减少。
- en: 'We will not get into the weeds discussing SQLite structure; suffice to say
    that each entry is made up of four elements: payload length, the ROWID, the payload
    header, and the payload itself. The previous recipe identifies missing ROWID values,
    which we will use here to find all such occurrences of the ROWID across the database.
    We will use other data, such as known standard payload header values, with the
    iPhone SMS database to validate any hits. While this recipe is focused on extracting
    data from the iPhone SMS database, it can be modified to work for any database.
    We will later point out the few lines of code one would need to change to use
    it for other databases.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入讨论SQLite结构；可以说每个条目由四个元素组成：有效载荷长度、ROWID、有效载荷头和有效载荷本身。前面的配方识别了缺失的ROWID值，我们将在这里使用它来查找数据库中所有这样的ROWID出现。我们将使用其他数据，例如已知的标准有效载荷头值，与iPhone短信数据库一起验证任何命中。虽然这个配方专注于从iPhone短信数据库中提取数据，但它可以修改为适用于任何数据库。我们稍后将指出需要更改的几行代码，以便将其用于其他数据库。
- en: Getting started
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门
- en: All libraries used in this script are present in Python's standard library.
    If you would like to follow along, obtain an iPhone SMS database. If the database
    does not contain any deleted entries, open it with an SQLite connection and delete
    a few. This is a good test to confirm the script works as intended on your dataset.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本中使用的所有库都包含在Python的标准库中。如果您想跟着操作，请获取iPhone短信数据库。如果数据库不包含任何已删除的条目，请使用SQLite连接打开它并删除一些条目。这是一个很好的测试，可以确认脚本是否按预期在您的数据集上运行。
- en: How to do it...
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'This recipe is made up of the following steps:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方由以下步骤组成：
- en: Connect to the input database.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接到输入数据库。
- en: Query table PRAGMA and identify active entry gaps.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询表PRAGMA并识别活动条目间隙。
- en: Convert ROWID gaps into their varint representation.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将ROWID间隙转换为它们的varint表示。
- en: Search the raw hex of the database for missing entries.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据库的原始十六进制中搜索缺失的条目。
- en: Output results to a CSV file.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输出结果保存到CSV文件中。
- en: How it works...
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'First, we import the required libraries to handle argument parsing, manipulating
    hex and binary data, writing spreadsheets, creating tuples of cartesian products,
    searching with regular expression, and interacting with SQLite databases:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入所需的库来处理参数解析、操作十六进制和二进制数据、编写电子表格、创建笛卡尔积的元组、使用正则表达式进行搜索以及与SQLite数据库交互：
- en: '[PRE74]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This recipe''s command-line handler takes three positional and one optional
    argument. This is largely the same as the *Identifying gaps in SQLite databases*
    recipe earlier in this chapter; however, we have also added an argument for the
    output CSV file:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方的命令行处理程序有三个位置参数和一个可选参数。这与本章前面的*在SQLite数据库中识别间隙*配方基本相同；但是，我们还添加了一个用于输出CSV文件的参数：
- en: '[PRE75]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'After we parse the arguments, we pass the supplied arguments to the `main()`
    function. If the optional column argument was supplied by the user, we pass it
    to the `main()` function using the `col` keyword argument:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析参数后，我们将提供的参数传递给`main()`函数。如果用户提供了可选的列参数，我们将使用`col`关键字参数将其传递给`main()`函数：
- en: '[PRE76]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Because this script leverages what we have previously built, the `main()` function
    is largely duplicative of what we have already shown. Rather than repeating the
    comments about the code (there's only so much one can say about a line of code)
    we refer you to the *Identifying gaps in SQLite databases* recipe for an explanation
    of that portion of the code.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这个脚本利用了我们之前构建的内容，`main()`函数在很大程度上是重复的。我们不会重复关于代码的注释（对于一行代码，只能说这么多），我们建议您参考*在SQLite数据库中识别间隙*配方，以了解代码的这部分内容。
- en: 'To refresh everyone''s collective memory, see the following summary of that
    recipe: the `main()` function performs basic input validation, identifies potential
    primary keys from a given table (unless the column was supplied by the user),
    and calls the `find_gaps()` function. The `find_gaps()` function is another holdover
    from the previous script and is almost identical to the previous with the exception
    of one line. Rather than printing all of the identified gaps, this function now
    returns the identified gaps back to the `main()` function. The remainder of the
    `main()` function and all other code covered here on out is new. This is where
    we pick back up the thread as we continue to understand this recipe.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让大家回忆起来，以下是该配方的摘要：`main()`函数执行基本的输入验证，从给定表中识别潜在的主键（除非用户提供了列），并调用`find_gaps()`函数。`find_gaps()`函数是前一个脚本的另一个保留部分，几乎与前一个相同，只有一行不同。这个函数现在不再打印所有已识别的间隙，而是将已识别的间隙返回给`main()`函数。`main()`函数的其余部分和此后涵盖的所有其他代码都是新的。这是我们继续理解这个配方的地方。
- en: 'With gaps identified, we call a function called `varint_converter()` to process
    each gap into its varint counterpart. Varints, also known as variable-length integers,
    are big-endian integers between one and nine bytes in size. Varints are used by
    SQLite because they can take up less space than actually storing the ROWID integer
    itself. Therefore, in order to search for the deleted ROWID effectively, we must
    first convert it to a varint as we must search for that instead:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 识别了间隙后，我们调用一个名为`varint_converter()`的函数来处理每个间隙，将其转换为其varint对应项。Varint，也称为可变长度整数，是大小为1到9个字节的大端整数。SQLite使用Varint，因为它们所占的空间比存储ROWID整数本身要少。因此，为了有效地搜索已删除的ROWID，我们必须首先将其转换为varint，然后再进行搜索：
- en: '[PRE77]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'For ROWIDs less than or equal to 127, their varint equivalent is simply the
    hex representation of the integer. We use the built-in `hex()` method to convert
    the integer into a hex string and use string slicing to remove the prepended `0x`.
    For example, executing `hex(42)` returns the string `0x2a`; in this case, we remove
    the leading `0x` hex designator as we are only interested in the value:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小于或等于127的ROWID，它们的varint等价物就是整数的十六进制表示。我们使用内置的`hex()`方法将整数转换为十六进制字符串，并使用字符串切片来删除前置的`0x`。例如，执行`hex(42)`返回字符串`0x2a`；在这种情况下，我们删除了前导的`0x`十六进制标识符，因为我们只对值感兴趣：
- en: '[PRE78]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'If the missing ROWID is `128` or greater, we start an infinite `while` loop
    to find the relevant varint. Before starting the loop, we use list comprehension
    to create a list containing numbers `0` through `255`. We also instantiate a counter
    variable with a value of `1`. The first part of the `while` loop creates a list
    of tuples, whose number of elements equals to the `counter` variable, containing
    every combination of the `combos` list. For example, if counter is equal to `2`,
    we see a list of tuples representing all possible 2-byte varints as `[(0, 0),
    (0, 1), (0, 2), ..., (255, 255)]`. After that process completes, we use list comprehension
    again to remove all tuples whose first element is less than or equal to `127`.
    Due to the fact that this part of the `if-else` loop deals with rows greater than
    or equal to `128`, we know the varint cannot be equal to or less than `127` and
    so those values are eliminated from consideration:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 如果缺失的ROWID是`128`或更大，我们开始一个无限的`while`循环来找到相关的varint。在开始循环之前，我们使用列表推导来创建一个包含数字`0`到`255`的列表。我们还实例化一个值为`1`的计数器变量。`while`循环的第一部分创建一个元组列表，其元素数量等于`counter`变量，包含`combos`列表的每个组合。例如，如果counter等于`2`，我们会看到一个元组列表，表示所有可能的2字节varints，如`[(0,
    0), (0, 1), (0, 2), ..., (255, 255)]`。完成这个过程后，我们再次使用列表推导来删除所有第一个元素小于或等于`127`的元组。由于`if-else`循环的这部分处理大于或等于`128`的行，我们知道varint不能等于或小于`127`，因此这些值被排除在考虑之外：
- en: '[PRE79]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: After creating the list of n-byte varints, we loop through each combination
    and pass it to the `integer_converter()` function. This function treats these
    numbers as part of a varint and decodes them into the corresponding ROWID. We
    can then check the returned ROWID against the missing ROWID. If it matches, we
    add a key and value pair to the `varints` dictionary where the key is the hexadecimal
    representation of the varint and the value is the missing ROWID. At this point,
    we increment the `i` variable by `1` and try to fetch the next row element. If
    successful, we process that ROWID and so on until we have reached the end of the
    ROWIDs that will generate an `IndexError`. We catch such an error and return the
    `varints` dictionary back to the `main()` function.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了n字节varints列表后，我们循环遍历每个组合，并将其传递给`integer_converter()`函数。这个函数将这些数字视为varint的一部分，并将它们解码为相应的ROWID。然后，我们可以将返回的ROWID与缺失的ROWID进行比较。如果匹配，我们将一个键值对添加到`varints`字典中，其中键是varint的十六进制表示，值是缺失的ROWID。此时，我们将`i`变量增加`1`，并尝试获取下一个行元素。如果成功，我们处理该ROWID，依此类推，直到我们已经到达将生成`IndexError`的ROWIDs的末尾。我们捕获这样的错误，并将`varints`字典返回给`main()`函数。
- en: 'One important thing to note about this function, because the input was a sorted
    list of ROWIDs, we only need to calculate the n-byte varint combinations once
    as the next ROWID in line can only be bigger not smaller. Additionally, due to
    the fact that we know the next ROWID is at least one greater than the previous,
    we continue looping through the varint combinations we created without restarting
    as it would be impossible for the next ROWID to be smaller. These techniques show
    a great use case for `while` loops as they vastly improve the execution speed
    of the recipe:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个函数需要注意的一件重要的事情是，因为输入是一个排序过的ROWIDs列表，我们只需要计算n字节varint组合一次，因为下一个ROWID只能比前一个更大而不是更小。另外，由于我们知道下一个ROWID至少比前一个大一，我们继续循环遍历我们创建的varint组合，而不重新开始，因为下一个ROWID不可能更小。这些技术展示了`while`循环的一个很好的用例，因为它们大大提高了该方法的执行速度：
- en: '[PRE80]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: The `integer_converter()` function is relatively straightforward. This function
    makes use of the built-in `bin()` method, similar to the `hex()` method already
    discussed, to convert an integer into its binary equivalent. We iterate through
    each value in the proposed varint, first converting each using `bin()`. This returns
    a string, this time with the binary prefix value `0b` prepended, which we remove
    using string slicing. We again use `zfill()` to ensure the bytes have all bits
    intact as the `bin()` method removes leading `0` bits by default. After that,
    we remove the first bit from every byte. As we iterate through each number of
    our varint, we add the resulting processed bits to a variable called `binary`.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '`integer_converter()`函数相对简单。这个函数使用内置的`bin()`方法，类似于已经讨论过的`hex()`方法，将整数转换为其二进制等价物。我们遍历建议的varint中的每个值，首先使用`bin()`进行转换。这将返回一个字符串，这次前缀值为`0b`，我们使用字符串切片去除它。我们再次使用`zfill()`来确保字节具有所有位，因为`bin()`方法默认会去除前导的`0`位。之后，我们移除每个字节的第一位。当我们遍历我们的varint中的每个数字时，我们将处理后的位添加到一个名为`binary`的变量中。'
- en: This process may sound a little confusing; however, this is the manual process
    of decoding varints.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可能听起来有点混乱，但这是解码varints的手动过程。
- en: 'Refer to this blog post on *Forensics from the sausage factory* for more details
    about how to manually convert varints to integers and other SQLite internals:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何手动将varints转换为整数和其他SQLite内部的更多详细信息，请参阅*Forensics from the sausage factory*上的这篇博文：
- en: "[https://forensicsfromthesausagefactory.blogspot.com/2011/05/analysis-of-record-structure-within.html](https://forensicsfromthesausagefactory.blogspot.com/2011/05/analysis-of-record-structure-within.html).[\uFEFF\
    ](https://forensicsfromthesausagefactory.blogspot.com/2011/05/analysis-of-record-structure-within.html)"
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: "[https://forensicsfromthesausagefactory.blogspot.com/2011/05/analysis-of-record-structure-within.html](https://forensicsfromthesausagefactory.blogspot.com/2011/05/analysis-of-record-structure-within.html).[\uFEFF\
    ](https://forensicsfromthesausagefactory.blogspot.com/2011/05/analysis-of-record-structure-within.html)"
- en: 'After we finish iterating through the list of numbers, we use `lstrip()` to
    strip out any leftmost zero values in the binary string. If the resulting string
    is empty, we return `0`; otherwise, we convert and then return the processed binary
    data back into an integer from the base-2 binary representation:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成对数字列表的迭代后，我们使用`lstrip()`来去除二进制字符串中的任何最左边的零值。如果结果字符串为空，我们返回`0`；否则，我们将处理后的二进制数据转换并返回为从二进制表示的基数2的整数：
- en: '[PRE81]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Back in the `main()` function, we pass the `varints` dictionary and the path
    to the database file to the `find_candidates()` function:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 回到`main（）`函数，我们将`varints`字典和数据库文件的路径传递给`find_candidates（）`函数：
- en: '[PRE82]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The two candidates we search for are `"350055"` and `"360055"`. As discussed
    before, in a database, following the ROWID for a cell is the payload header length.
    This payload header length is typically one of two values in the iPhone SMS database:
    either `0x35` or `0x36`. Following the payload header length is the payload header
    itself. The first serial type of the payload header will be `0x00` and represents
    a `NULL` value, which the primary key of the database--the first column and hence
    the first serial type--will always be recorded as. Next is the serial type `0x55`
    corresponding to the second column in the table, the message GUID, which is always
    a `21` byte string and therefore will always be represented by the serial type
    `0x55`. Any validated hits are appended to the results list.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们搜索的两个候选者是“350055”和“360055”。如前所述，在数据库中，跟随单元格的ROWID是有效载荷头长度。iPhone短信数据库中的有效载荷头长度通常是两个值中的一个：要么是0x35，要么是0x36。在有效载荷头长度之后是有效载荷头本身。有效载荷头的第一个序列类型将是0x00，表示为NULL值，数据库的主键--第一列，因此第一个序列类型--将始终被记录为。接下来是序列类型0x55，对应于表中的第二列，消息GUID，它始终是一个21字节的字符串，因此将始终由序列类型0x55表示。任何经过验证的命中都将附加到结果列表中。
- en: 'By searching for the ROWID varint and these three additional bytes, we can
    greatly reduce the number of false positives. Note that if you are working on
    a database other than the iPhone SMS database, you need to change the value of
    these candidates to reflect any static content proceeding the ROWID in your table:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 通过搜索ROWID varint和这三个附加字节，我们可以大大减少误报的数量。请注意，如果您正在处理的数据库不是iPhone短信数据库，则需要更改这些候选者的值，以反映表中ROWID之前的任何静态内容：
- en: '[PRE83]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'We open the database in `rb` mode to search its binary content. In order to
    do so, we must first read in the entire database and, using the `binascii.hexlify()`
    function, convert this data into hex. As we have already stored the varints as
    hex, we can now easily search this dataset for the varint and other surrounding
    data. We begin the search process by looping through each varint and creating
    two different search strings to account for either of the two static footholds
    in the iPhone SMS database:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以`rb`模式打开数据库以搜索其二进制内容。为了做到这一点，我们必须首先读取整个数据库，并使用`binascii.hexlify（）`函数将这些数据转换为十六进制。由于我们已经将varints存储为十六进制，因此现在可以轻松地搜索这些数据集以查找varint和其他周围的数据。我们通过循环遍历每个varint并创建两个不同的搜索字符串来开始搜索过程，以考虑iPhone短信数据库中的两个静态支点之一：
- en: '[PRE84]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We then use the `re.finditer()` method to iterate through each hit based on
    the `search_a` and `search_b` keywords. For each result, we append a list with
    the ROWID, the search term used, and the offset within the file. We must divide
    by 2 to accurately report the number of bytes rather than the number of hex digits.
    After we finish searching the data, we return the results to the `main()` function:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`re.finditer（）`方法基于`search_a`和`search_b`关键字来迭代每个命中。对于每个结果，我们附加一个包含ROWID、使用的搜索词和文件内的偏移量的列表。我们必须除以2来准确报告字节数，而不是十六进制数字的数量。在完成搜索数据后，我们将结果返回给`main（）`函数：
- en: '[PRE85]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'For the last time, we are back in the `main()` function. This time we check
    if there are any search results. If there are, we pass them along with the CSV
    output to the `csvWriter()` method. Otherwise, we print a status message to the
    console notifying the user that there were no intact recoverable ROWIDs identified:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一次，我们回到`main（）`函数。这次我们检查是否有搜索结果。如果有，我们将它们与CSV输出一起传递给`csvWriter（）`方法。否则，我们在控制台上打印状态消息，通知用户没有识别到完整可恢复的ROWID：
- en: '[PRE86]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The `write_csv()` method is true to form and simple as always. We open a new
    CSV file and create three columns for the three elements stored in the nested
    list structure. We then use the `writerows()` method to write all rows in the
    results data list to the file:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '`write_csv（）`方法一如既往地简单。我们打开一个新的CSV文件，并为嵌套列表结构中存储的三个元素创建三列。然后，我们使用`writerows（）`方法将结果数据列表中的所有行写入文件：'
- en: '[PRE87]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'When we look at the exported report we can clearly see our row ID, the searched
    hex value, and the offset within the database the record was found:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看导出的报告时，我们可以清楚地看到我们的行ID、搜索的十六进制值以及记录被发现的数据库内的偏移量：
- en: '![](../images/00030.jpeg)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00030.jpeg)'
- en: There's more…
  id: totrans-345
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'This script can be further improved. We have provided a recommendation here:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本可以进一步改进。我们在这里提供了一个建议：
- en: Rather than hard-coding the candidates, accept a text file of such candidates
    or command-line entries to increase the recipe's flexibility
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 而不是硬编码候选者，接受这些候选者的文本文件或命令行条目，以增加该脚本的灵活性
