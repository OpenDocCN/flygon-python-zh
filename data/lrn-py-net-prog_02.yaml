- en: Chapter 2. HTTP and Working with the Web
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。HTTP和网络应用
- en: The **Hypertext Transfer Protocol** (**HTTP**) is probably the most widely-used
    application layer protocol. It was originally developed to allow academics to
    share HTML documents. Nowadays, it is used as the core protocol of innumerable
    applications across the Internet, and it is the principle protocol of the World
    Wide Web.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**超文本传输协议**（**HTTP**）可能是最广泛使用的应用层协议。最初开发是为了让学者分享HTML文档。如今，它被用作互联网上无数应用程序的核心协议，并且是万维网的主要协议。'
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The HTTP protocol structure
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP协议结构
- en: Using Python for talking to services through HTTP
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python通过HTTP与服务通信
- en: Downloading files
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载文件
- en: HTTP capabilities, such as compression and cookies
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP功能，如压缩和cookies
- en: Handling errors
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理错误
- en: URLs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: URL
- en: The Python standard library `urllib` package
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python标准库`urllib`包
- en: Kenneth Reitz's third-party `Requests` package
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kenneth Reitz的第三方`Requests`包
- en: The `urllib` package is the recommended Python standard library package for
    HTTP tasks. The standard library also has a low-level module called `http`. Although
    this offers access to almost all aspects of the protocol, it has not been designed
    for everyday use. The `urllib` package has a simpler interface, and it deals with
    everything that we are going to cover in this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib`包是Python标准库中用于HTTP任务的推荐包。标准库还有一个名为`http`的低级模块。虽然这提供了对协议几乎所有方面的访问，但它并不是为日常使用而设计的。`urllib`包有一个更简单的接口，并且处理了我们将在本章中涵盖的所有内容。'
- en: The third-party `Requests` package is a very popular alternative to `urllib`.
    It has an elegant interface and a powerful featureset, and it is a great tool
    for streamlining HTTP workflows. We'll be discussing how it can be used in place
    of `urllib` at the end of the chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 第三方`Requests`包是`urllib`的一个非常受欢迎的替代品。它具有优雅的界面和强大的功能集，是简化HTTP工作流的绝佳工具。我们将在本章末讨论它如何替代`urllib`使用。
- en: Request and response
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 请求和响应
- en: HTTP is an application layer protocol, and it is almost always used on top of
    TCP. The HTTP protocol has been deliberately defined to use a human-readable message
    format, but it can still be used for transporting arbitrary bytes data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP是一个应用层协议，几乎总是在TCP之上使用。HTTP协议被故意定义为使用人类可读的消息格式，但仍然可以用于传输任意字节数据。
- en: An HTTP exchange consists of two elements. A **request** made by the client,
    which asks the server for a particular resource specified by a URL, and a **response**,
    sent by the server, which supplies the resource that the client has asked for.
    If the server can't provide the resource that the client has requested, then the
    response will contain information about the failure.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个HTTP交换包括两个元素。客户端发出的**请求**，请求服务器提供由URL指定的特定资源，以及服务器发送的**响应**，提供客户端请求的资源。如果服务器无法提供客户端请求的资源，那么响应将包含有关失败的信息。
- en: This order of events is fixed in HTTP. All interactions are initiated by the
    client. The server never sends anything to the client without the client explicitly
    asking for it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这个事件顺序在HTTP中是固定的。所有交互都是由客户端发起的。服务器不会在没有客户端明确要求的情况下向客户端发送任何内容。
- en: This chapter will teach you how to use Python as an HTTP client. We will learn
    how to make requests to servers and then interpret their responses. We will look
    at writing server-side applications in [Chapter 9](ch09.html "Chapter 9. Applications
    for the Web"), *Applications for the Web*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章将教你如何将Python用作HTTP客户端。我们将学习如何向服务器发出请求，然后解释它们的响应。我们将在[第9章](ch09.html "第9章。网络应用")中讨论编写服务器端应用程序，*网络应用*。
- en: By far, the most widely used version of HTTP is 1.1, defined in RFCs 7230 to
    7235\. HTTP 2 is the latest version, which was officially ratified just as this
    book was going to press. Most of the semantics and syntax remain the same between
    versions 1.1 and 2, the main changes are in how the TCP connections are utilised.
    As of now, HTTP 2 isn't widely supported, so we will focus on version 1.1 in this
    book. If you do want to know more, HTTP 2 is documented in RFCs 7540 and 7541.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，最广泛使用的HTTP版本是1.1，定义在RFC 7230到7235中。HTTP 2是最新版本，正式批准时本书即将出版。版本1.1和2之间的语义和语法大部分保持不变，主要变化在于TCP连接的利用方式。目前，HTTP
    2的支持并不广泛，因此本书将专注于版本1.1。如果你想了解更多，HTTP 2在RFC 7540和7541中有记录。
- en: 'HTTP version 1.0, documented in RFC 1945, is still used by some older softwares.
    Version 1.1 is backwards-compatible with 1.0 though, and the `urllib` package
    and `Requests` both support HTTP 1.1, so when we''re writing a client with Python
    we don''t need to worry about whether we''re connecting to an HTTP 1.0 server.
    It''s just that some more advanced features are not available. Almost all services
    nowadays use version 1.1, so we won''t go into the differences here. The stack
    overflow question is, a good starting point, if you need further information:
    [http://stackoverflow.com/questions/246859/http-1-0-vs-1-1](http://stackoverflow.com/questions/246859/http-1-0-vs-1-1).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP版本1.0，记录在RFC 1945中，仍然被一些较老的软件使用。版本1.1与1.0向后兼容，`urllib`包和`Requests`都支持HTTP
    1.1，所以当我们用Python编写客户端时，不需要担心连接到HTTP 1.0服务器。只是一些更高级的功能不可用。几乎所有现在的服务都使用版本1.1，所以我们不会在这里讨论差异。如果需要更多信息，可以参考堆栈溢出的问题：[http://stackoverflow.com/questions/246859/http-1-0-vs-1-1](http://stackoverflow.com/questions/246859/http-1-0-vs-1-1)。
- en: Requests with urllib
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用urllib进行请求
- en: We have already seen some examples of HTTP exchanges while discussing the RFC
    downloaders in [Chapter 1](ch01.html "Chapter 1. Network Programming and Python"),
    *Network Programming and Python*. The `urllib` package is broken into several
    submodules for dealing with the different tasks that we may need to perform when
    working with HTTP. For making requests and receiving responses, we employ the
    `urllib.request` module.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论RFC下载器时，我们已经看到了一些HTTP交换的例子，[第1章](ch01.html "第1章。网络编程和Python")*网络编程和Python*。`urllib`包被分成几个子模块，用于处理我们在使用HTTP时可能需要执行的不同任务。为了发出请求和接收响应，我们使用`urllib.request`模块。
- en: 'Retrieving the contents of a URL is a straightforward process when done using
    `urllib`. Load your Python interpreter and do the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`urllib`从URL检索内容是一个简单的过程。打开你的Python解释器，然后执行以下操作：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We use the `urllib.request.urlopen()` function for sending a request and receiving
    a response for the resource at [http://www.debian.org](http://www.debian.org),
    in this case an HTML page. We will then print out the first line of the HTML we
    receive.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`urllib.request.urlopen()`函数发送请求并接收[http://www.debian.org](http://www.debian.org)上资源的响应，这里是一个HTML页面。然后我们将打印出我们收到的HTML的第一行。
- en: Response objects
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应对象
- en: 'Let''s take a closer look at our response object. We can see from the preceding
    example that `urlopen()` returns an `http.client.HTTPResponse` instance. The response
    object gives us access to the data of the requested resource, and the properties
    and the metadata of the response. To view the URL for the response that we received
    in the previous section, do this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看一下我们的响应对象。从前面的例子中我们可以看到，`urlopen()`返回一个`http.client.HTTPResponse`实例。响应对象使我们能够访问请求资源的数据，以及响应的属性和元数据。要查看我们在上一节中收到的响应的URL，可以这样做：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We get the data of the requested resource through a file-like interface using
    the `readline()` and `read()` methods. We saw the `readline()` method in the previous
    section. This is how we use the `read()` method:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过类似文件的接口使用`readline()`和`read()`方法获取请求资源的数据。我们在前一节看到了`readline()`方法。这是我们使用`read()`方法的方式：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `read()` method returns the specified number of bytes from the data. Here
    it's the first 50 bytes. A call to the `read()` method with no argument will return
    all the data in one go.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`read()`方法从数据中返回指定数量的字节。这里是前50个字节。调用`read()`方法而不带参数将一次性返回所有数据。'
- en: 'The file-like interface is limited. Once the data has been read, it''s not
    possible to go back and re-read it by using either of the aforementioned functions.
    To demonstrate this, try doing the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 类似文件的接口是有限的。一旦数据被读取，就无法使用上述函数之一返回并重新读取它。为了证明这一点，请尝试执行以下操作：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can see that when we call the `read()` function a second time it returns
    an empty string. There are no `seek()` or `rewind()` methods, so we cannot reset
    the position. Hence, it's best to capture the `read()` output in a variable.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，当我们第二次调用`read()`函数时，它返回一个空字符串。没有`seek()`或`rewind()`方法，所以我们无法重置位置。因此，最好将`read()`输出捕获在一个变量中。
- en: Both `readline()` and `read()` functions return bytes objects, and neither `http`
    nor `urllib` will make any effort to decode the data that they receive to Unicode.
    Later on in the chapter, we'll be looking at a way in which we can handle this
    with the help of the `Requests` library.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`readline()`和`read()`函数都返回字节对象，`http`和`urllib`都不会对接收到的数据进行解码为Unicode。在本章的后面，我们将看到如何利用`Requests`库来处理这个问题。'
- en: Status codes
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 状态码
- en: What if we wanted to know whether anything unexpected had happened to our request?
    Or what if we wanted to know whether our response contained any data before we
    read the data out? Maybe we're expecting a large response, and we want to quickly
    see if our request has been successful without reading the whole response.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想知道我们的请求是否发生了意外情况怎么办？或者如果我们想知道我们的响应在读取数据之前是否包含任何数据怎么办？也许我们期望得到一个大的响应，我们想快速查看我们的请求是否成功而不必读取整个响应。
- en: HTTP responses provide a means for us to do this through **status codes**. We
    can read the status code of a response by using its `status` attribute.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP响应通过**状态码**为我们提供了这样的方式。我们可以通过使用其`status`属性来读取响应的状态码。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Status codes are integers that tell us how the request went. The `200` code
    informs us that everything went fine.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 状态码是告诉我们请求的情况的整数。`200`代码告诉我们一切都很好。
- en: 'There are a number of codes, and each one conveys a different meaning. According
    to their first digit, status codes are classified into the following groups:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多代码，每个代码传达不同的含义。根据它们的第一个数字，状态码被分为以下几组：
- en: '100: Informational'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 100：信息
- en: '200: Success'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 200：成功
- en: '300: Redirection'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 300：重定向
- en: '400: Client error'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 400：客户端错误
- en: '500: Server error'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 500：服务器错误
- en: 'A few of the more frequently encountered codes and their messages are as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的代码及其消息如下：
- en: '`200`: `OK`'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`200`：`OK`'
- en: '`404`: `Not Found`'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`404`：`未找到`'
- en: '`500`: `Internal Server Error`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`500`：`内部服务器错误`'
- en: The official list of status codes is maintained by IANA and it can be found
    at [https://www.iana.org/assignments/http-status-codes](https://www.iana.org/assignments/http-status-codes).
    We'll be looking at various codes in this chapter.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 状态码的官方列表由IANA维护，可以在[https://www.iana.org/assignments/http-status-codes](https://www.iana.org/assignments/http-status-codes)找到。我们将在本章中看到各种代码。
- en: Handling problems
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理问题
- en: Status codes help us to see whether our response was successful or not. Any
    code in the 200 range indicates a success, whereas any code in either the 400
    range or the 500 range indicates failure.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 状态码帮助我们查看响应是否成功。200范围内的任何代码表示成功，而400范围或500范围内的代码表示失败。
- en: Status codes should always be checked so that our program can respond appropriately
    if something goes wrong. The `urllib` package helps us in checking the status
    codes by raising an exception if it encounters a problem.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 应该始终检查状态码，以便我们的程序在出现问题时能够做出适当的响应。`urllib`包通过在遇到问题时引发异常来帮助我们检查状态码。
- en: 'Let''s go through how to catch these and handle them usefully. For this try
    the following command block:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何捕获这些异常并有用地处理它们。为此，请尝试以下命令块：
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here we've requested RFC 0, which doesn't exist. So the server has returned
    a 404 status code, and `urllib` has spotted this and raised an `HTTPError`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们请求了不存在的RFC 0。因此服务器返回了404状态代码，`urllib`已经发现并引发了`HTTPError`。
- en: You can see that `HTTPError` provide useful attributes regarding the request.
    In the preceding example, we used the `status`, `reason`, and `url` attributes
    to get some information about the response.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到`HTTPError`提供了有关请求的有用属性。在前面的示例中，我们使用了`status`、`reason`和`url`属性来获取有关响应的一些信息。
- en: 'If something goes wrong lower in the network stack, then the appropriate module
    will raise an exception. The `urllib` package catches these exceptions and then
    wraps them as `URLErrors`. For example, we might have specified a host or an IP
    address that doesn''t exist, as shown here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果网络堆栈中出现问题，那么适当的模块将引发异常。`urllib`包捕获这些异常，然后将它们包装为`URLErrors`。例如，我们可能已经指定了一个不存在的主机或IP地址，如下所示：
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this instance, we have asked for `index.html` from the `192.0.2.1`. host.
    The `192.0.2.0/24` IP address range is reserved to be used by documentation only,
    so you will never encounter a host using the preceding IP address. Hence the TCP
    connection times out and `socket` raises a timeout exception, which `urllib` catches,
    re-wraps, and re-raises for us. We can catch these exceptions in the same way
    as we did in the preceding example.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们已经从`192.0.2.1`主机请求了`index.html`。`192.0.2.0/24` IP地址范围被保留供文档使用，因此您永远不会遇到使用前述IP地址的主机。因此TCP连接超时，`socket`引发超时异常，`urllib`捕获，重新包装并为我们重新引发。我们可以像在前面的例子中一样捕获这些异常。
- en: HTTP headers
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP头部
- en: 'Requests, and responses are made up of two main parts, **headers** and a **body**.
    We briefly saw some HTTP headers when we used our TCP RFC downloader in [Chapter
    1](ch01.html "Chapter 1. Network Programming and Python"), *Network Programming
    and Python*. Headers are the lines of protocol-specific information that appear
    at the beginning of the raw message that is sent over the TCP connection. The
    body is the rest of the message. It is separated from the headers by a blank line.
    The body is optional, its presence depends on the type of request or response.
    Here''s an example of an HTTP request:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请求和响应由两个主要部分组成，**头部**和**正文**。当我们在[第1章](ch01.html "第1章。网络编程和Python")中使用TCP RFC下载器时，我们简要地看到了一些HTTP头部，*网络编程和Python*。头部是出现在通过TCP连接发送的原始消息开头的协议特定信息行。正文是消息的其余部分。它与头部之间由一个空行分隔。正文是可选的，其存在取决于请求或响应的类型。以下是一个HTTP请求的示例：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The first line is called the **request line**. It is comprised of the request
    **method**, which is `GET` in this case, the path to the resource, which is `/`
    here, and the HTTP version, `1.1`. The rest of the lines are request headers.
    Each line is comprised of a header name followed by a colon and a header value.
    The request in the preceding output only contains headers, it does not have a
    body.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行称为**请求行**。它由请求**方法**组成，在这种情况下是`GET`，资源的路径，在这里是`/`，以及HTTP版本`1.1`。其余行是请求头。每行由一个头部名称后跟一个冒号和一个头部值组成。前述输出中的请求只包含头部，没有正文。
- en: Headers are used for several purposes. In a request they can be used for passing
    extra data, such as cookies and authorization credentials, and for asking the
    server for preferred formats of resources.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 头部用于几个目的。在请求中，它们可以用于传递额外的数据，如cookies和授权凭据，并询问服务器首选资源格式。
- en: For example, an important header is the `Host` header. Many web server applications
    provide the ability to host more than one website on the same server using the
    same IP address. DNS aliases are set up for the various website domain names,
    so they all point to the same IP address. Effectively, the web server is given
    multiple hostnames, one for each website it hosts. IP and TCP (which HTTP runs
    on), can't be used to tell the server which hostname the client wants to connect
    to because both of them operate solely on IP addresses. The HTTP protocol allows
    the client to supply the hostname in the HTTP request by including a `Host` header.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个重要的头部是`Host`头部。许多Web服务器应用程序提供了在同一台服务器上使用相同的IP地址托管多个网站的能力。为各个网站域名设置了DNS别名，因此它们都指向同一个IP地址。实际上，Web服务器为每个托管的网站提供了多个主机名。IP和TCP（HTTP运行在其上）不能用于告诉服务器客户端想要连接到哪个主机名，因为它们都仅仅在IP地址上操作。HTTP协议允许客户端在HTTP请求中提供主机名，包括`Host`头部。
- en: We'll look at some more request headers in the following section.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中查看一些更多的请求头部。
- en: 'Here''s an example of a response:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是响应的一个示例：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The first line contains the protocol version, the status code, and the status
    message. Subsequent lines contain the headers, a blank line, and then the body.
    In the response, the server can use headers to inform the client about things
    such as the length of the body, the type of content the response body contains,
    and the cookie data that the client should store.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行包含协议版本、状态代码和状态消息。随后的行包含头部、一个空行，然后是正文。在响应中，服务器可以使用头部通知客户端有关正文长度、响应正文包含的内容类型以及客户端应存储的cookie数据等信息。
- en: 'Do the following to view a response object''s headers:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看响应对象的头部，请执行以下操作：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `getheaders()` method returns the headers as a list of tuples of the form
    (`header name`, `header value`). A complete list of HTTP 1.1 headers and their
    meanings can be found in RFC 7231\. Let's look at how to use some headers in requests
    and responses.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`getheaders()`方法以元组列表的形式返回头部（`头部名称`，`头部值`）。HTTP 1.1头部及其含义的完整列表可以在RFC 7231中找到。让我们看看如何在请求和响应中使用一些头部。'
- en: Customizing requests
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义请求
- en: 'To make use of the functionality that headers provide, we add headers to a
    request before sending it. To do this, we can''t just use `urlopen()`. We need
    to follow these steps:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 利用标头提供的功能，我们在发送请求之前向请求添加标头。为了做到这一点，我们不能只是使用`urlopen()`。我们需要按照以下步骤进行：
- en: Create a `Request` object
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个`Request`对象
- en: Add headers to the request object
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向请求对象添加标头
- en: Use `urlopen()` to send the request object
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`urlopen()`发送请求对象
- en: We're going to learn how to customize a request for retrieving a Swedish version
    of the Debian home page. We will use the `Accept-Language` header, which tells
    the server our preferred language for the resource it returns. Note that not all
    servers hold versions of resources in multiple languages, so not all servers will
    respond to `Accept-Language`Linux home page.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习如何自定义一个请求，以检索Debian主页的瑞典版本。我们将使用`Accept-Language`标头，告诉服务器我们对其返回的资源的首选语言。请注意，并非所有服务器都保存多种语言版本的资源，因此并非所有服务器都会响应`Accept-Language`。
- en: 'First, we create a `Request` object:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个`Request`对象：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next we add the header:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，添加标头：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `add_header()` method takes the name of the header and the contents of the
    header as arguments. The `Accept-Language` header takes two-letter ISO 639-1 language
    codes. The code for Swedish is `sv`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`add_header()`方法接受标头的名称和标头的内容作为参数。`Accept-Language`标头采用两字母的ISO 639-1语言代码。瑞典语的代码是`sv`。'
- en: 'Lastly, we submit the customized request with `urlopen()`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`urlopen()`提交定制的请求：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can check if the response is in Swedish by printing out the first few lines:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过打印前几行来检查响应是否是瑞典语：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Jetta bra! The `Accept-Language` header has informed the server about our preferred
    language for the response's content.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Jetta bra！`Accept-Language`标头已经告知服务器我们对响应内容的首选语言。
- en: 'To view the headers present in a request, do the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看请求中存在的标头，请执行以下操作：
- en: '[PRE14]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The `urlopen()` method adds some of its own headers when we run it on a request:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在请求上运行`urlopen()`时，`urlopen()`方法会添加一些自己的标头：
- en: '[PRE15]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'A shortcut for adding headers is to add them at the same time that we create
    the request object, as shown here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 添加标头的一种快捷方式是在创建请求对象的同时添加它们，如下所示：
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We supply the headers as a `dict` to the `Request` object constructor as the
    `headers` keyword argument. In this way, we can add multiple headers in one go,
    by adding more entries to the `dict`.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将标头作为`dict`提供给`Request`对象构造函数，作为`headers`关键字参数。通过这种方式，我们可以一次性添加多个标头，通过向`dict`添加更多条目。
- en: Let's take a look at some more things that we can do with headers.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们可以用标头做些什么其他事情。
- en: Content compression
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内容压缩
- en: The `Accept-Encoding` request header and the `Content-Encoding` response header
    can work together to allow us to temporarily encode the body of a response for
    transmission over the network. This is typically used for compressing the response
    and reducing the amount of data that needs to be transferred.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`Accept-Encoding`请求标头和`Content-Encoding`响应标头可以一起工作，允许我们临时对响应主体进行编码，以便通过网络传输。这通常用于压缩响应并减少需要传输的数据量。'
- en: 'This process follows these steps:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程遵循以下步骤：
- en: The client sends a request with acceptable encodings listed in an `Accept-Encoding`
    header
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端发送一个请求，其中在`Accept-Encoding`标头中列出了可接受的编码
- en: The server picks an encoding method that it supports
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器选择其支持的编码方法
- en: The server encodes the body using this encoding method
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器使用这种编码方法对主体进行编码
- en: The server sends the response, specifying the encoding it has used in a `Content-Encoding`
    header
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器发送响应，指定其在`Content-Encoding`标头中使用的编码
- en: The client decodes the response body using the specified encoding method
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户端使用指定的编码方法解码响应主体
- en: 'Let''s discuss how to request a document and get the server to use `gzip` compression
    for the response body. First, let''s construct the request:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论如何请求一个文档，并让服务器对响应主体使用`gzip`压缩。首先，让我们构造请求：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, add the `Accept-Encoding` header:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，添加`Accept-Encoding`标头：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And then, submit it with the help of `urlopen()`:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，借助`urlopen()`提交请求：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can check if the server is using `gzip` compression by looking at the response''s
    `Content-Encoding` header:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查看响应的`Content-Encoding`标头来检查服务器是否使用了`gzip`压缩：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can then decompress the body data by using the `gzip` module:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用`gzip`模块对主体数据进行解压：
- en: '[PRE21]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Encodings are registered with IANA. The current list contains: `gzip`, `compress`,
    `deflate`, and `identity`. The first three refer to specific compression methods.
    The last one allows the client to specify that it doesn''t want any encoding applied
    to the content.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 编码已在IANA注册。当前列表包括：`gzip`、`compress`、`deflate`和`identity`。前三个是指特定的压缩方法。最后一个允许客户端指定不希望对内容应用任何编码。
- en: 'Let''s see what happens if we ask for no compression by using the `identity`
    encoding:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如果我们使用`identity`编码来请求不进行压缩会发生什么：
- en: '[PRE22]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: When a server uses the `identity` encoding type, no `Content-Encoding` header
    is included in the response.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务器使用`identity`编码类型时，响应中不包括`Content-Encoding`标头。
- en: Multiple values
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多个值
- en: 'To tell the server that we can accept more than one encoding, add more values
    to the `Accept-Encoding` header and separate them by commas. Let''s try it. We
    create our `Request` object:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了告诉服务器我们可以接受多种编码，我们可以在`Accept-Encoding`标头中添加更多值，并用逗号分隔它们。让我们试试。我们创建我们的`Request`对象：
- en: '[PRE23]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, we add our header, and this time we include more encodings:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们添加我们的标头，这次我们包括更多的编码：
- en: '[PRE24]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, we submit the request and then check the response encoding:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们提交请求，然后检查响应的编码：
- en: '[PRE25]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If needed, relative weightings can be given to specific encodings by adding
    a `q` value:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，可以通过添加`q`值来给特定编码分配相对权重：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `q` value follows the encoding name, and it is separated by a semicolon.
    The maximum `q` value is `1.0`, and this is also the default if no `q` value is
    given. So, the preceding line should be interpreted as my first preference for
    encoding is `gzip`, my second preference is `deflate`, and my third preference
    is `identity`, if nothing else is available.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`q`值跟随编码名称，并且由分号分隔。最大的`q`值是`1.0`，如果没有给出`q`值，则默认为`1.0`。因此，前面的行应该被解释为我的首选编码是`gzip`，我的第二个首选是`deflate`，如果没有其他可用的编码，则我的第三个首选是`identity`。'
- en: Content negotiation
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内容协商
- en: 'Content compression with the `Accept-Encoding` header and language selection
    with the `Accept-Language` header are examples of **content negotiation,** where
    the client specifies its preferences regarding the format and the content of the
    requested resource. The following headers can also be used for this:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Accept-Encoding`标头进行内容压缩，使用`Accept-Language`标头进行语言选择是**内容协商**的例子，其中客户端指定其关于所请求资源的格式和内容的首选项。以下标头也可以用于此目的：
- en: '`Accept`: For requesting a preferred file format'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Accept`：请求首选文件格式'
- en: '`Accept-Charset`: For requesting the resource in a preferred character set'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Accept-Charset`：请求以首选字符集获取资源'
- en: There are additional aspects to the content negotiation mechanism, but because
    it's inconsistently supported and it can become quite involved, we won't be covering
    it in this chapter. RFC 7231 contain all the details that you need. Take a look
    at sections such as 3.4, 5.3, 6.4.1, and 6.5.6, if you find that your application
    requires this.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 内容协商机制还有其他方面，但由于支持不一致并且可能变得相当复杂，我们不会在本章中进行介绍。RFC 7231包含您需要的所有详细信息。如果您发现您的应用程序需要此功能，请查看3.4、5.3、6.4.1和6.5.6等部分。
- en: Content types
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内容类型
- en: HTTP can be used as a transport for any type of file or data. The server can
    use the `Content-Type` header in a response to inform the client about the type
    of data that it has sent in the body. This is the primary means an HTTP client
    determines how it should handle the body data that the server returns to it.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP可以用作任何类型文件或数据的传输。服务器可以在响应中使用`Content-Type`头来通知客户端有关它在主体中发送的数据类型。这是HTTP客户端确定如何处理服务器返回的主体数据的主要手段。
- en: 'To view the content type, we inspect the value of the response header, as shown
    here:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看内容类型，我们检查响应标头的值，如下所示：
- en: '[PRE27]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The values in this header are taken from a list which is maintained by IANA.
    These values are variously called **content types**, **Internet media types**,
    or **MIME types** (**MIME** stands for **Multipurpose Internet Mail Extensions**,
    the specification in which the convention was first established). The full list
    can be found at [http://www.iana.org/assignments/media-types](http://www.iana.org/assignments/media-types).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此标头中的值取自由IANA维护的列表。这些值通常称为**内容类型**、**互联网媒体类型**或**MIME类型**（**MIME**代表**多用途互联网邮件扩展**，在该规范中首次建立了这种约定）。完整列表可以在[http://www.iana.org/assignments/media-types](http://www.iana.org/assignments/media-types)找到。
- en: 'There are registered media types for many of the types of data that are transmitted
    across the Internet, some common ones are:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通过互联网传输的许多数据类型都有注册的媒体类型，一些常见的类型包括：
- en: '| Media type | Description |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 媒体类型 | 描述 |'
- en: '| --- | --- |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| text/html | HTML document |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| text/html | HTML文档 |'
- en: '| text/plain | Plain text document |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| text/plain | 纯文本文档 |'
- en: '| image/jpeg | JPG image |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| image/jpeg | JPG图像 |'
- en: '| application/pdf | PDF document |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| application/pdf | PDF文档 |'
- en: '| application/json | JSON data |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| application/json | JSON数据 |'
- en: '| application/xhtml+xml | XHTML document |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| application/xhtml+xml | XHTML文档 |'
- en: 'Another media type of interest is `application/octet-stream`, which in practice
    is used for files that don''t have an applicable media type. An example of this
    would be a pickled Python object. It is also used for files whose format is not
    known by the server. In order to handle responses with this media type correctly,
    we need to discover the format in some other way. Possible approaches are as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个感兴趣的媒体类型是`application/octet-stream`，在实践中用于没有适用的媒体类型的文件。这种情况的一个例子是一个经过pickle处理的Python对象。它还用于服务器不知道格式的文件。为了正确处理具有此媒体类型的响应，我们需要以其他方式发现格式。可能的方法如下：
- en: Examine the filename extension of the downloaded resource, if it has one. The
    `mimetypes` module can then be used for determining the media type (go to [Chapter
    3](ch03.html "Chapter 3. APIs in Action"), *APIs in Action* to see an example
    of this).
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查已下载资源的文件名扩展名（如果有）。然后可以使用`mimetypes`模块来确定媒体类型（转到[第3章](ch03.html "第3章。APIs in
    Action")，*APIs in Action*，以查看此示例）。
- en: Download the data and then use a file type analysis tool. TheUse the Python
    standard library `imghdr` module can be used for images, and the third-party `python-magic`
    package, or the `GNU` file command, can be used for other types.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载数据，然后使用文件类型分析工具。对于图像，可以使用Python标准库的`imghdr`模块，对于其他类型，可以使用第三方的`python-magic`包或`GNU`文件命令。
- en: Check the website that we're downloading from to see if the file type has been
    documented anywhere.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查我们正在下载的网站，看看文件类型是否已经在任何地方有文档记录。
- en: 'Content type values can contain optional additional parameters that provide
    further information about the type. This is usually used to supply the character
    set that the data uses. For example:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 内容类型值可以包含可选的附加参数，提供有关类型的进一步信息。这通常用于提供数据使用的字符集。例如：
- en: '[PRE28]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In this case, we're being told that the character set of the document is UTF-8\.
    The parameter is included after a semicolon, and it always takes the form of a
    key/value pair.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们被告知文档的字符集是UTF-8。参数在分号后面包括，并且它总是采用键/值对的形式。
- en: 'Let''s discuss an example, downloading the Python home page and using the `Content-Type`
    value it returns. First, we submit our request:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一个例子，下载Python主页并使用它返回的`Content-Type`值。首先，我们提交我们的请求：
- en: '[PRE29]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, we check the `Content-Type` value of our response, and extract the character
    set:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们检查响应的`Content-Type`值，并提取字符集：
- en: '[PRE30]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Lastly, we decode our response content by using the supplied character set:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过使用提供的字符集来解码我们的响应内容：
- en: '[PRE31]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note that quite often, the server either doesn't supply a `charset` in the `Content-Type`
    header, or it supplies the wrong `charset`. So, this value should be taken as
    a suggestion. This is one of the reasons that we look at the `Requests` library
    later in this chapter. It will automatically gather all the hints that it can
    find about what character set should be used for decoding a response body and
    make a best guess for us.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，服务器通常要么在`Content-Type`头中不提供`charset`，要么提供错误的`charset`。因此，这个值应该被视为一个建议。这是我们稍后在本章中查看`Requests`库的原因之一。它将自动收集关于解码响应主体应该使用的字符集的所有提示，并为我们做出最佳猜测。
- en: User agents
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户代理
- en: 'Another request header worth knowing about is the `User-Agent` header. Any
    client that communicates using HTTP can be referred to as a **user agent**. RFC
    7231 suggests that user agents should use the `User-Agent` header to identify
    themselves in every request. What goes in there is up to the software that makes
    the request, though it usually comprises a string that identifies the program
    and version, and possibly the operating system and the hardware that it''s running
    on. For example, the user agent for my current version of Firefox is shown here:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得了解的请求头是`User-Agent`头。使用HTTP通信的任何客户端都可以称为**用户代理**。RFC 7231建议用户代理应该在每个请求中使用`User-Agent`头来标识自己。放在那里的内容取决于发出请求的软件，尽管通常包括一个标识程序和版本的字符串，可能还包括操作系统和运行的硬件。例如，我当前版本的Firefox的用户代理如下所示：
- en: '[PRE32]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Although it has been broken over two lines here, it is a single long string.
    As you can probably decipher, I'm running Iceweasel (Debian's version of Firefox)
    version 24 on a 64-bit Linux system. User agent strings aren't intended for identifying
    individual users. They only identify the product that was used for making the
    request.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这里被分成了两行，但它是一个单独的长字符串。正如你可能能够解释的那样，我正在运行Iceweasel（Debian版的Firefox）24版本，运行在64位Linux系统上。用户代理字符串并不是用来识别个别用户的。它们只标识用于发出请求的产品。
- en: 'We can view the user agent that `urllib` uses. Perform the following steps:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看`urllib`使用的用户代理。执行以下步骤：
- en: '[PRE33]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, we have created a request and submitted it using `urlopen`, and `urlopen`
    added the user agent header to the request. We can examine this header by using
    the `get_header()` method. This header and its value are included in every request
    made by `urllib`, so every server we make a request to can see that we are using
    Python 3.4 and the `urllib` library.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个请求并使用`urlopen`提交了它，`urlopen`添加了用户代理头到请求中。我们可以使用`get_header()`方法来检查这个头。这个头和它的值包含在`urllib`发出的每个请求中，所以我们向每个服务器发出请求时都可以看到我们正在使用Python
    3.4和`urllib`库。
- en: 'Webmasters can inspect the user agents of requests and then use the information
    for various things, including the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 网站管理员可以检查请求的用户代理，然后将这些信息用于各种用途，包括以下内容：
- en: Classifying visits for their website statistics
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了他们的网站统计分类访问
- en: Blocking clients with certain user agent strings
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻止具有特定用户代理字符串的客户端
- en: Sending alternative versions of resources for user agents with known problems,
    such as bugs when interpreting certain languages like CSS, or not supporting some
    languages at all, such as JavaScript
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送给已知问题的用户代理的资源的替代版本，比如在解释某些语言（如CSS）时出现的错误，或者根本不支持某些语言（比如JavaScript）。
- en: 'The last two can cause problems for us because they can stop or interfere with
    us accessing the content that we''re after. To work around this, we can try and
    set our user agent so that it mimics a well known browser. This is known as **spoofing**,
    as shown here:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个可能会给我们带来问题，因为它们可能会阻止或干扰我们访问我们想要的内容。为了解决这个问题，我们可以尝试设置我们的用户代理，使其模拟一个知名的浏览器。这就是所谓的**欺骗**，如下所示：
- en: '[PRE34]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The server will respond as if our application is a regular Firefox client. User
    agent strings for different browsers are available on the web. I'm yet to come
    across a comprehensive resource for them, but Googling for a browser and version
    number will usually turn something up. Alternatively you can use Wireshark to
    capture an HTTP request made by the browser you want to emulate and look at the
    captured request's user agent header.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器将会响应，就好像我们的应用程序是一个普通的Firefox客户端。不同浏览器的用户代理字符串可以在网上找到。我还没有找到一个全面的资源，但是通过谷歌搜索浏览器和版本号通常会找到一些信息。或者你可以使用Wireshark来捕获浏览器发出的HTTP请求，并查看捕获的请求的用户代理头。
- en: Cookies
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Cookies
- en: A cookie is a small piece of data that the server sends in a `Set-Cookie` header
    as a part of the response. The client stores cookies locally and includes them
    in any future requests that are sent to the server.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Cookie是服务器在响应的一部分中以`Set-Cookie`头发送的一小段数据。客户端会将cookie存储在本地，并在以后发送到服务器的任何请求中包含它们。
- en: Servers use cookies in various ways. They can add a unique ID to them, which
    enables them to track a client as it accesses different areas of a site. They
    can store a login token, which will automatically log the client in, even if the
    client leaves the site and then accesses it later. They can also be used for storing
    the client's user preferences or snippets of personalizing information, and so
    on.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器以各种方式使用cookie。它们可以向其中添加一个唯一的ID，这使它们能够跟踪客户端访问站点的不同区域。它们可以存储一个登录令牌，这将自动登录客户端，即使客户端离开站点然后以后再次访问。它们也可以用于存储客户端的用户偏好或个性化信息的片段，等等。
- en: Cookies are necessary because the server has no other way of tracking a client
    between requests. HTTP is called a **stateless** protocol. It doesn't contain
    an explicit mechanism for a server to know for sure that two requests have come
    from the same client. Without cookies to allow the server to add some uniquely
    identifying information to the requests, things such as shopping carts (which
    were the original problem that cookies were developed to solve) would become impossible
    to build, because the server would not be able to determine which basket goes
    with which request.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Cookie是必需的，因为服务器没有其他方式在请求之间跟踪客户端。HTTP被称为**无状态**协议。它不包含一个明确的机制，让服务器确切地知道两个请求是否来自同一个客户端。如果没有cookie允许服务器向请求添加一些唯一标识信息，像购物车（这是cookie开发的最初问题）这样的东西将变得不可能构建，因为服务器将无法确定哪个篮子对应哪个请求。
- en: We may need to handle cookies in Python because without them, some sites don't
    behave as expected. When using Python, we may also want to access the parts of
    a site which require a login, and the login sessions are usually maintained through
    cookies.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能需要在Python中处理cookie，因为没有它们，一些网站的行为不如预期。在使用Python时，我们可能还想访问需要登录的站点的部分，登录会话通常通过cookie来维护。
- en: Cookie handling
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Cookie处理
- en: 'We''re going to discuss how to handle cookies with `urllib`. First, we need
    to create a place for storing the cookies that the server will send us:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论如何使用`urllib`处理cookie。首先，我们需要创建一个存储服务器将发送给我们的cookie的地方：
- en: '[PRE35]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, we build something called an `urllib` `opener` **.** This will automatically
    extract the cookies from the responses that we receive and then store them in
    our cookie jar:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们构建一个名为`urllib` `opener` **的东西。这将自动从我们收到的响应中提取cookie，然后将它们存储在我们的cookie
    jar中：
- en: '[PRE36]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Then, we can use our opener to make an HTTP request:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用我们的opener来发出HTTP请求：
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Lastly, we can check that the server has sent us some cookies:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以检查服务器是否发送了一些cookie：
- en: '[PRE38]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Whenever we use `opener` to make further requests, the `HTTPCookieProcessor`
    functionality will check our `cookie_jar` to see if it contains any cookies for
    that site and then it will automatically add them to our requests. It will also
    add any further cookies that are received to the cookie jar.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们使用`opener`发出进一步的请求时，`HTTPCookieProcessor`功能将检查我们的`cookie_jar`，看它是否包含该站点的任何cookie，然后自动将它们添加到我们的请求中。它还将接收到的任何进一步的cookie添加到cookie
    jar中。
- en: The `http.cookiejar` module also contains a `FileCookieJar` class, that works
    in the same way as `CookieJar`, but it provides an additional function for easily
    saving the cookies to a file. This allows persistence of cookies across Python
    sessions.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`http.cookiejar`模块还包含一个`FileCookieJar`类，它的工作方式与`CookieJar`相同，但它提供了一个额外的函数，用于轻松地将cookie保存到文件中。这允许在Python会话之间持久保存cookie。'
- en: Know your cookies
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解您的cookie
- en: It's worth looking at the properties of cookies in more detail. Let's examine
    the cookies that GitHub sent us in the preceding section.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 值得更详细地查看cookie的属性。让我们来检查GitHub在前一节中发送给我们的cookie。
- en: 'To do this, we need to pull the cookies out of the cookie jar. The `CookieJar`
    module doesn''t let us access them directly, but it supports the iterator protocol.
    So, a quick way of getting them is to create a `list` from it:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要从cookie jar中取出cookie。`CookieJar`模块不允许我们直接访问它们，但它支持迭代器协议。因此，一个快速获取它们的方法是从中创建一个`list`：
- en: '[PRE39]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You can see that we have two `Cookie` objects. Now, let''s pull out some information
    from the first one:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到我们有两个`Cookie`对象。现在，让我们从第一个对象中提取一些信息：
- en: '[PRE40]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The cookie''s name allows the server to quickly reference it. This cookie is
    clearly a part of the mechanism that GitHub uses for finding out whether we''ve
    logged in yet. Next, let''s do the following:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: cookie的名称允许服务器快速引用它。这个cookie显然是GitHub用来查明我们是否已经登录的机制的一部分。接下来，让我们做以下事情：
- en: '[PRE41]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The domain and the path are the areas for which this cookie is valid, so our
    `urllib` opener will include this cookie in any request that it sends to [www.github.com](http://www.github.com)
    and its sub-domains, where the path is anywhere below the root.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 域和路径是此cookie有效的区域，因此我们的`urllib` opener将在发送到[www.github.com](http://www.github.com)及其子域的任何请求中包含此cookie，其中路径位于根目录下方的任何位置。
- en: 'Now, let''s look at the cookie''s lifetime:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下cookie的生命周期：
- en: '[PRE42]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This is a Unix timestamp; we can convert it to `datetime`:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个Unix时间戳；我们可以将其转换为`datetime`：
- en: '[PRE43]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: So, our cookie will expire on 22nd of April, 2035\. An expiry date is the amount
    of time that the server would like the client to hold on to the cookie for. Once
    the expiry date has passed, the client can throw the cookie away and the server
    will send a new one with the next request. Of course, there's nothing to stop
    a client from immediately throwing the cookie away, though on some sites this
    may break functionality that depends on the cookie.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的cookie将在2035年4月22日到期。到期日期是服务器希望客户端保留cookie的时间。一旦到期日期过去，客户端可以丢弃cookie，并且服务器将在下一个请求中发送一个新的cookie。当然，没有什么能阻止客户端立即丢弃cookie，尽管在一些站点上，这可能会破坏依赖cookie的功能。
- en: 'Let''s discuss two common cookie flags:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论两个常见的cookie标志：
- en: '[PRE44]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Cookies that are stored on a client can be accessed in a number of ways:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在客户端上的cookie可以通过多种方式访问：
- en: By the client as part of an HTTP request and response sequence
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由客户端作为HTTP请求和响应序列的一部分
- en: By scripts running in the client, such as JavaScript
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由客户端中运行的脚本，比如JavaScript
- en: By other processes running in the client, such as Flash
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由客户端中运行的其他进程，比如Flash
- en: The `HttpOnly` flag indicates that the client should only allow access to a
    cookie when the access is part of an HTTP request or response. The other methods
    should be denied access. This will protect the client against Cross-site scripting
    attacks (see [Chapter 9](ch09.html "Chapter 9. Applications for the Web"), *Applications
    for the Web*, for more information on these). This is an important security feature,
    and when the server sets it, our application should behaves accordingly.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`HttpOnly`标志表示客户端只有在HTTP请求或响应的一部分时才允许访问cookie。其他方法应该被拒绝访问。这将保护客户端免受跨站脚本攻击的影响（有关这些攻击的更多信息，请参见[第9章](ch09.html
    "第9章。Web应用程序")*Web应用程序*）。这是一个重要的安全功能，当服务器设置它时，我们的应用程序应该相应地行事。'
- en: 'There is also a `secure` flag:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个`secure`标志：
- en: '[PRE45]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: If the value is true, the `Secure` flag indicates that the cookie should only
    ever be sent over a secure connection, such as HTTPS. Again, we should honor this
    if the flag has been set such that when our application send requests containing
    this cookie, it only sends them to HTTPS URLs.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果值为true，则`Secure`标志表示cookie只能通过安全连接发送，例如HTTPS。同样，如果已设置该标志，我们应该遵守这一点，这样当我们的应用程序发送包含此cookie的请求时，它只会将它们发送到HTTPS
    URL。
- en: You may have spotted an inconsistency here. Our URL has requested a response
    over HTTP, yet the server has sent us a cookie, which it's requesting to be sent
    only over secure connections. Surely the site designers didn't overlook a security
    loophole like that? Rest assured; they didn't. The response was actually sent
    over HTTPS. But, how did that happen? Well, the answer lies with redirects.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经发现了一个不一致之处。我们的URL已经请求了一个HTTP响应，然而服务器却发送了一个cookie给我们，要求它只能在安全连接上发送。网站设计者肯定没有忽视这样的安全漏洞吧？请放心，他们没有。实际上，响应是通过HTTPS发送的。但是，这是如何发生的呢？答案就在于重定向。
- en: Redirects
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重定向
- en: Sometimes servers move their content around. They also make some content obsolete
    and put up new stuff in a different location. Sometimes they'd like us to use
    the more secure HTTPS protocol instead of HTTP. In all these cases, they may get
    traffic that asks for the old URLs, and in all these cases they'd probably prefer
    to be able to automatically send visitors to the new ones.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 有时服务器会移动它们的内容。它们还会使一些内容过时，并在不同的位置放上新的东西。有时他们希望我们使用更安全的HTTPS协议而不是HTTP。在所有这些情况下，他们可能会得到请求旧URL的流量，并且在所有这些情况下，他们可能更愿意能够自动将访问者发送到新的URL。
- en: The 300 range of HTTP status codes is designed for this purpose. These codes
    indicate to the client that further action is required on their part to complete
    the request. The most commonly encountered action is to retry the request at a
    different URL. This is called a **redirect**.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP状态码的300系列是为此目的而设计的。这些代码指示客户端需要采取进一步的行动才能完成请求。最常见的操作是在不同的URL上重试请求。这被称为**重定向**。
- en: 'We''ll learn how this works when using `urllib`. Let''s make a request:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习在使用`urllib`时如何工作。让我们发出一个请求：
- en: '[PRE46]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Simple enough, but now, look at the URL of the response:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单，但现在，看一下响应的URL：
- en: '[PRE47]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This is not the URL that we requested! If we open this new URL in a browser,
    then we''ll see that it''s actually the Google login page (you may need to clear
    your browser cookies to see this if you already have a cached Google login session).
    Google redirected us from [http://www.gmail.com](http://www.gmail.com) to its
    login page, and `urllib` automatically followed the redirect. Moreover, we may
    have been redirected more than once. Look at the `redirect_dict` attribute of
    our request object:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是我们请求的URL！如果我们在浏览器中打开这个新的URL，我们会发现这实际上是Google的登录页面（如果您已经有缓存的Google登录会话，则可能需要清除浏览器的cookie才能看到这一点）。Google将我们从[http://www.gmail.com](http://www.gmail.com)重定向到其登录页面，`urllib`自动跟随了重定向。此外，我们可能已经被重定向了多次。看一下我们请求对象的`redirect_dict`属性：
- en: '[PRE48]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The `urllib` package adds every URL that we were redirected through to this
    `dict`. We can see that we have actually been redirected twice, first to [https://mail.google.com](https://mail.google.com),
    and second to the login page.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib`包将我们通过的每个URL添加到这个`dict`中。我们可以看到我们实际上被重定向了两次，首先是到[https://mail.google.com](https://mail.google.com)，然后是到登录页面。'
- en: When we send our first request, the server sends a response with a redirect
    status code, one of 301, 302, 303, or 307\. All of these indicate a redirect.
    This response includes a `Location` header, which contains the new URL. The `urllib`
    package will submit a new request to that URL, and in the aforementioned case,
    it will receive yet another redirect, which will lead it to the Google login page.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们发送第一个请求时，服务器会发送一个带有重定向状态代码的响应，其中之一是301、302、303或307。所有这些都表示重定向。此响应包括一个`Location`头，其中包含新的URL。`urllib`包将向该URL提交一个新的请求，在上述情况下，它将收到另一个重定向，这将导致它到达Google登录页面。
- en: Since `urllib` follows redirects for us, they generally don't affect us, but
    it's worth knowing that a response `urllib` returns may be for a URL different
    from what we had requested. Also, if we hit too many redirects for a single request
    (more than 10 for `urllib`), then `urllib` will give up and raise an `urllib.error.HTTPError`
    exception.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`urllib`为我们跟随重定向，它们通常不会影响我们，但值得知道的是，`urllib`返回的响应可能是与我们请求的URL不同的URL。此外，如果我们对单个请求进行了太多次重定向（对于`urllib`超过10次），那么`urllib`将放弃并引发`urllib.error.HTTPError`异常。
- en: URLs
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: URL
- en: Uniform Resource Locators, or **URL**s are fundamental to the way in which the
    web operates, and they have been formally described in RFC 3986\. A URL represents
    a resource on a given host. How URLs map to the resources on the remote system
    is entirely at the discretion of the system admin. URLs can point to files on
    the server, or the resources may be dynamically generated when a request is received.
    What the URL maps to though doesn't matter as long as the URLs work when we request
    them.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 统一资源定位符，或者**URL**是Web操作的基础，它们已经在RFC 3986中正式描述。URL代表主机上的资源。URL如何映射到远程系统上的资源完全取决于系统管理员的决定。URL可以指向服务器上的文件，或者在收到请求时资源可能是动态生成的。只要我们请求时URL有效，URL映射到什么并不重要。
- en: 'URLs are comprised of several sections. Python uses the `urllib.parse` module
    for working with URLs. Let''s use Python to break a URL into its component parts:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: URL由几个部分组成。Python使用`urllib.parse`模块来处理URL。让我们使用Python将URL分解为其组成部分：
- en: '[PRE49]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The `urllib.parse.urlparse()` function interprets our URL and recognizes `http`
    as the **scheme**, [https://www.python.org/](https://www.python.org/) as the **network
    location**, and `/dev/peps` as the **path**. We can access these components as
    attributes of the `ParseResult`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.parse.urlparse()`函数解释了我们的URL，并识别`http`作为**方案**，[https://www.python.org/](https://www.python.org/)作为**网络位置**，`/dev/peps`作为**路径**。我们可以将这些组件作为`ParseResult`的属性来访问：'
- en: '[PRE50]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: For almost all resources on the web, we'll be using the `http` or `https` schemes.
    In these schemes, to locate a specific resource, we need to know the host that
    it resides on and the TCP port that we should connect to (together these are the
    `netloc` component), and we also need to know the path to the resource on the
    host (the `path` component).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对于网上几乎所有的资源，我们将使用`http`或`https`方案。在这些方案中，要定位特定的资源，我们需要知道它所在的主机和我们应该连接到的TCP端口（这些组合在一起是`netloc`组件），我们还需要知道主机上资源的路径（`path`组件）。
- en: Port numbers can be specified explicitly in a URL by appending them to the host.
    They are separated from the host by a colon. Let's see what happens when we try
    this with `urlparse`.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过将端口号附加到主机后来在URL中明确指定端口号。它们与主机之间用冒号分隔。让我们看看当我们尝试使用`urlparse`时会发生什么。
- en: '[PRE51]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `urlparse` method just interprets it as a part of the netloc. This is fine
    because this is how handlers such as `urllib.request.urlopen()` expect it to be
    formatted.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '`urlparse`方法只是将其解释为netloc的一部分。这没问题，因为这是`urllib.request.urlopen()`等处理程序期望它格式化的方式。'
- en: If we don't supply a port (as is usually the case), then the default port 80
    is used for `http`, and the default port 443 is used for `https`. This is usually
    what we want, as these are the standard ports for the HTTP and HTTPS protocols
    respectively.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不提供端口（通常情况下），那么`http`将使用默认端口80，`https`将使用默认端口443。这通常是我们想要的，因为这些是HTTP和HTTPS协议的标准端口。
- en: Paths and relative URLs
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 路径和相对URL
- en: 'The path in a URL is anything that comes after the host and the port. Paths
    always start with a forward-slash (`/`), and when just a slash appears on its
    own, it''s called the **root**. We can see this by performing the following:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: URL中的路径是指主机和端口之后的任何内容。路径总是以斜杠(`/`)开头，当只有一个斜杠时，它被称为**根**。我们可以通过以下操作来验证这一点：
- en: '[PRE52]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: If no path is supplied in a request, then by default `urllib` will send a request
    for the root.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果请求中没有提供路径，默认情况下`urllib`将发送一个请求以获取根目录。
- en: 'When a scheme and a host are included in a URL (as in the previous example),
    the URL is called an **absolute URL**. Conversely, it''s possible to have **relative
    URL**s, which contain just a path component, as shown here:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 当URL中包含方案和主机时（如前面的例子），该URL被称为**绝对URL**。相反，也可能有**相对URL**，它只包含路径组件，如下所示：
- en: '[PRE53]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: We can see that `ParseResult` only contains a `path.` If we want to use a relative
    URL to request a resource, then we need to supply the missing scheme, the host,
    and the base path.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到`ParseResult`只包含一个`path`。如果我们想要使用相对URL请求资源，那么我们需要提供缺失的方案、主机和基本路径。
- en: Usually, we encounter relative URLs in a resource that we've already retrieved
    from a URL. So, we can just use this resource's URL to fill in the missing components.
    Let's look at an example.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们在已从URL检索到的资源中遇到相对URL。因此，我们可以使用该资源的URL来填充缺失的组件。让我们看一个例子。
- en: Suppose that we've retrieved the [http://www.debian.org](http://www.debian.org)
    URL, and within the webpage source code we found the relative URL for the 'About'
    page. We found that it's a relative URL for `intro/about`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经检索到了[http://www.debian.org](http://www.debian.org)的URL，并且在网页源代码中找到了“关于”页面的相对URL。我们发现它是`intro/about`的相对URL。
- en: 'We can create an absolute URL by using the URL for the original page and the
    `urllib.parse.urljoin()` function. Let''s see how we can do this:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用原始页面的URL和`urllib.parse.urljoin()`函数来创建绝对URL。让我们看看我们可以如何做到这一点：
- en: '[PRE54]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: By supplying `urljoin` with a base URL, and a relative URL, we've created a
    new absolute URL.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向`urljoin`提供基本URL和相对URL，我们创建了一个新的绝对URL。
- en: Here, notice how `urljoin` has filled in the slash between the host and the
    path. The only time that `urljoin` will fill in a slash for us is when the base
    URL does not have a path, as shown in the preceding example. Let's see what happens
    if the base URL does have a path.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，注意`urljoin`是如何在主机和路径之间填充斜杠的。只有当基本URL没有路径时，`urljoin`才会为我们填充斜杠，就像前面的例子中所示的那样。让我们看看如果基本URL有路径会发生什么。
- en: '[PRE55]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: This will give us varying results. Notice how `urljoin` appends to the path
    if the base URL ends in a slash, but it replaces the last path element in the
    base URL if the base URL doesn't end in a slash.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们带来不同的结果。请注意，如果基本URL以斜杠结尾，`urljoin`会将其附加到路径，但如果基本URL不以斜杠结尾，它将替换基本URL中的最后一个路径元素。
- en: 'We can force a path to replace all the elements of a base URL by prefixing
    it with a slash. Do the following:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在路径前加上斜杠来强制路径替换基本URL的所有元素。按照以下步骤进行：
- en: '[PRE56]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'How about navigating to parent directories? Let''s try the standard dot syntax,
    as shown here:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如何导航到父目录？让我们尝试标准的点语法，如下所示：
- en: '[PRE57]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: It work as we'd expect it to. Note the difference between the base URL having
    and not having a trailing slash.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 它按我们的预期工作。注意基本URL是否有尾随斜杠的区别。
- en: 'Lastly, what if the ''relative'' URL is actually an absolute URL:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果“相对”URL实际上是绝对URL呢：
- en: '[PRE58]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The relative URL completely replaces the base URL. This is handy, as it means
    that we don't need to worry about testing whether a URL is relative or not before
    using it with `urljoin`.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 相对URL完全替换了基本URL。这很方便，因为这意味着我们在使用`urljoin`时不需要担心URL是相对的还是绝对的。
- en: Query strings
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询字符串
- en: 'RFC 3986 defines another property of URLs. They can contain additional parameters
    in the form of key/value pairs that appear after the path. They are separated
    from the path by a question mark, as shown here:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: RFC 3986定义了URL的另一个属性。它们可以包含在路径之后以键/值对形式出现的附加参数。它们通过问号与路径分隔，如下所示：
- en: '[http://docs.python.org/3/search.html?q=urlparse&area=default](http://docs.python.org/3/search.html?q=urlparse&area=default)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://docs.python.org/3/search.html?q=urlparse&area=default](http://docs.python.org/3/search.html?q=urlparse&area=default)'
- en: 'This string of parameters is called a query string. Multiple parameters are
    separated by ampersands (`&`). Let''s see how `urlparse` handles it:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这一系列参数称为查询字符串。多个参数由`&`分隔。让我们看看`urlparse`如何处理它：
- en: '[PRE59]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: So, `urlparse` recognizes the query string as the `query` component.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`urlparse`将查询字符串识别为`query`组件。
- en: Query strings are used for supplying parameters to the resource that we wish
    to retrieve, and this usually customizes the resource in some way. In the aforementioned
    example, our query string tells the Python docs search page that we want to run
    a search for the term `urlparse`.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 查询字符串用于向我们希望检索的资源提供参数，并且通常以某种方式自定义资源。在上述示例中，我们的查询字符串告诉Python文档搜索页面，我们要搜索术语`urlparse`。
- en: 'The `urllib.parse` module has a function that helps us turn the `query` component
    returned by `urlparse` into something more useful:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`urllib.parse`模块有一个函数，可以帮助我们将`urlparse`返回的`query`组件转换为更有用的内容：'
- en: '[PRE60]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The `parse_qs()` method reads the query string and then converts it into a
    dictionary. See how the dictionary values are actually in the form of lists? This
    is because parameters can appear more than once in a query string. Try it with
    a repeated parameter:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '`parse_qs()` 方法读取查询字符串，然后将其转换为字典。看看字典值实际上是以列表的形式存在的？这是因为参数可以在查询字符串中出现多次。尝试使用重复参数：'
- en: '[PRE61]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: See how both of the values have been added to the list? It's up to the server
    to decide how it interprets this. If we send this query string, then it may just
    pick one of the values and use that, while ignoring the repeat. You can only try
    it, and see what happens.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 看看这两个值都已添加到列表中？由服务器决定如何解释这一点。如果我们发送这个查询字符串，那么它可能只选择一个值并使用它，同时忽略重复。您只能尝试一下，看看会发生什么。
- en: You can usually figure out what you need to put in a query string for a given
    page by submitting a query through the web interface using your web browser, and
    inspecting the URL of the results page. You should be able to spot the text of
    your search and consequently deduce the corresponding key for the search text.
    Quite often, many of the other parameters in the query string aren't actually
    needed for getting a basic result. Try requesting the page using only the search
    text parameter and see what happens. Then, add the other parameters, if it does
    not work as expected.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您可以通过使用Web浏览器通过Web界面提交查询并检查结果页面的URL来弄清楚对于给定页面需要在查询字符串中放置什么。您应该能够找到搜索文本的文本，从而推断出搜索文本的相应键。很多时候，查询字符串中的许多其他参数实际上并不需要获得基本结果。尝试仅使用搜索文本参数请求页面，然后查看发生了什么。然后，如果预期的结果没有实现，添加其他参数。
- en: If you submit a form to a page and the resulting page's URL doesn't have a query
    string, then the page would have used a different method for sending the form
    data. We'll look at this in the *HTTP methods* section in the following, while
    discussing the POST method.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您向页面提交表单并且结果页面的URL没有查询字符串，则该页面将使用不同的方法发送表单数据。我们将在接下来的*HTTP方法*部分中查看这一点，同时讨论POST方法。
- en: URL encoding
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: URL编码
- en: 'URLs are restricted to the ASCII characters and within this set, a number of
    characters are reserved and need to be escaped in different components of a URL.
    We escape them by using something called URL encoding. It is often called **percent
    encoding**, because it uses the percent sign as an escape character. Let''s URL-encode
    a string:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: URL仅限于ASCII字符，并且在此集合中，许多字符是保留字符，并且需要在URL的不同组件中进行转义。我们通过使用称为URL编码的东西来对它们进行转义。它通常被称为**百分比编码**，因为它使用百分号作为转义字符。让我们对字符串进行URL编码：
- en: '[PRE62]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The special characters `' '` and `?` have been replaced by escape sequences.
    The numbers in the escape sequences are the characters' ASCII codes in hexadecimal.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊字符`' '`和`?`已被转换为转义序列。转义序列中的数字是十六进制中的字符ASCII代码。
- en: The full rules for where the reserved characters need to be escaped are given
    in RFC 3986, however `urllib` provides us with a couple of methods for helping
    us construct URLs. This means that we don't need to memorize all of these!
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 需要转义保留字符的完整规则在RFC 3986中给出，但是`urllib`为我们提供了一些帮助我们构造URL的方法。这意味着我们不需要记住所有这些！
- en: 'We just need to:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要：
- en: URL-encode the path
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对路径进行URL编码
- en: URL-encode the query string
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对查询字符串进行URL编码
- en: Combine them by using the `urllib.parse.urlunparse()` function
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`urllib.parse.urlunparse()`函数将它们组合起来
- en: 'Let''s see how to use the aforementioned steps in code. First, we encode the
    path:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在代码中使用上述步骤。首先，我们对路径进行编码：
- en: '[PRE63]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Then, we encode the query string:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们对查询字符串进行编码：
- en: '[PRE64]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Lastly, we compose everything into a URL:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将所有内容组合成一个URL：
- en: '[PRE65]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The `quote()` function has been setup for specifically encoding paths. By default,
    it ignores slash characters and it doesn''t encode them. This isn''t obvious in
    the preceding example, try the following to see how this works:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '`quote()`函数已经设置用于特定编码路径。默认情况下，它会忽略斜杠字符并且不对其进行编码。在前面的示例中，这并不明显，尝试以下内容以查看其工作原理：'
- en: '[PRE66]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Notice that it ignores the slashes, but it escapes the `+`. That is perfect
    for paths.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，它忽略了斜杠，但转义了`+`。这对路径来说是完美的。
- en: The `urlencode()` function is similarly intended for encoding query strings
    directly from dicts. Notice how it correctly percent encodes our values and then
    joins them with `&`, so as to construct the query string.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '`urlencode()`函数类似地用于直接从字典编码查询字符串。请注意，它如何正确地对我们的值进行百分比编码，然后使用`&`将它们连接起来，以构造查询字符串。'
- en: Lastly, the `urlunparse()` method expects a 6-tuple containing the elements
    matching those of the result of `urlparse()`, hence the two empty strings.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`urlunparse()`方法期望包含与`urlparse()`结果匹配的元素的6元组，因此有两个空字符串。
- en: 'There is a caveat for path encoding. If the elements of a path themselves contain
    slashes, then we may run into problems. The example is shown in the following
    commands:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 对于路径编码有一个注意事项。如果路径的元素本身包含斜杠，那么我们可能会遇到问题。示例在以下命令中显示：
- en: '[PRE67]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Notice how the slash in the username doesn''t get escaped? This will be incorrectly
    interpreted as an extra level of directory structure, which is not what we want.
    In order to get around this, first we need to individually escape any path elements
    that may contain slashes, and then join them manually:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 注意用户名中的斜杠没有被转义吗？这将被错误地解释为额外的目录结构，这不是我们想要的。为了解决这个问题，首先我们需要单独转义可能包含斜杠的路径元素，然后手动连接它们：
- en: '[PRE68]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Notice how the username slash is now percent-encoded? We encode the username
    separately, telling `quote` not to ignore slashes by supplying the `safe=''` argument,
    which overwrites its default ignore list of `/`. Then, we combine the path elements
    by using a simple `join()` function.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 注意用户名斜杠现在是百分比编码了吗？我们单独对用户名进行编码，告诉`quote`不要忽略斜杠，通过提供`safe=''`参数来覆盖其默认的忽略列表`/`。然后，我们使用简单的`join()`函数组合路径元素。
- en: Here, it's worth mentioning that hostnames sent over the wire must be strictly
    ASCII, however the `socket` and `http` modules support transparent encoding of
    Unicode hostnames to an ASCII-compatible encoding, so in practice we don't need
    to worry about encoding hostnames. There are more details about this process in
    the `encodings.idna` section of the `codecs` module documentation.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，值得一提的是，通过网络发送的主机名必须严格遵循ASCII，但是`socket`和`http`模块支持将Unicode主机名透明地编码为ASCII兼容的编码，因此在实践中我们不需要担心编码主机名。关于这个过程的更多细节可以在`codecs`模块文档的`encodings.idna`部分找到。
- en: URLs in summary
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: URL总结
- en: 'There are quite a few functions that we''ve used in the preceding sections.
    Let''s just review what we have used each function for. All of these functions
    can be found in the `urllib.parse` module. They are as follows:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，我们使用了相当多的函数。让我们简要回顾一下我们每个函数的用途。所有这些函数都可以在`urllib.parse`模块中找到。它们如下：
- en: 'Splitting a URL into its components: `urlparse`'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将URL拆分为其组件：`urlparse`
- en: 'Combining an absolute URL with a relative URL: `urljoin`'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将绝对URL与相对URL组合：`urljoin`
- en: 'Parsing a query string into a `dict`: `parse_qs`'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将查询字符串解析为`dict`：`parse_qs`
- en: 'URL-encoding a path: `quote`'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对路径进行URL编码：`quote`
- en: 'Creating a URL-encoded query string from a `dict`: `urlencode`'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`dict`创建URL编码的查询字符串：`urlencode`
- en: 'Creating a URL from components (reverse of `urlparse`): `urlunparse`'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从组件创建URL（`urlparse`的反向）：`urlunparse`
- en: HTTP methods
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTP方法
- en: So far, we've been using requests for asking servers to send web resources to
    us, but HTTP provides more actions that we can perform. The `GET` in our request
    lines is an HTTP **method**, and there are several methods, such as `HEAD`, `POST`,
    `OPTION`, `PUT`, `DELETE`, `TRACE`, `CONNECT`, and `PATCH`.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在使用请求来请求服务器向我们发送网络资源，但是HTTP提供了更多我们可以执行的操作。我们请求行中的`GET`是一个HTTP **方法**，有几种方法，比如`HEAD`、`POST`、`OPTION`、`PUT`、`DELETE`、`TRACE`、`CONNECT`和`PATCH`。
- en: We'll be looking at several of these in some detail in the next chapter, but
    there are two methods, we're going to take a quick look at now.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中详细讨论其中的一些，但现在我们将快速查看两种方法。
- en: The HEAD method
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HEAD方法
- en: The `HEAD` method is the same as the `GET` method. The only difference is that
    the server will never include a body in the response, even if there is a valid
    resource at the requested URL. The `HEAD` method is used for checking if a resource
    exists or if it has changed. Note that some servers don't implement this method,
    but when they do, it can prove to be a huge bandwidth saver.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`HEAD`方法与`GET`方法相同。唯一的区别是服务器永远不会在响应中包含正文，即使在请求的URL上有一个有效的资源。`HEAD`方法用于检查资源是否存在或是否已更改。请注意，一些服务器不实现此方法，但当它们这样做时，它可以证明是一个巨大的带宽节省者。'
- en: 'We use alternative methods with `urllib` by supplying the method name to a
    `Request` object when we create it:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`urllib`中的替代方法，通过在创建`Request`对象时提供方法名称：
- en: '[PRE69]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Here the server has returned a `200 OK` response, yet the body is empty, as
    expected.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 这里服务器返回了一个`200 OK`响应，但是正文是空的，这是预期的。
- en: The POST method
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: POST方法
- en: The `POST` method is in some senses the opposite of the `GET` method. We use
    the `POST` method for sending data to the server. However, in return the server
    can still send us a full response. The `POST` method is used for submitting user
    input from HTML forms and for uploading files to a server.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '`POST`方法在某种意义上是`GET`方法的相反。我们使用`POST`方法向服务器发送数据。然而，服务器仍然可以向我们发送完整的响应。`POST`方法用于提交HTML表单中的用户输入和向服务器上传文件。'
- en: When using `POST`, the data that we wish to send will go in the body of the
    request. We can put any bytes data in there and declare its type by adding a `Content-Type`
    header to our request with an appropriate MIME type.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`POST`时，我们希望发送的数据将放在请求的正文中。我们可以在那里放入任何字节数据，并通过在我们的请求中添加`Content-Type`头来声明其类型，使用适当的MIME类型。
- en: 'Let''s look at an example for sending some HTML form data to a server by using
    a POST request, just as browsers do when we submitt a form on a website. The form
    data always consists of key/value pairs; `urllib` lets us work with regular dictionaries
    for supplying this (we''ll look at where this data comes from in the following
    section):'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看看如何通过POST请求向服务器发送一些HTML表单数据，就像浏览器在网站上提交表单时所做的那样。表单数据始终由键/值对组成；`urllib`让我们可以使用常规字典来提供这些数据（我们将在下一节中看到这些数据来自哪里）：
- en: '[PRE70]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: When posting the HTML form data, the form values must be formatted in the same
    way as **querystrings** are formatted in a URL, and must be URL-encoded. A `Content-Type`
    header must also be set to the special MIME type of `application/x-www-form-urlencoded`.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在发布HTML表单数据时，表单值必须以与URL中的**查询字符串**相同的方式进行格式化，并且必须进行URL编码。还必须设置`Content-Type`头为特殊的MIME类型`application/x-www-form-urlencoded`。
- en: 'Since this format is identical to querystrings, we can just use the `urlencode()`
    function on our `dict` for preparing the data:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种格式与查询字符串相同，我们可以在准备数据时使用`urlencode()`函数：
- en: '[PRE71]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Here, we also additionally encode the result to bytes, as it's to be sent as
    the body of the request. In this case, we use the UTF-8 character set.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们还将结果额外编码为字节，因为它将作为请求的主体发送。在这种情况下，我们使用UTF-8字符集。
- en: 'Next, we will construct our request:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建我们的请求：
- en: '[PRE72]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: By adding our data as the `data` keyword argument, we are telling `urllib` that
    we want our data to be sent as the body of the request. This will make the request
    use the `POST` method rather than the `GET method`.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将我们的数据作为`data`关键字参数添加，我们告诉`urllib`我们希望我们的数据作为请求的主体发送。这将使请求使用`POST`方法而不是`GET`方法。
- en: 'Next, we add the `Content-Type` header:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们添加`Content-Type`头：
- en: '[PRE73]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Lastly, we submit the request:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们提交请求：
- en: '[PRE74]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: If we save the response data to a file and open it in a web browser, then we
    should see some Debian website search results related to Python.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将响应数据保存到文件并在网络浏览器中打开它，那么我们应该会看到一些与Python相关的Debian网站搜索结果。
- en: Formal inspection
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正式检查
- en: 'In the previous section we used the URL `http://search.debian.org/cgibin/omega`,
    and the dictionary `data_dict = {''P'': ''Python''}`. But where did these come
    from?'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '在前一节中，我们使用了URL`http://search.debian.org/cgibin/omega`，和字典`data_dict = {''P'':
    ''Python''}`。但这些是从哪里来的呢？'
- en: We get these by visiting the web page containing the form we would submit to
    get the results manually. We then inspect the HTML source code of the web page.
    If we were carrying out the aforementioned search in a web browser, then we would
    most likely be on the [http://www.debian.org](http://www.debian.org) page, and
    we would be running a search by typing our search term into the search box at
    the top right corner and then clicking on **Search**.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过访问包含我们手动提交以获取结果的表单的网页来获得这些信息。然后我们检查网页的HTML源代码。如果我们在网络浏览器中进行上述搜索，那么我们很可能会在[http://www.debian.org](http://www.debian.org)页面上，并且我们将通过在右上角的搜索框中输入搜索词然后点击**搜索**来进行搜索。
- en: 'Most modern browsers allow you to directly inspect the source for any element
    on a page. To do this right-click on the element, which in this case is the search
    box, then select the **Inspect Element** option, as shown in the screenshot here:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代浏览器允许您直接检查页面上任何元素的源代码。要做到这一点，右键单击元素，这种情况下是搜索框，然后选择**检查元素**选项，如此屏幕截图所示：
- en: '![Formal inspection](graphics/6008OS_02_01.jpg)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![正式检查](graphics/6008OS_02_01.jpg)'
- en: 'The source code will pop up in a section of the window. In the preceding screenshot,
    it''s at the bottom left corner of the screen. Here, you will see some lines of
    code that looks like the following example:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码将在窗口的某个部分弹出。在前面的屏幕截图中，它位于屏幕的左下角。在这里，您将看到一些代码行，看起来像以下示例：
- en: '[PRE75]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: You should see the second `<input>` highlighted. This is the tag that corresponds
    to the search text box. The value of the `name` attribute on the highlighted `<input>`
    tag is the key that we use in our `data_dict`, which in this case is `P`. The
    value in our `data_dict` is the term that we want to search for.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到第二个高亮显示的`<input>`。这是对应于搜索文本框的标签。高亮显示的`<input>`标签上的`name`属性的值是我们在`data_dict`中使用的键，这种情况下是`P`。我们`data_dict`中的值是我们要搜索的术语。
- en: To get the URL, we need to look above the highlighted `<input>` for the enclosing
    `<form>` tag. Here, our URL will be of the value of the `action` attribute, [http://search.debian.org/cgi-bin/omega](http://search.debian.org/cgi-bin/omega).
    The source code for this web page is included in the source code download for
    this book, in case Debian changes their website before you read this.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取URL，我们需要在高亮显示的`<input>`上方查找包围的`<form>`标签。在这里，我们的URL将是`action`属性的值，[http://search.debian.org/cgi-bin/omega](http://search.debian.org/cgi-bin/omega)。本书的源代码下载中包含了此网页的源代码，以防Debian在您阅读之前更改他们的网站。
- en: This process can be applied to most HTML pages. To do this, look for the `<input>`
    corresponding to the input text box, then find the URL from the enclosing `<form>`
    tag. If you're not familiar with HTML, then this can be a bit of a trial and error
    process. We'll be looking at some more methods of parsing HTML in the next chapter.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以应用于大多数HTML页面。要做到这一点，找到与输入文本框对应的`<input>`，然后从包围的`<form>`标签中找到URL。如果您不熟悉HTML，那么这可能是一个反复试验的过程。我们将在下一章中看一些解析HTML的更多方法。
- en: Once we have our input name and URL, we can construct and submit the POST request,
    as shown in the previous section.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了我们的输入名称和URL，我们就可以构建并提交POST请求，就像在前一节中所示的那样。
- en: HTTPS
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HTTPS
- en: Unless otherwise protected, all HTTP requests and responses are sent in clear
    text. Anyone with access to the network that the messages travel over can potentially
    intercept our traffic and read it without hindrance.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有保护，所有HTTP请求和响应都是以明文发送的。任何可以访问消息传输的网络的人都有可能拦截我们的流量并毫无阻碍地阅读它。
- en: Since the web is used for transferring quite a lot of sensitive data, solutions
    have been created for preventing eavesdroppers from reading the traffic, even
    if they are able to intercept it. These solutions, for the most part, employ some
    form of encryption.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 由于网络用于传输大量敏感数据，已经创建了一些解决方案，以防止窃听者阅读流量，即使他们能够拦截它。这些解决方案在很大程度上采用了某种形式的加密。
- en: The standard method for encrypting HTTP traffic is called HTTP Secure, or **HTTPS**.
    It uses an encryption mechanism called TLS/SSL, and it is applied to the TCP connection
    on which the HTTP traffic travels. HTTPS typically uses TCP port 443, as opposed
    to the default HTTP port 80.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 加密HTTP流量的标准方法称为HTTP安全，或**HTTPS**。它使用一种称为TLS/SSL的加密机制，并应用于HTTP流量传输的TCP连接上。HTTPS通常使用TCP端口443，而不是默认的HTTP端口80。
- en: To most users, this process is almost transparent. In principle, we only need
    to change the http in a URL to an https. Since `urllib` supports HTTPS, the same
    is true for our Python clients.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数用户来说，这个过程几乎是透明的。原则上，我们只需要将URL中的http更改为https。由于`urllib`支持HTTPS，因此对于我们的Python客户端也是如此。
- en: Note that not all servers support HTTPS, so simply changing the URL scheme to
    `https:` isn't guaranteed to work for all sites. If this is the case, then the
    connection attempt may fail in a number of ways, including a socket timeout, a
    connection reset error, or possibly even an HTTP error, such as a 400 range error
    or a 500 range error. An increasing number of sites are enabling HTTPS however.
    Many others are switching to it and using it as their default protocol, so it's
    worth investigating whether it's available so you can give your application's
    users extra security.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，并非所有服务器都支持HTTPS，因此仅将URL方案更改为`https:`并不能保证适用于所有站点。如果是这种情况，连接尝试可能会以多种方式失败，包括套接字超时、连接重置错误，甚至可能是HTTP错误，如400范围错误或500范围错误。然而，越来越多的站点正在启用HTTPS。许多其他站点正在切换到HTTPS并将其用作默认协议，因此值得调查它是否可用，以便为应用程序的用户提供额外的安全性。
- en: The Requests library
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`Requests`库'
- en: So that's it for the `urllib` package. As you can see, access to the standard
    library is more than adequate for most HTTP tasks. We haven't touched upon all
    of its capabilities. There are numerous handler classes which we haven't discussed,
    plus the opener interface is extensible.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是关于`urllib`包的全部内容。正如你所看到的，访问标准库对于大多数HTTP任务来说已经足够了。我们还没有涉及到它的所有功能。还有许多处理程序类我们没有讨论，而且打开接口是可扩展的。
- en: However, the API isn't the most elegant, and there have been several attempts
    made to improve it. One of these is the very popular third-party library called
    **Requests**. It's available as the `requests` package on PyPi. It can either
    be installed through Pip or be downloaded from [http://docs.python-requests.org](http://docs.python-requests.org),
    which hosts the documentation.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，API并不是最优雅的，已经有几次尝试来改进它。其中一个是非常受欢迎的第三方库**Requests**。它作为`requests`包在PyPi上可用。它可以通过Pip安装，也可以从[http://docs.python-requests.org](http://docs.python-requests.org)下载，该网站提供了文档。
- en: The `Requests` library automates and simplifies many of the tasks that we've
    been looking at. The quickest way of illustrating this is by trying some examples.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '`Requests`库自动化并简化了我们一直在研究的许多任务。最快的说明方法是尝试一些示例。'
- en: 'The commands for retrieving a URL with `Requests` are similar to retrieving
    a URL with the `urllib` package, as shown here:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Requests`检索URL的命令与使用`urllib`包检索URL的命令类似，如下所示：
- en: '[PRE76]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'And we can look at properties of the response object. Try:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看响应对象的属性。尝试：
- en: '[PRE77]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Note that the header name in the preceding command is in lowercase. The keys
    in the `headers` attribute of `Requests` response objects are case insensitive.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面命令中的标头名称是小写的。`Requests`响应对象的`headers`属性中的键是不区分大小写的。
- en: 'There are some convenience attributes that have been added to the response
    object:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 响应对象中添加了一些便利属性：
- en: '[PRE78]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The `ok` attribute indicates whether the request was successful. That is, the
    request contained a status code in the 200 range. Also:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '`ok`属性指示请求是否成功。也就是说，请求包含的状态码在200范围内。另外：'
- en: '[PRE79]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The `is_redirect` attribute indicates whether the request was redirected. We
    can also access the request properties through the response object:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '`is_redirect`属性指示请求是否被重定向。我们还可以通过响应对象访问请求属性：'
- en: '[PRE80]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Notice that `Requests` is automatically handling compression for us. It''s
    including `gzip` and `deflate` in an `Accept-Encoding` header. If we look at the
    `Content-Encoding` response, then we will see that the response was in fact `gzip`
    compressed, and `Requests` transparently decompressed it for us:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`Requests`会自动处理压缩。它在`Accept-Encoding`头中包括`gzip`和`deflate`。如果我们查看`Content-Encoding`响应，我们会发现响应实际上是`gzip`压缩的，而`Requests`会自动为我们解压缩：
- en: '[PRE81]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'We can look at the response content in many more ways. To get the same bytes
    object as we got from an `HTTPResponse` object, perform the following:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以以更多的方式查看响应内容。要获得与`HTTPResponse`对象相同的字节对象，执行以下操作：
- en: '[PRE82]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'But `Requests` also performs automatic decoding for us. To get the decoded
    content, do this:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，`Requests`还会自动解码。要获取解码后的内容，请执行以下操作：
- en: '[PRE83]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Notice that this is now `str` rather than `bytes`. The `Requests` library uses
    values in the headers for choosing a character set and decoding the content to
    Unicode for us. If it can''t get a character set from the headers, then it uses
    the `chardet` library ([http://pypi.python.org/pypi/chardet](http://pypi.python.org/pypi/chardet))
    to make an estimate from the content itself. We can see what encoding `Requests`
    has chosen here:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这现在是`str`而不是`bytes`。`Requests`库使用头中的值来选择字符集并将内容解码为Unicode。如果无法从头中获取字符集，则使用`chardet`库（[http://pypi.python.org/pypi/chardet](http://pypi.python.org/pypi/chardet)）从内容本身进行估计。我们可以看到`Requests`选择了哪种编码：
- en: '[PRE84]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'We can even ask it to change the encoding that it has used:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以要求它更改已使用的编码：
- en: '[PRE85]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: After changing the encoding, subsequent references to the `text` attribute for
    this response will return the content decoded by using the new encoding setting.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 更改编码后，对于此响应的`text`属性的后续引用将返回使用新编码设置解码的内容。
- en: 'The `Requests` library automatically handles cookies. Give the following a
    try:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '`Requests`库会自动处理Cookie。试试这个：'
- en: '[PRE86]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The `Requests` library also has a `Session` class, which allows the reuse of
    cookies, and this is similar to using the `http` module''s `CookieJar` and the
    `urllib` module''s `HTTPCookieHandler` objects. Do the following to reuse the
    cookies in subsequent requests:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: “Requests”库还有一个“Session”类，允许重复使用cookie，这类似于使用“http”模块的“CookieJar”和“urllib”模块的“HTTPCookieHandler”对象。要在后续请求中重复使用cookie，请执行以下操作：
- en: '[PRE87]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: The `Session` object has the same interface as the `requests` module, so we
    use its `get()` method in the same way as we use the `requests.get()method`. Now,
    any cookies encountered are stored in the `Session` object, and they will be sent
    with corresponding requests when we use the `get()` method in the future.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: “Session”对象具有与“requests”模块相同的接口，因此我们可以像使用“requests.get()”方法一样使用其“get()”方法。现在，遇到的任何cookie都将存储在“Session”对象中，并且在将来使用“get()”方法时将随相应的请求发送。
- en: Redirects are also automatically followed, in the same way as when using `urllib`,
    and any redirected requests are captured in the `history` attribute.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 重定向也会自动跟随，方式与使用“urllib”时相同，并且任何重定向的请求都会被捕获在“history”属性中。
- en: 'The different HTTP methods are easily accessible, they have their own functions:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的HTTP方法很容易访问，它们有自己的功能：
- en: '[PRE88]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Custom headers are added to to requests in a similar way as they are when using
    `urllib`:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义标头以类似于使用“urllib”时的方式添加到请求中：
- en: '[PRE89]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Making requests with query strings is a straightforward process:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 使用查询字符串进行请求是一个简单的过程：
- en: '[PRE90]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: The `Requests` library takes care of all the encoding and formatting for us.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: “Requests”库为我们处理所有的编码和格式化工作。
- en: 'Posting is similarly simplified, although we use the `data` keyword argument
    here:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 发布也同样简化，尽管我们在这里使用“data”关键字参数：
- en: '[PRE91]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Handling errors with Requests
  id: totrans-395
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Requests处理错误
- en: 'Errors in `Requests` are handled slightly differently from how they are handled
    with `urllib`. Let''s work through some error conditions and see how it works.
    Generate a 404 error by doing the following:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: “Requests”中的错误处理与使用“urllib”处理错误的方式略有不同。让我们通过一些错误条件来看看它是如何工作的。通过以下操作生成一个404错误：
- en: '[PRE92]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'In this situation, `urllib` would have raised an exception, but notice that
    `Requests` doesn''t. The `Requests` library can check the status code and raise
    a corresponding exception, but we have to ask it to do so:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，“urllib”会引发异常，但请注意，“Requests”不会。 “Requests”库可以检查状态代码并引发相应的异常，但我们必须要求它这样做：
- en: '[PRE93]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Now, try it on a successful request:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，尝试在成功的请求上进行测试：
- en: '[PRE94]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: It doesn't do anything, which in most situations would let our program exit
    a `try/except` block and then continue as we would want it to.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 它不做任何事情，这在大多数情况下会让我们的程序退出“try/except”块，然后按照我们希望的方式继续。
- en: 'What happens if we get an error that is lower in the protocol stack? Try the
    following:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们遇到协议栈中较低的错误会发生什么？尝试以下操作：
- en: '[PRE95]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: We have made a request for a host that doesn't exist and once it has timed out,
    we get a `ConnectionError` exception.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经发出了一个主机不存在的请求，一旦超时，我们就会收到一个“ConnectionError”异常。
- en: The `Requests` library simply reduces the workload that is involved in using
    HTTP in Python as compared to `urllib`. Unless you have a requirement for using
    `urllib`, I would always recommend using `Requests` for your projects.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 与“urllib”相比，“Requests”库简化了在Python中使用HTTP所涉及的工作量。除非您有使用“urllib”的要求，我总是建议您在项目中使用“Requests”。
- en: Summary
  id: totrans-407
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We looked at the principles of the HTTP protocol. We saw how to perform numerous
    fundamental tasks with the standard library `urllib` and the third-party `Requests`
    packages.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了HTTP协议的原则。我们看到如何使用标准库“urllib”和第三方“Requests”包执行许多基本任务。
- en: We looked at the structure of HTTP messages, HTTP status codes, the different
    headers that we may encounter in requests and responses, and how to interpret
    them and use them for customizing our requests. We looked at how URLs are formed,
    and how to manipulate and construct them.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了HTTP消息的结构，HTTP状态代码，我们可能在请求和响应中遇到的不同标头，以及如何解释它们并用它们来定制我们的请求。我们看了URL是如何形成的，以及如何操作和构建它们。
- en: We saw how to handle cookies and redirects, how to handle errors that might
    occur, and how to use secure HTTP connections.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了如何处理cookie和重定向，如何处理可能发生的错误，以及如何使用安全的HTTP连接。
- en: We also covered how to submit data to websites in the manner of submitting a
    form on a web page, and how to extract the parameters that we need from a page's
    source code.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还介绍了如何以提交网页表单的方式向网站提交数据，以及如何从页面源代码中提取我们需要的参数。
- en: Finally, we looked at the third-party `Requests` package. We saw that as compared
    to the `urllib` package, `Requests`, automates and simplifies many of the tasks
    that we may routinely need to carry out with HTTP. This makes it a great choice
    for day-to-day HTTP work.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们看了第三方的“Requests”包。我们发现，与“urllib”包相比，“Requests”自动化并简化了我们可能需要用HTTP进行的许多常规任务。这使得它成为日常HTTP工作的绝佳选择。
- en: In the next chapter, we'll be employing what we've learned here to carry out
    detailed interactions with different web services, querying APIs for data, and
    uploading our own objects to the web.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将运用我们在这里学到的知识，与不同的网络服务进行详细的交互，查询API以获取数据，并将我们自己的对象上传到网络。
