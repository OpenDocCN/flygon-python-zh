- en: 3\. Python's Statistical Toolbox
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. Python的统计工具箱
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In the previous chapter, we learned about the three main libraries in Python
    that help us facilitate various tasks in our statistics/machine learning projects.
    This chapter, in turn, initiates the formal topic of statistics and its relevant
    concepts. While it contains a number of theoretical discussion points, we will
    also employ intuitive examples and hands-on coding activities to help facilitate
    understanding. What we learn in this chapter will then prepare us for later statistics-related
    chapters in this workshop.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了Python中三个主要的库，这些库帮助我们在统计学/机器学习项目中执行各种任务。而本章则开始了统计学及其相关概念的正式话题。虽然其中包含了一些理论讨论点，但我们也将使用直观的例子和实际编码活动来帮助理解。本章学到的内容将为我们在本工作坊的后续统计学相关章节做好准备。
- en: By the end of this chapter, you will understand the fundamental concepts in
    statistics and statistical methods. You'll also be able to carry out various statistics-related
    tasks using Python tools and libraries, and will have had an overview of a number
    of advanced statistics libraries in Python, such as statsmodels and PyMC3.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解统计学和统计方法的基本概念。您还将能够使用Python工具和库执行各种与统计学相关的任务，并且将对Python中一些高级统计库进行概述，例如statsmodels和PyMC3。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: So far, we have learned how to use the Python language, especially three of
    its core libraries—NumPy, pandas, and Matplotlib, for statistics and data science.
    However, in order to fully take advantage of these tools, we will need to have
    a solid theoretical understanding of statistics itself. By knowing the idea behind
    statistical tests and techniques, we will be able to utilize the tools that Python
    offers more effectively.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学会了如何使用Python语言，特别是它的三个核心库——NumPy、pandas和Matplotlib，用于统计学和数据科学。然而，为了充分利用这些工具，我们需要对统计学本身有扎实的理论理解。通过了解统计检验和技术背后的思想，我们将能够更有效地利用Python提供的工具。
- en: It is true that in statistics and machine learning, libraries in Python offer
    great options—from data cleaning/processing to modeling and making inferences.
    However, a fundamental understanding of statistics is still required so that we
    can make initial decisions regarding what kinds of techniques should be used in
    our process, depending on the data we have.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学和机器学习中，Python库提供了很好的选择——从数据清洗/处理到建模和推断。然而，仍然需要对统计学有基本的理解，这样我们才能根据手头的数据做出关于应该在我们的过程中使用什么样的技术的初步决定。
- en: As such, in this chapter, we will learn about core concepts in statistics such
    as , inference, sampling, variables, and so on. We will also be introduced to
    a wide range of Python tools that can help facilitate more advanced statistical
    techniques and needs. All of this will be demonstrated with hands-on discussions
    and examples.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，我们将学习统计学的核心概念，例如推断、抽样、变量等。我们还将介绍一系列可以帮助促进更高级统计技术和需求的Python工具。所有这些都将通过实际讨论和示例进行演示。
- en: An Overview of Statistics
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计学概述
- en: In this section, we will briefly discuss the goal of the overarching field of
    statistics and talk about some of its fundamental ideas. This conversation will
    set the context for the subsequent topics in this chapter and this book.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要讨论统计学这一总体领域的目标，并谈论一些其基本思想。这次对话将为本章和本书的后续主题设定背景。
- en: 'Generally speaking, statistics is all about working with data, be it processing,
    analyzing, or drawing a conclusion from the data we have. In the context of a
    given dataset, statistics has two main goals: describing the data, and drawing
    conclusions from it. These goals coincide with the two main categories of statistics
    — descriptive statistics and inferential statistics — respectively.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，统计学是关于处理数据的，无论是处理、分析还是从我们手头的数据中得出结论。在给定数据集的情境下，统计学有两个主要目标：描述数据和从中得出结论。这些目标与统计学的两个主要类别——描述性统计和推断性统计——分别相吻合。
- en: 'In descriptiv**e statistics**, questions are asked about the general characteristics
    of a dataset: What is the average amount? What is the difference between the maximum
    and the minimum? What value appears the most? And so forth. The answers to these
    questions help us get an idea of what the dataset in question constitutes and
    what the subject of the dataset is. We saw brief examples of this in the previous
    chapter.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在描述性统计中，会有关于数据集的一般特征的问题：平均数是多少？最大值和最小值之间的差异是多少？哪个值出现最多？等等。这些问题的答案帮助我们了解所讨论的数据集构成了什么，以及数据集的主题是什么。我们在上一章中看到了这方面的简要示例。
- en: 'In **inferential statistics**, the goal is to go a step further: after extracting
    appropriate insights from a given dataset, we''d like to use that information
    and infer on unknown data. One example of this is making predictions for the future
    from observed data. This is typically done via various statistical and machine
    learning models, each of which is only applicable to certain types of data. This
    is why it is highly important to understand what types of data there are in statistics,
    which are described in the next section.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在推断性统计中，目标是更进一步：在从给定数据集中提取适当的见解之后，我们希望利用这些信息并推断未知数据。其中一个例子是根据观察到的数据对未来进行预测。这通常是通过各种统计和机器学习模型来实现的，每种模型只适用于某些类型的数据。这就是为什么了解统计学中有哪些类型的数据是非常重要的，这将在下一节中描述。
- en: Overall, statistics can be thought of as a field that studies data, which is
    why it is the foundation for data science and machine learning. Using statistics,
    we can understand the state of the world using our sometimes-limited datasets,
    and from there make appropriate and actionable decisions, made from the data-driven
    knowledge that we obtain. This is why statistics is used ubiquitously in various
    fields of study, from sciences to social sciences, and sometimes even the humanities,
    when there are analytical elements involved in the research.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，统计学可以被认为是研究数据的领域，这就是为什么它是数据科学和机器学习的基础。使用统计学，我们可以通过我们有时有限的数据集来了解世界的状态，并从中做出适当和可操作的决策，这些决策是基于我们获得的数据驱动知识。这就是为什么统计学在各个研究领域被广泛使用，从科学到社会科学，有时甚至是人文科学，当研究中涉及到分析元素时。
- en: 'With that said, let''s begin our first technical topic of this chapter: distinguishing
    between data types.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 说到这里，让我们开始本章的第一个技术主题：区分数据类型。
- en: Types of Data in Statistics
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计学中的数据类型
- en: 'In statistics, there are two main types of data: categorical data and numerical
    data. Depending on which type an attribute or a variable in your dataset belongs
    to, its data processing, modeling, analysis, and visualization techniques might
    differ. In this section, we will explain the details of these two main data types
    and discuss relevant points for each of them, which are summarized in the following
    table:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，数据主要分为两种类型：分类数据和数值数据。根据数据集中属性或变量所属的类型，其数据处理、建模、分析和可视化技术可能会有所不同。在本节中，我们将解释这两种主要数据类型的细节，并讨论每种类型的相关要点，这些要点总结在下表中：
- en: '![Figure 3.1: Data type comparison'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.1：数据类型比较'
- en: '](image/B15968_03_01.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_01.jpg)'
- en: 'Figure 3.1: Data type comparison'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1：数据类型比较
- en: For the rest of this section, we will go into more detail about each of the
    preceding comparisons, starting with categorical data in the next subsection.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的其余部分，我们将更详细地讨论前述比较中的每一个，从下一小节开始讨论分类数据。
- en: Categorical Data
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类数据
- en: When an attribute or a variable is categorical, the possible values it can take
    belong to a predetermined and fixed set of values. For example, in a weather-related
    dataset, you might have an attribute to describe the overall weather for each
    day, in which case that attribute might be among a list of discrete values such
    as `"sunny"`, `"windy"`, `"cloudy"`, `"rain"`, and so on. A cell in this attribute
    column *must* take on one of these possible values; a cell cannot contain, for
    example, a number or an unrelated string like `"apple"`. Another term for this
    type of data is *nominal data*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当属性或变量是分类的时，它可以取的可能值属于一个预定的固定值集。例如，在与天气相关的数据集中，您可能有一个属性来描述每天的整体天气，这种情况下该属性可能属于一个离散值列表，如`"晴天"`、`"有风"`、`"多云"`、`"雨"`等。这个属性列中的单元格*必须*取这些可能的值之一；一个单元格不能包含，例如，一个数字或一个不相关的字符串，比如`"苹果"`。这种数据的另一个术语是*名义数据*。
- en: 'Because of the nature of the data, in most cases, there is no ordinal relationship
    between the possible values of a categorical attribute. For example, there is
    no comparison operation that can be applied to the weather-related data we described
    previously: `"sunny"` is neither greater than or less than `"windy"`, and so on.
    This is to be contrasted with numerical data, which, although we haven''t discussed
    it yet, expresses clear ordinality.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据的性质，在大多数情况下，分类属性的可能值之间没有顺序关系。例如，我们之前描述的天气相关数据没有可以应用的比较操作：`"晴天"`既不大于也不小于`"有风"`，依此类推。这与数值数据形成对比，尽管我们还没有讨论它，但它表达了明显的顺序性。
- en: On the topic of differences between data types, let's now go through a number
    of points to keep in mind when working with categorical data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论数据类型的差异时，让我们现在通过一些要点来了解处理分类数据时需要牢记的一些要点。
- en: If an unknown variable that is a categorical attribute is to be modeled using
    a probability distribution, a categorical distribution will be required. Such
    a distribution describes the probability that the variable is one out of *K* predefined
    possible categories. Luckily for us, most of the modeling will be done in the
    backend of various statistical/machine learning models when we call them from
    their respective libraries, so we don't have to worry about the problem of modeling
    right now.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果要使用概率分布对一个未知的分类属性进行建模，就需要一个分类分布。这种分布描述了变量是预定义的*K*个可能类别之一的概率。幸运的是，当我们从各自的库中调用它们时，大多数建模将在各种统计/机器学习模型的后端完成，所以我们现在不必担心建模的问题。
- en: In terms of data processing, an encoding scheme is typically used to *convert*
    the categorical values in an attribute to numerical, machine-interpretable values.
    As such, string values, which are highly common in categorical data, cannot be
    fed to a number of models that only take in numerical data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据处理方面，通常使用编码方案来*转换*属性中的分类值为数值，机器可解释的值。因此，在分类数据中，常见的字符串值不能被输入到只接受数值数据的模型中。
- en: 'For example, some tend to use the simple encoding of assigning each possible
    value with a positive integer and replacing them with their respective numerical
    value. Consider the following sample dataset (stored in the variable named `weather_df`):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，有些人倾向于使用简单的编码，将每个可能的值分配一个正整数，并用其相应的数值替换它们。考虑以下样本数据集（存储在名为`weather_df`的变量中）：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output will be as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, you could potentially call the `map()` method on the `weather` attribute
    and pass in the dictionary `{''windy'': 0, ''cloudy'': 1, ''sunny'': 2, ''rain'':
    3}` (the `map()` method simply applies the mapping defined by the dictionary on
    the attribute) to encode the categorical attribute like so:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，您可以在`weather`属性上调用`map()`方法，并传入字典`{''有风'': 0, ''多云'': 1, ''晴天'': 2, ''雨'':
    3}`（`map()`方法简单地将字典定义的映射应用于属性）来对分类属性进行编码，如下所示：'
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This DataFrame object will now hold the following data:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个DataFrame对象现在将包含以下数据：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output is as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We see that the categorical column `weather` has been successfully converted
    to numerical data in `weather_encoded` via a one-to-one mapping. However, this
    technique can be potentially dangerous: the new attribute implicitly places an
    order on its data. Since *0 < 1 < 2 < 3*, we are inadvertently imposing the same
    ordering on the original categorical data; this is especially dangerous if the
    model we are using specifically interprets that as truly numerical data.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到分类列`weather`已经成功通过一对一映射转换为了`weather_encoded`中的数值数据。然而，这种技术可能存在潜在的危险：新属性在数据上隐含地放置了一个顺序。由于*0
    < 1 < 2 < 3*，我们无意中对原始分类数据施加了相同的排序；如果我们使用的模型特别将其解释为真正的数值数据，这是特别危险的。
- en: 'This is the reason why we must be careful when transforming our categorical
    attributes into a numerical form. We have actually already discussed a certain
    technique that is able to convert categorical data without imposing a numerical
    relationship in the previous chapter: one-hot encoding. In this technique, we
    create a new attribute for every unique value in a categorical attribute. Then,
    for each row in the dataset, we place a `1` in a newly created attribute if that
    row has the corresponding value in the original categorical attribute and `0`
    in the other new attributes.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么当我们将分类属性转换为数值形式时必须小心。实际上，我们在上一章中已经讨论了一种能够在不施加数值关系的情况下转换分类数据的特定技术：独热编码。在这种技术中，我们为分类属性中的每个唯一值创建一个新属性。然后，对于数据集中的每一行，如果该行具有原始分类属性中的相应值，则在新创建的属性中放置`1`，在其他新属性中放置`0`。
- en: 'The following code snippet reiterates how we can implement one-hot encoding
    with pandas and what effect it will have on our current sample weather dataset:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段重申了我们如何可以使用pandas实现独热编码，以及它对我们当前的样本天气数据集会产生什么影响：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This will produce the following output:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Among the various descriptive statistics that we will discuss later in this
    chapter, the mode — the value that appears the most — is typically the only statistic
    that can be used on categorical data. As a consequence of this, when there are
    values missing from a categorical attribute in our dataset and we'd like to fill
    them with a central tendency statistic, a concept we will define later on in this
    chapter, the mode is the only one that should be considered.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后面我们将讨论的各种描述性统计中，众数——出现最多的值——通常是唯一可以用于分类数据的统计量。因此，当我们的数据集中的分类属性中有缺失值，并且我们希望用一个中心趋势统计量填充它们时，这是我们将在本章后面定义的一个概念，应该考虑的唯一统计量是众数。
- en: In terms of making predictions, if a categorical attribute is the target of
    our machine learning pipeline (as in, if we want to predict a categorical attribute),
    classification models are needed. As opposed to regression models, which make
    predictions on numerical, continuous data, classification models, or classifiers
    for short, keep in mind the possible values their target attribute can take and
    only predict among those values. Thus, when deciding which machine learning model(s)
    you should train on your dataset to predict categorical data, make sure to only
    use classifiers.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行预测方面，如果一个分类属性是我们机器学习流水线的目标（也就是说，如果我们想要预测一个分类属性），则需要使用分类模型。与回归模型相反，回归模型对数值连续数据进行预测，分类模型或简称分类器，要记住其目标属性可能取值的可能值，并且只在这些值中进行预测。因此，在决定应该对数据集进行训练以预测分类数据的机器学习模型时，请确保只使用分类器。
- en: The last big difference between categorical data and numerical data is in visualization
    techniques. A number of visualization techniques were discussed in the previous
    chapter that are applicable for categorical data, two of the most common of which
    are bar graphs (including stacked and grouped bar graphs) and pie charts.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 分类数据和数值数据之间的最后一个重大区别在于可视化技术。在上一章中讨论了许多适用于分类数据的可视化技术，其中最常见的两种是条形图（包括堆叠和分组条形图）和饼图。
- en: These types of visualization focus on the portion of the whole dataset each
    unique value takes up.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型的可视化关注每个唯一值在整个数据集中所占的比例。
- en: 'For example, with the preceding weather dataset, we can create a pie chart
    using the following code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于前面的天气数据集，我们可以使用以下代码创建一个饼图：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This will create the following visualization:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建以下可视化：
- en: '![Figure 3.2: Pie chart for weather data'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.2：天气数据的饼图'
- en: '](image/B15968_03_02.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_02.jpg)'
- en: 'Figure 3.2: Pie chart for weather data'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：天气数据的饼图
- en: We can see that in the whole dataset, the value `'sunny'` occurs 40 percent
    of the time, while each of the other values occurs 20 percent of the time.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到在整个数据集中，值为'sunny'的出现了40%的时间，而其他每个值都出现了20%的时间。
- en: 'We have so far covered most of the biggest theoretical differences between
    a categorical attribute and a numerical attribute, which we will discuss in the
    next section. However, before moving on, there is another subtype of the categorical
    data type that should be mentioned: binary data.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了分类属性和数值属性之间最大的理论差异，我们将在下一节中讨论。然而，在继续之前，还有一个应该提到的分类数据类型的子类型：二进制数据。
- en: A binary attribute, whose values can only be `True` and `False`, is a categorical
    attribute whose set of possible values contains the two Boolean values mentioned.
    Since Boolean values can be easily interpreted by machine learning and mathematical
    models, there is usually not a need to convert a binary attribute into any other
    form.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制属性，其值只能是`True`和`False`，是一个分类属性，其可能值集合包含了上述两个布尔值。由于布尔值可以被机器学习和数学模型轻松解释，通常不需要将二进制属性转换为其他形式。
- en: 'In fact, binary attributes that are not originally in the Boolean form should
    be converted into `True` and `False` values. We encountered an example of this
    in the sample student dataset in the previous chapter:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，原本不是布尔形式的二进制属性应该被转换为`True`和`False`值。在上一章的示例学生数据集中，我们遇到了这样的例子：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output is as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here, the column `''sex''` is a categorical attribute whose values can either
    be `''female''` or `''male''`. So instead, what we can do to make this data more
    machine-friendly (while ensuring no information will be lost or added in) is to
    *binarize* the attribute, which we have done via the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，列`'sex'`是一个分类属性，其值可以是`'female'`或`'male'`。因此，为了使这些数据更适合机器处理（同时确保不会丢失或添加任何信息），我们可以对属性进行*二值化*，我们已经通过以下代码完成了这一步骤：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output is as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: Since the newly created column `'female_flag'` contains all the information
    from the column `'sex'` and only that, we can simply drop the latter from our
    dataset.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于新创建的列`'female_flag'`包含了来自列`'sex'`的所有信息，而且只有这些信息，我们可以简单地从数据集中删除后者。
- en: Aside from that, binary attributes can be treated as categorical data in any
    other way (processing, making predictions, and visualization).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，二进制属性可以以任何其他方式（处理、预测和可视化）处理为分类数据。
- en: Let's now apply what we have discussed so far in the following exercise.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在将我们迄今讨论的内容应用到以下练习中。
- en: 'Exercise 3.01: Visualizing Weather Percentages'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习3.01：可视化天气百分比
- en: 'In this exercise, we are given a sample dataset that includes the weather in
    a specific city across five days. This dataset can be downloaded from [https://packt.live/2Ar29RG](https://packt.live/2Ar29RG).
    We aim to visualize the categorical information in this dataset to examine the
    percentages of different types of weather using the visualization techniques for
    categorical data that we have discussed so far:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们得到了一个样本数据集，其中包括特定城市在五天内的天气情况。这个数据集可以从[https://packt.live/2Ar29RG](https://packt.live/2Ar29RG)下载。我们的目标是使用迄今为止讨论的分类数据可视化技术，来可视化这个数据集中的分类信息，以检查不同类型天气的百分比：
- en: 'In a new Jupyter notebook, import pandas, Matplotlib, and seaborn and use pandas
    to read in the aforementioned dataset:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的Jupyter笔记本中，导入pandas、Matplotlib和seaborn，并使用pandas读取上述数据集：
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'When the first five rows of this dataset are printed out, you should see the
    following output:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当打印出此数据集的前五行时，您应该看到以下输出：
- en: '![Figure 3.3: The weather dataset'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.3：天气数据集'
- en: '](image/B15968_03_03.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_03.jpg)'
- en: 'Figure 3.3: The weather dataset'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：天气数据集
- en: As you can see, each row of this dataset tells us what the weather was on a
    given day in a given city. For example, on day `0`, it was sunny in `St Louis`
    while it was `cloudy` in `New York`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，此数据集的每一行告诉我们在给定城市的给定日期的天气情况。例如，在`0`号那天，`St Louis`是晴天，而`New York`是`多云`。
- en: 'In the next code cell in the notebook, compute the counts (the numbers of occurrences)
    for all the weather types in our dataset and visualize that information using
    the `plot.bar()` method:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在笔记本中的下一个代码单元中，计算数据集中所有天气类型的计数（发生次数），并使用`plot.bar()`方法可视化该信息：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This code will produce the following output:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将产生以下输出：
- en: '![Figure 3.4: Counts of weather types'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.4：天气类型的计数'
- en: '](image/B15968_03_04.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_04.jpg)'
- en: 'Figure 3.4: Counts of weather types'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4：天气类型的计数
- en: 'Visualize the same information we have in the previous step as a pie chart
    using the `plot.pie(autopct=''%1.1f%%'')` method:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`plot.pie(autopct='%1.1f%%')`方法将与上一步相同的信息可视化为饼图：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This code will produce the following output:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将产生以下输出：
- en: '![Figure 3.5: Counts of weather types'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.5：天气类型的计数'
- en: '](image/B15968_03_05.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_05.jpg)'
- en: 'Figure 3.5: Counts of weather types'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5：天气类型的计数
- en: 'Now, we would like to visualize these counts of weather types, together with
    the information on what percentage each weather type accounts for in each city.
    First, this information can be computed using the `groupby()` method, as follows:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们想要可视化这些天气类型的计数，以及每种天气类型在每个城市中所占百分比的信息。首先，可以使用`groupby()`方法计算这些信息，如下所示：
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE16]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We see that this object contains the information that we wanted. For example,
    looking at the `cloudy` row in the table, we see that the weather type `cloudy`
    occurs three times in New York and three times in St Louis. There are multiple
    places where we have `NaN` values, which denote non-occurrences.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这个对象包含了我们想要的信息。例如，看看表中`cloudy`行，我们可以看到`cloudy`天气类型在纽约出现了三次，在圣路易斯也出现了三次。我们有多个地方有`NaN`值，表示没有发生。
- en: 'We finally visualize the table we have in the previous step as a stacked bar
    plot:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将上一步中的表可视化为堆叠条形图：
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This will produce the following plot:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下图表：
- en: '![Figure 3.6: Counts of weather types with respect to cities'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.6：天气类型的计数与城市相关'
- en: '](image/B15968_03_06.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_06.jpg)'
- en: 'Figure 3.6: Counts of weather types with respect to cities'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6：天气类型的计数与城市相关
- en: Throughout this exercise, we have put our knowledge regarding categorical data
    into practice to visualize various types of counts computed from a sample weather dataset.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个练习过程中，我们已经将关于分类数据的知识付诸实践，以可视化从样本天气数据集中计算出的各种计数类型。
- en: Note
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: To access the source code for this specific section, please refer to [https://packt.live/2ArQAtw](https://packt.live/2ArQAtw).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问本节的源代码，请参阅[https://packt.live/2ArQAtw](https://packt.live/2ArQAtw)。
- en: You can also run this example online at [https://packt.live/3gkIWAw](https://packt.live/3gkIWAw).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3gkIWAw](https://packt.live/3gkIWAw)上在线运行此示例。
- en: 'With that, let''s move on to the second main type of data: numerical data.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，让我们继续讨论第二种主要类型的数据：数值数据。
- en: Numerical Data
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数值数据
- en: The term proves to be intuitive in helping us understand what type of data this
    is. A numerical attribute should contain numerical and continuous values or real
    numbers. The values belonging to a numerical attribute can have a specific range;
    for example, they can be positive, negative, or between 0 and 1\. However, an
    attribute being numerical implies that its data can take any value within its
    given range. This is notably different from values in a categorical attribute,
    which only belong to a given discrete set of values.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个术语在帮助我们理解这是什么类型的数据方面是直观的。数值属性应该包含数值和连续值或实数。数值属性的值可以具有特定的范围；例如，它们可以是正数、负数或在0和1之间。然而，数值属性意味着其数据可以在给定范围内取任何值。这与分类属性中的值明显不同，后者只属于给定的离散值集。
- en: 'There are many examples of numerical data: the height of the members of a population,
    the weight of the students in a school, the price of houses that are for sale
    in certain areas, the average speed of track-and-field athletes, and so on. As
    long as the data can be represented as real-valued numbers, it is most likely
    numerical data.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 数值数据有许多例子：人口成员的身高、学校学生的体重、某些地区待售房屋的价格、田径运动员的平均速度等。只要数据可以表示为实数，它很可能是数值数据。
- en: Given its nature, numerical data is vastly different from categorical data.
    In the following text, we will lay out some of the most important differences
    with respect to statistics and machine learning that we should keep in mind.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于其性质，数值数据与分类数据有很大的不同。在接下来的文本中，我们将阐述一些在统计和机器学习方面最重要的差异，我们应该牢记。
- en: As opposed to a few probability distributions that can be used to model categorical
    data, there are numerous probability distributions for numerical data. These include
    the normal distribution (also known as the bell curve distribution), the uniform
    distribution, the exponential distribution, the Student's t distribution, and
    many more. Each of these probability distributions is designed to model specific
    types of data. For example, the normal distribution is typically used to model
    quantities with linear growth such as age, height, or students' test scores, while
    the exponential distribution models the amount of time between the occurrences
    of a given event.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 与可以用于建模分类数据的少数概率分布相反，数值数据有许多概率分布。这些包括正态分布（也称为钟形曲线分布）、均匀分布、指数分布、学生t分布等。每种概率分布都设计用于建模特定类型的数据。例如，正态分布通常用于建模具有线性增长的数量，如年龄、身高或学生的考试成绩，而指数分布则用于建模给定事件发生之间的时间量。
- en: It is important, therefore, to research what specific probability distribution
    is suitable for the numerical attribute that you are attempting to model. An appropriate
    distribution will allow for coherent analysis as well as accurate predictions;
    on the other hand, an unsuitable choice of probability distribution might lead
    to unintuitive and incorrect conclusions.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重要的是研究哪种特定的概率分布适合你试图建模的数值属性。适当的分布将允许一致的分析和准确的预测；另一方面，选择不当的概率分布可能导致不直观和不正确的结论。
- en: On another topic, many processing techniques can be applied to numerical data.
    Two of the most common of these include scaling and normalization.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个话题是，许多处理技术可以应用于数值数据。其中最常见的两种包括缩放和归一化。
- en: Scaling involves adding and/or multiplying all the values in a numerical attribute
    by a fixed quantity to scale the range of the original data to another range.
    This method is used when statistical and machine learning models can only handle
    values within a given range (for example, positive numbers or numbers between
    0 and 1 can be processed and analyzed more easily).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放涉及将数值属性中的所有值添加和/或乘以固定数量，以将原始数据的范围缩放到另一个范围。当统计和机器学习模型只能处理给定范围内的值时（例如，正数或0到1之间的数字可以更容易地处理和分析），就会使用这种方法。
- en: 'One of the most commonly used scaling techniques is the min-max scaling method,
    which is explained by the following formula, where *a* and *b* are positive numbers:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的缩放技术之一是最小-最大缩放方法，其公式如下所示，其中*a*和*b*为正数：
- en: '![Figure 3.7: Formula for min-max scaling'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.7：最小-最大缩放的公式'
- en: '](image/B15968_03_07.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_07.jpg)'
- en: 'Figure 3.7: Formula for min-max scaling'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7：最小-最大缩放的公式
- en: '*X''* and *X* denote the data after and before the transformation, while *X*max
    and *X*min denote the maximum and minimum values within the data, respectively.
    It can be mathematically proven that the output of the formula is always greater
    than *a* and less than *b*, but we don''t need to go over that here. We will come
    back to this scaling method again in our next exercise.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*X''*和*X*分别表示变换后和变换前的数据，而*X*max和*X*min分别表示数据中的最大值和最小值。可以数学证明，公式的输出始终大于*a*且小于*b*，但我们不需要在这里详细讨论。我们将在下一个练习中再次回到这种缩放方法。'
- en: As for normalization, even though this term is sometimes used interchangeably
    with *scaling*, it denotes the process of specifically scaling a numerical attribute
    to the normalized form with respect to its probability distribution. The goal
    is for us to obtain a transformed dataset that nicely follows the shape of the
    probability distribution we have chosen.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 至于归一化，尽管有时这个术语与*缩放*可以互换使用，但它指的是将数值属性特定地缩放到其概率分布的归一化形式的过程。我们的目标是获得一个转换后的数据集，它很好地遵循我们选择的概率分布的形状。
- en: 'For example, say the data we have in a numerical attribute follows a normal
    distribution with a mean of `4` and a standard deviation of `10`. The following
    code randomly generates that data synthetically and visualizes it:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们在一个数值属性中拥有的数据遵循均值为`4`，标准差为`10`的正态分布。以下代码随机生成了这些数据，并对其进行可视化：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This produces the following plot:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下图表：
- en: '![Figure 3.8: Histogram for normally distributed data'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.8：正态分布数据的直方图'
- en: '](image/B15968_03_08.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_08.jpg)'
- en: 'Figure 3.8: Histogram for normally distributed data'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8：正态分布数据的直方图
- en: Now, say you have a model that assumes the standard form of the normal distribution
    for this data, where the mean is `0` and the standard deviation is `1`, and if
    the input data is not in this form, the model will have difficulty learning from
    it. Therefore, you'd like to somehow transform the preceding data into this standard
    form, without sacrificing the true pattern (specifically the general shape) of
    the data.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你有一个模型，假设这些数据符合正态分布的标准形式，其中均值为`0`，标准差为`1`，如果输入数据不符合这种形式，模型将难以学习。因此，你希望以某种方式将前述数据转换为这种标准形式，而不牺牲数据的真实模式（特别是一般形状）。
- en: 'Here, we can apply the normalization technique for normally distributed data,
    in which we subtract the true mean from the data points and divide the result
    by the true standard deviation. This scaling process is more generally known as
    a standard scaler. Since the preceding data is already a NumPy array, we can take
    advantage of vectorization and perform the normalization as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以应用正态分布数据的归一化技术，其中我们从数据点中减去真实均值，并将结果除以真实标准差。这个缩放过程更普遍地被称为标准缩放器。由于前述数据已经是一个NumPy数组，我们可以利用矢量化并进行如下归一化：
- en: '[PRE19]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This code will generate the histogram for our newly transformed data, which
    is shown here:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将生成我们新转换的数据的直方图，如下所示：
- en: '![Figure 3.9: Histogram for normalized data'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.9：归一化数据的直方图'
- en: '](image/B15968_03_09.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_09.jpg)'
- en: 'Figure 3.9: Histogram for normalized data'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9：归一化数据的直方图
- en: We see that while the data has been successfully shifted to the range we want,
    now it centers around `0` and most of the data lies between `-3` and `3`, which
    is the standard form of the normal distribution, but the general shape of the
    data has not been altered. In other words, the relative differences between the
    data points have not been changed.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，虽然数据已成功转移到我们想要的范围，现在它以`0`为中心，大部分数据位于`-3`和`3`之间，这是正态分布的标准形式，但数据的一般形状并没有改变。换句话说，数据点之间的相对差异没有改变。
- en: 'On an additional note, in practice, when the true mean and/or the true standard
    deviation are not available, we can approximate those statistics with the sample
    mean and standard deviation as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，在实践中，当真实均值和/或真实标准差不可用时，我们可以用样本均值和标准差来近似这些统计量，如下所示：
- en: '[PRE20]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: With a large number of samples, these two statistics offer a good approximation
    that can be further used for this type of transformation. With that, we can now
    feed this normalized data to our statistical and machine learning models for further
    analysis.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大量样本，这两个统计量提供了一个可以进一步用于这种转换的良好近似。有了这个，我们现在可以将这些归一化的数据输入到我们的统计和机器学习模型中进行进一步分析。
- en: Speaking of the mean and the standard deviation, those two statistics are usually
    used to describe numerical data. To fill in missing values in a numerical attribute,
    central tendency measures such as the mean and the median are typically used.
    In some special cases such as a time-series dataset, you can use more complex
    missing value imputation techniques such as interpolation, where we estimate the
    missing value to be somewhere *in between* the ones immediately before and after
    it in a sequence.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 说到均值和标准差，这两个统计量通常用于描述数值数据。为了填补数值属性中的缺失值，通常使用均值和中位数等集中趋势测量。在一些特殊情况下，比如时间序列数据集，可以使用更复杂的缺失值插补技术，比如插值，我们可以估计缺失值在序列中*在两者之间*的某个位置。
- en: When we'd like to train a predictive model to target a numerical attribute,
    regression models are used. Instead of making predictions on which possible categorical
    values an entry can take like a classifier, a regression model looks for a reasonable
    prediction across a continuous numerical range. As such, similar to what we have
    discussed, we must take care to only apply regression models on datasets whose
    target values are numerical attributes.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要训练一个预测模型来针对数值属性时，会使用回归模型。与分类器不同，回归模型不是对条目可能取的分类值进行预测，而是寻找连续数值范围内的合理预测。因此，与我们讨论过的类似，我们必须小心地只在目标值是数值属性的数据集上应用回归模型。
- en: Finally, in terms of visualizing numerical data, we have seen a wide range of
    visualization techniques that we can use. Immediately before this, we saw histograms
    being used to describe the distribution of a numerical attribute, which tells
    us how the data is dispersed along its range.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在可视化数值数据方面，我们已经看到了一系列可用的可视化技术。就在这之前，我们看到直方图被用来描述数值属性的分布，告诉我们数据在其范围内是如何分布的。
- en: In addition, line graphs and scatter plots are generally good tools to visualize
    patterns of an attribute with respect to other attributes. (For example, we plotted
    the PDF of various probability distributions as line graphs.) Lastly, we also
    saw a heatmap being used to visualize a two-dimensional structure, which can be
    applied to represent correlations between numerical attributes in a dataset.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，折线图和散点图通常是可视化属性与其他属性模式的良好工具。（例如，我们绘制了各种概率分布的概率密度函数作为折线图。）最后，我们还看到热图被用来可视化二维结构，可以用来表示数据集中数值属性之间的相关性。
- en: Before we move on with our next topic of discussion, let's performa quick exercise
    on the concept of scaling/normalization. Again, one of the most popular scaling/normalization
    methods is called *Min-Max scaling*, which allows us to transform all values in
    a numerical attribute into any arbitrary range *[a, b]*. We will explore this
    method next.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讨论下一个话题之前，让我们对缩放/归一化的概念进行快速练习。再次，最流行的缩放/归一化方法之一被称为*最小-最大缩放*，它允许我们将数值属性中的所有值转换为任意的范围*[a,
    b]*。我们将在下面探讨这种方法。
- en: 'Exercise 3.02: Min-Max Scaling'
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习3.02：最小-最大缩放
- en: 'In this exercise, we will write a function that facilitates the process of
    applying Min-Max scaling to a numerical attribute. The function should take in
    three parameters: `data`, `a`, and `b`. While `data` should be a NumPy array or
    a pandas `Series` object, `a` and `b` should be real-valued positive numbers denoting
    the endpoints of the numerical range that `data` should be transformed into.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将编写一个函数，以便简化将最小-最大缩放应用于数值属性的过程。该函数应该接受三个参数：`data`、`a`和`b`。`data`应该是一个NumPy数组或pandas的`Series`对象，`a`和`b`应该是实数正数，表示`data`应该转换成的数值范围的端点。
- en: 'Referring back to the formula included in the *Numerical Data* section, Min-Max
    scaling is given by the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾*数值数据*部分中包含的公式，最小-最大缩放由以下给出：
- en: '![Figure 3.10: Formula for min-max scaling'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.10：最小-最大缩放的公式'
- en: '](image/B15968_03_10.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_10.jpg)'
- en: 'Figure 3.10: Formula for min-max scaling'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10：最小-最大缩放的公式
- en: 'Let''s have a look at the steps that need to be followed to meet our goal:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看需要遵循的步骤：
- en: 'Create a new Jupyter notebook and in its first code cell, import the libraries
    that we will be using for this exercise, as follows:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Jupyter笔记本，在第一个代码单元格中，导入我们将在本练习中使用的库，如下所示：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the dataset that we will be using, the first column is named `''Column 1''`
    and contains 1,000 samples from a normal distribution with a mean of 4 and a standard
    deviation of 10\. The second column is named `''Column 2''` and contains 1,000
    samples from a uniform distribution from 1 to 2\. The third column is named `''Column
    3''` and contains 1,000 samples from a Beta distribution with parameters 2 and
    5\. In the next code cell, read in the `''data.csv''` file, which we generated
    for you beforehand (and which can be found at [https://packt.live/2YTrdKt](https://packt.live/2YTrdKt)),
    as a `DataFrame` object using pandas and print out the first five rows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将要使用的数据集中，第一列名为`'Column 1'`，包含来自均值为4，标准差为10的正态分布的1,000个样本。第二列名为`'Column 2'`，包含来自1到2的均匀分布的1,000个样本。第三列名为`'Column
    3'`，包含参数为2和5的Beta分布的1,000个样本。在下一个代码单元格中，读取我们预先为您生成的`'data.csv'`文件（可以在[https://packt.live/2YTrdKt](https://packt.live/2YTrdKt)找到），使用pandas作为`DataFrame`对象，并打印出前五行：
- en: '[PRE22]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You should see the following numbers:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下数字：
- en: '[PRE23]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In the next cell, write a function named `min_max_scale()` that takes in three
    parameters: `data`, `a`, and `b`. As mentioned, `data` should be an array of values
    in an attribute of a dataset, while `a` and `b` specify the range that the input
    data is to be transformed into.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个单元格中，编写一个名为`min_max_scale()`的函数，它接受三个参数：`data`、`a`和`b`。如前所述，`data`应该是数据集属性中的值数组，而`a`和`b`指定输入数据要转换成的范围。
- en: 'Given the (implicit) requirement we have about `data` (a NumPy array or a pandas
    `Series` object—both of which can utilize vectorization), implement the scaling
    function with vectorized operations:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到我们对`data`的（隐含）要求（一个NumPy数组或pandas的`Series`对象——两者都可以利用矢量化），使用矢量化操作实现缩放函数：
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We will consider the data in the `''Column 1''` attribute first. To observe
    the effect that this function will have on our data, let''s first visualize the
    distribution of what we currently have:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先我们将考虑`'Column 1'`属性中的数据。为了观察这个函数对我们数据的影响，让我们首先可视化当前数据的分布：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This code will generate a plot that is similar to the following:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将生成类似以下的图表：
- en: '![Figure 3.11: Histogram of unscaled data'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.11：未缩放数据的直方图'
- en: '](image/B15968_03_11.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_11.jpg)'
- en: 'Figure 3.11: Histogram of unscaled data'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11：未缩放数据的直方图
- en: 'Now, use the same `plt.hist()` function to visualize the returned value of
    the `min_max_scale()` function when called on `df[''Column 1'']` to scale that
    data to the range `[-3, 3]`:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用相同的`plt.hist()`函数来可视化调用`df['Column 1']`上的`min_max_scale()`函数返回的值，将数据缩放到范围`[-3,
    3]`：
- en: '[PRE26]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This will produce the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下结果：
- en: '![Figure 3.12: Histogram of scaled data'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12：缩放数据的直方图'
- en: '](image/B15968_03_12.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_12.jpg)'
- en: 'Figure 3.12: Histogram of scaled data'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12：缩放数据的直方图
- en: We see that while the general shape of the data distribution remains the same,
    the range of the data has been effectively changed to be from `-3` to `3`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，虽然数据分布的一般形状保持不变，但数据的范围已经有效地改变为从`-3`到`3`。
- en: 'Go through the same process (visualizing the data before and after scaling
    with histograms) for the `''Column 2''` attribute. First, we visualize the original
    data:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`'Column 2'`属性，进行相同的过程（使用直方图可视化缩放前后的数据）。首先，我们可视化原始数据：
- en: '[PRE27]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now we visualize the scaled data, which should be scaled to the range `[0,
    1]`:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可视化缩放后的数据，应该缩放到范围`[0, 1]`：
- en: '[PRE28]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The second block of code should produce a graph similar to the following:![Figure
    3.13: Histogram of scaled data'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个代码块应该生成类似以下的图表：![图3.13：缩放数据的直方图
- en: '](image/B15968_03_13.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_13.jpg)'
- en: 'Figure 3.13: Histogram of scaled data'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13：缩放数据的直方图
- en: 'Go through the same process (visualizing the data before and after the scaling
    with histograms) for the `''Column 3''` attribute. First, we visualize the original data:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`'Column 3'`属性，进行相同的过程（使用直方图可视化缩放前后的数据）。首先，我们可视化原始数据：
- en: '[PRE29]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now we visualize the scaled data, which should be scaled to the range `[10, 20]`:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可视化缩放后的数据，应该缩放到范围`[10, 20]`：
- en: '[PRE30]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The second block of code should produce a graph similar to the following:![Figure
    3.14: Histogram of scaled data'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个代码块应该生成类似以下的图表：![图3.14：缩放数据的直方图
- en: '](image/B15968_03_14.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_14.jpg)'
- en: 'Figure 3.14: Histogram of scaled data'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14：缩放数据的直方图
- en: In this exercise, we have considered the concept of scaling/normalization for
    numerical data in more detail. We have also revisited the `plt.hist()` function
    as a method to visualize the distribution of numerical data.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们更详细地考虑了数值数据的缩放/归一化概念。我们还重新访问了`plt.hist()`函数作为可视化数值数据分布的方法。
- en: Note
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2VDw3JP](https://packt.live/2VDw3JP).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/2VDw3JP](https://packt.live/2VDw3JP)。
- en: You can also run this example online at [https://packt.live/3ggiPdO](https://packt.live/3ggiPdO).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在[https://packt.live/3ggiPdO](https://packt.live/3ggiPdO)上在线运行此示例。
- en: The exercise concludes the topic of numerical data in this chapter. Together
    with categorical data, it makes up most of the data types that you might see in
    a given dataset. However, there is actually another data type in addition to these
    two, which is less common, as we will discuss in the next section.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习结束了本章关于数值数据的讨论。连同分类数据一起，它构成了您可能在给定数据集中看到的大多数数据类型。然而，实际上除了这两种数据类型之外，还有另一种数据类型，这种数据类型较少见，我们将在下一节中讨论。
- en: Ordinal Data
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 序数数据
- en: Ordinal data is somewhat of a combination of categorical data (values in an
    ordinal attribute belonging to a specific given set) and numerical data (where
    the values are numbers—this fact implies an ordered relationship between them).
    The most common examples of ordinal data are letter scores (`"A"`, `"B"`, `"C"`,
    `"D"`, and `"E"`), integer ratings (for example, on a scale of 1 to 10), or quality
    ranking (for example, `"excellent"`, `"okay"`, and `"bad"`, where `"excellent"`
    implies a higher level of quality than `"okay"`, which in itself is better than
    `"bad"`).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 序数数据在某种程度上是分类数据（序数属性中的值属于特定给定集合）和数值数据（其中值为数字——这一事实意味着它们之间存在有序关系）的组合。序数数据的最常见示例是字母分数（“A”，“B”，“C”，“D”和“E”），整数评分（例如，在1到10的范围内），或者质量排名（例如，“优秀”，“好”，和“差”，其中“优秀”意味着比“好”更高的质量级别，而“好”本身又比“差”更好）。
- en: Since entries in an ordinal attribute can only take on one out of a specific
    set of values, *categorical probability distributions* should be used to model
    this type of data. For the same reason, missing values in an ordinal attribute
    can be filled out using the mode of the attribute, and visualization techniques
    for categorical data can be applied to ordinal data as well.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于序数属性中的条目只能取特定一组值中的一个，应该使用*分类概率分布*来对这种类型的数据进行建模。出于同样的原因，序数属性中的缺失值可以使用属性的众数来填充，分类数据的可视化技术也可以应用于序数数据。
- en: However, other processes might prove different from what we have discussed for
    categorical data. In terms of data processing, you could potentially assign a
    one-to-one mapping between each ordinal value and a numerical value/range.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，其他过程可能与我们讨论的分类数据有所不同。在数据处理方面，您可能会为每个序数值分配一个一对一的映射，以及一个数字值/范围。
- en: In the letter score example, it is commonly the case that the grade `"A"` corresponds
    to the range `[90, 100]` in the raw score, and other letter grades have their
    own continuous ranges as well. In the quality ranking example, `"excellent"`,
    `"okay"`, and `"bad"` can be mapped to 10, 5, and 0, respectively, as an example;
    however, this type of transformation is undesirable unless the degree of difference
    in quality between the values can be quantified.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在字母分数的例子中，通常情况下，等级“A”对应于原始分数的范围[90, 100]，其他字母等级也有它们自己的连续范围。在质量排名的例子中，“优秀”，“好”和“差”可以分别映射为10，5和0，但是，除非可以量化值之间的质量差异程度，否则这种转换是不可取的。
- en: In terms of fitting a machine learning model to the data and having it predict
    unseen values of an ordinal attribute, classifiers should be used for this task.
    Furthermore, since ranking is a unique task that constitutes many different learning
    structures, considerable effort has been dedicated to *machine-learning ranking*,
    where models are designed and trained specifically to predict ranking data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在将机器学习模型拟合到数据并让其预测序数属性的未见值方面，应该使用分类器来执行此任务。此外，由于排名是构成许多不同学习结构的独特任务，已经付出了相当大的努力来进行*机器学习排名*，其中专门设计和训练模型以预测排名数据。
- en: 'This discussion concludes the topic of data types in statistics and machine
    learning. Overall, we have learned that there are two main data types commonly
    seen in datasets: categorical and numerical data. Depending on which type your
    data belongs to, you will need to employ different data processing, machine learning,
    and visualization techniques.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这个讨论结束了统计学和机器学习中的数据类型主题。总的来说，我们已经了解到数据集中常见的两种主要数据类型：分类和数值数据。根据您的数据属于哪种类型，您将需要使用不同的数据处理、机器学习和可视化技术。
- en: In the next section, we will talk about descriptive statistics and how they
    can be computed in Python.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论描述统计以及如何在Python中进行计算。
- en: Descriptive Statistics
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述统计
- en: As mentioned before, descriptive statistics and inferential statistics are the
    two main categories in the field of statistics. With descriptive statistics, our
    goal is to compute specific quantities that can convey important information about—or
    in other words, describe—our data.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，描述统计和推断统计是统计学领域的两个主要类别。通过描述统计，我们的目标是计算特定的数量，可以传达关于我们的数据的重要信息，或者换句话说，描述我们的数据。
- en: 'From within descriptive statistics, there are two main subcategories: central
    tendency statistics and dispersion statistics. The actual terms are suggestive
    of their respective meaning: **central tendency statistics** are responsible for
    describing the *center* of the distribution of the given data, while **dispersion
    statistics** convey information about the spread or range of the data away from
    its center.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在描述统计中，有两个主要的子类别：中心趋势统计和离散统计。实际术语暗示了它们各自的含义：中心趋势统计负责描述给定数据的*中心*，而离散统计传达有关数据远离其中心的传播或范围的信息。
- en: One of the clearest examples of this distinction is from the familiar normal
    distribution, whose statistics include a mean and a standard deviation. The mean,
    which is calculated to be the average of all the values from the probability distribution,
    is suitable for estimating the center of the distribution. In its standard form,
    as we have seen, the normal distribution has a mean of 0, indicating that its
    data revolves around point 0 on the axis.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区别最清晰的例子之一来自熟知的正态分布，其统计数据包括均值和标准差。均值是通过计算概率分布中所有值的平均值得出的，适用于估计分布的中心。正如我们所见，标准形式的正态分布的均值为0，表明其数据围绕着轴上的0点。
- en: The standard deviation, on the other hand, represents how much the data points
    vary from the mean. Without going into much detail, in a normal distribution,
    it is calculated to be the mean distance from the mean of the distribution. A
    low-valued standard deviation indicates that the data does not deviate too much
    from the mean, while a high-valued standard deviation implies that the individual
    data points are quite different from the mean.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，标准差表示数据点与均值的变化程度。在不深入细节的情况下，在正态分布中，它被计算为与分布均值的平均距离。低值的标准差表明数据与均值的偏差不大，而高值的标准差意味着个别数据点与均值相差很大。
- en: 'Overall, these types of statistics and their characteristics can be summarized
    in the following table:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这些类型的统计数据及其特性可以总结在以下表中：
- en: '![Figure 3.15: Types of descriptive statistics'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.15：描述性统计类型'
- en: '](image/B15968_03_15.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_15.jpg)'
- en: 'Figure 3.15: Types of descriptive statistics'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15：描述性统计类型
- en: There are also other, more specialized descriptive statistics, such as skewness,
    which measures the asymmetry of the data distribution, or kurtosis, which measures
    the sharpness of the distribution peak. However, these are not as commonly used
    as the ones we listed previously, and therefore will not be covered in this chapter.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他更专业的描述性统计，比如衡度，用于衡量数据分布的不对称性，或者峰度，用于衡量分布峰值的陡峭程度。然而，这些并不像我们之前列出的那些常用，因此本章不会涉及。
- en: In the next subsection, we will start discussing each of the preceding statistics
    in more depth, starting with central tendency measures.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将开始更深入地讨论前述统计数据，从集中趋势测量开始。
- en: Central Tendency
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集中趋势
- en: Formally, the three commonly used central tendency statistics are the mean,
    the median, and the mode. The **median** is defined as the middlemost value when
    all the data points are ordered along the axis. The **mode**, as we have mentioned
    before, is the value that occurs the most. Due to their characteristics, the mean
    and the median are only applicable for numerical data, while the mode is often
    used on categorical data.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 形式上，常用的集中趋势统计数据有均值、中位数和众数。**中位数**被定义为当所有数据点沿着轴排序时的中间值。**众数**，正如我们之前提到的，是出现最多次的值。由于它们的特性，均值和中位数仅适用于数值数据，而众数通常用于分类数据。
- en: All three of these statistics capture the concept of central tendency well by
    representing the center of a dataset in different ways. This is also why they
    are often used as replacements for missing values in an attribute. As such, with
    a missing numerical value, you can choose either the mean or the median as a potential
    replacement, while the mode could be used if a categorical attribute contains
    missing values.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个统计数据都很好地捕捉了集中趋势的概念，以不同的方式代表了数据集的中心。这也是为什么它们经常被用来替换属性中的缺失值。因此，对于缺失的数值，你可以选择均值或中位数作为潜在的替代，而如果分类属性包含缺失值，则可以使用众数。
- en: In particular, it is actually not arbitrary that the mean is often used to fill
    in missing values in a numerical attribute. If we were to fit a probability distribution
    to the given numerical attribute, the mean of that attribute would actually be
    the sample mean, an estimation of the true population mean. Another term for the
    population mean is the expected value of an unknown value within that population,
    which, in other words, is what we should expect an arbitrary value from that population
    to be.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，均值经常被用来填补数值属性中的缺失值并非是任意的。如果我们要将概率分布拟合到给定的数值属性上，那么该属性的均值实际上将是样本均值，对真实总体均值的估计。总体均值的另一个术语是该总体内未知值的期望值，换句话说，就是我们应该期望来自该总体的任意值是多少。
- en: This is why the mean, or the expectation of a value from the corresponding distribution,
    should be used to fill in missing values in certain cases. While it is not exactly
    the case for the median, a somewhat similar argument can be made for its role
    in replacing missing numerical values. The mode, on the other hand, is a good
    estimation for missing categorical values, being the most commonly occurring value
    in an attribute.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么均值，或者来自相应分布的值的期望，应该在某些情况下用来填补缺失值。虽然对于中位数来说情况并非如此，但对于它在替换缺失数值方面的作用可以提出类似的论点。另一方面，众数是替换缺失分类值的良好估计，因为它是属性中出现最频繁的值。
- en: Dispersion
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离散度
- en: Different from central tendency statistics, dispersion statistics, again, attempt
    to quantify how much variation there is in a dataset. Some common dispersion statistics
    are the standard deviation, the range (the difference between the maximum and
    the minimum), and quartiles.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 与集中趋势统计不同，离散度统计再次试图量化数据集中的变化程度。一些常见的离散度统计包括标准差、范围（最大值和最小值之间的差异）和四分位数。
- en: The standard deviation, as we have mentioned, calculates the difference between
    each data point and the mean of a numerical attribute, squares them, takes their
    average, and finally takes the square root of the result. The further away the
    individual data points are from the mean, the larger this quantity gets, and vice
    versa. This is why it is a good indicator of how dispersed a dataset is.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差，正如我们所提到的，计算了每个数据点与数值属性的均值之间的差异，对它们进行平方，取平均值，最后取结果的平方根。个别数据点离均值越远，这个数量就越大，反之亦然。这就是为什么它是一个很好的指标，用来衡量数据集的离散程度。
- en: The range—the distance between the maximum and the minimum, or the 0- and 100-percent
    quartiles—is another, simpler way to describe the level of dispersion of a dataset.
    However, because of its simplicity, sometimes this statistic does not convey as
    much information as the standard deviation or the quartiles.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 范围——最大值和最小值之间的距离，或者0%和100%分位数之间的距离——是描述数据集离散程度的另一种更简单的方法。然而，由于其简单性，有时这个统计量并不能传达与标准差或四分位数一样多的信息。
- en: A quartile is defined to be a threshold below which a specific portion of a
    given dataset falls. For example, the median, the middlemost value of a numerical
    dataset, is the 50-percent quartile for that dataset, as (roughly) half of the
    dataset is less than that number. Similarly, we can compute common quartile quantities
    such as the 5-, 25-, 75-, and 95-percent quartiles. These quartiles are arguably
    more informative in terms of quantifying how dispersed our data is than the range,
    as they can account for different distributions of the data.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 四分位数被定义为数据集中特定部分落在其下的阈值。例如，中位数，数值数据集的中间值，是该数据集的50%分位数，因为（大致上）一半的数据集小于该数字。同样，我们可以计算常见的四分位数数量，如5%，25%，75%和95%分位数。这些四分位数在量化我们的数据分散程度方面可能更具信息量，因为它们可以解释数据的不同分布。
- en: In addition, the *interquartile range*, another common dispersion statistic,
    is defined to be the difference between the 25- and 75-percent quartiles of a
    dataset.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*四分位距*，另一个常见的离散统计量，被定义为数据集的25%和75%分位数之间的差异。
- en: So far, we have discussed the concepts of central tendency statistics and dispersion
    statistics. Let's go through a quick exercise to reinforce some of these important ideas.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了中心趋势统计和离散统计的概念。让我们通过一个快速练习来加强一些重要的想法。
- en: 'Exercise 3.03: Visualizing Probability Density Functions'
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习3.03：可视化概率密度函数
- en: 'In *Exercise 2.04*, *Visualization of Probability Distributions* of *Chapter
    2*, *Python''s Main Tools for Statistics*, we considered the task of comparing
    the PDF of a probability distribution against the histogram of its sampled data.
    Here, we will implement an extension of that program, where we also visualize
    various descriptive statistics for each of these distributions:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第2章*的*Python统计学的主要工具*的*练习2.04*中，我们考虑了比较概率分布的概率密度函数与其抽样数据的直方图的任务。在这里，我们将实现该程序的扩展，我们还将可视化每个分布的各种描述性统计信息：
- en: 'In the first cell of a new Jupyter notebook, import NumPy and Matplotlib:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新的Jupyter笔记本的第一个单元格中，导入NumPy和Matplotlib：
- en: '[PRE31]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In a new cell, randomly generate 1,000 samples from the normal distribution
    using `np.random.normal()`. Compute the mean, median, and the 25- and 75-percent
    quartiles descriptive statistics as follows:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的单元格中，使用`np.random.normal()`随机生成来自正态分布的1,000个样本。计算均值、中位数和25%和75%四分位数的描述性统计如下：
- en: '[PRE32]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'In the next cell, visualize the samples using a histogram. We will also indicate
    where the various descriptive statistics are by drawing vertical lines—a red vertical
    line at the mean point, a black one at the median, a blue line at each of the
    quartiles:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个单元格中，使用直方图可视化样本。我们还将通过绘制垂直线来指示各种描述性统计的位置——在均值点处绘制红色垂直线，在中位数处绘制黑色垂直线，在每个四分位数处绘制蓝色线：
- en: '[PRE33]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Note here that we are combining the specification of the `label` argument in
    various plotting function calls and the `plt.legend()` function. This will help
    us create a legend with appropriate labels, as can be seen here:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在各种绘图函数调用中结合了`label`参数的规范和`plt.legend()`函数。这将帮助我们创建一个带有适当标签的图例，如下所示：
- en: '![Figure 3.16: Descriptive statistics for a normal distribution'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.16：正态分布的描述性统计'
- en: '](image/B15968_03_16.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_16.jpg)'
- en: 'Figure 3.16: Descriptive statistics for a normal distribution'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16：正态分布的描述性统计
- en: 'One thing is of interest here: the mean and the median almost coincide on the
    x axis. This is one of the many mathematically convenient features of a normal
    distribution that is not found in many other distributions: its mean is equal
    to both its median and its mode.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一件有趣的事情：均值和中位数几乎在x轴上重合。这是正态分布的许多数学上方便的特性之一，在许多其他分布中找不到：它的均值等于它的中位数和众数。
- en: 'Apply the same process to a Beta distribution with parameters `2` and `5`,
    as follows:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相同的过程应用于参数为`2`和`5`的Beta分布，如下所示：
- en: '[PRE34]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This should generate a graph similar to the following:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成一个类似于以下的图表：
- en: '![Figure 3.17: Descriptive statistics for a Beta distribution'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.17：Beta分布的描述性统计'
- en: '](image/B15968_03_17.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_17.jpg)'
- en: 'Figure 3.17: Descriptive statistics for a Beta distribution'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17：Beta分布的描述性统计
- en: 'Apply the same process to a Gamma distribution with parameter `5`, as follows:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相同的过程应用于参数为`5`的Gamma分布，如下所示：
- en: '[PRE35]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This should generate a graph similar to the following:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该生成一个类似于以下的图表：
- en: '![Figure 3.18: Descriptive statistics for a Gamma distribution'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.18：Gamma分布的描述性统计'
- en: '](image/B15968_03_18.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_18.jpg)'
- en: 'Figure 3.18: Descriptive statistics for a Gamma distribution'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18：Gamma分布的描述性统计
- en: With this exercise, we have learned how to compute various descriptive statistics
    of a dataset using NumPy and visualize them in a histogram.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个练习，我们学会了如何使用NumPy计算数据集的各种描述性统计，并在直方图中可视化它们。
- en: Note
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YTobpm](https://packt.live/2YTobpm).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/2YTobpm](https://packt.live/2YTobpm)。
- en: You can also run this example online at [https://packt.live/2CZf26h](https://packt.live/2CZf26h).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/2CZf26h](https://packt.live/2CZf26h)上在线运行此示例。
- en: In addition to computing descriptive statistics, Python also offers other additional
    methods to describe data, which we will discuss in the next section.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 除了计算描述性统计信息，Python还提供其他附加方法来描述数据，我们将在下一节讨论。
- en: Python-Related Descriptive Statistics
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与Python相关的描述性统计
- en: Here, we will examine two intermediate methods for describing data. The first
    is the `describe()` method, to be called on a `DataFrame` object. From the official
    documentation (which can be found at [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)),
    the function "generate(s) descriptive statistics that summarize the central tendency,
    dispersion, and shape of a dataset's distribution, excluding `NaN` values."
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将讨论描述数据的两种中间方法。第一种是在`DataFrame`对象上调用的`describe()`方法。根据官方文档（可在[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)找到），该函数“生成总结数据集分布的集中趋势、离散度和形状的描述性统计，不包括`NaN`值。”
- en: 'Let''s see the effect of this method in action. First, we will create a sample
    dataset with a numerical attribute, a categorical attribute, and an ordinal one,
    as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这种方法的效果。首先，我们将创建一个包含数值属性、分类属性和顺序属性的样本数据集，如下所示：
- en: '[PRE36]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now, if we were to call the `describe()` method on the `df` variable, a tabular
    summary would be generated:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们在`df`变量上调用`describe()`方法，将生成一个表格摘要：
- en: '[PRE37]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is as follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE38]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As you can see, each row in the printed output denotes a different descriptive
    statistic about each attribute in our dataset: the number of values (`count`),
    mean, standard deviation, and various quartiles. Since both the `numerical` and
    `ordinal` attributes were interpreted as numerical data (given the data they contain),
    `describe()` only generates these reports for them by default. The `categorical`
    column, on the other hand, was excluded. To force the reports to apply to all
    columns, we can specify the `include` argument as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，打印输出中的每一行表示数据集中每个属性的不同描述统计信息：值的数量（`count`）、均值、标准差和各种四分位数。由于`numerical`和`ordinal`属性都被解释为数值数据（根据它们包含的数据），`describe()`默认只为它们生成这些报告。另一方面，`categorical`列被排除在外。为了强制报告适用于所有列，我们可以指定`include`参数如下：
- en: '[PRE39]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output is as follows:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE40]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: This forces the method to compute other statistics that apply for categorical
    data, such as the number of unique values (`unique`), the mode (`top`), and the
    count/frequency of the mode (`freq`). As we have discussed, most of the descriptive
    statistics for numerical data do not apply for categorical data and vice versa,
    which is why `NaN` values are used in the preceding reports to indicate such a
    non-application.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这迫使该方法计算适用于分类数据的其他统计信息，例如唯一值的数量（`unique`）、众数（`top`）和众数的计数/频率（`freq`）。正如我们讨论过的，大多数数值数据的描述统计不适用于分类数据，反之亦然，这就是为什么在前面的报告中使用`NaN`值来指示这种非适用性。
- en: Overall, the `describe()` method from pandas offers a quick way to summarize
    and obtain an overview of a dataset and its attributes. This especially comes
    in handy during exploratory data analysis tasks, where we'd like to broadly explore
    a new dataset that we are not familiar with yet.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，pandas的`describe()`方法提供了一种快速概括数据集及其属性的方法。这在探索性数据分析任务中特别方便，当我们想要广泛地探索一个我们尚不熟悉的新数据集时。
- en: The second descriptive statistics-related method that is supported by Python
    is the visualization of boxplots. Obviously, a boxplot is a visualization technique
    that is not unique to the language itself, but Python, specifically its seaborn
    library, provides a rather convenient API, the `sns.boxplot()` function, to facilitate
    the process.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Python支持的第二种与描述统计相关的方法是箱线图的可视化。显然，箱线图是一种可视化技术，不仅仅是语言本身的独特之处，但是Python，特别是其seaborn库，提供了一个相当方便的API，即`sns.boxplot()`函数，以便于这个过程。
- en: 'Theoretically, a boxplot is another method to visualize the distribution of
    a numerical dataset. It, again, can be generated with the `sns.boxplot()` function:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，箱线图是可视化数值数据集分布的另一种方法。同样，可以使用`sns.boxplot()`函数生成它：
- en: '[PRE41]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This code will produce a graph roughly similar to the following:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将产生一个与以下类似的图形：
- en: '![Figure 3.19: Boxplot using seaborn'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.19：使用seaborn的箱线图'
- en: '](image/B15968_03_19.jpg)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_19.jpg)'
- en: 'Figure 3.19: Boxplot using seaborn'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19：使用seaborn的箱线图
- en: In the preceding boxplot, the blue box in the middle denotes the interquartile
    range of the input data (from the 25- to 75-percent quartile). The vertical line
    in the middle of the box is the median, while the two thresholds on the left and
    right but outside of the box denote the minimum and maximum of the input data,
    respectively.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的箱线图中，中间的蓝色框表示输入数据的四分位距（从25%到75%的四分位数）。框中间的垂直线是中位数，而框外左右两个阈值分别表示输入数据的最小值和最大值。
- en: It is important to note that the minimum is calculated to be the 25-percent
    quartile *minus* the interquartile range multiplied by 1.5, and the maximum the
    75-percent quartile *plus* the interquartile range also multiplied by 1.5\. It
    is common practice to consider any number outside of this range between the minimum
    and the maximum to be outliers, visualized as black dots in the preceding graph.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，最小值被计算为25%四分位数*减去*四分位距乘以1.5，最大值是75%四分位数*加上*四分位距也乘以1.5。通常做法是将最小值和最大值之间的任何数字视为异常值，在前面的图中显示为黑点。
- en: In essence, a boxplot can represent the statistics computed by the `describe()`
    function from pandas visually. What sets this function from seaborn apart from
    other visualization tools is the ease in creating multiple boxplots given a criterion
    provided by seaborn.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，箱线图可以在视觉上表示由 pandas 的 `describe()` 函数计算的统计数据。这个 seaborn 中的函数与其他可视化工具的不同之处在于，它可以轻松地根据
    seaborn 提供的标准创建多个箱线图。
- en: 'Let''s see this in this next example, where we extend the sample dataset to
    `1000` rows with random data generation:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下一个示例中看到这一点，我们将扩展样本数据集到 `1000` 行，并生成随机数据：
- en: '[PRE42]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Here, the `'numerical'` attribute contains random draws from the standard normal
    distribution, the `'categorical'` attribute contains values randomly chosen from
    the list `['a', 'b', 'c']`, while `'ordinal'` also contains values randomly chosen
    from a list, `[1, 2, 3, 4, 5]`.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`'numerical'` 属性包含来自标准正态分布的随机抽样，`'categorical'` 属性包含从列表 `['a'，'b'，'c']`
    中随机选择的值，而 `'ordinal'` 也包含从列表 `[1, 2, 3, 4, 5]` 中随机选择的值。
- en: Our goal with this dataset is to generate a slightly more complex boxplot visualization—a
    boxplot representing the distribution of the data in `'numerical'` for the different
    values in `'categorical'`. The general process is to split the dataset into different
    groups, each corresponding to the unique value in `'categorical'`, and for each
    group, we'd like to generate a boxplot using the respective data in the `'numerical'`
    attribute.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是使用这个数据集生成一个稍微复杂的箱线图可视化——一个表示 `'categorical'` 中不同值的 `'numerical'` 数据分布的箱线图。一般的过程是将数据集分成不同的组，每个组对应于
    `'categorical'` 中的唯一值，并且对于每个组，我们希望使用 `'numerical'` 属性中的相应数据生成一个箱线图。
- en: 'However, with seaborn, we can streamline this process by specifying the `x`
    and `y` arguments for the `sns.boxplot()` function. Specifically, we will have
    our *x* axis contain the different unique values in `''categorical''` and the
    *y* axis represent the data in `''numerical''` with the following code:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用 seaborn，我们可以通过为 `sns.boxplot()` 函数指定 `x` 和 `y` 参数来简化这个过程。具体来说，我们将使我们的
    *x* 轴包含 `'categorical'` 中不同的唯一值，*y* 轴表示 `'numerical'` 中的数据，代码如下：
- en: '[PRE43]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This will generate the following plot:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![Figure 3.20: Multi-boxplot using seaborn'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.20：使用 seaborn 的多重箱线图'
- en: '](image/B15968_03_20.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_20.jpg)'
- en: 'Figure 3.20: Multi-boxplot using seaborn'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.20：使用 seaborn 的多重箱线图
- en: 'The visualization contains what we wanted to display: the distribution of the
    data in the `''numerical''` attribute, represented as boxplots and separated by
    the unique values in the `''categorical''` attribute. Considering the unique values
    in `''ordinal''`, we can apply the same process as follows:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这个可视化包含了我们想要显示的内容：`'numerical'` 属性数据的分布，表示为箱线图，并按 `'categorical'` 属性中的唯一值进行分隔。考虑到
    `'ordinal'` 中的唯一值，我们可以按照以下相同的过程进行：
- en: '[PRE44]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This will generate the following graph:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![Figure 3.21: Multi-boxplot using seaborn'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.21：使用 seaborn 的多重箱线图'
- en: '](image/B15968_03_21.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_21.jpg)'
- en: 'Figure 3.21: Multi-boxplot using seaborn'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.21：使用 seaborn 的多重箱线图
- en: As you can imagine, this method of visualization is ideal when we'd like to
    analyze the differences in the distribution of a numerical attribute with respect
    to categorical or ordinal data.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想象的，当我们想要分析数值属性在分类或有序数据方面的分布差异时，这种可视化方法是理想的。
- en: 'And that concludes the topic of descriptive statistics in this chapter. In
    the next section, we will talk about the other category of statistics: inferential
    statistics.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了本章关于描述性统计的话题。在下一节中，我们将讨论另一类统计学：推断统计。
- en: Inferential Statistics
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推断统计
- en: Unlike descriptive statistics, where our goal is to describe various characteristics
    of a dataset using specific quantities, with inferential statistics, we'd like
    to perform a particular statistical modeling process on our dataset so that we
    can *infer* further information, either about the dataset itself or even about
    unseen data points that are from the same population.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 与描述性统计不同，我们的目标是使用特定的数量描述数据集的各种特征，而在推断统计中，我们希望对数据集执行特定的统计建模过程，以便我们可以*推断*进一步的信息，无论是关于数据集本身还是关于来自同一总体的未见数据点。
- en: In this section, we will go through a number of different methods of inferential
    statistics. From these discussions, we will see that each method is designed for
    specific data and situations, and it is the responsibility of the statistician
    or machine learning engineer to appropriately apply them.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将介绍一些不同的推断统计方法。通过这些讨论，我们将看到每种方法都是针对特定数据和情况设计的，统计学家或机器学习工程师有责任适当地应用它们。
- en: 'The first method that we will discuss is one of the most fundamental in classical
    statistics: t-tests.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论的第一种方法是古典统计学中最基本的方法之一：t 检验。
- en: T-Tests
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: T-Tests
- en: In general, t-tests (also known as Student's t-tests) are used to compare two
    mean (average) statistics and conclude whether they are different enough from
    each other. The main application of a t-test is comparing the effect of an event
    (for example, an experimental drug, an exercise routine, and so on) on a population
    against a controlled group. If the means are different enough (we call this statistically
    significant), then we have good reason to believe in the effect of the given event.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，t 检验（也称为学生 t 检验）用于比较两个均值（平均）统计量，并得出它们是否足够不同的结论。t 检验的主要应用是比较事件（例如实验药物、锻炼常规等）对总体的影响与对照组。如果均值足够不同（我们称之为统计显著），那么我们有充分的理由相信给定事件的影响。
- en: 'There are three main types of t-tests in statistics: independent samples t-tests
    (used to compare the means of two independent samples), paired sample t-tests
    (used to compare the means of the same group at different times), and one-sample
    t-tests (used to compare the mean of one group with a predetermined mean).'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学中有三种主要类型的 t 检验：独立样本 t 检验（用于比较两个独立样本的均值），配对样本 t 检验（用于比较同一组在不同时间的均值），以及单样本
    t 检验（用于将一组的均值与预定均值进行比较）。
- en: The general workflow of a t-test is to first declare the null hypothesis that
    the two means are indeed equal and then consider the output of the t-test, which
    is the corresponding p-value. If the p-value is larger than a fixed threshold
    (usually, 0.05 is chosen), then we cannot reject the null hypothesis. If, on the
    other hand, the p-value is lower than the threshold, we can reject the null hypothesis,
    implying that the two means are different. We see that this is an inferential
    statistics method as, from it, we can *infer* a fact about our data; in this case,
    it is whether the two means we are interested in are different from each other.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: t检验的一般工作流程是首先声明这两个均值确实相等的零假设，然后考虑t检验的输出，即相应的p值。如果p值大于一个固定的阈值（通常选择0.05），那么我们就不能拒绝零假设。另一方面，如果p值低于阈值，我们就可以拒绝零假设，这意味着这两个均值是不同的。我们看到这是一种推断统计方法，因为我们可以从中*推断*出关于我们的数据的事实；在这种情况下，我们可以推断出我们感兴趣的两个均值是否不同。
- en: We will not go into the theoretical details of these tests; instead, we will
    see how we can simply take advantage of the API offered in Python, or specifically
    the SciPy library. We used this library in the last chapter, so if you are not
    yet familiar with the tool, be sure to head back to *Chapter 2*, *Python's Main
    Tools for Statistics* to see how it can be installed in your environment.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入讨论这些测试的理论细节；相反，我们将看到如何简单地利用Python提供的API，或者具体来说是SciPy库。我们在上一章中使用了这个库，所以如果你还不熟悉这个工具，一定要回到*第2章*，*Python的统计主要工具*，看看它如何在你的环境中安装。
- en: Let's design our sample experiment. Say we have two arrays of numbers, each
    was drawn from an unknown distribution, and we'd like to find out whether their
    respective means are equal to each other. Thus, we have our null hypothesis that
    the means of these two arrays are equal, which can be rejected if the p-value
    of our t-test is less than 0.05.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设计我们的样本实验。假设我们有两个数字数组，每个数组都是从一个未知分布中抽取的，我们想要找出它们各自的均值是否相等。因此，我们有我们的零假设，即这两个数组的均值相等，如果我们的t检验的p值小于0.05，则可以拒绝这个假设。
- en: 'To generate the synthetic data for this example, we will use `20` samples from
    the standard form of the normal distribution (a mean of `0`, and a standard deviation
    of `1`) for the first array, and another `20` samples from a normal distribution
    with a mean of `0.2` and a standard deviation of `1` for the second array:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成这个例子的合成数据，我们将从标准正态分布（均值为0，标准差为1）中使用`20`个样本来生成第一个数组，然后从均值为`0.2`，标准差为1的正态分布中使用另外`20`个样本来生成第二个数组：
- en: '[PRE45]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'To quickly visualize this dataset, we can use the `plt.hist()` function as
    follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速可视化这个数据集，我们可以使用`plt.hist()`函数，如下所示：
- en: '[PRE46]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This generates the following plot (note that your own output might be different):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了以下的图表（注意你自己的输出可能会有所不同）：
- en: '![Figure 3.22: Histogram of sample data for a t-test'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.22：t检验样本数据的直方图'
- en: '](image/B15968_03_22.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_22.jpg)'
- en: 'Figure 3.22: Histogram of sample data for a t-test'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22：t检验样本数据的直方图
- en: 'Now, we will call the `ttest_ind()` function from the `scipy.stats` package.
    This function facilitates an independent samples t-test and will return an object
    having an attribute named `pvalue`; this attribute contains the p-value that will
    help us decide whether to reject our null hypothesis or not:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将从`scipy.stats`包中调用`ttest_ind()`函数。这个函数便利了独立样本t检验，并将返回一个具有名为`pvalue`的属性的对象；这个属性包含了p值，将帮助我们决定是否拒绝我们的零假设：
- en: '[PRE47]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE48]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: With this result, we do not reject our null hypothesis. Again, your p-value
    might be different from the preceding output, but chances are it is not lower
    than 0.05 either. Our final conclusion here is that we don't have enough evidence
    to say that the means of our two arrays are different (even though they were actually
    generated from two normal distributions with different means).
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个结果，我们不拒绝我们的零假设。再次强调，你的p值可能与前面的输出不同，但很可能也不会低于0.05。我们最终的结论是，我们没有足够的证据表明我们的两个数组的均值是不同的（即使它们实际上是从两个均值不同的正态分布中生成的）。
- en: 'Let''s repeat this experiment, but this time we have significantly more data—each
    array now contains 1,000 numbers:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重复这个实验，但这次我们有更多的数据——每个数组现在包含1,000个数字：
- en: '[PRE49]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The histogram now looks like the following:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的直方图看起来像这样：
- en: '![Figure 3.23: Histogram of sample data for a t-test'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.23：t检验样本数据的直方图'
- en: '](image/B15968_03_23.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_23.jpg)'
- en: 'Figure 3.23: Histogram of sample data for a t-test'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23：t检验样本数据的直方图
- en: 'Running the t-test again, we see that this time, we obtain a different result:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 再次运行t检验，我们看到这次我们得到了不同的结果：
- en: '[PRE50]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output is as follows:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '[PRE51]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This p-value is a lot lower than 0.05, thus rejecting the null hypothesis and
    giving us enough evidence to say that the two arrays have different means.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这个p值远低于0.05，因此拒绝了零假设，并给了我们足够的证据表明这两个数组的均值是不同的。
- en: These two experiments demonstrated a phenomenon we should keep in mind. In the
    first experiment, our p-value wasn't low enough for us to reject the null hypothesis,
    even though our data was indeed generated from two distributions with different
    means. In the second experiment, with more data, the t-test was more conclusive
    in terms of differentiating the two means.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个实验展示了我们应该牢记的一个现象。在第一个实验中，我们的p值不够低，无法拒绝零假设，即使我们的数据确实是从两个均值不同的分布中生成的。在第二个实验中，有了更多的数据，t检验在区分这两个均值方面更具有决定性。
- en: In essence, with only 20 samples in each array, the first t-test didn't have
    a high enough level of confidence to output a lower p-value, even if the two means
    were indeed different. With 1,000 samples, this difference was more consistent
    and robust so that the second t-test was able to positively output a lower p-value.
    In general, many other statistical methods will similarly prove to be more conclusive
    as more data is used as input.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，每个数组中只有20个样本，第一个t检验没有足够高的置信水平来输出较低的p值，即使两个均值确实不同。有了1,000个样本，这种差异更加一致和稳健，因此第二个t检验能够积极地输出较低的p值。一般来说，许多其他统计方法在使用更多数据作为输入时也会同样证明更具有决定性。
- en: We have looked at an example of the independent samples t-test as a method of
    inferential statistics to test for the degree of difference between the averages
    of two given populations. Overall, the `scipy.stats` package offers a wide range
    of statistical tests that take care of all of the computation in the background
    and only return the final test output. This follows the general philosophy of
    the Python language, keeping the API at a high level so that users can take advantage
    of complex methodologies in a flexible and convenient manner.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过独立样本t检验的一个例子，作为推断统计的一种方法，用于测试两个给定总体的平均值之间的差异程度。总的来说，`scipy.stats`包提供了一系列广泛的统计测试，它们处理所有的计算工作，并且只返回最终的测试输出。这符合Python语言的一般哲学，保持API在高层次，以便用户可以以灵活和便利的方式利用复杂的方法。
- en: Note
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: More details on what is available in the `scipy.stats` package can be found
    in its official documentation at [https://docs.scipy.org/doc/scipy-0.15.1/reference/tutorial/stats.html](https://docs.scipy.org/doc/scipy-0.15.1/reference/tutorial/stats.html).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`scipy.stats`包中可用内容的更多详细信息可以在其官方文档中找到[https://docs.scipy.org/doc/scipy-0.15.1/reference/tutorial/stats.html](https://docs.scipy.org/doc/scipy-0.15.1/reference/tutorial/stats.html)。
- en: 'Some of the most commonly used tests that can be called from the package include:
    t-tests or ANOVAs for differences in means; normality testing to ascertain whether
    samples have been drawn from a normal distribution; and computation of the Bayesian
    credible intervals for the mean and standard deviation of a sample population.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从该包中调用的一些最常用的测试包括：用于均值差异的t检验或ANOVA；用于确定样本是否来自正态分布的正态性测试；以及计算样本总体的均值和标准差的贝叶斯可信区间。
- en: 'Moving away from the `scipy.stats` package, we have seen that the pandas library
    also supports a wide range of statistical functionalities, especially with its
    convenient `describe()` method. In the next section, we will look into the second
    inferential statistics method: the correlation matrix of a dataset.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 摆脱`scipy.stats`包，我们已经看到pandas库也支持各种统计功能，特别是其方便的`describe()`方法。在下一节中，我们将研究第二种推断统计方法：数据集的相关矩阵。
- en: Correlation Matrix
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关矩阵
- en: A correlation matrix is a two-dimensional table containing correlation coefficients
    between each pair of attributes of a given dataset. A correlation coefficient
    between two attributes quantifies their level of linear correlation, or in other
    words, how similarly they behave in a linear fashion. A correlation coefficient
    lies in the range between -1 and +1, where +1 denotes perfect linear correlation,
    0 denotes no correlation, and -1 denotes perfect negative correlation.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 相关矩阵是一个二维表，包含给定数据集中每对属性之间的相关系数。两个属性之间的相关系数量化了它们的线性相关程度，或者换句话说，它们在线性方面的行为有多相似。相关系数的范围在-1到+1之间，其中+1表示完美的线性相关，0表示没有相关性，-1表示完美的负相关。
- en: If two attributes have a high linear correlation, then when one increases, the
    other tends to increase by the same amount multiplied by a constant. In other
    words, if we were to plot the data in the two attributes on a scatter plot, the
    individual points would tend to follow a line with a positive slope. For two attributes
    having no correlation, the best-fit line tends to be horizontal, and two attributes
    having a negative correlation are represented by a line with a negative slope.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个属性具有很高的线性相关性，那么当一个属性增加时，另一个属性也倾向于以相同的常数乘以增加。换句话说，如果我们在散点图上绘制两个属性的数据，个别点倾向于沿着一个具有正斜率的直线。对于没有相关性的两个属性，最佳拟合线倾向于水平，而具有负相关性的两个属性则由具有负斜率的直线表示。
- en: The correlation between two attributes can, in a way, tell us how much information
    is shared among the attributes. We can infer from two correlated attributes, either
    positively or negatively, that there is some underlying relationship between them.
    This is the idea behind the correlation matrix as an inferential statistics tool.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 两个属性之间的相关性在某种程度上可以告诉我们属性之间共享多少信息。我们可以从两个相关的属性中推断出，无论是正相关还是负相关，它们之间都存在某种潜在的关系。这就是相关矩阵作为推断统计工具的背后思想。
- en: In some machine learning models, it is recommended that if we have highly correlated
    features, we should only leave one in the dataset before feeding it to the models.
    In most cases, having another attribute that is highly correlated to one that
    a model has been trained on does not improve its performance; what's more, in
    some situations, correlated features can even mislead our models and steer their
    predictions in the wrong direction.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些机器学习模型中，建议如果我们有高度相关的特征，应该在将其输入模型之前只保留一个特征。在大多数情况下，拥有另一个与模型已经训练的特征高度相关的属性并不会提高其性能；更重要的是，在某些情况下，相关特征甚至会误导我们的模型，使其预测走向错误的方向。
- en: This is to say that the correlation coefficient between two data attributes,
    and thus the correlation matrix of the dataset, is an important statistical object
    for us to consider. Let's see this in a quick example.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着两个数据属性之间的相关系数，以及数据集的相关矩阵，对我们来说是一个重要的统计对象。让我们通过一个快速的例子来看看这一点。
- en: 'Say we have a dataset of three attributes, `''x''`, `''y''`, and `''z''`. The
    data in `''x''` and `''z''` is randomly generated in an independent way, so there
    should be no correlation between them. On the other hand, we will generate `''y''`
    as the data in `''x''` multiplied by 2 and add in some random noise. This can
    be done with the following code, which creates a dataset with 500 entries:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个包含三个属性'x'、'y'和'z'的数据集。'x'和'z'中的数据是以独立的方式随机生成的，因此它们之间不应该有相关性。另一方面，我们将'y'生成为'x'中的数据乘以2再加上一些随机噪音。这可以通过以下代码实现，该代码创建了一个包含500个条目的数据集：
- en: '[PRE52]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'From here, the correlation matrix (which, again, contains correlation coefficients
    of every pair of attributes in our dataset) can be easily computed with the `corr()` method:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，相关矩阵（其中包含数据集中每对属性的相关系数）可以很容易地通过`corr()`方法计算出来：
- en: '[PRE53]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output is as follows:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE54]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: We see that this is a 3 x 3 matrix, as there are three attributes in the calling
    `DataFrame` object. Each number denotes the correlation between the row and the
    column attributes. One effect of this representation is that we have all of the
    diagonal values in the matrix as 1, as each attribute is perfectly correlated
    to itself.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到这是一个3x3的矩阵，因为在调用的DataFrame对象中有三个属性。每个数字表示行和列属性之间的相关性。这种表示的一个效果是矩阵中的对角线值都为1，因为每个属性与自身完全相关。
- en: 'What''s more interesting to us is the correlation between different attributes:
    as `''z''` was generated independently of `''x''` (and therefore `''y''`), the
    values in the `''z''` row and column are relatively close to 0\. In contrast to
    this, the correlation between `''x''` and `''y''` is quite close to 1, as one
    was generated to be roughly two times the other.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说更有趣的是不同属性之间的相关性：由于'z'是独立于'x'（因此也独立于'y'）生成的，'z'行和列中的值相对接近0。相比之下，'x'和'y'之间的相关性接近1，因为一个属性被生成为大约是另一个属性的两倍。
- en: 'Additionally, it is common to visually represent the correlation matrix with
    a heatmap. This is because when we have a large number of attributes in our dataset,
    a heatmap will help us identify the regions that correspond to highly correlated
    attributes more efficiently. The visualization of a heatmap can be done using
    the `sns.heatmap()` function from the seaborn library:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通常使用热力图来直观表示相关矩阵。这是因为当数据集中有大量属性时，热力图可以帮助我们更有效地识别高度相关的属性所对应的区域。可以使用seaborn库中的`sns.heatmap()`函数来可视化热力图：
- en: '[PRE55]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The `annot=True` argument specifies that the values in the matrix should be
    printed out in each cell of the heatmap.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`annot=True`参数指定矩阵中的值应该打印在热力图的每个单元格中。'
- en: 'The code will produce the following:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将产生以下结果：
- en: '![Figure 3.24: Heatmap representing a correlation matrix'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.24：代表相关矩阵的热力图'
- en: '](image/B15968_03_24.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_24.jpg)'
- en: 'Figure 3.24: Heatmap representing a correlation matrix'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.24：代表相关矩阵的热力图
- en: In this case, while visually inspecting a correlation matrix heatmap, we can
    focus on the bright regions, aside from the diagonal cells, to identify highly
    correlated attributes. If there were negatively correlated attributes in a dataset
    (which we don't have in our current example), those could be detected with dark
    regions as well.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，当通过视觉检查相关矩阵热力图时，我们可以专注于明亮的区域，除了对角线单元格，以识别高度相关的属性。如果数据集中存在负相关的属性（在我们当前的例子中没有），那么这些属性也可以通过暗区域来检测。
- en: Overall, the correlation matrix of a given dataset can be a useful tool for
    us to understand the relationship between the different attributes of that dataset.
    We will see an example of this in the upcoming exercise.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，给定数据集的相关矩阵可以成为我们理解数据集中不同属性之间关系的有用工具。我们将在接下来的练习中看到一个例子。
- en: 'Exercise 3.04: Identifying and Testing Equality of Means'
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习3.04：识别和测试均值的相等性
- en: In this exercise, we will practice the two inferential statistics methods to
    analyze a synthetic dataset that we have generated for you. The dataset can be
    downloaded from the GitHub repository at [https://packt.live/3ghKkDS](https://packt.live/3ghKkDS).
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将练习两种推断统计方法来分析我们为您生成的一个合成数据集。可以从GitHub仓库[https://packt.live/3ghKkDS](https://packt.live/3ghKkDS)下载数据集。
- en: Here, our goal is to first identify which attributes in this dataset are correlated
    with each other and then apply a t-test to determine whether any pair of attributes
    have the same mean.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们的目标是首先确定数据集中哪些属性彼此相关，然后应用t检验来确定任何一对属性是否具有相同的均值。
- en: 'With that said, let''s get started:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些说法，让我们开始吧：
- en: 'In a new Jupyter notebook, import `pandas`, `matplotlib`, `seaborn`, and the
    `ttest_ind()` method from the `stats` module from SciPy:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的Jupyter笔记本中，导入`pandas`、`matplotlib`、`seaborn`，以及从SciPy的`stats`模块中导入`ttest_ind()`方法：
- en: '[PRE56]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Read in the dataset that you have downloaded. The first five rows should look
    like the following:![Figure 3.25: Reading the first five rows of the dataset'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取您下载的数据集。前五行应该如下所示：![图3.25：读取数据集的前五行
- en: '](image/B15968_03_25.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_25.jpg)'
- en: 'Figure 3.25: Reading the first five rows of the dataset'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.25：读取数据集的前五行
- en: 'In the next code cell, use seaborn to generate the heatmap that represents
    the correlation matrix for this dataset. From the visualization, identify the
    pair of attributes that are correlated with each other the most:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个代码单元中，使用seaborn生成代表该数据集相关矩阵的热力图。从可视化中，确定哪对属性彼此相关性最高：
- en: '[PRE57]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'This code should produce the following visualization:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码应该产生以下可视化效果：
- en: '![Figure 3.26: Correlation matrix for the dataset'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.26：数据集的相关矩阵'
- en: '](image/B15968_03_26.jpg)'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_26.jpg)'
- en: 'Figure 3.26: Correlation matrix for the dataset'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.26：数据集的相关矩阵
- en: 'From this output, we see that attributes `''x''` and `''y''` have a correlation
    coefficient that is quite high: `0.94`.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们可以看到属性'x'和'y'的相关系数相当高：0.94。
- en: 'Using this `jointplot()` method in seaborn, create a combined plot with two
    elements: a scatter plot on a two-dimensional plane where the coordinates of the
    points correspond to the individual values in `''x''` and `''y''` respectively,
    and two histograms representing the distributions of those values. Observe the
    output and decide whether the two distributions have the same mean:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用seaborn中的`jointplot()`方法，创建一个组合图，其中包括一个二维平面上的散点图，点的坐标分别对应于'x'和'y'中的个别值，以及代表这些值分布的两个直方图。观察输出并决定这两个分布是否具有相同的均值：
- en: '[PRE58]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'This will produce the following output:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 3.27: Combined plot of correlated attributes'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.27：相关属性的组合图'
- en: '](image/B15968_03_27.jpg)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_27.jpg)'
- en: 'Figure 3.27: Combined plot of correlated attributes'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.27：相关属性的组合图
- en: From this visualization, it is not clear whether the two attributes have the
    same mean or not.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个可视化中，不清楚这两个属性是否具有相同的均值。
- en: 'Instead of using a visualization, run a t-test with 0.05 level of significance
    to decide whether the two attributes have the same mean:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不使用可视化，而是使用0.05的显著性水平运行t检验，以决定这两个属性是否具有相同的均值：
- en: '[PRE59]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'This command will have the following output:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将产生以下输出：
- en: '[PRE60]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: This p-value is indeed lower than 0.05, allowing us to reject the null hypothesis
    that the two distributions have the same mean, even though they are highly correlated.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 这个p值确实低于0.05，使我们能够拒绝这两个分布具有相同均值的零假设，尽管它们高度相关。
- en: In this exercise, we applied the two inferential statistics methods that we
    have learned in this section to analyze a pair of correlated attributes in a dataset.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们应用了本节中学到的两种推断统计方法来分析数据集中一对相关属性。
- en: Note
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31Au1hc](https://packt.live/31Au1hc).
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问本特定部分的源代码，请参阅[https://packt.live/31Au1hc](https://packt.live/31Au1hc)。
- en: You can also run this example online at [https://packt.live/2YTt7L7](https://packt.live/2YTt7L7).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/2YTt7L7](https://packt.live/2YTt7L7)上在线运行此示例。
- en: In the next and final section on the topic of inferential statistics, we will
    discuss the process of using statistical and machine learning models as a method
    of making inferences using statistics.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在关于推断统计的下一个和最后一节中，我们将讨论使用统计和机器学习模型作为使用统计进行推断的方法。
- en: Statistical and Machine Learning Models
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计和机器学习模型
- en: Modeling a given dataset using a mathematical or machine learning model, which
    in itself is capable of generalizing any potential patterns and trends in the
    dataset to unseen data points, is another form of inferential statistics. Machine
    learning itself is arguably one of the fastest-growing fields in computer science.
    However, most machine learning models actually leverage mathematical and statistical
    theories, which is why the two fields are heavily connected. In this section,
    we will consider the process of training a model on a given dataset and how Python
    can help facilitate that process.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数学或机器学习模型对给定数据集进行建模，这本身就能够将数据集中的任何潜在模式和趋势推广到未见数据点，是推断统计学的另一种形式。机器学习本身可以说是计算机科学中增长最快的领域之一。然而，大多数机器学习模型实际上利用了数学和统计理论，这就是为什么这两个领域密切相关的原因。在本节中，我们将考虑在给定数据集上训练模型的过程以及Python如何帮助促进该过程。
- en: It is important to note that a machine learning model does not actually learn
    in the same sense that humans do. Most of the time, a model attempts to solve
    an optimization problem that minimizes its training error, which represents how
    well it can process the pattern within the training data, with the hope that the
    model can generalize well on unseen data that is drawn from the same distributions
    as the training data.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，机器学习模型实际上并不像人类那样学习。大多数情况下，模型试图解决一个最小化训练误差的优化问题，这代表了它在训练数据中处理模式的能力，希望模型能够很好地推广到从相同分布中抽取的未见数据。
- en: For example, a linear regression model generates the line of best fit that passes
    through all the data points in a given dataset. In the model definition, this
    line corresponds to the line that has the minimal sum of distances to the individual
    data points, and by solving the optimization problem of minimizing the sum of
    distances, a linear regression model is able to output that best-fitted line.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，线性回归模型生成最佳拟合线，通过给定数据集中的所有数据点。在模型定义中，这条线对应于具有最小距离和的线，通过解决最小化距离和的优化问题，线性回归模型能够输出最佳拟合线。
- en: Overall, each machine learning algorithm models the data and therefore the optimization
    problem in a different way, each suitable for specific settings. However, different
    levels of abstraction built into the Python language allow us to skip through
    these details and apply different machine learning models at a high level. All
    we need to keep in mind is that statistical and machine learning models are another
    method of inferential statistics where we are able to make predictions on unseen
    data, given the pattern represented in a training dataset.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，每个机器学习算法以不同的方式对数据和优化问题进行建模，每种适用于特定的设置。然而，Python语言内置的不同抽象级别使我们能够跳过这些细节，并在高层次应用不同的机器学习模型。我们需要记住的是，统计和机器学习模型是推断统计的另一种方法，我们能够根据训练数据集中的模式对未见数据进行预测。
- en: Let's say we are given the task of training a model on the sample dataset we
    have in the previous section, where the learning features are `'x'` and `'z'`,
    and our prediction target is `'y'`. That is, our model should learn any potential
    relationship between `'x'` or `'z'` and `'y'`, and from there know how to predict
    unseen values of `'y'` from the data in `'x'` and `'z'`.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的任务是在前一节中拥有的样本数据集上训练模型，其中学习特征是'x'和'z'，我们的预测目标是'y'。也就是说，我们的模型应该学习'x'或'z'与'y'之间的任何潜在关系，并从中知道如何从'x'和'z'的数据中预测'y'的未见值。
- en: 'Since `''y''` is a numerical attribute, we will need a regression model, as
    opposed to a classifier, to train on our data. Here, we will use one of the most
    commonly used regressors in statistics and machine learning: linear regression.
    For that, we will require the scikit-learn library, one of the most—if not the
    most—popular predictive data analysis tools in Python.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`'y'`是一个数值属性，我们将需要一个回归模型来训练我们的数据，而不是一个分类器。在这里，我们将使用统计学和机器学习中最常用的回归器之一：线性回归。为此，我们将需要scikit-learn库，这是Python中最受欢迎的预测数据分析工具之一，如果不是最受欢迎的。
- en: 'To install scikit-learn, run the following `pip` command:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装scikit-learn，请运行以下`pip`命令：
- en: '[PRE61]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'You can also use the `conda` command to install it:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用`conda`命令来安装它：
- en: '[PRE62]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Now, we import the linear regression model and fit it to our training data:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们导入线性回归模型并将其拟合到我们的训练数据：
- en: '[PRE63]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'In general, the `fit()` method, called by a machine learning model object,
    takes in two arguments: the independent features (that is, the features that will
    be used to make predictions), which in this case are `''x''` and `''z''`, and
    the dependent feature or the prediction target (that is, the attribute that we''d
    like to make predictions on), which in this case is `''y''`.'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，由机器学习模型对象调用的`fit()`方法接受两个参数：独立特征（即用于进行预测的特征），在这种情况下是`'x'`和`'z'`，以及依赖特征或预测目标（即我们想要进行预测的属性），在这种情况下是`'y'`。
- en: This `fit()` method will initiate the training process of the model on the given
    data. Depending on the complexity of the model as well as the size of the training
    data, this process might take a significant amount of time. For a linear regression,
    however, the training process should be relatively fast.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`fit()`方法将在给定数据上启动模型的训练过程。根据模型的复杂性以及训练数据的大小，这个过程可能需要相当长的时间。然而，对于线性回归，训练过程应该相对快速。
- en: Once our model has finished training, we can look at its various statistics.
    What statistics are available depends on the specific model being used; for a
    linear regression, it is common for us to consider the coefficients. A regression
    coefficient is an estimate of the linear relationship between an independent feature
    and the prediction target. In essence, the regression coefficients are what the
    linear regression model estimates for the slope of the best-fit line for a specific
    predictor variable, `'x'` or `'z'` in our case, and the feature we'd like to predict—`'y'`.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的模型训练完成，我们可以查看它的各种统计数据。可用的统计数据取决于所使用的具体模型；对于线性回归，我们通常考虑系数。回归系数是独立特征和预测目标之间线性关系的估计值。实质上，回归系数是线性回归模型为特定预测变量（在我们的情况下是`'x'`或`'z'`）和我们想要预测的特征的最佳拟合线的斜率估计值。
- en: 'These statistics can be accessed as follows:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 这些统计数据可以按如下方式访问：
- en: '[PRE64]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'This will give us the following output:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下输出：
- en: '[PRE65]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Again, the output from your own experiment might not be exactly the same as
    the preceding. However, there is a clear trend to these coefficients: the first
    coefficient (denoting the estimated linear relationship between `''x''` and `''y''`)
    is approximately 2, while the second (denoting the estimated linear relationship
    between `''z''` and `''y''`) is close to 0.'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 你自己实验的输出可能与前面的不完全相同。然而，这些系数存在明显的趋势：第一个系数（表示`'x'`和`'y'`之间的估计线性关系）约为2，而第二个系数（表示`'z'`和`'y'`之间的估计线性关系）接近于0。
- en: 'This result is quite consistent with what we did to generate this dataset:
    `''y''` was generated to be roughly equal to the elements in `''x''` multiplied
    by 2, while `''z''` was independently generated. By looking at these regression
    coefficients, we can obtain information about which features are the best (linear)
    predictors for our prediction target. Some consider these types of statistics
    to be explainability/interpretability statistics, as they give us insights regarding
    how the prediction process was done.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果与我们生成这个数据集的方法非常一致：`'y'`被生成为大致等于`'x'`中的元素乘以2，而`'z'`是独立生成的。通过观察这些回归系数，我们可以获得关于哪些特征是最佳（线性）预测器的信息。一些人认为这些类型的统计数据是可解释性统计数据，因为它们为我们提供了关于预测过程如何进行的见解。
- en: 'What''s more interesting to us is the process of making predictions on unseen
    data. This can be done by calling the `predict()` method on the model object like
    so:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说更有趣的是对未见数据进行预测的过程。这可以通过在模型对象上调用`predict()`方法来完成，如下所示：
- en: '[PRE66]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The output will be as follows:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE67]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Here, we pass to the `predict()` method any data structure that can represent
    a two-dimensional table (in the preceding code, we used a nested list, but in
    theory, you could also use a two-dimensional NumPy array or a pandas `DataFrame`
    object). This table needs to have its number of columns equal to the number of
    independent features in the training data; in this case, we have two (`'x'` and
    `'z'`), so each sub-list in `[[1, 2], [2, 3]]` has two elements.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将任何能表示二维表的数据结构传递给`predict()`方法（在前面的代码中，我们使用了嵌套列表，但理论上，你也可以使用二维NumPy数组或pandas的`DataFrame`对象）。这个表的列数需要等于训练数据中独立特征的数量；在这种情况下，我们有两个（`'x'`和`'z'`），所以`[[1,
    2], [2, 3]]`中的每个子列表都有两个元素。
- en: From the predictions produced by the model, we see that when `'x'` is equal
    to 1 and `'z'` is equal to 2 (our first test case), the corresponding prediction
    is roughly 2\. This is consistent with the fact that the coefficient for `'x'`
    is approximately 2 and the one for `'z'` is close to 0\. The same goes for the
    second test case.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 从模型产生的预测中，我们看到当`'x'`等于1且`'z'`等于2（我们的第一个测试案例）时，相应的预测大约为2。这与`'x'`的系数约为2和`'z'`的系数接近0的事实一致。第二个测试案例也是如此。
- en: 'And that is an example of how a machine learning model can be used to make
    predictions on data. Overall, the scikit-learn library offers a wide range of
    models for different types of problems: classification, regression, clustering,
    dimensionality reduction, and so on. The API among the models is consistent with
    the `fit()` and `predict()` methods, as we have seen. This allows a greater degree
    of flexibility and streamlining.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是机器学习模型如何用于对数据进行预测的一个例子。总的来说，scikit-learn库为不同类型的问题提供了各种模型：分类、回归、聚类、降维等等。模型之间的API与我们所见到的`fit()`和`predict()`方法一致。这使得灵活性和流程化程度更高。
- en: An important concept in machine learning is model selection. Not all models
    are created equal; some models, due to their design or characteristics, are better
    suited to a given dataset than others. This is why model selection is an important
    phase in the whole machine learning pipeline. After collecting and preparing a
    training dataset, machine learning engineers typically feed the dataset to a number
    of different models, and some models might be excluded from the process due to
    poor performance.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的一个重要概念是模型选择。并非所有模型都是平等的；由于其设计或特性，某些模型更适合于给定的数据集。这就是为什么模型选择是整个机器学习流程中的重要阶段。在收集和准备训练数据集之后，机器学习工程师通常会将数据集馈送到多个不同的模型中，一些模型可能由于性能不佳而被排除在外。
- en: We will see a demonstration of this in the following exercise, where we are
    introduced to the process of model selection.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的练习中演示这一点，我们将介绍模型选择的过程。
- en: 'Exercise 3.05: Model Selection'
  id: totrans-420
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习3.05：模型选择
- en: 'In this exercise, we will go through a sample model selection procedure, where
    we attempt to fit three different models to a synthetic dataset and consider their performance:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将进行一个样本模型选择过程，尝试将三种不同的模型拟合到一个合成数据集中，并考虑它们的性能：
- en: 'In the first code cell of a new Jupyter notebook, import the following tools:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新的Jupyter笔记本的第一个代码单元中，导入以下工具：
- en: '[PRE68]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Note
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We are not yet familiar with some of the tools, but they will be explained to
    us as we go through this exercise.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还不熟悉一些工具，但随着我们进行这个练习，它们将被解释给我们。
- en: Now, we'd like to create a synthetic dataset of points lying on a two-dimensional
    plane. Each of these points belongs to a specific group, and points belonging
    to the same group should revolve around a common center point.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要创建一个位于二维平面上的合成数据集。这些点中的每一个都属于一个特定的组，属于同一组的点应该围绕一个共同的中心点旋转。
- en: 'This synthetic data can be generated using the `make_blobs` function that we
    have imported from the `sklearn.datasets` package:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些合成数据可以使用我们从`sklearn.datasets`包中导入的`make_blobs`函数生成：
- en: '[PRE69]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: As we can see, this function takes in an argument named `n_samples`, which specifies
    the number of data points that should be produced. The `centers` argument, on
    the other hand, specifies the total number of groups that the individual points
    belong to and their respective coordinates. In this case, we have three groups
    of points centering around `(-2, 2)`, `(0, 0)`, and `(2, 2)` respectively.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，这个函数接受一个名为`n_samples`的参数，该参数指定应该生成的数据点的数量。另一方面，`centers`参数指定了个体点所属的总组数以及它们各自的坐标。在这种情况下，我们有三组围绕着`(-2,
    2)`，`(0, 0)`和`(2, 2)`的点。
- en: Lastly, by specifying the `random_state` argument as `0`, we ensure that the
    same data is generated every time we rerun this notebook. As we mentioned in *Chapter
    1*, *Fundamentals of Python*, this is good practice in terms of reproducibility.
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过将`random_state`参数指定为`0`，我们确保每次重新运行此笔记本时生成相同的数据。正如我们在*第1章*，*Python基础*中提到的，这在可重现性方面是一个良好的实践。
- en: Our goal here is to train various models on this data so that when fed a new
    list of points, the model can decide which group each point should belong to with
    high accuracy.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是在这些数据上训练各种模型，以便当馈送一个新的点列表时，模型可以以高准确度决定每个点应该属于哪个组。
- en: This function returns a tuple of two objects that we are assigning to the variables
    `X` and `y`, respectively. The first element in the tuple contains the independent
    features of the dataset; in this case, they are the *x* and *y* coordinates of
    the points. The second tuple element is our prediction target, the index of the
    group each point belongs to. The convention is to store the independent features
    in a matrix named `X`, and the prediction targets in a vector named `y`, as we
    are doing.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数返回一个包含两个对象的元组，我们分别将它们分配给变量`X`和`y`。元组中的第一个元素包含数据集的独立特征；在这种情况下，它们是点的* x *和*
    y *坐标。第二个元组元素是我们的预测目标，即每个点所属组的索引。约定是将独立特征存储在名为`X`的矩阵中，将预测目标存储在名为`y`的向量中，就像我们正在做的那样。
- en: 'Print out these variables to see what we are dealing with. Type `X` as the
    input:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出这些变量，看看我们正在处理什么。将`X`作为输入类型：
- en: '[PRE70]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This will give the following output:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE71]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Now, type `y` as the input:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将`y`作为输入类型：
- en: '[PRE72]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'This will give the following output:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE73]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Now, in a new code cell, we''d like to visualize this dataset using a scatter
    plot:'
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在一个新的代码单元中，我们想要使用散点图来可视化这个数据集：
- en: '[PRE74]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We use the first attribute in our dataset as the *x* coordinates and the second
    as the *y* coordinates for the points in the scatter plot. We can also quickly
    specify that points belonging to the same group should have the same color by
    passing our prediction target `y` to argument `c`.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用数据集中的第一个属性作为* x *坐标，第二个属性作为散点图中点的* y *坐标。我们还可以通过将我们的预测目标`y`传递给参数`c`来快速指定属于同一组的点应该具有相同的颜色。
- en: 'This code cell will produce the following scatter plot:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码单元将产生以下散点图：
- en: '![Figure 3.28: Scatter plot for a machine learning problem'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.28：用于机器学习问题的散点图'
- en: '](image/B15968_03_28.jpg)'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15968_03_28.jpg)'
- en: 'Figure 3.28: Scatter plot for a machine learning problem'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.28：用于机器学习问题的散点图
- en: The most common strategy of a model selection process is to first split our
    data into a training dataset and a test/validation dataset. The training dataset
    is used to train the machine learning models we'd like to use, and the test dataset
    is used to validate the performance of those models.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 模型选择过程中最常见的策略是首先将数据分成训练数据集和测试/验证数据集。训练数据集用于训练我们想要使用的机器学习模型，而测试数据集用于验证这些模型的性能。
- en: 'The `train_test_split()` function from the `sklearn.model_selection` package
    facilitates the process of splitting our dataset into the training and test datasets.
    In the next code cell, enter the following code:'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`sklearn.model_selection`包中的`train_test_split()`函数简化了将数据集拆分为训练和测试数据集的过程。在下一个代码单元中，输入以下代码：'
- en: '[PRE75]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'As we can see, this function returns a tuple of four objects, which we are
    assigning to the four preceding variables: `X_train` contains the data in the
    independent features for the training dataset, while `X_test` contains the data
    of the same features for the test dataset, and the equivalent goes for `y_train`
    and `y_test`.'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，这个函数返回了四个对象的元组，我们将其分配给了前面的四个变量：`X_train`包含训练数据集中独立特征的数据，而`X_test`包含测试数据集中相同特征的数据，`y_train`和`y_test`也是如此。
- en: 'We can inspect how the split was done by considering the shape of our training dataset:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过考虑我们的训练数据集的形状来检查拆分是如何进行的：
- en: '[PRE76]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: By default, the training dataset is randomly selected from 75 percent of the
    input data, and the test dataset is the remaining data, randomly shuffled. This
    is demonstrated by the preceding output, where we have 7,500 entries in our training
    dataset from the original data with 10,000 entries.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，训练数据集是从输入数据的75%中随机选择的，而测试数据集是剩余的数据，随机洗牌。这由前面的输出所示，我们的训练数据集中有7500条记录，原始数据中有10000条记录。
- en: 'In the next code cell, we will initialize the machine learning models that
    we have imported without specifying any hyperparameters (more on this later):'
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个代码单元中，我们将初始化我们导入的机器学习模型，而不指定任何超参数（稍后会详细介绍）：
- en: '[PRE77]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Next, we will loop through each of them, train them on our training dataset,
    and finally compute their accuracy on the test dataset using the `accuracy_score`
    function, which compares the values stored in `y_test` and the predictions generated
    by our models in `y_pred`:'
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将循环遍历每个模型，在我们的训练数据集上对它们进行训练，并最终使用`accuracy_score`函数计算它们在测试数据集上的准确性，该函数比较`y_test`中存储的值和我们模型在`y_pred`中生成的预测值：
- en: '[PRE78]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Again, the `fit()` method is used to train each model on `X_train` and `y_train`,
    while `predict()` is used to have the models make predictions on `X_test`. This
    will produce an output similar to the following:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，`fit()`方法用于在`X_train`和`y_train`上训练每个模型，而`predict()`用于让模型对`X_test`进行预测。这将产生类似以下的输出：
- en: '[PRE79]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: From here, we see that the `SVC` model performed the best, which is somewhat
    expected as it is the most complex model out of the three used. In an actual model
    selection process, you might incorporate more tasks, such as cross-validation,
    to ensure that the model you select in the end is the best option.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以看到`SVC`模型表现最好，这在某种程度上是预期的，因为它是使用的三种模型中最复杂的模型。在实际的模型选择过程中，您可能会加入更多的任务，比如交叉验证，以确保最终选择的模型是最佳选项。
- en: And that is the end of our model selection exercise. Through the exercise, we
    have familiarized ourselves with the general procedure of working with a scikit-learn
    model. As we have seen, the fit/predict API is consistent across all models implemented
    in the library, which leads to a high level of flexibility and convenience for
    Python programmers.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们模型选择练习的结束。通过这个练习，我们熟悉了使用scikit-learn模型的一般流程。正如我们所看到的，fit/predict API在库中实现的所有模型中都是一致的，这为Python程序员提供了高度的灵活性和便利性。
- en: This exercise also concludes the general topic of inferential statistics.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习也结束了推断统计的一般主题。
- en: Note
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2BowiBI](https://packt.live/2BowiBI).
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问本节的源代码，请参阅[https://packt.live/2BowiBI](https://packt.live/2BowiBI)。
- en: You can also run this example online at [https://packt.live/3dQdZ5h](https://packt.live/3dQdZ5h).
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/3dQdZ5h](https://packt.live/3dQdZ5h)上线运行此示例。
- en: In the next and final section of this chapter, we will iterate a number of other
    libraries that can support various specific statistical procedures.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的下一个和最后一节中，我们将迭代许多其他库，这些库可以支持各种特定的统计程序。
- en: Python's Other Statistics Tools
  id: totrans-468
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python的其他统计工具
- en: 'In the previous chapter, we considered Python''s three main libraries, which
    make up the majority of a common data science/scientific computing pipeline: NumPy
    for multi-dimensional matrix computation, pandas for tabular data manipulation,
    and Matplotlib for data visualization.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们考虑了Python的三个主要库，它们构成了常见数据科学/科学计算流程的大部分内容：NumPy用于多维矩阵计算，pandas用于表格数据操作，Matplotlib用于数据可视化。
- en: Along the way, we have also discussed a number of supporting tools that complement
    those three libraries well; they are seaborn for the implementation of complex
    visualizations, SciPy for statistical and scientific computing capability, and
    scikit-learn for advanced data analysis needs.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，我们还讨论了一些支持工具，这些工具很好地补充了这三个库；它们是seaborn用于实现复杂可视化、SciPy用于统计和科学计算能力、scikit-learn用于高级数据分析需求。
- en: Needless to say, there are also other tools and libraries that, even though
    they did not fit into our discussions well, offer unique and powerful capabilities
    for particular tasks in scientific computing. In this section, we will briefly
    consider some of them so that we can gain a comprehensive understanding of what
    Python tools are available for which specific tasks.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 不用说，还有其他工具和库，即使它们在我们的讨论中没有很好地融入，也为科学计算中的特定任务提供了独特而强大的功能。在本节中，我们将简要讨论其中一些，以便我们可以全面了解Python工具可用于哪些特定任务。
- en: 'These tools include:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具包括：
- en: '**statsmodels**: This library was originally part of SciPy''s overarching ecosystem
    but ultimately split off into its own project. The library offers a wide range
    of statistical tests and analysis techniques, models, and plotting functionalities,
    all grouped into one comprehensive tool with a consistent API, including time-series
    analysis capabilities, which its predecessor SciPy somewhat lacks.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: statsmodels：这个库最初是SciPy整体生态系统的一部分，但最终分拆成了自己的项目。该库提供了广泛的统计测试和分析技术、模型和绘图功能，全部组合成一个具有一致API的综合工具，包括时间序列分析能力，而其前身SciPy在这方面有些欠缺。
- en: 'The main website for statsmodels can be found here: [http://www.statsmodels.org/stable/index.html](http://www.statsmodels.org/stable/index.html).'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: statsmodels的主网站可以在这里找到：[http://www.statsmodels.org/stable/index.html](http://www.statsmodels.org/stable/index.html)。
- en: '**PyMC3**: In a subfield of statistics called Bayesian statistics, there are
    many unique concepts and procedures that can offer powerful capabilities in modeling
    and making predictions that are not well supported by the libraries that we have considered.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyMC3：在称为贝叶斯统计学的统计学子领域中，有许多独特的概念和程序，可以在建模和预测方面提供强大的能力，而这些能力在我们考虑的库中得不到很好的支持。
- en: In PyMC3, Bayesian statistical modeling and probabilistic programming techniques
    are implemented to make up its own ecosystem with plotting, testing, and diagnostic
    capabilities, making it arguably the most popular probabilistic programming tool,
    not just for Python users but for all scientific computing engineers.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyMC3中，贝叶斯统计建模和概率编程技术被实现为其自己的生态系统，具有绘图、测试和诊断能力，这使得它成为可能是最受欢迎的概率编程工具，不仅适用于Python用户，还适用于所有科学计算工程师。
- en: More information on how to get started with PyMC3 can be found on its home page,
    at [https://docs.pymc.io/](https://docs.pymc.io/).
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何开始使用PyMC3的更多信息，请访问其主页[https://docs.pymc.io/](https://docs.pymc.io/)。
- en: '**SymPy**: Moving away from statistics and machine learning, if you are looking
    for a Python library that supports symbolic mathematics, SymPy is most likely
    your best bet. The library covers a wide range of core mathematical subfields
    such as algebra, calculus, discrete math, geometry, and physics-related applications.
    SymPy is also known to have quite a simple API and extensible source code, making
    it a popular choice for users looking for a symbolic math library in Python.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SymPy：远离统计学和机器学习，如果您正在寻找一个支持符号数学的Python库，SymPy很可能是您最好的选择。该库涵盖了代数、微积分、离散数学、几何和与物理相关的应用等广泛的核心数学子领域。SymPy也以其相对简单的API和可扩展的源代码而闻名，这使得它成为寻找Python中符号数学库的用户的热门选择。
- en: You can learn more about SymPy from its website at [https://www.sympy.org/en/index.html](https://www.sympy.org/en/index.html).
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从SymPy的网站了解更多信息[https://www.sympy.org/en/index.html](https://www.sympy.org/en/index.html)。
- en: '**Bokeh**: Our last entry on this list is a visualization library. Unlike Matplotlib
    or seaborn, Bokeh is a visualization tool specifically designed for interactivity
    and web browsing. Bokeh is typically the go-to tool for visualization engineers
    who need to process a large amount of data in Python but would like to generate
    interactive reports/dashboards as web applications.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bokeh：我们列表中的最后一个条目是一个可视化库。与Matplotlib或seaborn不同，Bokeh是一个专门设计用于交互和网页浏览的可视化工具。Bokeh通常是可视化工程师的首选工具，他们需要在Python中处理大量数据，但希望生成交互式报告/仪表板作为Web应用程序。
- en: To read the official documentation and see the gallery of some of its examples,
    you can visit the main website at [https://docs.bokeh.org/en/latest/index.html](https://docs.bokeh.org/en/latest/index.html).
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 要阅读官方文档并查看一些示例的画廊，您可以访问主网站[https://docs.bokeh.org/en/latest/index.html](https://docs.bokeh.org/en/latest/index.html)。
- en: These libraries offer great support to their respective subfields of statistics
    and mathematics. Again, it is also always possible to find other tools that fit
    your specific needs. One of the biggest advantages of using a programming language
    as popular as Python is the fact that many developers are working to develop new
    tools and libraries every day for all purposes and needs. The libraries we have
    discussed so far will help us achieve most of the basic tasks in statistical computing
    and modeling, and from there we can incorporate other more advanced tools to extend
    our projects further.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库为各自的统计学和数学子领域提供了很好的支持。同样，也总是可能找到其他符合您特定需求的工具。使用像Python这样受欢迎的编程语言的最大优势之一是，许多开发人员每天都在努力开发新的工具和库，以满足各种目的和需求。到目前为止，我们讨论过的库将帮助我们完成大部分统计计算和建模的基本任务，然后我们可以整合其他更高级的工具来进一步扩展我们的项目。
- en: Before we close out this chapter, we will go through an activity as a way to
    reinforce some of the important concepts that we have learned so far.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束本章之前，我们将通过一项活动来巩固我们迄今为止学到的一些重要概念。
- en: 'Activity 3.01: Revisiting the Communities and Crimes Dataset'
  id: totrans-484
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动3.01：重新审视社区和犯罪数据集
- en: 'In this activity, we will once again consider the *Communities and Crimes*
    dataset that we analyzed in the previous chapter. This time, we will apply the
    concepts we have learned in this chapter to gain additional insights from this
    dataset:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将再次考虑我们在上一章中分析过的“社区和犯罪”数据集。这一次，我们将应用本章学到的概念，从这个数据集中获得额外的见解：
- en: In the same directory that you stored the dataset in, create a new Jupyter notebook.
    Alternatively, you can download the dataset again at [https://packt.live/2CWXPdD](https://packt.live/2CWXPdD).
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在存储数据集的同一目录中，创建一个新的Jupyter笔记本。或者，您可以再次在[https://packt.live/2CWXPdD](https://packt.live/2CWXPdD)下载数据集。
- en: 'In the first code cell, import the libraries that we will be using: `numpy`,
    `pandas`, `matplotlib`, and `seaborn`.'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个代码单元格中，导入我们将使用的库：`numpy`、`pandas`、`matplotlib`和`seaborn`。
- en: As we did in the previous chapter, read in the dataset and print out its first
    five rows.
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与上一章一样，读取数据集并打印出它的前五行。
- en: Replace every `'?'` character with a `nan` object from NumPy.
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用NumPy中的`nan`对象替换每个'?'字符。
- en: 'Focus on the following columns: `''population''` (which includes the total
    population count of a given region), `''agePct12t21''`, `''agePct12t29''`, `''agePct16t24''`,
    and `''agePct65up''`, each of which includes the percentage of different age groups
    in that population.'
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关注以下列：`'population'`（包括给定地区的总人口数量）、`'agePct12t21'`、`'agePct12t29'`、`'agePct16t24'`和`'agePct65up'`，每个列中包括该人口中不同年龄组的百分比。
- en: Write the code that creates new columns in our dataset that contain the actual
    number of people in these age groups. These should be the product of the data
    in the column `'population'` and each of the age percentage columns.
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写代码，在我们的数据集中创建包含这些年龄组实际人数的新列。这些应该是列`'population'`中的数据和每个年龄百分比列的乘积。
- en: Use the `groupby()` method from pandas to compute the total number of people
    in different age groups for each state.
  id: totrans-492
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas的`groupby()`方法计算每个州不同年龄组的总人数。
- en: Call the `describe()` method on our dataset to print out its various descriptive statistics.
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用我们数据集上的`describe()`方法，打印出其各种描述性统计信息。
- en: Focus on the `'burglPerPop'`, `'larcPerPop'`, `'autoTheftPerPop'`, `'arsonsPerPop'`,
    and `'nonViolPerPop'` columns, each of which describes the number of various crimes
    (burglary, larceny, auto theft, arson, and non-violent crimes) committed per 100,000
    people.
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关注`'burglPerPop'`、`'larcPerPop'`、`'autoTheftPerPop'`、`'arsonsPerPop'`和`'nonViolPerPop'`列，每个列描述了各种犯罪（入室盗窃、偷窃、汽车盗窃、纵火和非暴力犯罪）每10万人中的数量。
- en: Visualize the distribution of the data in each of these columns in a boxplot
    while having all the boxplots in a single visualization. From the plot, identify
    which type of crime out of the five is the most common and which is the least
    common.
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个单一的可视化中，通过箱线图来展现这些列中数据的分布。从图中识别出五种犯罪中哪一种最常见，哪一种最不常见。
- en: Focus on the `'PctPopUnderPov'`, `'PctLess9thGrade'`, `'PctUnemployed'`, `'ViolentCrimesPerPop'`,
    and `'nonViolPerPop'` columns. The first three describe the percentage of the
    population in a given region that falls into the corresponding categories (percentages
    of people living under the poverty level, over 25 years old with less than a ninth-grade
    education, and in the labor force but unemployed). The last two give us the number
    of violent and non-violent crimes per 100,000 people.
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关注`'PctPopUnderPov'`、`'PctLess9thGrade'`、`'PctUnemployed'`、`'ViolentCrimesPerPop'`和`'nonViolPerPop'`列。前三个描述了给定地区人口中属于相应类别的百分比（生活在贫困线以下的人口比例、25岁以上没有完成九年级教育的人口比例、劳动力中失业的人口比例）。最后两个给出了每10万人中的暴力和非暴力犯罪数量。
- en: Compute the appropriate statistical object and visualize it accordingly to answer
    this question. Identify the pair of columns that correlate with each other the most.
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算适当的统计对象，并相应地对其进行可视化以回答这个问题。识别与彼此相关性最大的一对列。
- en: Note
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 659.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在659页找到。
- en: Summary
  id: totrans-500
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter formalized various introductory concepts in statistics and machine
    learning, including different types of data (categorical, numerical, and ordinal),
    and the different sub-categories of statistics (descriptive statistics and inferential
    statistics). During our discussions, we also introduced relevant Python libraries
    and tools that can help facilitate procedures corresponding to the topics covered.
    Finally, we briefly touched on a number of other Python libraries, such as statsmodels,
    PyMC3, and Bokeh, that can serve more complex and advanced purposes in statistics
    and data analysis.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 本章正式阐述了统计学和机器学习中的各种入门概念，包括不同类型的数据（分类、数值和有序），以及统计学的不同子类别（描述性统计和推断统计）。在我们的讨论中，我们还介绍了相关的Python库和工具，可以帮助促进相应主题的程序。最后，我们简要介绍了一些其他Python库，如statsmodels、PyMC3和Bokeh，它们可以在统计和数据分析中提供更复杂和高级的用途。
- en: In the next chapter, we will begin a new part of the book looking at mathematics-heavy
    topics such as sequences, vectors, complex numbers, and matrices. Specifically,
    in the next chapter, we will take a deep dive into functions and algebraic equations.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将开始书中的新部分，涉及数学密集型主题，如序列、向量、复数和矩阵。具体来说，在下一章中，我们将深入研究函数和代数方程。
- en: PSQ66
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: PSQ66
- en: WRC42
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: WRC42
