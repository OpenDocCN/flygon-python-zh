- en: Message Passing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息传递
- en: This chapter will briefly cover the **Message Passing Interface** (**MPI**),
    which is a specification for message exchange. The primary goal of the MPI is
    to establish an efficient, flexible, and portable standard for message exchange
    communication.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将简要介绍**消息传递接口**（**MPI**），这是一种消息交换规范。MPI的主要目标是建立一种高效、灵活和可移植的消息交换通信标准。
- en: Mainly, we will show the functions of the library that include synchronous and
    asynchronous communication primitives, such as (send/receive) and (broadcast/all-to-all),
    the operations of combining the partial results of the calculation (gather/reduce), and
    finally, the synchronization primitives between processes (barriers).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 主要是展示库的函数，包括同步和异步通信原语，如（发送/接收）和（广播/全对全），计算的部分结果的组合操作（gather/reduce），最后是进程之间的同步原语（屏障）。
- en: Furthermore, the control functions of the communication network will be presented
    by defining the topologies.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过定义拓扑来介绍通信网络的控制函数。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下内容：
- en: Using the `mpi4py` Python module
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`mpi4py` Python模块
- en: Implementing point-to-point communication
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现点对点通信
- en: Avoiding deadlock problems
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免死锁问题
- en: Collective communication using a broadcast
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用广播进行集体通信
- en: Collective communication using the `scatter` function
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`scatter`函数进行集体通信
- en: Collective communication using the`gather` function
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`gather`函数进行集体通信
- en: Collective communication using `Alltoall`
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`Alltoall`进行集体通信
- en: The reduction operation
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少操作
- en: Optimizing communication
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化通信
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need the `mpich`and `mpi4py` libraries for this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要`mpich`和`mpi4py`库。
- en: The `mpich`library is a portable implementation of MPI. It is free software
    and is available for various versions of Unix (including Linux and macOS) and
    Microsoft Windows.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpich`库是MPI的可移植实现。它是免费软件，适用于各种Unix版本（包括Linux和macOS）和Microsoft Windows。'
- en: To install `mpich`, use the installer downloaded from the downloads page ([http://www.mpich.org/static/downloads/1.4.1p1/](http://www.mpich.org/static/downloads/1.4.1p1/)).
    Moreover, make sure to choose between the 32-bit or 64-bit versions to get the
    right one for your machine.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`mpich`，请使用从下载页面下载的安装程序（[http://www.mpich.org/static/downloads/1.4.1p1/](http://www.mpich.org/static/downloads/1.4.1p1/)）。此外，请确保选择32位或64位版本，以获取适合您的计算机的正确版本。
- en: The `mpi4py` Python module provides Python bindings for the MPI ([https://www.mpi-forum.org](https://www.mpi-forum.org))
    standard. It is implemented on top of the MPI-1/2/3 specification and exposes
    an API that is based on the standard MPI-2 C++ bindings.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py` Python模块为MPI（[https://www.mpi-forum.org](https://www.mpi-forum.org)）标准提供了Python绑定。它是基于MPI-1/2/3规范实现的，并公开了基于标准MPI-2
    C++绑定的API。'
- en: 'The installation procedure of `mpi4py` on a Windows machine is as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows机器上安装`mpi4py`的过程如下：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Anaconda users must type the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda用户必须输入以下内容：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that for all the examples in this chapter, we used `mpi4py` installed by
    using the `pip` installer
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在本章的所有示例中，我们使用了通过`pip`安装的`mpi4py`
- en: 'This implies that the notation used to run the `mpi4py` examples is as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着运行`mpi4py`示例所使用的表示法如下：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `mpiexec` command is the typical way to start parallel jobs: `x` is the
    total number of processes to use, while `mpi4py_script_name.py` is the name of
    the script to be executed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpiexec`命令是启动并行作业的典型方式：`x`是要使用的进程总数，而`mpi4py_script_name.py`是要执行的脚本的名称。'
- en: Understanding the MPI structure
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解MPI结构
- en: The MPI standard defines the primitives for the management of virtual topologies,
    synchronization, and communication between processes. There are several MPI implementations
    that differ in the version and features of the standard supported.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MPI标准定义了虚拟拓扑、同步和进程之间通信的原语。有几种MPI实现，它们在支持的标准版本和功能上有所不同。
- en: We will introduce the MPI standard through the Python `mpi4py` library.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过Python的`mpi4py`库介绍MPI标准。
- en: Before the 1990s, writing parallel applications for different architectures
    was a more difficult job than what it is today. Many libraries facilitated the
    process, but there was not a standard way to do it. At that time, most parallel
    applications were destined for scientific research environments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪90年代之前，为不同架构编写并行应用程序比今天更加困难。许多库简化了这个过程，但没有标准的方法来做。那时，大多数并行应用程序都是为科学研究环境而设计的。
- en: The model that was most commonly adopted by the various libraries was the message-passing
    model, in which the communication between the processes takes place through the
    exchange of messages and without the use of shared resources. For example, the
    master process can assign a job to the slaves simply by sending a message that
    describes the work to be done. A second, very simple, example here is a parallel
    application that performs a merge sort. The data is sorted locally to the processes
    and the results are passed to other processes that will deal with the merge.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 各种库最常采用的模型是消息传递模型，其中进程之间的通信通过交换消息进行，而不使用共享资源。例如，主进程可以通过发送描述要完成的工作的消息来简单地将工作分配给从进程。这里还有一个非常简单的例子，即执行合并排序的并行应用程序。数据在进程本地排序，然后将结果传递给其他处理合并的进程。
- en: Since the libraries largely used the same model, albeit with minor differences
    from each other, the authors of the various libraries met in 1992 to define a
    standard interface for the exchange of messages, and, from here, MPI was born.
    This interface had to allow programmers to write portable parallel applications
    on most parallel architectures, using the same features and models they were already
    used to.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些库大部分使用了相同的模型，尽管彼此之间存在细微差异，各个库的作者在1992年会面，以定义消息交换的标准接口，从而诞生了MPI。这个接口必须允许程序员在大多数并行架构上编写可移植的并行应用程序，使用他们已经习惯的相同特性和模型。
- en: 'Originally, MPI was designed for distributed memory architectures, which began
    to grow in popularity 20 years ago:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，MPI是为分布式内存架构设计的，20年前开始流行：
- en: '![](assets/c5eade1c-0ee1-4194-a00c-d8686149c550.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/c5eade1c-0ee1-4194-a00c-d8686149c550.png)'
- en: The distributed memory architecture schema
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存架构图
- en: 'Over time, distributed memory systems began to be combined with each other,
    creating hybrid systems with distributed/shared memory:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，分布式内存系统开始相互结合，创建了具有分布式/共享内存的混合系统：
- en: '![](assets/0ac1b93c-4e24-4612-b1d7-1935c8f0a661.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/0ac1b93c-4e24-4612-b1d7-1935c8f0a661.png)'
- en: The hybrid system architecture schema
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 混合系统架构图
- en: Today, MPI runs on distributed memory, shared memory, and hybrid systems. However,
    the programming model remains that of distributed memory, although the true architecture
    on which the calculation is performed may be different.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，MPI在分布式内存、共享内存和混合系统上运行。然而，编程模型仍然是分布式内存，尽管计算执行的真正架构可能不同。
- en: 'The strengths of MPI can be summarized as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: MPI的优势可以总结如下：
- en: '**Standardization**: It is supported by all **High-Performance** **Computing**
    (**HPC**) platforms.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化**：它受到所有**高性能计算**（**HPC**）平台的支持。'
- en: '**Portability**: The changes applied to the source code are minimal, which
    is useful if you decide to use the application on a different platform that also
    supports the same standard.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可移植性**：对源代码的更改很小，这在您决定在支持相同标准的不同平台上使用应用程序时非常有用。'
- en: '**Performance**: Manufacturers can create implementations optimized for a specific
    type of hardware and get better performance.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：制造商可以创建针对特定类型硬件进行优化的实现，并获得更好的性能。'
- en: '**Functionality**: Over 440 routines are defined in MPI-3, but many parallel
    programs can be written using fewer than even 10 routines.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能性**：MPI-3中定义了超过440个例程，但许多并行程序可以使用少于甚至10个例程来编写。'
- en: 'In the following sections, we will examine the main Python library for message
    passing: the `mpi4py` library.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将研究消息传递的主要Python库：`mpi4py`库。
- en: Using the mpi4py Python module
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用mpi4py Python模块
- en: The Python programming language provides several MPI modules to write parallel
    programs. The most interesting of these is the `mpi4py` library. It is constructed
    on top of the MPI-1/2 specifications and provides an object-oriented interface,
    which closely follows the MPI-2 C++ bindings. A C MPI user could use this module
    without learning a new interface. Therefore, it is widely used as an almost-full
    package of an MPI library in Python.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Python编程语言提供了几个MPI模块来编写并行程序。其中最有趣的是`mpi4py`库。它是基于MPI-1/2规范构建的，并提供了一个面向对象的接口，紧密遵循MPI-2
    C++绑定。C MPI用户可以在不学习新接口的情况下使用此模块。因此，它被广泛用作Python中几乎完整的MPI库包。
- en: 'The main applications of the module, which will be described in this chapter,
    are as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 模块的主要应用，将在本章中描述，如下：
- en: Point-to-point communication
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点对点通信
- en: Collective communication
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集体通信
- en: Topologies
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拓扑结构
- en: How to do it...
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s start our journey to the MPI library by examining the classic code of
    a program that prints the phrase `Hello, world!` on each process that is instantiated:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过检查一个经典程序的代码来开始我们对MPI库的旅程，该程序在每个实例化的进程上打印短语`Hello, world!`：
- en: 'Import the `mpi4py` library:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`mpi4py`库：
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In MPI, the processes involved in the execution of a parallel program are identified by
    a sequence of non-negative integers called **ranks**.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在MPI中，执行并行程序的进程由一系列非负整数称为**排名**来标识。
- en: 'If we have a number (*p* of processes) that runs a program, then the processes
    will have a `rank` that goes from *0* to *p*-1\. In particular, in order to assess
    the rank of each process, we must use the `COMM_WORLD` MPI function in particular.
    This function is called a **communicator**, as it defines its own set of all processes
    that can communicate together:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们有一个程序运行的进程数（*p*个进程），那么这些进程将有一个从*0*到*p*-1的`rank`。特别是，为了评估每个进程的`rank`，我们必须使用特定的`COMM_WORLD`
    MPI函数。这个函数被称为**通信器**，因为它定义了自己的所有可以一起通信的进程集：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, the following `Get_rank()` function returns `rank` of the process
    calling it:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，以下`Get_rank()`函数返回调用它的进程的`rank`：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once evaluated, `rank` is printed:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦评估，`rank`就会被打印出来：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: How it works...
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: According to the MPI execution model, our application consists of *N* (5 in
    this example) autonomous processes, each with their own local memory able to communicate
    data through the exchange of messages.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 根据MPI执行模型，我们的应用程序由*N*（在本例中为5）个自治进程组成，每个进程都有自己的本地内存，能够通过消息交换来通信数据。
- en: The communicator defines a group of processes that can communicate with each
    other. The `MPI_COMM_WORLD` work used here is the default communicator and includes
    all processes.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通信器定义了可以相互通信的一组进程。这里使用的`MPI_COMM_WORLD`是默认通信器，包括所有进程。
- en: The identification of a process is based on ranks. Each process is assigned
    a rank for each communicator to which it belongs. The rank is an integer that
    is assigned, which starts from zero and identifies each individual process in
    the context of a specific communicator. The common practice is to define the process
    with a global rank of *0* as the master process. Through the rank, the developer
    can specify what the sending process is and what the recipient processes are instead.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 进程的标识是基于`rank`的。每个进程为其所属的每个通信器分配一个`rank`。`rank`是一个从零开始分配的整数，用于在特定通信器的上下文中标识每个单独的进程。通常做法是将全局`rank`为*0*的进程定义为主进程。通过`rank`，开发人员可以指定发送进程和接收进程。
- en: 'It should be noted that, for illustration purposes only, the `stdout` output
    will not always be ordered, as multiple processes can apply at the same time by
    writing on the screen and the OS arbitrarily chooses the order. So, we are ready
    for a fundamental observation: every process involved in the execution of MPI
    runs the same compiled binary, so each process receives the same instructions
    to be executed.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，仅用于说明目的，`stdout`输出不总是有序的，因为多个进程可以同时在屏幕上写入，操作系统会任意选择顺序。因此，我们做好了一个基本观察的准备：MPI执行中涉及的每个进程都运行相同的编译二进制文件，因此每个进程都接收相同的指令来执行。
- en: 'To execute the code, type the following command line:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行代码，请输入以下命令行：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is the result that we will get after executing this code (notice how the
    order of execution of the processes *is not sequential*):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是执行此代码后我们将得到的结果（注意进程执行顺序*不是顺序的*）：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It should be noted that the number of processes to be used is strictly dependent
    on the characteristics of the machine on which the program must run.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，要使用的进程数量严格依赖于程序必须运行的机器的特性。
- en: There's more...
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: MPI belongs to the **Single Program Multiple Data** (**SPMD**) programming technique.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: MPI属于**单程序多数据**（**SPMD**）编程技术。
- en: SPMD is a programming technique in which all processes execute the same program,
    each on different data. The distinction in executions between different processes
    occurs by differentiating the flow of the program, based on the local rank of
    the process.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: SPMD是一种编程技术，所有进程执行相同的程序，但每个进程操作不同的数据。不同进程之间的执行区别在于基于进程的本地`rank`来区分程序的流程。
- en: SPMD is a programming technique in which a single program is executed by several
    processes at the same time, but each process can operate on different data. At
    the same time, the processes can execute both the same instruction and different
    instructions. Obviously, the program will contain appropriate instructions that
    allow the execution of only parts of the code and/or to operate on a subset of
    the data. This can be implemented using different programming models, and all
    executables start at the same time.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: SPMD是一种编程技术，其中单个程序同时由多个进程执行，但每个进程可以操作不同的数据。同时，进程可以执行相同的指令和不同的指令。显然，程序将包含适当的指令，允许仅执行代码的部分和/或对数据的子集进行操作。这可以使用不同的编程模型来实现，所有可执行文件同时启动。
- en: See also
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The complete reference to the `mpi4py` library can be found at[https://mpi4py.readthedocs.io/en/stable/](https://mpi4py.readthedocs.io/en/stable/).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py`库的完整参考资料可以在[https://mpi4py.readthedocs.io/en/stable/](https://mpi4py.readthedocs.io/en/stable/)找到。'
- en: Implementing point-to-point communication
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现点对点通信
- en: Point-to-point operations consist of the exchange of messages between two processes.
    In a perfect world, every sending operation would be perfectly synchronized with
    the respective reception operation. Obviously, this is not the case, and the MPI
    implementation must be able to preserve the data sent when the sender and recipient
    processes are not synchronized. Typically, this occurs using a buffer, which is
    transparent to the developer and entirely managed by the `mpi4py` library.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 点对点操作包括在两个进程之间交换消息。在理想情况下，每个发送操作都将与相应的接收操作完全同步。显然，这并非总是如此，当发送方和接收方进程不同步时，MPI实现必须能够保留发送的数据。通常，这是通过一个对开发人员透明且完全由`mpi4py`库管理的缓冲区来实现的。
- en: 'The `mpi4py` Python module enables point-to-point communication via two functions:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py` Python模块通过两个函数实现点对点通信：'
- en: '`Comm.Send(data, process_destination)`: This function sends data to the destination
    process identified by its rank in the communicator group.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Comm.Send(data, process_destination)`: 此函数将数据发送到通过其在通信器组中的`rank`进行标识的目标进程。'
- en: '`Comm.Recv(process_source)`: This function receives data from the sourcing process,
    which is also identified by its rank in the communicator group.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Comm.Recv(process_source)`: 此函数从源进程接收数据，源进程也通过其在通信器组中的`rank`进行标识。'
- en: The `Comm` parameter, which is short for *communicator*, defines the group of
    processes that may communicate through message passing using `comm = MPI.COMM_WORLD`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`Comm`参数，简称*通信器*，定义了可以通过消息传递进行通信的进程组，使用`comm = MPI.COMM_WORLD`。'
- en: How to do it...
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In the following example, we will utilize the `comm.send` and `comm.recv` directives
    to exchange messages between different processes:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将利用`comm.send`和`comm.recv`指令在不同进程之间交换消息：
- en: 'Import the relevant `mpi4py` library:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关的`mpi4py`库：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we define the communicator parameter, namely `comm`, through the `MPI.COMM_WORLD`
    statement:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过`MPI.COMM_WORLD`语句定义通信器参数，即`comm`：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `rank` parameter is used to identify the process itself:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`参数用于标识进程本身：'
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It is useful to print out the `rank` of a process:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出进程的`rank`是有用的：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, we start considering the rank of the process. In this case, for the process
    of `rank` equal to `0`, we set `destination_process` and`data` (in this case `data
    = 10000000`) to be sent:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们开始考虑进程的`rank`。在这种情况下，对于`rank`等于`0`的进程，我们设置`destination_process`和`data`（在这种情况下`data
    = 10000000`）要发送的：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, by using the `comm.send` statement, the data that was previously set
    is sent to the destination process:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过使用`comm.send`语句，将先前设置的数据发送到目标进程：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For the process of `rank` equal to `1`, the `destination_process` value is
    `8`, while the data to be sent is the `"hello"` string:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`rank`等于`1`的进程，`destination_process`值为`8`，要发送的数据是`"hello"`字符串：
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The process of `rank` equal to `4` is a receiver process. Indeed, the source
    process (that is, the process of `rank` equal to `0`) is set as a parameter in
    the `comm.recv` statement:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`等于`4`的进程是接收进程。实际上，在`comm.recv`语句的参数中设置了源进程（即`rank`等于`0`的进程）：'
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, using the following code, the data received from the process of `0` must
    be displayed:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下代码，必须显示来自进程`0`的数据接收：
- en: '[PRE17]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The last process to be set is number `9`. Here, we define the source process
    of `rank` equal to `1` as a parameter in the `comm.recv` statement:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后要设置的进程是编号为`9`的进程。在这里，我们在`comm.recv`语句中将`rank`等于`1`的源进程定义为参数：
- en: '[PRE18]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `data1` value is then printed:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后打印`data1`的值：
- en: '[PRE19]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How it works...
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'We ran the example with a total number of processes equal to `9`. So, in the `comm` communicator
    group, we have nine tasks that can communicate with each other:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用总进程数等于`9`来运行示例。因此，在`comm`通信器组中，我们有九个可以相互通信的任务：
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Also, to identify a task or processes inside the group, we use their `rank` value:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了识别组内的任务或进程，我们使用它们的`rank`值：
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We have two sender processes and two receiver processes. The process of `rank`
    equal to`0` sends numerical data to the receiver process of `rank` equal to `4`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个发送进程和两个接收进程。`rank`等于`0`的进程向`rank`等于`4`的接收进程发送数值数据：
- en: '[PRE22]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Similarly, we must specify the receiver process of `rank` equal to `4`. We
    also note that the `comm.recv` statement must contain, as an argument, the rank
    of the sender process:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们必须指定`rank`等于`4`的接收进程。我们还注意到`comm.recv`语句必须包含发送进程的rank作为参数：
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: For the other sender and receiver processes (the process of `rank` equal to
    `1` and the process of `rank` equal to `8`, respectively), the situation is the
    same, the only difference being the type of data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他发送和接收进程（`rank`等于`1`的进程和`rank`等于`8`的进程），情况是相同的，唯一的区别是数据类型。
- en: 'In this case, for the sender process, we have a string that is to be sent:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，对于发送进程，我们有一个要发送的字符串：
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'For the receiver process of `rank` equal to `8`, the rank of the sender process
    is pointed out:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`rank`等于`8`的接收进程，指出了发送进程的rank：
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following diagram summarizes the point-to-point communication protocol
    in `mpi4py`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了`mpi4py`中的点对点通信协议：
- en: '![](assets/c92bb67f-1f34-4624-9dd7-9907f38c32e1.png)The send/receive transmission
    protocol'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/c92bb67f-1f34-4624-9dd7-9907f38c32e1.png)发送/接收传输协议'
- en: As you can see, it describes a two-step process, consisting of sending some **DATA**from
    one task (*sender*) and another task (*receiver*) receiving this data. The sending
    task must specify the data to be sent and its destination (the *receiver *process), while
    the receiving task has to specify the source of the message to be received.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，它描述了一个两步过程，包括从一个任务（*发送者*）发送一些**数据**到另一个任务（*接收者*）接收这些数据。发送任务必须指定要发送的数据及其目的地（*接收者*进程），而接收任务必须指定要接收的消息的*源*。
- en: 'To run the script, we shall use `9` processes:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行脚本，我们将使用`9`个进程：
- en: '[PRE26]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This is the output that you''ll get after you run the script:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这是运行脚本后将获得的输出：
- en: '[PRE27]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: There's more...
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The `comm.send()` and `comm.recv()` functions are blocking functions, which
    means that they block the caller until the buffered data involved can be used safely.
    Also, in MPI, there are two management methods of sending and receiving messages:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`comm.send()`和`comm.recv()`函数是阻塞函数，这意味着它们会阻塞调用者，直到涉及的缓冲数据可以安全使用。此外，在MPI中，有两种发送和接收消息的管理方法：'
- en: '**Buffered mode**: The flow control returns to the program as soon as the data
    to be sent has been copied to a buffer. This does not mean that the message is
    sent or received.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缓冲模式**：当要发送的数据已被复制到缓冲区时，流控制会立即返回到程序。这并不意味着消息已发送或接收。'
- en: '**Synchronous mode**: The function only gets terminated when the corresponding
    `receive` function begins receiving the message.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**同步模式**：当相应的`receive`函数开始接收消息时，该函数才终止。'
- en: See also
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: An interesting tutorial on this topic can be found at [https://github.com/antolonappan/MPI_tutorial](https://github.com/antolonappan/MPI_tutorial).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个主题的有趣教程可以在[https://github.com/antolonappan/MPI_tutorial](https://github.com/antolonappan/MPI_tutorial)找到。
- en: Avoiding deadlock problems
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免死锁问题
- en: A common problem we face is deadlock. This is a situation where two (or more)
    processes block each other and wait for the other to perform a certain action
    that serves another and vice versa. The `mpi4py` module doesn't provide any specific
    functionality to resolve the deadlock problem, but there are some measures that
    the developer must follow in order to avoid the problem of deadlock.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们面临的一个常见问题是死锁。这是一种情况，其中两个（或更多）进程相互阻塞，并等待另一个执行某个为另一个服务的动作，反之亦然。`mpi4py`模块没有提供解决死锁问题的特定功能，但开发人员必须遵循一些措施以避免死锁问题。
- en: How to do it...
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Let''s first analyze the following Python code, which will introduce a typical
    deadlock problem. We have two processes—`rank` equal to `1` and `rank` equal to
    `5`—that communicate with each other and both have the data sender and data receiver
    functionalities:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先分析以下Python代码，它将介绍一个典型的死锁问题。我们有两个进程——`rank`等于`1`和`rank`等于`5`——它们相互通信，并且都具有数据发送者和数据接收者功能：
- en: 'Import the `mpi4py` library:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`mpi4py`库：
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Define the communicator as `comm` and the `rank` parameter:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将通信器定义为`comm`和`rank`参数：
- en: '[PRE29]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The process of `rank` equal to `1` sends and receives data from the processof
    `rank` equal to `5`:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`等于`1`的进程向`rank`等于`5`的进程发送和接收数据：'
- en: '[PRE30]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the same way, here, we define the process of `rank` equal to `5`:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，在这里，我们定义`rank`等于`5`的进程：
- en: '[PRE31]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The destination and sender processes are equal to `1`:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标和发送进程都等于`1`：
- en: '[PRE32]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: How it works...
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'If we try to run this program (it makes sense to execute it with only two processes),
    then we note that none of the two processes can proceed:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试运行这个程序（只用两个进程执行它是有意义的），那么我们会发现两个进程都无法继续：
- en: '[PRE33]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Both the processes prepare to receive a message from the other and get stuck
    there. This happens because of the `comm.recv()` MPI function andthe `comm.send()`MPI
    blocking them. This means that the calling process awaits their completion. As
    for the `comm.send()` MPI, the completion occurs when the data has been sent and
    may be overwritten without modifying the message.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 两个进程都准备从另一个进程接收消息，并在那里被阻塞。这是因为`comm.recv()`MPI函数和`comm.send()`MPI阻塞了它们。这意味着调用进程等待它们的完成。至于`comm.send()`MPI，完成发生在数据已发送并且可以被覆盖而不修改消息时。
- en: 'The completion of the `comm.recv()`MPI instead occurs when the data has been
    received and can be used. To solve this problem, the first idea is to invert the
    `comm.recv()` MPI with the `comm.send()` MPI, as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`comm.recv()`MPI的完成发生在数据已接收并且可以使用时。为了解决这个问题，第一个想法是将`comm.recv()`MPI与`comm.send()`MPI颠倒，如下所示：'
- en: '[PRE34]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This solution, even if correct, does not guarantee that we will avoid deadlock.
    In fact, communication is performed through a buffer with the instruction of `comm.send()`.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这个解决方案是正确的，也不能保证我们会避免死锁。事实上，通信是通过带有`comm.send()`指令的缓冲区执行的。
- en: 'MPI copies the data to be sent. This mode works without problems, but only
    if the buffer is able to keep them all. If this does not happen, then there is
    a deadlock: the sender cannot finish sending the data because the buffer is busy,
    and the receiver cannot receive data because it is blocked by the `comm.send()` MPI
    call, which has not yet completed.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: MPI复制要发送的数据。这种模式可以无问题地工作，但前提是缓冲区能够容纳所有数据。如果不能容纳，就会发生死锁：发送者无法完成发送数据，因为缓冲区正忙，接收者无法接收数据，因为被`comm.send()`MPI调用阻塞，而这个调用还没有完成。
- en: 'At this point, the solution that allows us to avoid deadlocks is used to swap
    the sending and receiving functions so as to make them asymmetrical:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，允许我们避免死锁的解决方案是交换发送和接收函数，使它们不对称：
- en: '[PRE35]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we get the correct output:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们得到了正确的输出：
- en: '[PRE36]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: There's more...
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The solution proposed to the deadlock is not the only solution.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 解决死锁的方案不是唯一的解决方案。
- en: 'There is, for example, a function that unifies the single call that sends a
    message to a given process and receives another message that comes from another
    process. This function is called `Sendrecv`:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，有一个函数可以统一发送消息到给定进程并接收来自另一个进程的消息的单个调用。这个函数叫做`Sendrecv`：
- en: '[PRE37]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As you can see, the required parameters are the same as the `comm.send()`  and `comm.recv()`MPI
    (in this case, also the function blocks). However, `Sendrecv` offers the advantage
    of leaving the communication subsystem responsible for checking the dependencies
    between sending and receiving, thus avoiding the deadlock.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，所需的参数与`comm.send()`和`comm.recv()`MPI相同（在这种情况下，函数也会阻塞）。然而，`Sendrecv`提供了一个优势，即让通信子系统负责检查发送和接收之间的依赖关系，从而避免死锁。
- en: 'In this way, the code of the previous example becomes the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，上一个示例的代码变成了以下内容：
- en: '[PRE38]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: See also
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: An interesting analysis of how parallel programming is difficult due to deadlock
    management can be found at [https://codewithoutrules.com/2017/08/16/concurrency-python/](https://codewithoutrules.com/2017/08/16/concurrency-python/).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 关于并行编程由于死锁管理而变得困难的有趣分析可以在[https://codewithoutrules.com/2017/08/16/concurrency-python/](https://codewithoutrules.com/2017/08/16/concurrency-python/)找到。
- en: Collective communication using a broadcast
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用广播进行集体通信
- en: During the development of parallel code, we often find ourselves in a situation
    where we must share, between multiple processes, the value of a certain variable
    at runtime or certain operations on variables that each process provides (presumably
    with different values).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行代码的开发过程中，我们经常发现自己处于这样一种情况：我们必须在多个进程之间共享某个变量的值或每个进程提供的变量的某些操作（可能具有不同的值）。
- en: To resolve these types of situations, communication trees are used (for example,
    process 0 sends data to the processes 1 and 2, which will, respectively, take
    care of sending them to processes 3, 4, 5, 6, and so on).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这类情况，使用通信树（例如，进程0将数据发送到进程1和2，它们将分别负责将数据发送到进程3、4、5、6等）。
- en: 'Instead, MPI libraries provide functions that are ideal for the exchange of
    information or the use of multiple processes that are clearly optimized for the
    machine in which they are performed:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，MPI库提供了一些函数，这些函数非常适合于信息交换或明显针对在其上执行的机器进行了优化的多个进程的使用：
- en: '![](assets/48fa28e4-27d9-4ee6-981e-3c72d22b1c27.png)Broadcasting data from
    process 0 to processes 1, 2, 3, and 4'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/48fa28e4-27d9-4ee6-981e-3c72d22b1c27.png)从进程0广播数据到进程1、2、3和4'
- en: A communication method that involves all the processes that belong to a communicator
    is called a collective communication. Consequently, collective communication generally
    involves more than two processes. However, instead of this, we will call the collective
    communication broadcast, wherein a single process sends the same data to any other
    process.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及到属于一个通信器的所有进程的通信方法称为集体通信。因此，集体通信通常涉及多于两个进程。然而，我们将这种集体通信称为广播，其中一个单独的进程将相同的数据发送给任何其他进程。
- en: Getting ready
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: 'The `mpi4py` broadcast functionalities are offered by the following method:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py`提供了以下方法的广播功能：'
- en: '[PRE39]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This function sends the information contained in the message process root to
    every other process that belongs to the `comm` communicator.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将消息进程根中包含的信息发送到属于`comm`通信器的每个其他进程。
- en: How to do it...
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Let''s now see an example in which we''ve used the `broadcast` function. We
    have a root process of `rank` equal to `0` that shares its own data, `variable_to_share`,
    with the other processes defined in the communicator group:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个使用`broadcast`函数的例子。我们有一个`rank`等于`0`的根进程，它与通信器组中定义的其他进程共享自己的数据`variable_to_share`：
- en: 'Let''s import the `mpi4py` library:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入`mpi4py`库：
- en: '[PRE40]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, let''s define the communicator and the `rank` parameter:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们定义通信器和`rank`参数：
- en: '[PRE41]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'As far as the process of `rank` equal to `0` is concerned, we define the variable
    to be shared among the other processes:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就`rank`等于`0`的进程而言，我们定义变量在其他进程之间共享：
- en: '[PRE42]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, we define a broadcast, having the `rank` process equal to zero as
    its `root`:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们定义一个广播，将`rank`进程等于零作为其`root`：
- en: '[PRE43]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: How it works...
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The root process of `rank` equal to `0` instantiates a variable, `variable_to_share`,
    which is equal to `100`. This variable will be shared with the other processes
    of the communication group:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`rank`等于`0`的根进程实例化一个变量`variable_to_share`，其值为`100`。这个变量将与通信组的其他进程共享：'
- en: '[PRE44]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'To perform this, we also introduce the broadcast communication statement:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行这个操作，我们还引入了广播通信语句：
- en: '[PRE45]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Here, the parameters in the function are as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，函数中的参数如下：
- en: The data to be shared (`variable_to_share`).
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要共享的数据（`variable_to_share`）。
- en: The root process, that is, the process of rank equal to 0 (`root=0`).
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根进程，即`rank`等于0的进程（`root=0`）。
- en: 'Running the code, we have a communication group of 10 processes, and `variable_to_share` is
    shared between the other processes in the group. Finally, the `print` statement
    visualizes the rank of the running process and the value of its variable:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码，我们有一个由10个进程组成的通信组，`variable_to_share`在组中的其他进程之间共享。最后，`print`语句可视化运行进程的等级及其变量的值：
- en: '[PRE46]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'After setting `10` processes, the output obtained is as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 设置`10`个进程后，获得的输出如下：
- en: '[PRE47]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: There's more...
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Collective communication allows simultaneous data transmission between multiple
    processes in a group. The `mpi4py` library provides collective communications,
    but only in the blocking version (that is, it blocks the caller method until the
    buffered data involved can safely be used).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 集体通信允许在组中的多个进程之间进行同时数据传输。`mpi4py`库提供了集体通信，但只有在阻塞版本中（即它阻塞调用者方法，直到涉及的缓冲数据可以安全使用）。
- en: 'The most commonly used collective communication operations are as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的集体通信操作如下：
- en: Barrier synchronization across the group's processes
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨组的进程进行屏障同步
- en: 'Communication functions:'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通信功能：
- en: Broadcasting data from one process to all processes in the group
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从一个进程广播数据到组中的所有进程
- en: Gathering data from all processes to one process
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从所有进程中收集数据到一个进程
- en: Scattering data from one process to all processes
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从一个进程分发数据到所有进程
- en: Reduction operations
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少操作
- en: See also
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Refer to this link ([https://nyu-cds.github.io/python-mpi/](https://nyu-cds.github.io/python-mpi/))
    to find a complete introduction to Python and MPI.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅此链接([https://nyu-cds.github.io/python-mpi/](https://nyu-cds.github.io/python-mpi/))，以找到Python和MPI的完整介绍。
- en: Collective communication using the scatter function
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用scatter功能的集体通信
- en: 'The scatter functionality is very similar to a scatter broadcast, but with
    one major difference: while `comm.bcast` sends the same data to all listening
    processes, `comm.scatter` can send chunks of data in an array to different processes.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: scatter功能与scatter广播非常相似，但有一个主要区别：虽然`comm.bcast`将相同的数据发送到所有监听进程，但`comm.scatter`可以将数组中的数据块发送到不同的进程。
- en: 'The following diagram illustrates the scatter functionality:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了scatter功能：
- en: '![](assets/7a6e8b54-06df-43d5-ad30-aa1221ae3f85.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7a6e8b54-06df-43d5-ad30-aa1221ae3f85.png)'
- en: Scattering data from process 0 to processes 1, 2, 3, and 4
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 从进程0到进程1、2、3和4中分发数据
- en: 'The **`comm.scatter`** function takes the elements of the array and distributes
    them to the processes according to their rank, for which the first element will
    be sent to process 0, the second element to process 1, and so on. The function
    implemented in **`mpi4py`** is as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**`comm.scatter`**函数获取数组的元素并根据它们的等级将它们分发给进程，第一个元素将发送到进程0，第二个元素将发送到进程1，依此类推。**`mpi4py`**中实现的函数如下：'
- en: '[PRE48]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: How to do it...
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In the following example, we''ll see how to distribute data to different processes
    using the `scatter` functionality:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将看到如何使用`scatter`功能将数据分发给不同的进程：
- en: 'Import the `mpi4py` library:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`mpi4py`库：
- en: '[PRE49]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Next, we define the `comm` and `rank` parameters in the usual way:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们以通常的方式定义`comm`和`rank`参数：
- en: '[PRE50]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'For the process of `rank` equal to `0`, the following array will be scattered:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`rank`等于`0`的进程，将分发以下数组：
- en: '[PRE51]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, `recvbuf` is set. The `root` process is the process of `rank` equal to `0`:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，设置`recvbuf`。`root`进程是`rank`等于`0`的进程：
- en: '[PRE52]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: How it works...
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The process of `rank` equal to `0` distributes the `array_to_share` data structure
    to other processes:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '`rank`等于`0`的进程将`array_to_share`数据结构分发给其他进程：'
- en: '[PRE53]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The `recvbuf` parameter indicates the value of the *i^(th)* variable that will
    be sent to the process through the `comm.scatter` statement:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`recvbuf`参数指示将通过`comm.scatter`语句发送到进程的第*i*个变量的值：'
- en: '[PRE54]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output is as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE55]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We also remark that one of the restrictions to `comm.scatter`is that you can
    scatter as many elements as the processors you specify in the execution statement.
    In fact, if you attempt to scatter more elements than the processors specified
    (three, in this example), then you will get an error similar to the following:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还要注意`comm.scatter`的限制之一是，您可以在执行语句中指定的处理器数量中分散多少元素。实际上，如果您尝试分散比指定的处理器（在本例中为3）更多的元素，那么您将收到类似以下的错误：
- en: '[PRE56]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: There's more...
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The `mpi4py` library provides two other functions that are used to scatter
    data:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '`mpi4py`库提供了另外两个用于分发数据的函数：'
- en: '`comm.scatter(sendbuf, recvbuf, root=0)`: This function sends data from one
    process to all other processes in a communicator.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.scatter(sendbuf, recvbuf, root=0)`：此函数将数据从一个进程发送到通信器中的所有其他进程。'
- en: '`comm.scatterv(sendbuf, recvbuf, root=0)`: This function scatters data from
    one process to all other processes in a given group that provide a different amount
    of data and displacements at the sending side.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.scatterv(sendbuf, recvbuf, root=0)`：此函数将数据从一个进程散布到给定组中的所有其他进程，在发送端提供不同数量的数据和位移。'
- en: 'The `sendbuf` and `recvbuf` arguments must be given in terms of a list (as
    in the`comm.send` point-to-point function):'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`sendbuf`和`recvbuf`参数必须以列表的形式给出（就像`comm.send`点对点函数中一样）：'
- en: '[PRE57]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Here, `data` must be a buffer-like object of the`data_size` size and of the `data_type` type.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`data`必须是`data_size`大小的类似缓冲区的对象，并且是`data_type`类型。
- en: See also
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: An interesting tutorial on MPI broadcasting is presented at [https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/](https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 有关MPI广播的有趣教程，请访问[https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/](https://pythonprogramming.net/mpi-broadcast-tutorial-mpi4py/)。
- en: Collective communication using the gather function
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用gather函数进行集体通信
- en: The `gather` function performs the inverse of the `scatter` function. In this
    case, all processes send data to a root process that collects the data received.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '`gather`函数执行`scatter`函数的逆操作。在这种情况下，所有进程都将数据发送到收集接收到的数据的根进程。'
- en: Getting ready
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备好
- en: 'The `gather` function, which is implemented in `mpi4py`, is as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在`mpi4py`中实现的`gather`函数如下：
- en: '[PRE58]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Here, `sendbuf` is the data that is sent, and `rank_of_root_process` represents
    the processing of the receiver of all the data:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`sendbuf`是发送的数据，`rank_of_root_process`表示所有数据的接收处理：
- en: '![](assets/3fc357c4-5541-4c15-94f4-2dd7bee64b9b.png)Gathering data from processes
    1, 2, 3, and 4'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/3fc357c4-5541-4c15-94f4-2dd7bee64b9b.png)从进程1、2、3和4收集数据'
- en: How to do it...
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'In the following example, we''ll represent the condition shown in the preceding
    diagram, in which each process builds its own data, which is to be sent to the
    root processes that are identified with the `rank` zero:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将表示前图中显示的条件，其中每个进程构建其自己的数据，这些数据将被发送到用`rank`零标识的根进程：
- en: 'Type the necessary import:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 键入必要的导入：
- en: '[PRE59]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Next, we define the following three parameters. The `comm` parameter is the
    communicator, `rank` provides the rank of the process, and`size` is the total
    number of processes:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义以下三个参数。`comm`参数是通信器，`rank`提供进程的等级，`size`是进程的总数：
- en: '[PRE60]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Here, we define the data to be gathered from the process of `rank` zero:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们定义了要从`rank`为零的进程中收集的数据：
- en: '[PRE61]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, the gathering is provided through the `comm.gather` function. Also,
    note that the root process (the process that will gather the data from the other
    ones) is the zero rank process:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过`comm.gather`函数提供收集。还要注意，根进程（从其他进程收集数据的进程）是零级进程：
- en: '[PRE62]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'For the `rank` equal to the `0` process, the data gathered and the sending
    process are printed out:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`rank`等于`0`的进程，收集的数据和发送的进程将被打印出来：
- en: '[PRE63]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: How it works...
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The root process of `0` receives data from the other four processes, as represented
    in the previous diagram.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`0`的根进程从其他四个进程接收数据，如前图所示。'
- en: 'We set *n (= 5)* processes sending their data:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设置*n（= 5）*个进程发送它们的数据：
- en: '[PRE64]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'If the `rank` of the process is `0`, then the data is collected in an array:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如果进程的`rank`为`0`，那么数据将被收集到一个数组中：
- en: '[PRE65]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The gathering of data is given, instead, by the following function:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的收集是通过以下函数给出的：
- en: '[PRE66]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, we run the code setting the group of processes equal to `5`:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们运行代码，将进程组设置为`5`：
- en: '[PRE67]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: There's more...
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To collect data, `mpi4py` provides the following functions:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 要收集数据，`mpi4py`提供了以下函数：
- en: Gathering to one task*:* `comm.Gather`, `comm.Gatherv`, and `comm.gather`
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集到一个任务*：*`comm.Gather`，`comm.Gatherv`和`comm.gather`
- en: 'Gathering to all tasks: `comm.Allgather`, `comm.Allgatherv`, and `comm.allgather`'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集到所有任务：`comm.Allgather`，`comm.Allgatherv`和`comm.allgather`
- en: See also
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: More information on `mpi4py` can be found at [http://www.ceci-hpc.be/assets/training/mpi4py.pdf](http://www.ceci-hpc.be/assets/training/mpi4py.pdf).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`mpi4py`的更多信息，请访问[http://www.ceci-hpc.be/assets/training/mpi4py.pdf](http://www.ceci-hpc.be/assets/training/mpi4py.pdf)。
- en: Collective communication using Alltoall
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Alltoall进行集体通信
- en: The `Alltoall` collective communication combines the `scatter` and `gather`
    functionalities.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`Alltoall`集体通信结合了`scatter`和`gather`的功能。'
- en: How to do it...
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'In the following example, we''ll see an `mpi4py` implementation of `comm.Alltoall`.
    We''ll consider a communicator a group of processes, where each process sends
    and receives an array of numerical data from the other processes defined in the
    group:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将看到`comm.Alltoall`的`mpi4py`实现。我们将考虑一个通信器，其中每个进程从组中定义的其他进程发送和接收数值数据的数组：
- en: 'For this example, the relevant `mpi4py` and `numpy` libraries must be imported:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于此示例，必须导入相关的`mpi4py`和`numpy`库：
- en: '[PRE68]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'As in the previous example, we need to set the same parameters, `comm`, `size`,
    and `rank`:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与前面的示例一样，我们需要设置相同的参数，`comm`，`size`和`rank`：
- en: '[PRE69]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Hence, we must define the data that each process will send (`senddata`) and,
    at the same time, receive (`recvdata`) from the other processes:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们必须定义每个进程将从其他进程发送的数据（`senddata`）和同时接收的数据（`recvdata`）：
- en: '[PRE70]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Finally, the `Alltoall` function is executed:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，执行`Alltoall`函数：
- en: '[PRE71]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The data that is sent and received for each process is displayed:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示每个进程发送和接收的数据：
- en: '[PRE72]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: How it works...
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `comm.alltoall` method takes the *i^(th)* object fromthe `sendbuf` argument
    of task `j` and copies it into the *j^(th)*object of the `recvbuf` argument of
    task `i`.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '`comm.alltoall`方法从任务`j`的`sendbuf`参数中获取第*i^(th)*个对象，并将其复制到任务`i`的`recvbuf`参数的第*j^(th)*对象中。'
- en: 'If we runthe code with a communicator group of `5` processes, then our output
    is as follows:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行具有`5`个进程的通信器组的代码，那么输出如下：
- en: '[PRE73]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'We could also figure out what happened by using the following schema:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过以下模式弄清楚发生了什么：
- en: '![](assets/ae2c13f2-c674-4f5e-a05b-bf8982a010bd.png)The Alltoall collective
    communication'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/ae2c13f2-c674-4f5e-a05b-bf8982a010bd.png)Alltoall 集体通信'
- en: 'Our observations regarding the schema are as follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关于模式的观察如下：
- en: The *P0* process contains the [**0 1 2 3 4**]  data array, where it assigns
    0 to itself, 1 to the *P1 *process,2 to the *P2 *process, 3 to the *P3 *process,
    and 4 to the *P4 *process;
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P0* 进程包含 [**0 1 2 3 4**] 数据数组，其中它将 0 分配给自己，1 分配给 *P1* 进程，2 分配给 *P2* 进程，3 分配给
    *P3* 进程，4 分配给 *P4* 进程；'
- en: The *P1* process contains the [**0 2 4 6 8**] data array, where it assigns 0
    to the *P0 *process, 2 to itself, 4 to the *P2 *process, 6 to the *P3 *process,
    and 8 to the *P4 *process;
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P1* 进程包含 [**0 2 4 6 8**] 数据数组，其中它将 0 分配给 *P0* 进程，2 分配给自己，4 分配给 *P2* 进程，6 分配给
    *P3* 进程，8 分配给 *P4* 进程；'
- en: The *P2* process contains the [**0 3 6 9 12**] data array, where it assigns
    0 to the *P0 *process, 3 to the *P1 *process, 6 to itself, 9 to the *P3 *process, and
    12 to the *P4 *process;
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P2* 进程包含 [**0 3 6 9 12**] 数据数组，其中它将 0 分配给 *P0* 进程，3 分配给 *P1* 进程，6 分配给自己，9
    分配给 *P3* 进程，12 分配给 *P4* 进程；'
- en: The *P3* process contains the [**0 4 8 12 16**] data array, where it assigns
    0 to the *P0 *process, 4 to the *P1 *process, 8 to the *P2* process, 12 to itself,
    and 16 to the *P4 *process;
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P3* 进程包含 [**0 4 8 12 16**] 数据数组，其中它将 0 分配给 *P0* 进程，4 分配给 *P1* 进程，8 分配给 *P2*
    进程，12 分配给自己，16 分配给 *P4* 进程；'
- en: The *P4* process contains the [**0 5 10 15 20**] data array, where it assigns
    0 to the *P0* process, 5 to the *P1 *process, 10 to the *P2 *process, 15 to the
    *P3 *process, and 20 to itself.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P4* 进程包含 [**0 5 10 15 20**] 数据数组，其中它将 0 分配给 *P0* 进程，5 分配给 *P1* 进程，10 分配给 *P2*
    进程，15 分配给 *P3* 进程，20 分配给自己。'
- en: There's more...
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: '`Alltoall` personalized communication is also known as a total exchange. This
    operation is used in a variety of parallel algorithms, such as the fast Fourier
    transform, matrix transpose, sample sort, and some parallel database join operations.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '`Alltoall` 个性化通信也被称为总交换。这个操作在各种并行算法中使用，比如快速傅立叶变换、矩阵转置、样本排序和一些并行数据库连接操作。'
- en: 'In `mpi4py`, there are *three types* of `Alltoall` collective communication:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `mpi4py` 中，有 *三种类型* 的 `Alltoall` 集体通信：
- en: '`comm.Alltoall(sendbuf, recvbuf)`: The `Alltoall` scatter/gather sends data
    from all-to-all processes in a group.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.Alltoall(sendbuf, recvbuf)`: `Alltoall` 散列/聚集从组中的所有进程发送数据到所有进程。'
- en: '`comm.Alltoallv(sendbuf, recvbuf)`: The `Alltoall` scatter/gather vector sends
    data fromall-to-all processes in a group, providing a different amount of data
    and displacements.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.Alltoallv(sendbuf, recvbuf)`: `Alltoall` 散列/聚集向组中的所有进程发送数据，提供不同数量的数据和位移。'
- en: '`comm.Alltoallw(sendbuf, recvbuf)`: Generalized `Alltoall` communication allows
    different counts, displacements, and datatypes for each partner.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`comm.Alltoallw(sendbuf, recvbuf)`: 广义的 `Alltoall` 通信允许每个伙伴的不同计数、位移和数据类型。'
- en: See also
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: An interesting analysis of MPI Python modules can be downloaded from [https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf](https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从[https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf](https://www.duo.uio.no/bitstream/handle/10852/10848/WenjingLinThesis.pdf)下载
    MPI Python 模块的有趣分析。
- en: The reduction operation
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减少操作
- en: Similar to `comm.gather`, `comm.reduce` takes an array of input elements in
    each process and returns an array of output elements to the root process. The
    output elements contain the reduced result.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `comm.gather` 类似，`comm.reduce` 接受每个进程中输入元素的数组，并将输出元素数组返回给根进程。输出元素包含减少的结果。
- en: Getting ready
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In `mpi4py`, we define the reduction operation through the following statement:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `mpi4py` 中，我们通过以下语句定义减少操作：
- en: '[PRE74]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: We must note that the difference with the `comm.gather` statement resides in
    the `op` parameter, which is the operation that you wish to apply to your data,
    and the `mpi4py` module contains a set of reduction operations that can be used.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须注意，与 `comm.gather` 语句的不同之处在于 `op` 参数，它是您希望应用于数据的操作，而 `mpi4py` 模块包含一组可以使用的减少操作。
- en: How to do it...
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Now, we'll see how to implement the sum of an array of elements with the `MPI.SUM` reduction
    operationby using the reduction functionality. Each process will manipulate an
    array of size 10.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将看到如何使用减少功能实现对元素数组的和的 `MPI.SUM` 减少操作。
- en: 'For array manipulation, we use the functions provided by the `numpy` Python
    module:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数组操作，我们使用 `numpy` Python 模块提供的函数：
- en: 'Here, the relevant libraries, `mpi4py` and `numpy`, are imported:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，导入相关的库 `mpi4py` 和 `numpy`：
- en: '[PRE75]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Define the `comm`, `size`, and `rank` parameters:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 `comm`、`size` 和 `rank` 参数：
- en: '[PRE76]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Then, the size of the array (`array_size`) is set:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，设置数组的大小（`array_size`）：
- en: '[PRE77]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The data to be sent and received is defined:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义要发送和接收的数据：
- en: '[PRE78]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The process sender and the sent data are printed out:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出进程发送者和发送的数据：
- en: '[PRE79]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Finally, the `Reduce` operation is executed. Note that the `root` process is set
    to `0`and the `op` parameter is set to `MPI.SUM`:'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，执行 `Reduce` 操作。请注意，`root` 进程设置为 `0`，`op` 参数设置为 `MPI.SUM`：
- en: '[PRE80]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The output of the reduction operation is then shown, as follows:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后显示减少操作的输出，如下所示：
- en: '[PRE81]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: How it works...
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'To perform the reduction sum, we use the `comm.Reduce` statement. Also, we
    identify with `rank` zero, which is the `root` process that will contain `recvbuf`,
    which represents the final result of the computation:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 为执行减少求和，我们使用 `comm.Reduce` 语句。此外，我们将标识为 `rank` 为零，这是将包含计算最终结果的 `recvbuf` 的 `root`
    进程：
- en: '[PRE82]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: It makes sense to run the code with a communicator group of `10` processes,
    as this is the size of the manipulated array.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 以 `10` 个进程的通信器组运行代码是有意义的，因为这是被操作数组的大小。
- en: 'The output appears as follows:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下所示：
- en: '[PRE83]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: There's more...
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Note that with the `op=MPI.SUM` option, we apply the sum operation to all the
    elements of the column array. To better understand how the reduction operates,
    let''s look at the following diagram:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用`op=MPI.SUM`选项，我们对列数组的所有元素应用求和操作。为了更好地理解减少操作的运行方式，让我们看一下下面的图表：
- en: '![](assets/aa28bcc1-08cf-4699-b559-9f4f1e6e948c.png)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aa28bcc1-08cf-4699-b559-9f4f1e6e948c.png)'
- en: Reduction in collective communication
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 集体通信中的减少
- en: 'The sending operation is as follows:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 发送操作如下：
- en: The **P0** process sends the [**0 1 2**] data array.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P0**进程发送[**0 1 2**]数据数组。'
- en: The **P1** process sends the [**0 2 4**] data array.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P1**进程发送[**0 2 4**]数据数组。'
- en: The **P2** process sends the [**0 3 6**] data array.
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P2**进程发送[**0 3 6**]数据数组。'
- en: The reduction operation sums the *i^(th)* elements of each task and then puts
    the result in the *i^(th)* element of the array in the **P0** rootprocess. For
    the receiving operation, the **P0** process receives the [**0 6 12**] data array.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 减少操作对每个任务的第*i*个元素求和，然后将结果放入**P0**根进程数组的第*i*个元素中。对于接收操作，**P0**进程接收[**0 6 12**]数据数组。
- en: 'Some of the reduction operations defined by MPI are as follows:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: MPI定义的一些减少操作如下：
- en: '`MPI.MAX`: This returns the maximum element.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MAX`：返回最大元素。'
- en: '`MPI.MIN`: This returns the minimum element.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MIN`：返回最小元素。'
- en: '`MPI.SUM`: This sums up the elements.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.SUM`：对元素求和。'
- en: '`MPI.PROD`: This multiplies all elements.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.PROD`：将所有元素相乘。'
- en: '`MPI.LAND`: This performs the AND logical operation across the elements.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.LAND`：对元素执行AND逻辑操作。'
- en: '`MPI.MAXLOC`: This returns the maximum value and the rank of the process that
    owns it.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MAXLOC`：返回最大值及其所属进程的等级。'
- en: '`MPI.MINLOC`: This returns the minimum value and the rank of the process that
    owns it.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MPI.MINLOC`：返回最小值及其所属进程的等级。'
- en: See also
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: At [http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/](http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/),
    you can find a good tutorial on this topic and much more.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 在[http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/](http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/)，您可以找到有关此主题的良好教程以及更多内容。
- en: Optimizing communication
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化通信
- en: An interesting feature that is provided by MPI regards virtual topologies. As
    already noted, all the communication functions (point-to-point or collective)
    refer to a group of processes. We have always used the `MPI_COMM_WORLD` group
    that includes all processes. It assigns a rank of *0* to *n-1* for each process
    that belongs to a communicator of the size *n*.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: MPI提供的一个有趣功能是虚拟拓扑。如前所述，所有通信函数（点对点或集体）都涉及一组进程。我们一直使用包括所有进程的`MPI_COMM_WORLD`组。它为每个属于大小为*n*的通信器的进程分配了*0*到*n-1*的等级。
- en: 'However, MPI allows us to assign a virtual topology to a communicator. It defines
    an assignment of labels to the different processes: by building a virtual topology,
    each node will communicate only with its virtual neighbor, improving performance
    because it reduces execution times.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，MPI允许我们为通信器分配虚拟拓扑。它定义了对不同进程的标签分配：通过构建虚拟拓扑，每个节点将只与其虚拟邻居通信，提高性能，因为它减少了执行时间。
- en: For example, if the rank was randomly assigned, then a message could be forced
    to pass to many other nodes before it reaches the destination. Beyond the question
    of performance, a virtual topology makes sure that the code is clearer and more
    readable.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果等级是随机分配的，那么消息可能被迫传递到达目的地之前经过许多其他节点。除了性能问题，虚拟拓扑确保代码更清晰、更易读。
- en: MPI provides two building topologies. The first construct creates Cartesian
    topologies, while the latter creates any kind of topologies. Specifically, in
    the second case, we must supply the adjacency matrix of the graph that you want
    to build. We will only deal with Cartesian topologies, through which it is possible
    to build several structures that are widely used, such as mesh, ring, and toroid.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: MPI提供两种构建拓扑的方法。第一种构建创建笛卡尔拓扑，而后者创建任何类型的拓扑。具体来说，在第二种情况下，我们必须提供要构建的图的邻接矩阵。我们只处理笛卡尔拓扑，通过它可以构建广泛使用的几种结构，如网格、环和环面。
- en: 'The `mpi4py` function used to create a Cartesian topology is as follows:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建笛卡尔拓扑的`mpi4py`函数如下：
- en: '[PRE84]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Here, `number_of_rows` and `number_of_columns` specify the rows and columns
    of the grid that is to be made.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`number_of_rows`和`number_of_columns`指定要创建的网格的行和列。
- en: How to do it...
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In the following example, we see how to implement a Cartesian topology of the
    size *M×N*. Also, we define a set of coordinates to understand how all the processes
    are disposed of:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们看到如何实现大小为*M×N*的笛卡尔拓扑。此外，我们定义一组坐标以了解所有进程的位置：
- en: 'Import all the relevant libraries:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有相关库：
- en: '[PRE85]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Define the following parameter in order to move along the topology:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义以下参数以沿着拓扑移动：
- en: '[PRE86]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'For each process, the following array defines the neighbor processes:'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个进程，以下数组定义了邻近进程：
- en: '[PRE87]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'In the `main` program, the `comm.rank` and `size` parameters are then defined:'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`main`程序中，然后定义了`comm.rank`和`size`参数：
- en: '[PRE88]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Now, let''s build the topology:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们构建拓扑：
- en: '[PRE89]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The following conditions ensure that the processes are always within the topology:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下条件确保进程始终在拓扑结构内：
- en: '[PRE90]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The `rank`equal to `0` process starts the topology construction:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rank`等于`0`的进程开始拓扑构建：'
- en: '[PRE91]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: How it works...
  id: totrans-390
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'For each process, the output should read as follows: if `neighbour_processes
    = -1`, then it has no topological proximity, otherwise, `neighbour_processes`
    shows the rank of the process closely.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个进程，输出应该如下所示：如果`neighbour_processes = -1`，则它没有拓扑接近性，否则，`neighbour_processes`显示接近进程的等级。
- en: 'The resulting topology is a mesh of *2*×*2* (refer to the previous diagram
    for a mesh representation), the size of which is equal to the number of processes
    in the input; that is, four:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的拓扑是*2*×*2*的网格（参考前面的图表以获取网格表示），其大小等于输入中的进程数，即四个：
- en: '[PRE92]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Then, the Cartesian topology is built using the `comm.Create_cart` function
    (note also the parameter, `periods = (False,False)`):'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用`comm.Create_cart`函数构建笛卡尔拓扑结构（还要注意参数`periods = (False,False)`）：
- en: '[PRE93]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'To know the position of the process, we use the `Get_coords()` method in the
    following form:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 要知道进程的位置，我们使用以下形式的`Get_coords()`方法：
- en: '[PRE94]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'For the processes, in addition to getting their coordinates, we must calculate
    and find out which processes are topologically closer. For this purpose, we use
    the `comm.Shift (rank_source,rank_dest)` function:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进程，除了获取它们的坐标外，我们还必须计算并找出哪些进程在拓扑上更接近。为此，我们使用`comm.Shift (rank_source,rank_dest)`函数：
- en: '[PRE95]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The topology obtained is as follows:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的拓扑结构如下：
- en: '![](assets/f716b5dc-9c4c-4e31-9fc3-b128b439f010.png)The virtual mesh 2x2 topology'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/f716b5dc-9c4c-4e31-9fc3-b128b439f010.png)虚拟网格2x2拓扑结构'
- en: As the diagram shows, the *P0* process is chained to the**P1** `(RIGHT)` and
    **P2** `(DOWN)` processes. The **P1** process is chained to the**P3** `(DOWN)`
    and **P0** `(LEFT)` processes, the**P3** process is chained to the**P1** `(UP)`
    and **P2** `(LEFT)` processes, and the**P2** process is chained to the**P3** `(RIGHT)`
    and **P0** `(UP)` processes.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，*P0*进程与**P1**（`RIGHT`）和**P2**（`DOWN`）进程链接。**P1**进程与**P3**（`DOWN`）和**P0**（`LEFT`）进程链接，**P3**进程与**P1**（`UP`）和**P2**（`LEFT`）进程链接，**P2**进程与**P3**（`RIGHT`）和**P0**（`UP`）进程链接。
- en: 'Finally, by running the script, we obtain the following result:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过运行脚本，我们获得以下结果：
- en: '[PRE96]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: There's more...
  id: totrans-405
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'To obtain a toroidal topology of the size *M*×*N*, let''s use `comm.Create_cart`
    again, but, this time, let''s set the `periods` parameter to `periods=(True,True)`:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得大小为*M*×*N*的环面拓扑结构，让我们再次使用`comm.Create_cart`，但是这次，让我们将`periods`参数设置为`periods=(True,True)`：
- en: '[PRE97]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'The following output is obtained:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 获得以下输出：
- en: '[PRE98]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The output covers the topology represented here:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 输出涵盖了此处表示的拓扑结构：
- en: '![](assets/0de01d9b-fe04-43f0-9700-68e7955534b8.png)The virtual toroidal 2x2
    topology'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/0de01d9b-fe04-43f0-9700-68e7955534b8.png)虚拟环面2x2拓扑结构'
- en: The topology represented in the previous diagram indicates that the **P0** process
    is chained to the**P1** (`RIGHT` and `LEFT`) and **P2** (`UP` and `DOWN`) processes,
    the **P1** process is chained to the**P3** (`UP` and `DOWN`) and **P0** (`RIGHT`
    and `LEFT`) processes, the **P3** process is chained to the **P1** (`UP` and `DOWN`)
    and **P2** (`RIGHT` and `LEFT`) processes, and the **P2** process is chained to the
    **P3** (`LEFT` and `RIGHT`) and **P0** (`UP` and `DOWN`) processes.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图表中表示的拓扑结构表明，**P0**进程与**P1**（`RIGHT`和`LEFT`）和**P2**（`UP`和`DOWN`）进程链接，**P1**进程与**P3**（`UP`和`DOWN`）和**P0**（`RIGHT`和`LEFT`）进程链接，**P3**进程与**P1**（`UP`和`DOWN`）和**P2**（`RIGHT`和`LEFT`）进程链接，**P2**进程与**P3**（`LEFT`和`RIGHT`）和**P0**（`UP`和`DOWN`）进程链接。
- en: See also
  id: totrans-413
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: More information on MPI can be found at [http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html](http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html).
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 有关MPI的更多信息可以在[http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html](http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html)找到。
