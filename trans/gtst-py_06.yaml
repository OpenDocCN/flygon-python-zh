- en: Principles of Algorithm Design
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法设计原则
- en: Why do we want to study algorithm design? There are of course many reasons,
    and our motivation for learning something is very much dependent on our own circumstances.
    There are without doubt important professional reasons for being interested in
    algorithm design. Algorithms are the foundations of all computing. We think of
    a computer as being a piece of hardware, a hard drive, memory chips, processors,
    and so on. However, the essential component, the thing that, if missing, would
    render modern technology impossible, is algorithms.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么要学习算法设计？当然有很多原因，我们学习某事的动机很大程度上取决于我们自己的情况。对于对算法设计感兴趣有重要的职业原因。算法是所有计算的基础。我们认为计算机是硬件，硬盘、内存芯片、处理器等等。然而，如果缺少的是算法，现代技术将不可能存在。
- en: The theoretical foundation of algorithms, in the form of the Turing machine,
    was established several decades before digital logic circuits could actually implement
    such a machine. The Turing machine is essentially a mathematical model that, using
    a predefined set of rules, translates a set of inputs into a set of outputs. The
    first implementations of Turing machines were mechanical and the next generation
    may likely see digital logic circuits replaced by quantum circuits or something
    similar. Regardless of the platform, algorithms play a central predominant role.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的理论基础是图灵机，几十年前就建立了这种机器的数学模型，而数字逻辑电路实际上能够实现这样的机器。图灵机本质上是一个数学模型，它使用预定义的一组规则，将一组输入转换为一组输出。图灵机的第一批实现是机械的，下一代可能会看到数字逻辑电路被量子电路或类似的东西所取代。无论平台如何，算法都起着中心主导的作用。
- en: Another aspect is the effect algorithms have in technological innovation. As
    an obvious example, consider the page rank search algorithm, a variation of which
    the Google search engine is based on. Using this and similar algorithms allows
    researchers, scientists, technicians, and others to quickly search through vast
    amounts of information extremely quickly. This has a massive effect on the rate
    at which new research can be carried out, new discoveries made, and new innovative
    technologies developed.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的另一个方面是它对技术创新的影响。显而易见的例子是页面排名搜索算法，谷歌搜索引擎就是基于它的变体。使用这种算法和类似的算法允许研究人员、科学家、技术人员和其他人能够快速地搜索大量信息。这对新研究的速度、新发现的速度以及新的创新技术的发展速度都有巨大影响。
- en: 'The study of algorithms is also important because it trains us to think very
    specifically about certain problems. It can serve to increase our mental and problem
    solving abilities by helping us isolate the components of a problem and define
    relationships between these components. In summary, there are four broad reasons
    for studying algorithms:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的研究也很重要，因为它训练我们对某些问题进行非常具体的思考。它可以通过帮助我们分离问题的组成部分并定义这些组成部分之间的关系，来增强我们的思维和问题解决能力。总之，学习算法有四个主要原因：
- en: They are essential for computer science and *intelligent* systems.
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们对计算机科学和*智能*系统至关重要。
- en: They are important in many other domains (computational biology, economics,
    ecology, communications, ecology, physics, and so on).
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们在许多其他领域（计算生物学、经济学、生态学、通信、生态学、物理学等）中都很重要。
- en: They play a role in technology innovation.
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们在技术创新中发挥作用。
- en: They improve problem solving and analytical thinking.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们改善问题解决和分析思维能力。
- en: Algorithms, in their simplest form, are just a sequence of actions, a list of
    instructions. It may just be a linear construct of the form do *x*, then do *y*,
    then do *z*, then finish. However, to make things more useful we add clauses to
    the effect of, *x* then do *y*, in Python the `if-else` statements. Here, the
    future course of action is dependent on some conditions; say the state of a data
    structure. To this we also add the operation, iteration, the while, and for statements.
    Expanding our algorithmic literacy further we add recursion. Recursion can often
    achieve the same result as iteration, however, they are fundamentally different.
    A recursive function calls itself, applying the same function to progressively
    smaller inputs. The input of any recursive step is the output of the previous
    recursive step.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 算法在最简单的形式中只是一系列操作，一系列指令。它可能只是一个线性结构，形式为做*x*，然后做*y*，然后做*z*，然后完成。然而，为了使事情更有用，我们添加了诸如在Python中的`if-else`语句的子句。在这里，未来的行动取决于某些条件；比如数据结构的状态。我们还添加了操作、迭代，while和for语句。进一步扩展我们的算法素养，我们添加了递归。递归通常可以实现与迭代相同的结果，但它们在根本上是不同的。递归函数调用自身，将相同的函数应用于逐渐减小的输入。任何递归步骤的输入都是前一个递归步骤的输出。
- en: 'Essentially, we can say that algorithms are composed of the following four
    elements:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们可以说算法由以下四个元素组成：
- en: Sequential operations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺序操作
- en: Actions based on the state of a data structure
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于数据结构状态的操作
- en: Iteration, repeating an action a number of times
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代，重复执行一定次数的操作
- en: Recursion, calling itself on a subset of inputs
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递归，在一组输入上调用自身
- en: Algorithm design paradigms
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法设计范式
- en: 'In general, we can discern three broad approaches to algorithm design. They
    are:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们可以分辨出三种广泛的算法设计方法。它们是：
- en: Divide and conquer
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分而治之
- en: Greedy algorithms
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贪婪算法
- en: Dynamic programming
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态规划
- en: As the name suggests, the divide and conquer paradigm involves breaking a problem
    into smaller sub problems, and then in some way combining the results to obtain
    a global solution. This is a very common and natural problem solving technique,
    and is, arguably, the most commonly used approach to algorithm design.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，分而治之范式涉及将问题分解为较小的子问题，然后以某种方式将结果组合起来以获得全局解。这是一种非常常见和自然的问题解决技术，可以说是最常用的算法设计方法。
- en: Greedy algorithms often involve optimization and combinatorial problems; the
    classic example is applying it to the traveling salesperson problem, where a greedy
    approach always chooses the closest destination first. This shortest path strategy
    involves finding the best solution to a local problem in the hope that this will
    lead to a global solution.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 贪婪算法通常涉及优化和组合问题；经典的例子是将其应用于旅行推销员问题，贪婪方法总是首先选择最近的目的地。这种最短路径策略涉及在希望这将导致全局解决方案的情况下找到局部问题的最佳解决方案。
- en: The dynamic programming approach is useful when our sub problems overlap. This
    is different from divide and conquer. Rather than break our problem into independent
    sub problems, with dynamic programming, intermediate results are cached and can
    be used in subsequent operations. Like divide and conquer it uses recursion; however,
    dynamic programming allows us to compare results at different stages. This can
    have a performance advantage over divide and conquer for some problems because
    it is often quicker to retrieve a previously calculated result from memory rather
    than having to recalculate it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 动态规划方法在我们的子问题重叠时非常有用。这与分治不同。与将问题分解为独立的子问题不同，动态规划中间结果被缓存并可以在后续操作中使用。与分治一样，它使用递归；然而，动态规划允许我们在不同阶段比较结果。对于某些问题，这可能比分治具有性能优势，因为通常更快地从内存中检索先前计算的结果，而不必重新计算它。
- en: Recursion and backtracking
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归和回溯
- en: 'Recursion is particularly useful for divide and conquer problems; however,
    it can be difficult to understand exactly what is happening, since each recursive
    call is itself spinning off other recursive calls. At the core of a recursive
    function are two types of cases: base cases, which tell the recursion when to
    terminate, and recursive cases that call the function they are in. A simple problem
    that naturally lends itself to a recursive solution is calculating factorials.
    The recursive factorial algorithm defines two cases: the base case when *n* is
    zero, and the recursive case when *n* is greater than zero. A typical implementation
    is the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 递归特别适用于分治问题；然而，要准确理解发生了什么可能有些困难，因为每次递归调用都会产生其他递归调用。递归函数的核心是两种类型的情况：基本情况，告诉递归何时终止，和递归情况，调用它们所在的函数。一个自然适合递归解决方案的简单问题是计算阶乘。递归阶乘算法定义了两种情况：当*n*为零时的基本情况，和当*n*大于零时的递归情况。一个典型的实现如下：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This code prints out the digits 1, 2, 4, 24\. To calculate 4 requires four
    recursive calls plus the initial parent call. On each recursion, a copy of the
    methods variables is stored in memory. Once the method returns it is removed from
    memory. The following is a way we can visualize this process:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码打印出数字1、2、4、24\. 要计算4需要进行四次递归调用加上初始的父调用。在每次递归中，方法的变量副本都存储在内存中。一旦方法返回，它就会从内存中移除。以下是我们可以将这个过程可视化的一种方式：
- en: '![](assets/ceaff8fe-caa4-42cf-8dd5-f0e739a5d7fa.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ceaff8fe-caa4-42cf-8dd5-f0e739a5d7fa.png)'
- en: 'It may not necessarily be clear if recursion or iteration is a better solution
    to a particular problem; after all they both repeat a series of operations and
    both are very well suited to divide and conquer approaches to algorithm design.
    Iteration churns away until the problem is done. Recursion breaks the problem
    down into smaller and smaller chunks and then combines the results. Iteration
    is often easier for programmers, because control stays local to a loop, whereas
    recursion can more closely represent mathematical concepts such as factorials.
    Recursive calls are stored in memory, whereas iterations are not. This creates
    a trade off between processor cycles and memory usage, so choosing which one to
    use may depend on whether the task is processor or memory intensive. The following
    table outlines the key differences between recursion and iteration:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 可能并不清楚递归还是迭代对于特定问题更好的解决方案；毕竟它们都重复一系列操作，并且都非常适合分治算法设计。迭代一直运行直到问题完成。递归将问题分解为越来越小的块，然后将结果组合起来。迭代对程序员来说通常更容易，因为控制保持在循环内部，而递归可以更接近数学概念，比如阶乘。递归调用存储在内存中，而迭代不会。这在处理器周期和内存使用之间产生了一种权衡，因此选择使用哪种可能取决于任务是处理器密集型还是内存密集型。以下表格概述了递归和迭代之间的主要区别：
- en: '| **Recursion** | **Iteration** |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **递归** | **迭代** |'
- en: '| Terminates when a base case is reached | Terminates when a defined condition
    is met |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 当达到基本情况时终止 | 当满足定义的条件时终止 |'
- en: '| Each recursive call requires space in memory | Each iteration is not stored
    in memory |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 每次递归调用都需要内存空间 | 每次迭代都不会存储在内存中 |'
- en: '| An infinite recursion results in a stack overflow error | An infinite iteration
    will run while the hardware is powered |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 无限递归会导致堆栈溢出错误 | 无限迭代将在硬件通电时运行 |'
- en: '| Some problems are naturally better suited to recursive solutions | Iterative
    solutions may not always be obvious |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 有些问题自然更适合递归解决方案 | 迭代解决方案可能并不总是显而易见 |'
- en: Backtracking
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回溯
- en: Backtracking is a form of recursion that is particularly useful for types of
    problems such as traversing tree structures, where we are presented with a number
    of options at each node, from which we must choose one. Subsequently we are presented
    with a different set of options, and depending on the series of choices made either
    a goal state or a dead end is reached. If it is the latter, we must backtrack
    to a previous node and traverse a different branch. Backtracking is a divide and
    conquer method for exhaustive search. Importantly backtracking **prunes** branches
    that cannot give a result.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 回溯是一种特别适用于遍历树结构等问题类型的递归形式，在每个节点我们都有多个选项可供选择。随后我们会面临不同的选项，并根据所做的选择系列达到目标状态或死胡同。如果是后者，我们必须回溯到上一个节点并遍历不同的分支。回溯是一种穷举搜索的分治方法。重要的是，回溯会剪枝不能给出结果的分支。
- en: 'An example of back tracking is given in the following example. Here, we have
    used a recursive approach to generating all the possible permutations of a given
    string, *s*, of a given length *n*:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中给出了回溯的一个例子。在这里，我们使用了递归方法来生成给定长度*n*的给定字符串*s*的所有可能的排列：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This generates the following output:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下输出：
- en: '![](assets/b1ab5929-7ac9-4dec-b033-e9fde81b5b2b.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b1ab5929-7ac9-4dec-b033-e9fde81b5b2b.png)'
- en: Notice the double list compression and the two recursive calls within this comprehension.
    This recursively concatenates each element of the initial sequence, returned when
    `*n* = 1`, with each element of the string generated in the previous recursive
    call. In this sense it is *backtracking* to uncover previously ingenerated combinations.
    The final string that is returned is all *n* letter combinations of the initial
    string.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这个双列表压缩和这个理解中的两个递归调用。这个递归地连接了初始序列的每个元素，当`*n* = 1`时返回，与前一个递归调用中生成的字符串的每个元素。在这个意义上，它是*回溯*，以揭示先前未生成的组合。返回的最终字符串是初始字符串的所有*n*个字母组合。
- en: Divide and conquer - long multiplication
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分而治之 - 长乘法
- en: For recursion to be more than just a clever trick, we need to understand how
    to compare it to other approaches, such as iteration, and to understand when its
    use will lead to a faster algorithm. An iterative algorithm that we are all familiar
    with is the procedure we learned in primary math classes, used to multiply two
    large numbers. That is, long multiplication. If you remember, long multiplication
    involved iterative multiplying and carry operations followed by a shifting and
    addition operation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使递归不仅仅是一个聪明的技巧，我们需要了解如何将其与其他方法进行比较，比如迭代，以及了解何时使用它将导致更快的算法。我们都熟悉的迭代算法是我们在小学数学课上学到的程序，用于相乘两个大数。也就是说，长乘法。如果你记得的话，长乘法涉及迭代相乘和进位操作，然后是移位和加法操作。
- en: Our aim here is to examine ways to measure how efficient this procedure is and
    attempt to answer the question; is this the most efficient procedure we can use
    for multiplying two large numbers together?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是在这里检查如何测量这个过程的效率，并尝试回答这个问题：这是我们用来相乘两个大数的最有效的程序吗？
- en: 'In the following figure, we can see that multiplying two 4 digit numbers together
    requires 16 multiplication operations, and we can generalize to say that an *n*
    digit number requires, approximately, *n²* multiplication operations:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们可以看到将两个4位数相乘需要16次乘法运算，我们可以推广说，一个*n*位数需要大约*n²*次乘法运算：
- en: '![](assets/a349984a-9f69-4c49-b418-7ff885bc6a42.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a349984a-9f69-4c49-b418-7ff885bc6a42.png)'
- en: This method of analyzing algorithms, in terms of the number of computational
    primitives such as multiplication and addition, is important because it gives
    us a way to understand the relationship between the time it takes to complete
    a certain computation and the size of the input to that computation. In particular,
    we want to know what happens when the input, the number of digits, n, is very
    large. This topic, called asymptotic analysis, or time complexity, is essential
    to our study of algorithms and we will revisit it often during this chapter and
    the rest of this book.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以计算原语的数量，如乘法和加法，来分析算法的方法很重要，因为它为我们提供了一种理解完成某个计算所需的时间与该计算的输入大小之间的关系的方法。特别是，我们想知道当输入，即数字的位数*n*非常大时会发生什么。这个主题，称为渐近分析，或时间复杂度，对我们研究算法至关重要，我们将在本章和本书的其余部分经常回顾它。
- en: Can we do better? A recursive approach
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们能做得更好吗？递归方法
- en: 'It turns out that in the case of long multiplication the answer is yes, there
    are in fact several algorithms for multiplying large numbers that require less
    operations. One of the most well-known alternatives to long multiplication is
    the **Karatsuba algorithm**, first published in 1962\. This takes a fundamentally
    different approach: rather than iteratively multiplying single digit numbers,
    it recursively carries out multiplication operations on progressively smaller
    inputs. Recursive programs call themselves on smaller subsets of the input. The
    first step in building a recursive algorithm is to decompose a large number into
    several smaller numbers. The most natural way to do this is to simply split the
    number in to two halves, the first half of most significant digits, and a second
    half of least significant digits. For example, our four-digit number, 2345, becomes
    a pair of two-digit numbers, 23 and 45\. We can write a more general decomposition
    of any 2 *n* digit numbers, *x* and *y* using the following, where *m* is any
    positive integer less than *n*:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，在长乘法的情况下，答案是肯定的，实际上有几种算法可以用于乘法大数，需要更少的操作。最著名的长乘法替代方案之一是**Karatsuba算法**，首次发表于1962年。这采用了一种基本不同的方法：而不是迭代地相乘单个数字，它以递归的方式对逐渐变小的输入进行乘法运算。递归程序在输入的较小子集上调用自己。构建递归算法的第一步是将一个大数分解为几个较小的数。这样做的最自然的方式是将数字简单地分成两半，前半部分是最重要的数字，后半部分是最不重要的数字。例如，我们的四位数2345变成了一对两位数23和45。我们可以使用以下更一般的分解来分解任何2
    *n*位数*x*和*y*，其中*m*是小于*n*的任何正整数：
- en: '![](assets/0ca172df-86c2-4780-bf6a-9570e18aab94.png)![](assets/55df9f14-ece8-4cbb-ae31-8b23c3267211.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/0ca172df-86c2-4780-bf6a-9570e18aab94.png)![](assets/55df9f14-ece8-4cbb-ae31-8b23c3267211.png)'
- en: 'So now we can rewrite our multiplication problem *x*, *y* as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将我们的乘法问题*x*，*y*重写如下：
- en: '![](assets/35b80ce5-cbcc-4638-8799-346532ee2154.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/35b80ce5-cbcc-4638-8799-346532ee2154.png)'
- en: 'When we expand and gather like terms we get the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们展开并收集同类项时，我们得到以下结果：
- en: '![](assets/d5f89699-bf11-480c-9db2-0deae29ac8eb.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d5f89699-bf11-480c-9db2-0deae29ac8eb.png)'
- en: 'More conveniently, we can write it like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 更方便的是，我们可以这样写：
- en: '![](assets/ad955c99-182e-4f77-a7d2-df5800b6215f.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ad955c99-182e-4f77-a7d2-df5800b6215f.jpg)'
- en: 'Where:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '![](assets/7bb07889-0803-436c-84b5-8edb5a6eb21d.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7bb07889-0803-436c-84b5-8edb5a6eb21d.jpg)'
- en: It should be pointed out that this suggests a recursive approach to multiplying
    two numbers since this procedure does itself involve multiplication. Specifically,
    the products *ac*, *ad*, *bc*, and *bd* all involve numbers smaller than the input
    number and so it is conceivable that we could apply the same operation as a partial
    solution to the overall problem. This algorithm, so far, consists of four recursive
    multiplication steps and it is not immediately clear if it will be faster than
    the classic long multiplication approach.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 应该指出，这表明了一种递归方法来计算两个数字的乘法，因为这个过程本身涉及乘法。具体来说，乘积*ac*、*ad*、*bc*和*bd*都涉及比输入数字小的数字，因此我们可以将相同的操作作为整体问题的部分解决方案。到目前为止，这个算法包括四个递归乘法步骤，目前还不清楚它是否比经典的长乘法方法更快。
- en: What we have discussed so far in regards to the recursive approach to multiplication,
    has been well known to mathematicians since the late 19^(th) century. The Karatsuba
    algorithm improves on this is by making the following observation. We really only
    need to know three quantities: *z[2]*= *ac* ; *z[1]=ad +bc*, and *z[0]*= *bd*
    to solve equation 3.1\. We need to know the values of *a, b, c, d* only in so
    far as they contribute to the overall sum and products involved in calculating
    the quantities *z[2]*, *z[1]*, and *z[0]*. This suggests the possibility that
    perhaps we can reduce the number of recursive steps. It turns out that this is
    indeed the situation.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，关于递归乘法的讨论对数学家来说自19世纪末就已经很熟悉了。卡拉茨巴算法改进了这一点，方法是做出以下观察。我们实际上只需要知道三个量：*z[2]*=
    *ac*；*z[1]=ad +bc*，和*z[0]*= *bd* 来解方程3.1。我们只需要知道*a, b, c, d*的值，因为它们对计算*z[2]*,
    *z[1]*, 和*z[0]*所涉及的总和和乘积有贡献。这表明也许我们可以减少递归步骤的数量。事实证明的确是这种情况。
- en: 'Since the products *ac* and *bd* are already in their simplest form, it seems
    unlikely that we can eliminate these calculations. We can however make the following
    observation:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于乘积*ac*和*bd*已经处于最简形式，似乎我们不太可能消除这些计算。然而，我们可以做出以下观察：
- en: '![](assets/319a0a26-74e5-4319-9eff-7b0e7dea8bef.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/319a0a26-74e5-4319-9eff-7b0e7dea8bef.jpg)'
- en: 'When we subtract the quantities *ac* and *bd,* which we have calculated in
    the previous recursive step, we get the quantity we need, namely (*ad* + *bc*):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们减去我们在上一个递归步骤中计算的*ac*和*bd*时，我们得到我们需要的数量，即(*ad* + *bc*)：
- en: '![](assets/03bddaec-240b-473a-a996-0718fc542efd.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/03bddaec-240b-473a-a996-0718fc542efd.jpg)'
- en: 'This shows that we can indeed compute the sum of *ad + bc* without separately
    computing each of the individual quantities. In summary, we can improve on equation
    3.1 by reducing from four recursive steps to three. These three steps are as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们确实可以计算*ad + bc*的和，而无需单独计算每个单独的数量。总之，我们可以通过将递归步骤从四步减少到三步来改进方程3.1。这三个步骤如下：
- en: Recursively calculate *ac.*
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归计算*ac*。
- en: Recursively calculate *bd.*
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归计算*bd*。
- en: Recursively calculate (*a* +*b*)(*c* + *d*) and subtract *ac* and *bd.*
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归计算(*a* +*b*)(*c* + *d*)并减去*ac*和*bd*。
- en: 'The following example shows a Python implementation of the Karatsuba algorithm:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了卡拉茨巴算法的Python实现：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To satisfy ourselves that this does indeed work, we can run the following test
    function:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保这确实有效，我们可以运行以下测试函数：
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Runtime analysis
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行时间分析
- en: It should be becoming clear that an important aspect to algorithm design is
    gauging the efficiency both in terms of space (memory) and time (number of operations).
    This second measure, called runtime performance, is the subject of this section.
    It should be mentioned that an identical metric is used to measure an algorithm's
    memory performance. There are a number of ways we could, conceivably, measure
    run time and probably the most obvious is simply to measure the time the algorithm
    takes to complete. The major problem with this approach is that the time it takes
    for an algorithm to run is very much dependent on the hardware it is run on. A
    platform-independent way to gauge an algorithm's runtime is to count the number
    of operations involved. However, this is also problematic in that there is no
    definitive way to quantify an operation. This is dependent on the programming
    language, the coding style, and how we decide to count operations. We can use
    this idea, though, of counting operations, if we combine it with the expectation
    that as the size of the input increases the runtime will increase in a specific
    way. That is, there is a mathematical relationship between *n*, the size of the
    input, and the time it takes for the algorithm to run.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，算法设计的一个重要方面是评估效率，无论是在空间（内存）还是时间（操作次数）方面。第二个度量，称为运行性能，是本节的主题。值得一提的是，用于衡量算法内存性能的度量标准与此相同。我们可以以多种方式衡量运行时间，最明显的可能是简单地测量算法完成所需的时间。这种方法的主要问题在于算法运行所需的时间很大程度上取决于其运行的硬件。衡量算法运行时间的一个与平台无关的方法是计算所涉及的操作次数。然而，这也存在问题，因为没有明确的方法来量化一个操作。这取决于编程语言、编码风格以及我们决定如何计算操作。然而，如果我们将这种计算操作的想法与一个期望相结合，即随着输入规模的增加，运行时间将以特定方式增加，那么我们就可以使用这个想法。也就是说，输入规模*n*与算法运行时间之间存在数学关系。
- en: 'Much of the discussion that follows will be framed by the following three guiding
    principles. The rational and importance of these principles should become clearer
    as we proceed. These principles are as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的讨论大部分将围绕以下三个指导原则展开。随着我们的进行，这些原则的合理性和重要性将变得更加清晰。这些原则如下：
- en: Worst case analysis. Make no assumptions on the input data.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最坏情况分析。不对输入数据做任何假设。
- en: Ignore or suppress constant factors and lower order terms. At large inputs higher
    order terms dominate.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 忽略或抑制常数因子和低阶项。在大输入中，高阶项占主导地位。
- en: Focus on problems with large input sizes.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关注输入规模较大的问题。
- en: Worst case analysis is useful because it gives us a tight upper bound that our
    algorithm is guaranteed not to exceed. Ignoring small constant factors, and lower
    order terms is really just about ignoring the things that, at large values of
    the input size, *n*, do not contribute, in a large degree, to the overall run
    time. Not only does it make our work mathematically easier, it also allows us
    to focus on the things that are having the most impact on performance.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最坏情况分析是有用的，因为它给出了我们算法保证不会超过的严格上界。忽略小的常数因子和低阶项实际上就是忽略那些在输入大小*n*的大值时并不对总运行时间有很大贡献的事物。这不仅使我们的工作在数学上更容易，也使我们能够专注于对性能影响最大的事物。
- en: We saw with the Karatsuba algorithm that the number of multiplication operations
    increased to the square of the size, *n*, of the input. If we have a four-digit
    number the number of multiplication operations is 16; an eight-digit number requires
    64 operations. Typically, though, we are not really interested in the behavior
    of an algorithm at small values of *n*, so we most often ignore factors that increase
    at slower rates, say linearly with *n*. This is because at high values of *n*,
    the operations that increase the fastest as we increase *n*, will dominate.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Karatsuba算法中看到，乘法操作的数量增加到了输入大小*n*的平方。如果我们有一个四位数，乘法操作的数量是16；一个八位数需要64次操作。通常，我们并不真正关心算法在*n*的小值上的行为，所以我们通常忽略那些随着*n*线性增长的因素。这是因为在较大的*n*值上，随着*n*的增加，增长最快的操作将占主导地位。
- en: We will explain this in more detail with an example, the merge sort algorithm.
    Sorting is the subject of [Chapter 13](40b124ee-3b32-4a76-9524-463dbe813217.xhtml),
    *Sorting*, however, as a precursor and as a useful way to learn about runtime
    performance, we will introduce merge sort here.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个例子，归并排序算法，更详细地解释这一点。排序是[第13章](40b124ee-3b32-4a76-9524-463dbe813217.xhtml)的主题，*排序*，然而，作为一个前导和了解运行时性能的有用方式，我们将在这里介绍归并排序。
- en: The merge sort algorithm is a classic algorithm developed over 60 years ago.
    It is still used widely in many of the most popular sorting libraries. It is relatively
    simple and efficient. It is a recursive algorithm that uses a divide and conquer
    approach. This involves breaking the problem into smaller sub problems, recursively
    solving them, and then somehow combining the results. Merge sort is one of the
    most obvious demonstrations of the divide and conquer paradigm.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序算法是一个经典的算法，已经发展了60多年。它仍然广泛应用于许多最流行的排序库中。它相对简单而高效。它是一个使用分治法的递归算法。这涉及将问题分解为更小的子问题，递归地解决它们，然后以某种方式将结果合并。归并排序是分治范式的最明显的演示之一。
- en: 'The merge sort algorithm consists of three simple steps:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序算法由三个简单的步骤组成：
- en: Recursively sort the left half of the input array.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归地对输入数组的左半部分进行排序。
- en: Recursively sort the right half of the input array.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归地对输入数组的右半部分进行排序。
- en: Merge two sorted sub arrays into one.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两个排序好的子数组合并成一个。
- en: 'A typical problem is sorting a list of numbers into a numerical order. Merge
    sort works by splitting the input into two halves and working on each half in
    parallel. We can illustrate this process schematically with the following diagram:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的问题是将一组数字按数字顺序排序。归并排序通过将输入分成两半并同时处理每一半来工作。我们可以用以下图表来形象地说明这个过程：
- en: '![](assets/250a5ae4-7c53-4800-9d19-06c6c7f8dc5c.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/250a5ae4-7c53-4800-9d19-06c6c7f8dc5c.png)'
- en: 'Here is the Python code for the merge sort algorithm:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是归并排序算法的Python代码：
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We run this program for the following results:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们运行这个程序得到以下结果：
- en: '![](assets/038ce698-89ab-4d99-82b2-ac75765f7e84.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/038ce698-89ab-4d99-82b2-ac75765f7e84.png)'
- en: The problem that we are interested in is how we determine the running time performance,
    that is, what is the rate of growth in the time it takes for the algorithm to
    complete relative to the size of *n*. To understand this a bit better, we can
    map each recursive call onto a tree structure.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的问题是如何确定运行时间性能，也就是说，算法完成所需的时间与*n*的大小相关的增长率是多少。为了更好地理解这一点，我们可以将每个递归调用映射到一个树结构上。
- en: 'Each node in the tree is a recursive call working on progressively smaller
    sub problems:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 树中的每个节点都是一个递归调用，处理逐渐变小的子问题：
- en: '![](assets/bdb1209e-db62-4741-8468-d4809f3d0f48.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bdb1209e-db62-4741-8468-d4809f3d0f48.png)'
- en: Each invocation of merge-sort subsequently creates two recursive calls, so we
    can represent this with a binary tree. Each of the child nodes receives a sub
    set of the input. Ultimately we want to know the total time it takes for the algorithm
    to complete relative to the size of *n*. To begin with we can calculate the amount
    of work and the number of operations at each level of the tree.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 每次调用归并排序都会随后创建两个递归调用，因此我们可以用二叉树表示这一点。每个子节点都接收输入的一个子集。最终，我们想知道算法完成所需的总时间与*n*的大小相关。首先，我们可以计算树的每一层的工作量和操作数量。
- en: Focusing on the runtime analysis, at level 1, the problem is split into two
    *n*/2 sub problems, at level 2 there is four *n*/4 sub problems, and so on. The
    question is when does the recursion bottom out, that is, when does it reach its
    base case. This is simply when the array is either zero or one.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 关注运行时分析，在第1层，问题被分成两个*n*/2的子问题，在第2层，有四个*n*/4的子问题，依此类推。问题是递归何时结束，也就是说，何时达到基本情况。这只是当数组要么是零要么是一时。
- en: The number of recursive levels is exactly the number of times you need to divide
    *n* by 2 until you get a number that is at most 1\. This is precisely the definition
    of log2\. Since we are counting the initial recursive call as level 0, the total
    number of levels is log[2]*n* + 1.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 递归级别的数量正好是你需要将*n*除以2的次数，直到得到最多为1的数字。这恰好是log2的定义。由于我们将初始递归调用计为级别0，总级别数是log[2]*n*
    + 1。
- en: Let's just pause to refine our definitions. So far we have been describing the
    number of elements in our input by the letter *n*. This refers to the number of
    elements in the first level of the recursion, that is, the length of the initial
    input. We are going to need to differentiate between the size of the input at
    subsequent recursive levels. For this we will use the letter *m* or specifically
    *m[j]* for the length of the input at recursive level *j.*
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂停一下，重新定义一下。到目前为止，我们一直用字母*n*来描述输入中的元素数量。这指的是递归的第一级中元素的数量，也就是初始输入的长度。我们需要区分后续递归级别的输入大小。为此，我们将使用字母*m*或者特定的*m[j]*来表示递归级别*j*的输入长度。
- en: Also there are a few details we have overlooked, and I am sure you are beginning
    to wonder about. For example, what happens when *m*/2 is not an integer, or when
    we have duplicates in our input array. It turns out that this does not have an
    important impact on our analysis here.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些细节我们忽略了，我相信你也开始好奇了。例如，当*m*/2不是整数时会发生什么，或者当我们的输入数组中有重复元素时会发生什么。事实证明，这对我们的分析没有重要影响。
- en: The advantage of using a recursion tree to analyze algorithms is that we can
    calculate the work done at each level of the recursion. How to define this work
    is simply as the total number of operations and this of course is related to the
    size of the input. It is important to measure and compare the performance of algorithms
    in a platform independent way. The actual run time will of course be dependent
    on the hardware on which it is run. Counting the number of operations is important
    because it gives us a metric that is directly related to an algorithm's performance,
    independent of the platform.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用递归树来分析算法的优势在于我们可以计算每个递归级别的工作量。定义这个工作量就是操作的总数，这当然与输入的大小有关。以平台无关的方式来衡量和比较算法的性能是很重要的。实际运行时间当然取决于运行的硬件。计算操作次数很重要，因为它给了我们一个与算法性能直接相关的度量标准，与平台无关。
- en: 'In general, since each invocation of merge sort is making two recursive calls,
    the number of calls is doubling at each level. At the same time each of these
    calls is working on an input that is half of its parents. We can formalize this
    and say that:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，由于归并排序的每次调用都会进行两次递归调用，调用次数在每个级别都会翻倍。同时，每次调用都会处理其父级别大小一半的输入。我们可以形式化地表达为：
- en: For level j , where *j* is an integer 0, 1, 2 ... log[2]*n*, there are two ^j
    sub problems each of size *n*/2^j.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于级别*j*，其中*j*是整数0、1、2... log[2]*n*，每个大小为*n*/2^j的子问题有2^j个。
- en: To calculate the total number of operations, we need to know the number of operations
    encompassed by a single merge of two sub arrays. Let's count the number of operations
    in the previous Python code. What we are interested in is all the code after the
    two recursive calls have been made. Firstly, we have the three assignment operations.
    This is followed by three while loops. In the first loop we have an if else statement
    and within each of are two operations, a comparison followed by an assignment.
    Since there are only one of these sets of operations within the if else statements,
    we can count this block of code as two operations carried out *m* times. This
    is followed by two while loops with an assignment operation each. This makes a
    total of 4*m* + 3 operations for each recursion of merge sort.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算总操作次数，我们需要知道单个合并两个子数组所包含的操作次数。让我们来数一下之前Python代码中的操作次数。我们感兴趣的是在进行两次递归调用后的所有代码。首先，我们有三个赋值操作。然后是三个while循环。在第一个循环中，我们有一个if
    else语句，每个if else语句中有两个操作，一个比较，一个赋值。由于在if else语句中只有一个这样的操作集，我们可以将这段代码计为每次递归执行2次。接下来是两个while循环，每个有一个赋值操作。这使得每次归并排序递归的总操作次数为4*m*
    + 3。
- en: Since *m* must be at least 1, the upper bound for the number of operations is
    7*m*. It has to be said that this has no pretense at being an exact number. We
    could of course decide to count operations in a different way. We have not counted
    the increment operations or any of the housekeeping operations; however, this
    is not so important as we are more concerned with the rate of growth of the runtime
    with respect to *n* at high values of *n*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*m*至少为1，操作次数的上限为7*m*。必须指出，这并不是一个精确的数字。当然，我们可以决定以不同的方式计算操作次数。我们没有计算增量操作或任何维护操作；然而，在*n*的高值时，我们更关心运行时间的增长速度。
- en: This may seem a little daunting since each call of a recursive call itself spins
    off more recursive calls, and seemingly explodes exponentially. The key fact that
    makes this manageable is that as the number of recursive calls doubles, the size
    of each sub problem halves. These two opposing forces cancel out nicely as we
    can demonstrate.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来有点令人生畏，因为每次递归调用本身都会产生更多的递归调用，似乎呈指数级增长。使这个问题可控的关键事实是，随着递归调用次数翻倍，每个子问题的大小减半。这两股相反的力量会很好地抵消，我们可以证明这一点。
- en: 'To calculate the maximum number of operations at each level of the recursion
    tree we simply multiply the number of sub problems by the number of operations
    in each sub problem as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算递归树每个级别的最大操作次数，我们只需将子问题的数量乘以每个子问题中的操作次数，如下所示：
- en: '![](assets/a6d82944-b30f-4e9c-b46e-9e467765e528.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: （图片）
- en: Importantly this shows that, because the 2^j cancels out the number of operations
    at each level is independent of the level. This gives us an upper bound to the
    number of operations carried out on each level, in this example, 7*n*. It should
    be pointed out that this includes the number of operations performed by each recursive
    call on that level, not the recursive calls made on subsequent levels. This shows
    that the work done, as the number of recursive calls doubles with each level,
    is exactly counter balanced by the fact that the input size for each sub problem
    is halved.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，这表明，因为2^j取消了每个级别上的操作数，所以每个级别上的操作数与级别无关。这给我们每个级别上执行的操作数的上限，例如，在这个例子中，是7*n*。应该指出，这包括该级别上每个递归调用执行的操作数，而不是在后续级别上进行的递归调用。这表明，随着每个级别的递归调用数量翻倍，所做的工作正好被每个子问题的输入大小减半所抵消。
- en: 'To find the total number of operations for a complete merge sort we simply
    multiply the number of operations on each level by the number of levels. This
    gives us the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到完整归并排序的总操作数，我们只需将每个级别上的操作数乘以级别数。这给我们以下结果：
- en: '![](assets/ac440c24-f7c5-48a7-a083-75d67cff8b8f.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ac440c24-f7c5-48a7-a083-75d67cff8b8f.jpg)'
- en: 'When we expand this out, we get the following:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们展开这个式子时，我们得到以下结果：
- en: '![](assets/d4c151e6-ea4e-4fb6-804c-648353a68837.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d4c151e6-ea4e-4fb6-804c-648353a68837.jpg)'
- en: 'The key point to take from this is that there is a logarithmic component to
    the relationship between the size of the input and the total running time. If
    you remember from school mathematics, the distinguishing characteristic of the
    logarithm function is that it flattens off very quickly. As an input variable,
    *x*, increases in size, the output variable, *y* increases by smaller and smaller
    amounts. For example, compare the log function to a linear function:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从中要得出的关键点是，输入大小和总运行时间之间存在对数关系。如果您还记得学校数学，对数函数的显著特征是它非常快地变平。作为输入变量，*x*增大，输出变量*y*增加的幅度越来越小。例如，将对数函数与线性函数进行比较：
- en: '![](assets/983df66e-1889-4df2-98ba-d00d8853a7c0.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/983df66e-1889-4df2-98ba-d00d8853a7c0.png)'
- en: In the previous example, multiplying the *n*log[2]*n* component and comparing
    it to *n*² .
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，将*n*log[2]*n*组件与*n*²进行比较。
- en: '![](assets/0c0197f3-2cd7-4b71-91f8-c4bb4a4f5f8c.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/0c0197f3-2cd7-4b71-91f8-c4bb4a4f5f8c.png)'
- en: Notice how for very low values of *n*, the time to complete, *t* , is actually
    lower for an algorithm that runs in n² time. However, for values above about 40,
    the log function begins to dominate, flattening the output until at the comparatively
    moderate size *n* = 100, the performance is more than twice than that of an algorithm
    running in *n*² time. Notice also that the disappearance of the constant factor,
    + 7 is irrelevant at high values of *n*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，对于非常小的*n*值，完成时间*t*实际上比运行时间为n²的算法更短。然而，对于大约40以上的值，对数函数开始占主导地位，使输出变平，直到在相对适中的大小*n*=100时，性能比运行时间为n²的算法高出两倍以上。还要注意，在高*n*值时，常数因子+7的消失是无关紧要的。
- en: 'The code used to generate these graphs is as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 生成这些图表所使用的代码如下：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You will need to install the matplotlib library, if it is not installed already,
    for this to work. Details can be found at the following address; I encourage you
    to experiment with this list comprehension expression used to generate the plots.
    For example, adding the following plot statement:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尚未安装matplotlib库，您需要安装它才能运行。有关详细信息，请访问以下地址；我鼓励您尝试使用列表推导式表达式来生成图表。例如，添加以下绘图语句：
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Gives the following output:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 得到以下输出：
- en: '![](assets/4129159f-5b74-4138-94d0-02abb037cc78.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4129159f-5b74-4138-94d0-02abb037cc78.png)'
- en: The preceding graph shows the difference between counting six operations or
    seven operations. We can see how the two cases diverge, and this is important
    when we are talking about the specifics of an application. However, what we are
    more interested in here is a way to characterize growth rates. We are not so much
    concerned with the absolute values, but how these values change as we increase
    *n*. In this way we can see that the two lower curves have similar growth rates,
    when compared to the top (*x*²) curve. We say that these two lower curves have
    the same **complexity class**. This is a way to understand and describe different
    runtime behaviors. We will formalize this performance metric in the next section.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表显示了计算六次操作或七次操作之间的差异。我们可以看到这两种情况是如何分歧的，这在谈论应用程序的具体情况时很重要。然而，我们在这里更感兴趣的是一种表征增长率的方法。我们更关心的不是绝对值，而是这些值随着*n*的增加而变化的方式。通过这种方式，我们可以看到这两条较低的曲线具有相似的增长率，与顶部（*x*²）曲线相比。我们说这两条较低的曲线具有相同的**复杂度类**。这是一种理解和描述不同运行时行为的方法。我们将在下一节正式化这个性能指标。
- en: Asymptotic analysis
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 渐近分析
- en: 'There are essentially three things that characterize an algorithm''s runtime
    performance. They are:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上有三个特征来表征算法的运行时间性能。它们是：
- en: Worst case - Use an input that gives the slowest performance
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最坏情况 - 使用能够获得最慢性能的输入
- en: Best case - Use an input that give, the best results
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳情况 - 使用能够给出最佳结果的输入
- en: Average case - Assumes the input is random
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均情况 - 假设输入是随机的
- en: To calculate each of these, we need to know the upper and lower bounds. We have
    seen a way to represent an algorithm's runtime using mathematical expressions,
    essentially adding and multiplying operations. To use asymptotic analyses, we
    simply create two expressions, one each for the best and worst cases.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算这些，我们需要知道上限和下限。我们已经看到了用数学表达式来表示算法的运行时间的方法，基本上是加法和乘法运算。要使用渐近分析，我们只需创建两个表达式，一个用于最佳情况，一个用于最坏情况。
- en: Big O notation
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大O符号
- en: 'The letter "O" in big *O* notation stands for order, in recognition that rates
    of growth are defined as the order of a function. We say that one function *T*(*n*)
    is a big O of another function, *F*(*n*), and we define this as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 大O符号中的字母“O”代表顺序，以承认增长速度被定义为函数的顺序。我们说一个函数*T*(*n*)是另一个函数*F*(*n*)的大O，我们将其定义如下：
- en: '![](assets/4b0a93a3-4b55-4fd3-8226-64d255fca9cc.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4b0a93a3-4b55-4fd3-8226-64d255fca9cc.jpg)'
- en: 'The function, *g*(*n*), of the input size, *n*, is based on the observation
    that for all sufficiently large values of *n*, *g*(*n*) is bounded above by a
    constant multiple of *f*(*n*). The objective is to find the smallest rate of growth
    that is less than or equal to *f*(*n*). We only care what happens at higher values
    of *n*. The variable *n[0]*represents the threshold below which the rate of growth
    is not important, The function T(n) represents the **tight upper bound** F(n).
    In the following plot we see that *T*(*n*) = *n²* + 500 = *O*(*n²*) with *C* =
    2 and *n[0]* is approximately 23:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 输入大小*n*的函数*g*(*n*)基于这样的观察：对于所有足够大的*n*值，*g*(*n*)都受到*F*(*n*)的常数倍的上界限制。目标是找到小于或等于*F*(*n*)的增长速度。我们只关心*n*的较高值发生了什么。变量*n[0]*表示增长速度不重要的阈值。函数T(n)表示**紧密上界**F(n)。在下图中，我们看到*T*(*n*)
    = *n²* + 500 = *O*(*n²*)，其中*C* = 2，*n[0]*约为23：
- en: '![](assets/6ba4595b-ba4b-4157-9a3f-632eaa3e382a.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6ba4595b-ba4b-4157-9a3f-632eaa3e382a.png)'
- en: You will also see the notation *f*(*n*) = *O*(*g*(*n*)). This describes the
    fact that *O*(*g*(*n*)) is really a set of functions that include all functions
    with the same or smaller rates of growth than *f*(n). For example, *O*(*n²*) also
    includes the functions *O*(*n*), *O*(*n*log*n*), and so on.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 您还会看到符号*f*(*n*) = *O*(*g*(*n*)）。这描述了*O*(*g*(*n*)）实际上是一个包含所有增长速度与*f*(*n*)相同或更小的函数的集合。例如，*O*(*n²*)也包括函数*O*(*n*)，*O*(*n*log*n*），等等。
- en: 'In the following table, we list the most common growth rates in order from
    lowest to highest. We sometimes call these growth rates the **time complexity**
    of a function, or the complexity class of a function:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，我们按从最低到最高的顺序列出了最常见的增长率。我们有时称这些增长率为函数的**时间复杂度**，或者函数的复杂度类：
- en: '| **Complexity Class** | **Name** | **Example operations** |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| **复杂度类** | **名称** | **示例操作** |'
- en: '| O(1) | Constant | append, get item, set item. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| O(1) | 常数 | 追加，获取项目，设置项目。 |'
- en: '| O(log*n*) | Logarithmic | Finding an element in a sorted array. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| O(log*n*) | 对数 | 在排序数组中查找元素。 |'
- en: '| O(n) | Linear | copy, insert, delete, iteration. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| O(n) | 线性 | 复制，插入，删除，迭代。 |'
- en: '| *n*Log*n* | Linear-Logarithmic | Sort a list, merge - sort. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| *n*Log*n* | 线性对数 | 对列表进行排序，合并 - 排序。 |'
- en: '| *n²* | Quadratic | Find the shortest path between two nodes in a graph. Nested
    loops. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| *n²* | 二次 | 在图中找到两个节点之间的最短路径。嵌套循环。 |'
- en: '| *n³* | Cubic | Matrix multiplication. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| *n³* | 立方 | 矩阵乘法。 |'
- en: '| 2*^n* | Exponential | ''Towers of Hanoi'' problem, backtracking. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 2*^n* | 指数 | ''汉诺塔''问题，回溯。 |'
- en: Composing complexity classes
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组合复杂度类
- en: Normally, we need to find the total running time of a number of basic operations.
    It turns out that we can combine the complexity classes of simple operations to
    find the complexity class of more complex, combined operations. The goal is to
    analyze the combined statements in a function or method to understand the total
    time complexity of executing several operations. The simplest way to combine two
    complexity classes is to add them. This occurs when we have two sequential operations.
    For example, consider the two operations of inserting an element into a list and
    then sorting that list. We can see that inserting an item occurs in O(*n*) time
    and sorting is O(*n*log*n*) time. We can write the total time complexity as O(*n*
    + *n*log*n*), that is, we bring the two functions inside the O(...). We are only
    interested in the highest order term, so this leaves us with just O(*n*log*n*).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们需要找到一系列基本操作的总运行时间。事实证明，我们可以将简单操作的复杂度类组合起来，以找到更复杂的组合操作的复杂度类。目标是分析函数或方法中的组合语句，以了解执行多个操作的总时间复杂度。组合两个复杂度类的最简单方法是将它们相加。这发生在我们有两个连续的操作时。例如，考虑将元素插入列表，然后对该列表进行排序的两个操作。我们可以看到插入一个项目需要O(*n*)时间，排序需要O(*n*log*n*)时间。我们可以将总时间复杂度写为O(*n*
    + *n*log*n*)，也就是说，我们将两个函数放在O(...)中。我们只关心最高阶项，因此这让我们只剩下O(*n*log*n*)。
- en: 'If we repeat an operation, for example, in a while loop, then we multiply the
    complexity class by the number of times the operation is carried out. If an operation
    with time complexity O(*f*(*n*)) is repeated O(*n*) times then we multiply the
    two complexities:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们重复一个操作，例如在while循环中，那么我们将复杂度类乘以操作执行的次数。如果一个时间复杂度为O(*f*(*n*))的操作重复执行O(*n*)次，那么我们将这两个复杂度相乘：
- en: O(*f*(*n*) * O(*n*)) = O(*nf*(*n*)).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: O(*f*(*n*) * O(*n*)) = O(*nf*(*n*)）。
- en: 'For example, suppose the function f(...) has a time complexity of O(*n*²) and
    it is executed *n* times in a while loop as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设函数f(...)的时间复杂度为O(*n*²)，并且在while循环中执行*n*次，如下所示：
- en: '[PRE7]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The time complexity of this loop then becomes O(*n*²) * O(*n*) = O(*n * n²*)
    = O(*n³*). Here we are simply multiplying the time complexity of the operation
    with the number of times this operation executes. The running time of a loop is
    at most the running time of the statements inside the loop multiplied by the number
    of iterations. A single nested loop, that is, one loop nested inside another loop,
    will run in *n*² time assuming both loops run *n* times. For example:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这个循环的时间复杂度变成了O(*n*²) * O(*n*) = O(*n * n²*) = O(*n³*）。在这里，我们只是将操作的时间复杂度乘以这个操作执行的次数。循环的运行时间最多是循环内语句的运行时间乘以迭代次数。一个单独的嵌套循环，也就是一个循环嵌套在另一个循环中，假设两个循环都运行*n*次，那么运行时间就是*n*²。例如：
- en: '[PRE8]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Each statement is a constant, c, executed *n**n* times, so we can express the
    running time as ; *c**n* *n* = *cn*² = O(*n*2).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 每个语句是一个常数c，执行*n**n*次，因此我们可以将运行时间表示为；*c**n* *n* = *cn*² = O(*n*2）。
- en: 'For consecutive statements within nested loops we add the time complexities
    of each statement and multiply by the number of times the statement executed.
    For example:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于嵌套循环中的连续语句，我们将每个语句的时间复杂度相加，并乘以语句执行的次数。例如：
- en: '[PRE9]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This can be written as *c*[0] +*c*[1]*n* + *cn*² = O(*n*²).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以写成*c*[0] +*c*[1]*n* + *cn*² = O(*n*²)。
- en: 'We can define (base 2) logarithmic complexity, reducing the size of the problem
    by ½, in constant time. For example, consider the following snippet:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义（以2为底）对数复杂度，将问题的大小减少一半，所需的时间是常数。例如，考虑以下代码片段：
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Notice that `i` is doubling on each iteration, if we run this with *n* = 10
    we see that it prints out four numbers; 2, 4, 8, and 16\. If we double *n* we
    see it prints out five numbers. With each subsequent doubling of n the number
    of iterations is only increased by 1\. If we assume *k* iterations, we can write
    this as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`i`在每次迭代中都会加倍，如果我们以*n*=10运行这个程序，我们会看到它打印出四个数字；2、4、8和16。如果我们将*n*加倍，我们会看到它打印出五个数字。随着*n*的每次加倍，迭代次数只增加了1。如果我们假设*k*次迭代，我们可以写成如下：
- en: '![](assets/e7efcb8e-d08f-4c5c-8ba8-ff765a96cdbf.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e7efcb8e-d08f-4c5c-8ba8-ff765a96cdbf.png)'
- en: From this we can conclude that the total time = **O**(*log(n)*).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 由此我们可以得出总时间 = **O**(*log(n)*)。
- en: Although Big O is the most used notation involved in asymptotic analysis, there
    are two other related notations that should be briefly mentioned. They are Omega
    notation and Theta notation.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大O是渐近分析中最常用的符号，但还有两个相关的符号应该简要提到。它们是Omega符号和Theta符号。
- en: Omega notation (Ω)
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Omega符号（Ω）
- en: 'In a similar way that Big O notation describes the upper bound, Omega notation
    describes a **tight lower bound**. The definition is as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 大O符号描述了上界的情况，Omega符号描述了**紧密的下界**。定义如下：
- en: '![](assets/0be56dbf-c79b-4d73-b1f6-7b1411bb36f6.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/0be56dbf-c79b-4d73-b1f6-7b1411bb36f6.png)'
- en: The objective is to give the largest rate of growth that is equal to or less
    than the given algorithms, T(*n*), rate of growth.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是找到与给定算法T(*n*)的增长率相等或小于的最大增长率。
- en: Theta notation (ϴ)
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Theta符号（ϴ）
- en: 'It is often the case where both the upper and lower bounds of a given function
    are the same and the purpose of Theta notation is to determine if this is the
    case. The definition is as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，给定函数的上界和下界是相同的，Theta符号的目的就是确定这种情况是否存在。定义如下：
- en: '![](assets/1da75a4c-29dc-4ab9-a25e-ae5b5209db08.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/1da75a4c-29dc-4ab9-a25e-ae5b5209db08.png)'
- en: Although Omega and Theta notations are required to completely describe growth
    rates, the most practically useful is Big O notation and this is the one you will
    see most often.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Omega和Theta符号需要完全描述增长率，但最实用的是大O符号，这是你经常会看到的。
- en: Amortized analysis
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摊销分析
- en: Often we are not so interested in the time complexity of individual operations,
    but rather the time averaged running time of sequences of operations. This is
    called amortized analysis. It is different from average case analysis, which we
    will discuss shortly, in that it makes no assumptions regarding the data distribution
    of input values. It does, however, take into account the state change of data
    structures. For example, if a list is sorted it should make any subsequent find
    operations quicker. Amortized analysis can take into account the state change
    of data structures because it analyzes sequences of operations, rather then simply
    aggregating single operations.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们对单个操作的时间复杂度不太感兴趣，而是更关注操作序列的平均运行时间。这被称为摊销分析。它与平均情况分析不同，我们很快会讨论，因为它不对输入值的数据分布做任何假设。但是，它考虑了数据结构的状态变化。例如，如果列表已排序，则任何后续查找操作都应该更快。摊销分析可以考虑数据结构的状态变化，因为它分析操作序列，而不仅仅是聚合单个操作。
- en: Amortized analysis finds an upper bound on runtime by imposing an artificial
    cost on each operation in a sequence of operations, and then combining each of
    these costs. The artificial cost of a sequence takes in to account that the initial
    expensive operations can make subsequent operations cheaper.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 摊销分析通过对操作序列中的每个操作施加人为成本，然后组合这些成本，找到运行时间的上界。序列的人为成本考虑到初始昂贵的操作可能使后续操作变得更便宜。
- en: When we have a small number of expensive operations, such as sorting, and lots
    of cheaper operations such as lookups, standard worst case analysis can lead to
    overly pessimistic results, since it assumes that each lookup must compare each
    element in the list until a match is found. We should take into account that once
    we sort the list we can make subsequent find operations cheaper.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有少量昂贵的操作，比如排序，和大量更便宜的操作，比如查找时，标准的最坏情况分析可能导致过于悲观的结果，因为它假设每次查找都必须比较列表中的每个元素直到找到匹配项。我们应该考虑到一旦我们对列表进行排序，我们可以使后续的查找操作变得更便宜。
- en: 'So far in our runtime analysis we have assumed that the input data was completely
    random and have only looked at the effect the size of the input has on the runtime.
    There are two other common approaches to algorithm analysis; they are:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在我们的运行时间分析中，我们假设输入数据是完全随机的，并且只关注输入大小对运行时间的影响。算法分析还有另外两种常见的方法：
- en: Average case analysis
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均情况分析
- en: Benchmarking
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试
- en: Average case analysis finds the average running time based on some assumptions
    regarding the relative frequencies of various input values. Using real-world data,
    or data that replicates the distribution of real-world data, is many times on
    a particular data distribution and the average running time is calculated.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 平均情况分析根据对各种输入值的相对频率的一些假设，找到平均运行时间。使用真实世界的数据，或者模拟真实世界数据的分布，往往是基于特定数据分布的，然后计算平均运行时间。
- en: Benchmarking is simply having an agreed set of typical inputs that are used
    to measure performance. Both benchmarking and average time analysis rely on having
    some domain knowledge. We need to know what the typical or expected datasets are.
    Ultimately we will try to find ways to improve performance by fine-tuning to a
    very specific application setting.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试就是有一组约定的典型输入，用于衡量性能。基准测试和平均时间分析都依赖于一些领域知识。我们需要知道典型或预期的数据集是什么。最终，我们将尝试通过微调到一个非常具体的应用设置来改善性能。
- en: Let's look at a straightforward way to benchmark an algorithm's runtime performance.
    This can be done by simply timing how long the algorithm takes to complete given
    various input sizes. As we mentioned earlier, this way of measuring runtime performance
    is dependent on the hardware that it is run on. Obviously faster processors will
    give better results, however, the relative growth rates as we increase the input
    size will retain characteristics of the algorithm itself rather than the hardware
    it is run on. The absolute time values will differ between hardware (and software)
    platforms; however, their relative growth will still be bound by the time complexity
    of the algorithm.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一种简单的方法来衡量算法的运行时间性能。这可以通过简单地计算算法在不同输入大小下完成所需的时间来实现。正如我们之前提到的，这种衡量运行时间性能的方式取决于它运行的硬件。显然，更快的处理器会给出更好的结果，然而，随着输入大小的增加，它们的相对增长率仍将保留算法本身的特征，而不是它运行的硬件。绝对时间值会因硬件（和软件）平台的不同而有所不同；然而，它们的相对增长仍将受到算法的时间复杂度的限制。
- en: 'Let''s take a simple example of a nested loop. It should be fairly obvious
    that the time complexity of this algorithm is O(n²) since for each n iterations
    in the outer loop there are also n iterations in the inter loop. For example,
    our simple nested for loop consists of a simple statement executed on the inner
    loop:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个嵌套循环的简单例子来说明。很明显，这个算法的时间复杂度是O(n²)，因为在外部循环的每n次迭代中，内部循环也有n次迭代。例如，我们简单的嵌套for循环由内部循环上执行的简单语句组成：
- en: '[PRE11]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following code is a simple test function that runs the nest function with
    increasing values of `n`. With each iteration we calculate the time this function
    takes to complete using the `timeit.timeit` function. The `timeit` function, in
    this example, takes three arguments, a string representation of the function to
    be timed, a setup function that imports the nest function, and an `int` parameter
    that indicates the number of times to execute the main statement. Since we are
    interested in the time the nest function takes to complete relative to the input
    size, `n`, it is sufficient, for our purposes, to call the nest function once
    on each iteration. The following function returns a list of the calculated runtimes
    for each value of n:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是一个简单的测试函数，它使用不断增加的`n`值运行嵌套函数。在每次迭代中，我们使用`timeit.timeit`函数计算该函数完成所需的时间。在这个例子中，`timeit`函数接受三个参数，一个表示要计时的函数的字符串表示，一个导入嵌套函数的设置函数，以及一个`int`参数，表示执行主语句的次数。由于我们对嵌套函数完成所需的时间相对于输入大小`n`感兴趣，因此对于我们的目的来说，在每次迭代中调用一次嵌套函数就足够了。以下函数返回每个n值的计算运行时间的列表：
- en: '[PRE12]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the following code we run the test2 function and graph the results, together
    with the appropriately scaled n² function for comparison, represented by the dashed
    line:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们运行test2函数并绘制结果，以及适当缩放的n²函数进行比较，用虚线表示：
- en: '[PRE13]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This gives the following results:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下结果：
- en: '![](assets/44c2f6b6-a425-4914-93b4-03030c9acde8.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/44c2f6b6-a425-4914-93b4-03030c9acde8.png)'
- en: As we can see, this gives us pretty much what we expect. It should be remembered
    that this represents both the performance of the algorithm itself as well as the
    behavior of underlying software and hardware platforms, as indicated by both the
    variability in the measured runtime and the relative magnitude of the runtime.
    Obviously a faster processor will result in faster runtimes, and also performance
    will be affected by other running processes, memory constraints, clock speed,
    and so on.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，这基本上符合我们的预期。应该记住，这既代表了算法本身的性能，也代表了底层软件和硬件平台的行为，这一点可以从测量运行时间的变化和运行时间的相对大小看出。显然，更快的处理器会导致更快的运行时间，而性能也会受到其他运行进程、内存限制、时钟速度等的影响。
- en: Summary
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have taken a general overview of algorithm design. Importantly,
    we saw a platform independent way to measure an algorithm's performance. We looked
    at some different approaches to algorithmic problems. We looked at a way to recursively
    multiply large numbers and also a recursive approach for merge sort. We saw how
    to use backtracking for exhaustive search and generating strings. We also introduced
    the idea of benchmarking and a simple platform-dependent way to measure runtime.
    In the following chapters, we will revisit many of these ideas with reference
    to specific data structures. In the next chapter, we will discuss linked lists
    and other pointer structures.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们对算法设计进行了一般概述。重要的是，我们看到了一种平台无关的方法来衡量算法的性能。我们看了一些不同的算法问题解决方法。我们看了一种递归相乘大数的方法，也看了归并排序的递归方法。我们看到了如何使用回溯进行穷举搜索和生成字符串。我们还介绍了基准测试的概念以及衡量运行时间的简单平台相关方法。在接下来的章节中，我们将参考特定的数据结构重新讨论这些想法。在下一章中，我们将讨论链表和其他指针结构。
