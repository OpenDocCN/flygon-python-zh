["```py\nwhile(gradient!=0):\n if (gradient < 0); move right\n if (gradient > 0); move left\n```", "```py\ndef sigmoidFunction(z): \n      return 1/ (1+np.exp(-z))\n```", "```py\ndef ReLU(x): \nif x<0: \n    return 0 \nelse: \n    return x\n```", "```py\ndef leakyReLU(x,beta=0.01):\n    if x<0:\n        return (beta*x)    \n    else:        \n        return x\n```", "```py\ndef tanh(x): \n    numerator = 1-np.exp(-2*x) \n    denominator = 1+np.exp(-2*x) \n    return numerator/denominator\n```", "```py\nimport random\nimport numpy as np\nimport tensorflow as tf\n```", "```py\ndef createTemplate():\n      return tf.keras.models.Sequential([\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.15),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dropout(0.15),\n        tf.keras.layers.Dense(64, activation='relu'), \n        ])\n```", "```py\ndef prepareData(inputs: np.ndarray, labels: np.ndarray):\n      classesNumbers = 10\n      digitalIdx = [np.where(labels == i)[0] for i in range(classesNumbers)]\n      pairs = list()\n      labels = list()\n      n = min([len(digitalIdx[d]) for d in range(classesNumbers)]) - 1\n      for d in range(classesNumbers):\n        for i in range(n):\n            z1, z2 = digitalIdx[d][i], digitalIdx[d][i + 1]\n            pairs += [[inputs[z1], inputs[z2]]]\n            inc = random.randrange(1, classesNumbers)\n            dn = (d + inc) % classesNumbers\n            z1, z2 = digitalIdx[d][i], digitalIdx[dn][i]\n            pairs += [[inputs[z1], inputs[z2]]]\n            labels += [1, 0] \n      return np.array(pairs), np.array(labels, dtype=np.float32)\n```", "```py\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nx_train = x_train.astype(np.float32)\nx_test = x_test.astype(np.float32)\nx_train /= 255\nx_test /= 255\ninput_shape = x_train.shape[1:]\ntrain_pairs, tr_labels = prepareData(x_train, y_train)\ntest_pairs, test_labels = prepareData(x_test, y_test)\n```", "```py\ninput_a = tf.keras.layers.Input(shape=input_shape)\nenconder1 = base_network(input_a)\ninput_b = tf.keras.layers.Input(shape=input_shape)\nenconder2 = base_network(input_b)\n```", "```py\ndistance = tf.keras.layers.Lambda( \n    lambda embeddings: tf.keras.backend.abs(embeddings[0] - embeddings[1])) ([enconder1, enconder2])\nmeasureOfSimilarity = tf.keras.layers.Dense(1, activation='sigmoid') (distance)\n```"]