- en: Implementations, Applications, and Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现、应用和工具
- en: Learning about algorithms without any real-life application remains a purely
    academic pursuit. In this chapter, we will explore the data structures and algorithms
    that are shaping our world.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 学习算法而没有任何现实生活的应用仍然是一种纯粹的学术追求。在本章中，我们将探讨正在塑造我们世界的数据结构和算法。
- en: One of the golden nuggets of this age is the abundance of data. Emails, phone
    numbers, text documents, and images contain large amounts of data. In this data,
    there is valuable information that makes the data more important. But to extract
    this information from the raw data, we have to use data structures, processes,
    and algorithms that specialize in this task.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这个时代的一个黄金机会是数据的丰富。电子邮件、电话号码、文本文档和图像包含大量的数据。在这些数据中，有着使数据更加重要的有价值信息。但是要从原始数据中提取这些信息，我们必须使用专门从事这项任务的数据结构、过程和算法。
- en: Machine learning employs a significant number of algorithms to analyze and predict
    the occurrence of certain variables. Analyzing data on a purely numerical basis
    still leaves much of the latent information buried in the raw data. Presenting
    data visually thus enables one to understand and gain valuable insights too.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习使用大量算法来分析和预测某些变量的发生。仅基于纯数字的数据分析仍然使得许多潜在信息埋藏在原始数据中。因此，通过可视化呈现数据，使人们能够理解并获得有价值的见解。
- en: 'By the end of this chapter, you should be able to do the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您应该能够做到以下几点：
- en: Prune and present data accurately
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确修剪和呈现数据
- en: Use both supervised and unsupervised learning algorithms for the purposes of
    prediction
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了预测，需要同时使用监督学习和无监督学习算法。
- en: Visually represent data in order to gain more insight
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过可视化呈现数据以获得更多见解
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In order to proceed with this chapter, you will need to install the following
    packages. These packages will be used to pre-process and visually represent the
    data being processed. Some of the packages also contain a well-written implementation
    of the algorithms that will operate on our data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了继续本章，您需要安装以下包。这些包将用于对正在处理的数据进行预处理和可视化呈现。其中一些包还包含对我们的数据进行操作的算法的良好实现。
- en: 'Preferably, these modules should be installed using `pip`. So, firstly, we
    need to install pip for Python 3 using the following commands:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最好使用`pip`安装这些模块。因此，首先，我们需要使用以下命令为Python 3安装pip：
- en: '`sudo apt-get update`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sudo apt-get update`'
- en: '`sudo apt-get install python3-pip`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sudo apt-get install python3-pip`'
- en: 'Furthermore, the following commands are to be run to install the `numpy`, `scikit-learn`,
    `matplotlib`, `pandas`, and `textblob` packages:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，需要运行以下命令来安装`numpy`、`scikit-learn`、`matplotlib`、`pandas`和`textblob`包：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you are using the old version of Python (that is, Python 2), the packages
    can be installed using the same commands by replacing `pip3` with `pip`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是旧版本的Python（即Python 2），则可以使用相同的命令来安装这些包，只需将`pip3`替换为`pip`。
- en: 'You are also required to install the `nltk` and `punkt` packages, which provide
    inbuilt text processing functions. To install them, open the Python Terminal and
    run the following commands:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要安装`nltk`和`punkt`包，这些包提供了内置的文本处理功能。要安装它们，请打开Python终端并运行以下命令：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'These packages may require other platform-specific modules to be installed
    first. Take note and install all dependencies:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些包可能需要先安装其他特定于平台的模块。请注意并安装所有依赖项：
- en: '**NumPy**: A library with functions to operate on n-dimensional arrays and
    matrices.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy**：一个具有操作n维数组和矩阵功能的库。'
- en: '**Scikit-learn**: A highly advanced module for machine learning. It contains
    an implementation of many algorithms for classification, regression, and clustering,
    among others.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn**：用于机器学习的高级模块。它包含许多用于分类、回归和聚类等算法的实现。'
- en: '**Matplotlib**: This is a plotting library that makes use of NumPy to graph
    a good variety of charts, including line plots, histograms, scatter plots, and
    even 3D graphs.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**：这是一个绘图库，利用NumPy绘制各种图表，包括折线图、直方图、散点图，甚至3D图表。'
- en: '**Pandas**: This library deals with data manipulation and analysis.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pandas**：这个库处理数据操作和分析。'
- en: The GitHub link is as follows: [https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-3.x-Second-Edition/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-3.x-Second-Edition/tree/master/Chapter14).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub链接如下：[https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-3.x-Second-Edition/tree/master/Chapter14](https://github.com/PacktPublishing/Hands-On-Data-Structures-and-Algorithms-with-Python-3.x-Second-Edition/tree/master/Chapter14)。
- en: Data preprocessing
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: To analyze the data, first of all, we have to preprocess the data to remove
    the noise and convert it in to an appropriate format so that it can be further
    analyzed. A collection of data from the real world is mostly full of noise, which
    makes it difficult to apply any algorithm directly. The raw data collected is
    plagued by a lot of issues so we need to adopt ways to sanitize the data to make
    it suitable for use in further studies.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，要分析数据，我们必须对数据进行预处理，以去除噪音并将其转换为适当的格式，以便进一步分析。来自现实世界的数据集大多充满噪音，这使得直接应用任何算法变得困难。收集到的原始数据存在许多问题，因此我们需要采取方法来清理数据，使其适用于进一步的研究。
- en: Processing raw data
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理原始数据
- en: The data collected may also be inconsistent with other records collected over
    time. The existence of duplicate entries and incomplete records warrant that we
    treat the data in such a way as to bring out hidden and useful information.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 收集到的数据可能与随时间收集的其他记录不一致。重复条目的存在和不完整的记录要求我们以这样的方式处理数据，以揭示隐藏的有用信息。
- en: To clean the data, we totally discard irrelevant and noisy data. Data with missing
    parts or attributes can be replaced with sensible estimates. Also, where the raw
    data suffers from inconsistency, detecting and correcting that becomes necessary.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清理数据，我们完全丢弃了不相关和嘈杂的数据。缺失部分或属性的数据可以用合理的估计值替换。此外，当原始数据存在不一致性时，检测和纠正就变得必要了。
- en: Let's explore how we can use `NumPy` and `pandas` for data preprocessing techniques.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨如何使用`NumPy`和`pandas`进行数据预处理技术。
- en: Missing data
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失数据
- en: 'The performance of the machine learning algorithm deteriorates if the data
    has missing values. Just because a dataset has missing fields or attributes does
    not mean it is not useful. Several methods can be used to fill in the missing
    values. Some of these methods are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据存在缺失值，机器学习算法的性能会下降。仅仅因为数据集存在缺失字段或属性并不意味着它没有用处。可以使用几种方法来填补缺失值。其中一些方法如下：
- en: Using a global constant to fill in the missing values.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用全局常数填补缺失值。
- en: Using the mean or median value in the dataset.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数据集中的均值或中位数值。
- en: Supplying the data manually.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动提供数据。
- en: Using the attribute mean or median to fill in the missing values. The choice
    is based on the context and sensitivity of what the data is going to be used for.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用属性的均值或中位数来填补缺失值。选择基于数据将要使用的上下文和敏感性。
- en: 'Take, for instance, the following data:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下数据：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As we can see, the data elements `data[1][0]` and `data[1][1]` have values of `np.NAN`,
    representing the fact that they have no value. If the `np.NAN` values are not
    desired in a given dataset, they can be set to a constant figure.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 可以看到，数据元素`data[1][0]`和`data[1][1]`的值为`np.NAN`，表示它们没有值。如果不希望在给定数据集中存在`np.NAN`值，可以将其设置为一个常数。
- en: 'Let''s set data elements with the value `np.NAN` to `0.1`:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将值为`np.NAN`的数据元素设置为`0.1`：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The new state of the data becomes the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的新状态如下：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To apply the mean values instead, we do the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用均值，我们需要做如下操作：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The mean value for each column is calculated and inserted into those data areas
    with the `np.NAN` value:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为每列计算均值，并将其插入到具有`np.NAN`值的数据区域中：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For the first column, column `0`, the mean value was obtained by `(4 + 94)/2`.
    The resulting `49.0` is then stored at `data[1][0]`. A similar operation is carried
    out for columns `1` and `2`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一列，列`0`，均值通过`(4 + 94)/2`得到。然后将结果`49.0`存储在`data[1][0]`中。对列`1`和`2`也进行类似的操作。
- en: Feature scaling
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征缩放
- en: The columns in a data frame are known as its features. The rows are known as
    records or observations. The performance of the machine learning algorithm decreases
    if one attribute has values in a higher range compared to other attributes' values.
    Thus, it is often required to scale or normalize the attribute values in a common
    range.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框中的列称为其特征。行称为记录或观察。如果一个属性的值比其他属性的值具有更高的范围，机器学习算法的性能会下降。因此，通常需要将属性值缩放或归一化到一个公共范围内。
- en: 'Consider an example, the following data matrix. This data will be referenced
    in subsections so please do take note:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个例子，以下数据矩阵。这些数据将在后续部分中被引用，请注意：
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Feature one, with data of `58`, `10`, and `20`, has its values lying between
    `10` and `58`. For feature two, the data lies between `1` and `200`. Inconsistent
    results will be produced if we supply this data to any machine learning algorithm.
    Ideally, we will need to scale the data to a certain range in order to get consistent
    results.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 特征一的数据为`58`、`10`和`20`，其值位于`10`和`58`之间。对于特征二，数据位于`1`和`200`之间。如果将这些数据提供给任何机器学习算法，将产生不一致的结果。理想情况下，我们需要将数据缩放到一定范围内以获得一致的结果。
- en: Once again, closer inspection reveals that each feature (or column) lies around
    different mean values. Therefore, what we want to do is to align the features
    around similar means.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 再次仔细检查发现，每个特征（或列）的均值都在不同的范围内。因此，我们要做的是使特征围绕相似的均值对齐。
- en: One benefit of feature scaling is that it boosts the learning parts of machine
    learning. The `scikit` module has a considerable number of scaling algorithms
    that we shall apply to our data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 特征缩放的一个好处是它提升了机器学习的学习部分。`scikit`模块有大量的缩放算法，我们将应用到我们的数据中。
- en: Min-max scalar form of normalization
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小-最大标量形式的归一化
- en: 'The min-max scalar form of normalization uses the mean and standard deviation
    to box all the data into a range lying between certain min and max values. Generally,
    the range is set between `0` and `1`; although other ranges may be applied, the
    `0` to `1` range remains the default:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最小-最大标量形式的归一化使用均值和标准差将所有数据装箱到位于某些最小和最大值之间的范围内。通常，范围设置在`0`和`1`之间；尽管可以应用其他范围，但`0`到`1`范围仍然是默认值：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'An instance of the `MinMaxScaler` class is created with the range `(0,1)` and
    passed to the `scaled_values` variables. The `fit` function is called to make
    the necessary calculations that are used internally to change the dataset. The
    `transform` function affects the actual operation on the dataset, returning the
    value to `results`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`MinMaxScaler`类的一个实例，范围为`(0,1)`，并传递给`scaled_values`变量。调用`fit`函数进行必要的计算，用于内部使用以改变数据集。`transform`函数对数据集进行实际操作，并将值返回给`results`：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can see from the preceding output that all the data is normalized and lies
    between `0` and `1`. This kind of output can now be supplied to a machine learning
    algorithm.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中可以看出，所有数据都经过了归一化，并位于`0`和`1`之间。这种输出现在可以提供给机器学习算法。
- en: Standard scalar
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准缩放
- en: 'The mean values for the respective features in our initial dataset or table
    are 29.3, 92, and 38\. To make all the data have a similar mean, that is, a zero
    mean and a unit variance across the data, we can apply the standard scalar algorithm,
    shown as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初始数据集或表中各特征的均值分别为29.3、92和38。为了使所有数据具有相似的均值，即数据的均值为零，方差为单位，我们可以应用标准缩放算法，如下所示：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`data` is passed to the `fit` method of the object returned from instantiating
    the `StandardScaler` class. The `transform` method acts on the data elements in
    the data and returns the output to the results:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`data`被传递给从实例化`StandardScaler`类返回的对象的`fit`方法。`transform`方法作用于数据元素，并将输出返回给结果：'
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Examining the results, we observe that all our features are now evenly distributed.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 检查结果，我们观察到所有特征现在都是均匀分布的。
- en: Binarizing data
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二值化数据
- en: 'To binarize a given feature set, we can make use of a threshold. If any value
    within a given dataset is greater than the threshold, the value is replaced by
    `1`, and if the value is less than the threshold, it is replaced with `0`. Consider
    the following code snippet, where we take 50 as the threshold to binarize the
    original data:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要对给定的特征集进行二值化，我们可以使用一个阈值。如果给定数据集中的任何值大于阈值，则该值将被替换为`1`，如果该值小于阈值，则替换为`0`。考虑以下代码片段，我们以50作为阈值来对原始数据进行二值化：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'An instance of `Binarizer` is created with the argument `50.0`. `50.0` is the
    threshold that will be used in the binarizing algorithm:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`Binarizer`的实例，并使用参数`50.0`。`50.0`是将在二值化算法中使用的阈值：
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: All values in the data that are less than 50 will have a value of `0`, and hold
    a value of `1` otherwise.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中所有小于50的值将为`0`，否则为`1`。
- en: Learning about machine learning
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习机器学习
- en: Machine learning is a subfield of artificial intelligence. Machine learning
    is basically an algorithm that can learn from the example data and can provide
    predictions based on that. Machine learning models learn the patterns from the
    data examples and use those learned patterns to make predictions for unseen data. For
    example, we feed many examples of spam and ham email messages to develop a machine
    learning model that can learn the patterns in emails and can classify new emails
    as spam or ham.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的一个子领域。机器学习基本上是一个可以从示例数据中学习并可以基于此提供预测的算法。机器学习模型从数据示例中学习模式，并使用这些学习的模式来预测未见数据。例如，我们将许多垃圾邮件和正常邮件的示例输入来开发一个机器学习模型，该模型可以学习邮件中的模式，并可以将新邮件分类为垃圾邮件或正常邮件。
- en: Types of machine learning
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习类型
- en: 'There are three broad categories of machine learning, as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习有三个广泛的类别，如下：
- en: '**Supervised learning**: Here, an algorithm is fed a set of inputs and their
    corresponding outputs. The algorithm then has to figure out what the output will
    be for an unseen input. Supervised learning algorithms try to learn the patterns
    in the input features and target output in such a way that the learned model can
    predict the output for the new unseen data. Classification and regression are
    two kinds of problem that are solved using a supervised learning approach, in
    which the machine learning algorithm learns from the given data and labels. Classification
    is a process that classifies the given unseen data into one of the predefined
    sets of classes, given a set of input features and labels associated with them.
    Regression is very similar to classification, with one exception—in this, we have
    continuous target values instead of a fixed pre-defined set of classes (nominal
    or categorical attribute), and we predict the value in a continuous response for
    new unseen data.  Examples of such algorithms include naive bayes, support vector
    machines, k-nearest neighbors, linear regression, neural networks, and decision
    tree algorithms.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：在这里，算法会接收一组输入和相应的输出。然后算法必须找出对于未见过的输入，输出将会是什么。监督学习算法试图学习输入特征和目标输出中的模式，以便学习的模型可以预测新的未见数据的输出。分类和回归是使用监督学习方法解决的两种问题，其中机器学习算法从给定的数据和标签中学习。分类是一个将给定的未见数据分类到预定义类别集合中的过程，给定一组输入特征和与其相关的标签。回归与分类非常相似，唯一的区别在于，在回归中，我们有连续的目标值，而不是固定的预定义类别集合（名义或分类属性），我们预测连续响应中的值。这样的算法包括朴素贝叶斯、支持向量机、k-最近邻、线性回归、神经网络和决策树算法。'
- en: '**Unsupervised learning**: Without using the relationship that exists between
    a set of input and output variables, the unsupervised learning algorithm uses
    only the input to learn the patterns and clusters within the data. Unsupervised
    algorithms are used to learn the patterns in the given input data without labels
    associated with them. Clustering problems are one of the most popular types of
    problems that are solved using an unsupervised learning approach. In this, the
    data points are grouped together to form groups or clusters on the basis of the
    similarities among the features. Examples of such algorithms include k-means clustering,
    agglomerative clustering, and hierarchical clustering.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：无监督学习算法仅使用输入来学习数据中的模式和聚类，而不使用存在于一组输入和输出变量之间的关系。无监督算法用于学习给定输入数据中的模式，而不带有与其相关的标签。聚类问题是使用无监督学习方法解决的最流行的问题之一。在这种情况下，数据点根据特征之间的相似性被分组成组或簇。这样的算法包括k均值聚类、凝聚聚类和层次聚类。'
- en: '**Reinforcement learning**: The computer in this kind of learning method dynamically
    interacts with its environment in such a way as to improve its performance.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**：在这种学习方法中，计算机动态地与环境交互，以改善其性能。'
- en: The hello classifier
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你好分类器
- en: Let's take a simple example to understand how machine learning works; we begin
    with a `hello world` example of a text classifier. This is meant to be a gentle
    introduction to machine learning.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个简单的例子来理解机器学习的工作原理；我们从一个文本分类器的`hello world`例子开始。这是对机器学习的一个温和的介绍。
- en: This example will predict whether the given text carries a negative or positive
    connotation. Before this can be done, we need to train our algorithm (model) with
    some data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子将预测给定文本是否带有负面或正面的含义。在这之前，我们需要用一些数据来训练我们的算法（模型）。
- en: The naive bayes model is suited for text classification purposes. Algorithms
    based on the naive bayes models are generally fast and produce accurate results.
    It is based on the assumption that features are independent of each other. To
    accurately predict the occurrence of rainfall, three conditions need to be considered.
    These are wind speed, temperature, and the amount of humidity in the air. In reality,
    these factors do have an influence on each other to determine the likelihood of
    rainfall. But the abstraction in naive bayes is to assume that these features
    are unrelated in any way and thus independently contribute to the chances of rainfall.
    Naive bayes is useful in predicting the class of an unknown dataset, as we will
    see soon.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯模型适用于文本分类目的。基于朴素贝叶斯模型的算法通常速度快，产生准确的结果。它基于特征相互独立的假设。要准确预测降雨的发生，需要考虑三个条件。这些条件是风速、温度和空气中的湿度量。实际上，这些因素确实会相互影响，以确定降雨的可能性。但朴素贝叶斯的抽象是假设这些特征在任何方面都是无关的，因此独立地影响降雨的可能性。朴素贝叶斯在预测未知数据集的类别时非常有用，我们很快就会看到。
- en: 'Now, back to our hello classifier. After we have trained our model, its prediction
    will fall into either the positive or negative categories:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到我们的hello分类器。在我们训练模型之后，它的预测将属于正类别或负类别之一：
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: First, we will import the `NaiveBayesClassifier` class from the `textblob` package.
    This classifier is very easy to work with and is based on the bayes theorem.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从`textblob`包中导入`NaiveBayesClassifier`类。这个分类器非常容易使用，基于贝叶斯定理。
- en: The `train` variable consists of tuples that each hold the actual training data.
    Each tuple contains the sentence and the group it is associated with.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`变量由每个包含实际训练数据的元组组成。每个元组包含句子和它所关联的组。'
- en: 'Now, to train our model, we will instantiate a `NaiveBayesClassifier` object
    by passing train to it:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了训练我们的模型，我们将通过传递`train`来实例化一个`NaiveBayesClassifier`对象：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The updated naive bayesian model `cl` will predict the category that an unknown
    sentence belongs to. Up to this point, our model has known of only two categories
    that a phrase can belong to, `neg` and `pos`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的朴素贝叶斯模型`cl`将预测未知句子所属的类别。到目前为止，我们的模型只知道短语可以属于`neg`和`pos`两个类别中的一个。
- en: 'The following code runs tests using our model:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码使用我们的模型运行测试：
- en: '[PRE16]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output of our tests is as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们测试的输出如下：
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can see that the algorithm has had some degree of success in classifying
    the input phrases into their categories correctly.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到算法在正确将输入短语分类到它们的类别方面取得了一定程度的成功。
- en: This contrived example is overly simplistic, but it does show the promise that
    if given the right amount of data and a suitable algorithm or model, it is possible
    for a machine to carry out tasks without any human help.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个刻意构造的例子过于简单，但它确实显示了如果提供了正确数量的数据和合适的算法或模型，机器是可以在没有任何人类帮助的情况下执行任务的。
- en: In our next example, we will use the `scikit` module to predict the category
    that a phrase may belong to.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的下一个例子中，我们将使用`scikit`模块来预测一个短语可能属于的类别。
- en: A supervised learning example
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个监督学习的例子
- en: Let's consider an example of the text classification problem, which can be solved
    using a supervised learning approach. The text classification problem is to classify
    a new document into one of the pre-defined sets of categories of documents when
    we have a set of documents related to a fixed number of categories. As with supervised
    learning, we need to first train the model in order to accurately predict the
    category of an unknown document.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个文本分类问题的例子，可以使用监督学习方法来解决。文本分类问题是在我们有一组与固定数量的类别相关的文档时，将新文档分类到预定义的文档类别集合之一。与监督学习一样，我们需要首先训练模型，以便准确预测未知文档的类别。
- en: Gathering data
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集数据
- en: 'The `scikit` module comes with sample data that we can use for training the
    machine learning model. In this example, we will use the newsgroups documents,
    which have 20 categories of documents. To load those documents, we will use the
    following lines of code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit`模块带有我们可以用于训练机器学习模型的示例数据。在这个例子中，我们将使用包含20个文档类别的新闻组文档。为了加载这些文档，我们将使用以下代码行：'
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s take only four categories of documents for training the model. After
    we have trained our model, the results of the prediction will belong to one of
    the following categories:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们只取四个文档类别来训练模型。在我们训练模型之后，预测的结果将属于以下类别之一：
- en: '[PRE19]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The total number of records we are going to use as training data is obtained
    by the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用作训练数据的记录总数是通过以下方式获得的：
- en: '[PRE20]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Machine learning algorithms do not work on textual attributes directly, so
    the names of the categories that each document belongs to are denoted as numbers
    (for example, `alt.atheism` is denoted as `0`) using the following code line:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法不能直接处理文本属性，因此每个文档所属类别的名称被表示为数字（例如，`alt.atheism`表示为`0`），使用以下代码行：
- en: '[PRE21]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The categories have integer values that we can map back to the categories themselves
    with `print(training_data.target_names[0])`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 类别具有整数值，我们可以使用`print(training_data.target_names[0])`将其映射回类别本身。
- en: Here, `0` is a numerical random index picked from `set(training_data.target)`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`0`是从`set(training_data.target)`中随机选择的数字索引。
- en: Now that the training data has been obtained, we must feed the data to a machine
    learning algorithm. The bag of words model is an approach to convert the text
    document into a feature vector in order to turn the text into a form on which
    the learning algorithm or model can be applied. Furthermore, those feature vectors
    will be used for training the machine learning model.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练数据已经获得，我们必须将数据提供给机器学习算法。词袋模型是一种将文本文档转换为特征向量的方法，以便将文本转换为学习算法或模型可以应用的形式。此外，这些特征向量将用于训练机器学习模型。
- en: Bag of words
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词袋模型
- en: 'Bag of words is a model that is used for representing text data in such a way
    that it does not take into consideration the order of words but rather uses word
    counts. Let''s consider an example to understand how the bag of words method is
    used to represent text. Look at the following two sentences:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 词袋是一种模型，用于表示文本数据，它不考虑单词的顺序，而是使用单词计数。让我们看一个例子来理解词袋方法如何用于表示文本。看看以下两个句子：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Bag of words enables us to split the text into numerical feature vectors represented
    by a matrix.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 词袋使我们能够将文本拆分为由矩阵表示的数值特征向量。
- en: 'To reduce our two sentences using the bag of words model, we need to obtain
    a unique list of all the words:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用词袋模型减少我们的两个句子，我们需要获得所有单词的唯一列表：
- en: '[PRE23]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This set will become our columns in the matrix, called the features in machine
    learning terminology. The rows in the matrix will represent the documents that
    are being used for training. The intersection of a row and column will store the
    number of times that word occurs in the document. Using our two sentences as examples,
    we obtain the following matrix:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这个集合将成为我们矩阵中的列，被称为机器学习术语中的特征。矩阵中的行将代表用于训练的文档。行和列的交集将存储单词在文档中出现的次数。使用我们的两个句子作为例子，我们得到以下矩阵：
- en: '|  | **as** | **fit** | **a** | **fiddle** | **you** | **like** | **it** |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | **as** | **fit** | **a** | **fiddle** | **you** | **like** | **it** |'
- en: '| **Sentence 1** | 2 | 1 | 1 | 1 | 0 | 0 | 0 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **句子1** | 2 | 1 | 1 | 1 | 0 | 0 | 0 |'
- en: '| **Sentence 2** | 1 | 0 | 0 | 0 | 1 | 1 | 1 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| **句子2** | 1 | 0 | 0 | 0 | 1 | 1 | 1 |'
- en: The preceding data has many features that are generally not important for text
    classification. The stop words can be removed to make sure only relevant data
    is analyzed. Stop words include is, am, are, was, and so on. Since the bag of
    words model does not include grammar in its analysis, the stop words can safely
    be dropped.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的数据有很多特征，通常对文本分类不重要。停用词可以被移除，以确保只分析相关的数据。停用词包括is，am，are，was等等。由于词袋模型在分析中不包括语法，停用词可以安全地被删除。
- en: 'To generate the values that go into the columns of our matrix, we have to tokenize
    our training data:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成进入矩阵列的值，我们必须对我们的训练数据进行标记化：
- en: '[PRE24]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '`training_matrix` has a dimension of (2,257 x 35,788) for the four categories
    of data we used in this example. This means that 2,257 corresponds to the total
    number of documents while 35,788 corresponds to the number of columns, which is
    the total number of features that make up the unique set of words in all documents.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`training_matrix`的维度为（2,257 x 35,788），对应于我们在这个例子中使用的四个数据类别。这意味着2,257对应于文档的总数，而35,788对应于列的数量，即构成所有文档中唯一单词集的特征的总数。
- en: We instantiate the `CountVectorizer` class and pass `training_data.data` to
    the `fit_transform` method of the `count_vect` object. The result is stored in
    `training_matrix`. `training_matrix` holds all the unique words and their respective
    frequencies.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化`CountVectorizer`类，并将`training_data.data`传递给`count_vect`对象的`fit_transform`方法。结果存储在`training_matrix`中。`training_matrix`包含所有唯一的单词及其相应的频率。
- en: Sometimes, frequency counts do not perform well for a text-classification problem;
    instead of using frequency count, we may use the **term frequency-inverse document
    frequency** (**TF-IDF**) weighting method for representing the features.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，频率计数对于文本分类问题表现不佳；我们可以使用**词项频率-逆文档频率**（**TF-IDF**）加权方法来表示特征，而不是使用频率计数。
- en: 'Here, will import `TfidfTransformer`, which helps to assign the weights of
    each feature in our data:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将导入`TfidfTransformer`，它有助于为我们的数据中的每个特征分配权重：
- en: '[PRE25]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`tfidf_data[1:4].todense()` only shows a truncated list of a three rows by
    35,788 columns matrix. The values seen are the TF-IDF; it is a better representation
    method compared to using a frequency count.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`tfidf_data[1:4].todense()`只显示了一个三行35,788列矩阵的截断列表。所见的值是TF-IDF；与使用频率计数相比，它是一种更好的表示方法。'
- en: Once we have extracted features and represented them in a tabular format, we
    can apply a machine learning algorithm for training. There are many supervising
    learning algorithms; let's look at an example of the naive bayes algorithm to
    train a text classifier model.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们提取了特征并以表格格式表示它们，我们就可以应用机器学习算法进行训练。有许多监督学习算法；让我们看一个朴素贝叶斯算法的例子来训练文本分类器模型。
- en: 'The naive bayes algorithm is a simple classification algorithm that is based
    on the bayes theorem. It is a probability-based learning algorithm that constructs
    a model by using the term frequency of a feature/word/term to compute the probability
    of belonging. The naive bayes algorithm classifies a given document into one of
    the predefined categories where there is the maximum probability of observing
    the words of the new document in that category. The naive bayes algorithm works
    as follows—initially, all training documents are processed to extract the vocabulary
    of all the words that appear in the text, then it counts their frequencies among
    the different target classes to obtain their probabilities. Next, a new document
    is classified in the category, which has the maximum probability of belonging
    to that particular class. The naive bayes classifier is based on the assumption
    that the probability of word occurrence is independent of position within the
    text. Multinomial naive bayes can be implemented using the `MultinomialNB` function
    of the `scikit` library, shown as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯算法是一种简单的分类算法，它基于贝叶斯定理。它是一种基于概率的学习算法，通过使用特征/单词/术语的词频来计算属于的概率来构建模型。朴素贝叶斯算法将给定的文档分类为预定义类别中的一个，其中新文档中观察到的单词的最大概率所在的类别。朴素贝叶斯算法的工作方式如下——首先，处理所有训练文档以提取出现在文本中的所有单词的词汇，然后计算它们在不同目标类别中的频率以获得它们的概率。接下来，将新文档分类到具有属于特定类别的最大概率的类别中。朴素贝叶斯分类器基于这样的假设，即单词出现的概率与文本中的位置无关。多项式朴素贝叶斯可以使用`scikit`库的`MultinomialNB`函数来实现，如下所示：
- en: '[PRE26]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`MultinomialNB` is a variant of the naive bayes model. We pass the rationalized
    data matrix, `tfidf_data`, and categories, `training_data.target`, to its `fit`
    method.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`MultinomialNB`是朴素贝叶斯模型的一个变体。我们将经过合理化的数据矩阵`tfidf_data`和类别`training_data.target`传递给其`fit`方法。'
- en: Prediction
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测
- en: 'To test how the trained model works to predict the category of an unknown document,
    let''s consider some example test data to evaluate the model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试训练模型如何预测未知文档的类别，让我们考虑一些示例测试数据来评估模型：
- en: '[PRE27]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `test_data` list is passed to the `count_vect.transform` function to obtain
    the vectorized form of the test data. To obtain the TF-IDF representation of the
    test dataset, we call the `transform` method of the `matrix_transformer` object.
    When we pass new test data to the machine learning model, we have to process the
    data in the same way as we did in preparing the training data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 将`test_data`列表传递给`count_vect.transform`函数，以获得测试数据的向量化形式。为了获得测试数据集的TF-IDF表示，我们调用`matrix_transformer`对象的`transform`方法。当我们将新的测试数据传递给机器学习模型时，我们必须以与准备训练数据相同的方式处理数据。
- en: 'To predict which category the docs may belong to, we use the `predict` function
    as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测文档可能属于哪个类别，我们使用`predict`函数如下：
- en: '[PRE28]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The loop can be used to iterate over the prediction, showing the categories
    they are predicted to belong to:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 循环可以用于迭代预测，显示它们被预测属于的类别：
- en: '[PRE29]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'When the loop has run to completion, the phrase, together with the category
    that it may belong to, is displayed. A sample output is as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当循环运行完成时，将显示短语及其可能属于的类别。示例输出如下：
- en: '[PRE30]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: All that we have seen up to this point is a prime example of supervised learning.
    We started by loading documents whose categories were already known. These documents
    were then fed into the machine learning algorithm most suited for text processing,
    based on the naive bayes theorem. A set of test documents was supplied to the
    model and the category was predicted.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所看到的都是监督学习的一个典型例子。我们首先加载已知类别的文档。然后将这些文档输入到最适合文本处理的机器学习算法中，基于朴素贝叶斯定理。一组测试文档被提供给模型，并预测类别。
- en: To explore an example of an unsupervised learning algorithm, we will discuss
    the k-means algorithm for clustering some data.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 探索一个无监督学习算法的例子，我们将讨论k均值算法对一些数据进行聚类。
- en: An unsupervised learning example
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习示例
- en: Unsupervised learning algorithms are able to discover inherent patterns in the
    data that may exist and can cluster them in groups in such a way that the data
    points in one cluster are very similar and data points from two different clusters
    are highly dissimilar in nature. An example of these algorithms is the k-means
    algorithm.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习算法能够发现数据中可能存在的固有模式，并以这样的方式将它们聚类成组，使得一个组中的数据点非常相似，而来自两个不同组的数据点在性质上非常不相似。这些算法的一个例子就是k均值算法。
- en: K-means algorithm
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: k均值算法
- en: The k-means algorithm uses the mean points in a given dataset to cluster and
    discover groups within the dataset. The `K` is the number of clusters that we
    want and are hoping to discover. After the k-means algorithm has generated the
    groupings/clusters, we can pass unknown data to this model to predict which cluster
    the new data should belong to.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: k均值算法使用给定数据集中的均值点来对数据进行聚类并发现数据集中的组。`K`是我们希望发现的聚类的数量。k均值算法生成了分组/聚类之后，我们可以将未知数据传递给该模型，以预测新数据应该属于哪个聚类。
- en: Note that in this kind of algorithm, only the raw uncategorized data is fed
    to the algorithm without any labels associated with the data. It is up to the
    algorithm to find out if the data has inherent groups within it.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这种算法中，只有原始的未分类数据被输入到算法中，没有任何与数据相关联的标签。算法需要找出数据是否具有固有的组。
- en: The k-means algorithm iteratively assigns the data points to the clusters based
    on the similarities among the features provided. K-means clustering groups the
    data points in k clusters/groups using the mean point. It works as follows. Firstly,
    we create k non-empty sets, and we compute the distance between the data point
    and the cluster center. Next, we assign the data point to the cluster that has
    the minimum distance and is closest. Next, we recalculate the cluster point and
    we iteratively follow the same process until all the data is clustered.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: k均值算法通过迭代地根据提供的特征之间的相似性将数据点分配到聚类中。k均值聚类使用均值点将数据点分组成k个聚类/组。它的工作方式如下。首先，我们创建k个非空集合，并计算数据点与聚类中心之间的距离。接下来，我们将数据点分配给具有最小距离且最接近的聚类。然后，我们重新计算聚类点，并迭代地遵循相同的过程，直到所有数据都被聚类。
- en: To understand how this algorithm works, let's examine `100` data points consisting
    of x and y values (assuming two attributes). We will feed these values to the
    learning algorithm and expect that the algorithm will cluster the data into two
    sets. We will color the two sets so that the clusters are visible.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这个算法的工作原理，让我们检查包含x和y值的100个数据点（假设有两个属性）。我们将把这些值传递给学习算法，并期望算法将数据聚类成两组。我们将对这两组进行着色，以便看到聚类。
- en: 'Let''s create a sample data of 100 records of *x* and *y* pairs:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个包含100条*x*和*y*对的样本数据：
- en: '[PRE31]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: First, we create 100 records with `-2 * np.random.rand(100, 2)`. In each of
    the records, we will use the data in it to represent *x* and *y* values that will
    eventually be plotted.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建100条记录，其中包含`-2 * np.random.rand(100, 2)`。在每条记录中，我们将使用其中的数据来表示最终将绘制的*x*和*y*值。
- en: The last 50 numbers in `original_set` will be replaced by `1+2*np.random.rand(50,
    2)`. In effect, what we have done is to create two subsets of data, where one
    set has numbers in the negative while the other set has numbers in the positive.
    It is now the responsibility of the algorithm to discover these segments appropriately.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`original_set`中的最后50个数字将被`1+2*np.random.rand(50, 2)`替换。实际上，我们已经创建了两个数据子集，其中一个集合中的数字为负数，而另一个集合中的数字为正数。现在算法的责任是适当地发现这些段。'
- en: 'We instantiate the `KMeans` algorithm class and pass it `n_clusters=2`. That
    makes the algorithm cluster all its data into two groups. In the k-means algorithm,
    the number of clusters has to be known in advance. The implementation of the k-means
    algorithm using the `scikit` library is as shown:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实例化`KMeans`算法类，并传递`n_clusters=2`。这使得算法将其所有数据聚类成两组。在k均值算法中，簇的数量必须事先知道。使用`scikit`库实现k均值算法如下所示：
- en: '[PRE32]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The dataset is passed to the `fit` function of `kmean`, `kmean.fit(original_set)`.
    The clusters generated by the algorithm will revolve around a certain mean point.
    The points that define these two mean points are obtained by `kmean.cluster_centers_`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集被传递给`kmean`的`fit`函数，`kmean.fit(original_set)`。算法生成的聚类将围绕某个平均点旋转。定义这两个平均点的点是通过`kmean.cluster_centers_`获得的。
- en: 'The mean points when printed appear as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出的平均点如下所示：
- en: '[PRE33]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Each data point in `original_set` will belong to a cluster after our k-means
    algorithm has finished its training. The k-mean algorithm represents the two clusters
    it discovers as ones and zeros. If we had asked the algorithm to cluster the data
    into four, the internal representation of these clusters would have been 0, 1,
    2, and 3\. To print out the various clusters that each dataset belongs to, we
    do the following:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`original_set`中的每个数据点在我们的k均值算法完成训练后将属于一个簇。k均值算法将它发现的两个簇表示为1和0。如果我们要求算法将数据分成四个簇，这些簇的内部表示将是0、1、2和3。要打印出每个数据集所属的不同簇，我们执行以下操作：'
- en: '[PRE34]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This gives the following output:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE35]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'There are `100` ones and zeros. Each shows the cluster that each data point
    falls under. By using `matplotlib.pyplot`, we can chart the points of each group
    and color it appropriately to show the clusters:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 有`100`个1和0。每个显示每个数据点所属的簇。通过使用`matplotlib.pyplot`，我们可以绘制每个组的点并适当着色以显示簇：
- en: '[PRE36]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`index = kmean.labels_ == i` is a nifty way by which we select all points that
    correspond to group `i`. When `i=0`, all points belonging to group zero are returned
    to the variable index. It''s the same for `index =1, 2`, and so on.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`index = kmean.labels_ == i`是一种巧妙的方法，通过它我们选择与组`i`对应的所有点。当`i=0`时，所有属于零组的点都返回到变量`index`。对于`index
    =1, 2`，依此类推。'
- en: '`plt.plot(original_set[index,0], original_set[index,1], ''o'')` then plots
    these data points using `o` as the character for drawing each point.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`plt.plot(original_set[index,0], original_set[index,1], ''o'')`然后使用`o`作为绘制每个点的字符绘制这些数据点。'
- en: 'Next, we will plot the centroids or mean values around which the clusters have
    formed:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将绘制形成簇的质心或平均值：
- en: '[PRE37]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Lastly, we show the whole graph with the two means illustrated by red star
    using the code snippet  `plt.show()`  as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用代码片段`plt.show()`显示整个图形，其中两个平均值用红色星号表示，如下所示：
- en: '![](Images/9130b340-90ee-4cee-b5ff-ca93c2b01e27.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9130b340-90ee-4cee-b5ff-ca93c2b01e27.png)'
- en: The algorithm discovers two distinct clusters in our sample data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法在我们的样本数据中发现了两个不同的簇。
- en: Prediction
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测
- en: With the two clusters that we have obtained, we can predict the group that a
    new set of data might belong to.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 有了我们得到的两个簇，我们可以预测新一组数据可能属于哪个组。
- en: 'Let''s predict which group the points `[[-1.4, -1.4]]` and `[[2.5, 2.5]]` will
    belong to:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们预测点`[[-1.4, -1.4]]`和`[[2.5, 2.5]]`将属于哪个组：
- en: '[PRE38]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output is as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE39]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Here, two test samples are assigned to two different clusters.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，两个测试样本分配到了两个不同的簇。
- en: Data visualization
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据可视化
- en: The numerical analysis is sometimes not that easy to understand. In this section,
    we show you some methods to visualize the data and results. Images present a quick
    way to analyze data. Differences in size and length are quick markers in an image,
    upon which conclusions can be drawn. In this section, we will take a tour of the
    different ways to represent data. Besides the graphs listed here, there is more
    that can be achieved when dealing with data.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 数值分析有时不那么容易理解。在本节中，我们将向您展示一些可视化数据和结果的方法。图像是分析数据的一种快速方式。图像中大小和长度的差异是快速标记，可以得出结论。在本节中，我们将介绍表示数据的不同方法。除了这里列出的图表外，在处理数据时还可以实现更多。
- en: Bar chart
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条形图
- en: 'To chart the values 25, 5, 150, and 100 into a bar graph, we will store the
    values in an array and pass it to the `bar` function. The bars in the graph represent
    the magnitude along the *y*-axis:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 要将值25、5、150和100绘制成条形图，我们将把这些值存储在一个数组中，并将其传递给`bar`函数。图中的条代表*y*轴上的大小：
- en: '[PRE40]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`x_values` stores an array of values generated by `range(len(data))`. Also,
    `x_values` will determine the points on the *x*-axis where the bars will be drawn.
    The first bar will be drawn on the *x*-axis where *x* is zero. The second bar
    with data 5 will be drawn on the *x*-axis where *x* is 1:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`x_values`存储由`range(len(data))`生成的值数组。此外，`x_values`将确定在*x*轴上绘制条形的点。第一根条将在*x*轴上绘制，其中*x*为零。第二根带有数据5的条将在*x*轴上绘制，其中*x*为1：'
- en: '![](Images/5c2618e0-70aa-41eb-aa32-ff94e8b3f8c6.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/5c2618e0-70aa-41eb-aa32-ff94e8b3f8c6.png)'
- en: 'The width of each bar can be changed by modifying the following line:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通过修改以下行可以改变每个条的宽度：
- en: '[PRE41]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This should produce the following graph:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该产生以下图形：
- en: '![](Images/9cd8e72f-79e7-4c7e-9cfc-e80a375153f0.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9cd8e72f-79e7-4c7e-9cfc-e80a375153f0.png)'
- en: However, this is not visually appealing because there is no space between the
    bars anymore, which makes it look clumsy. Each bar now occupies one unit on the
    *x*-axis.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这样做并不直观，因为条之间不再有空间，这使得看起来很笨拙。每个条现在在*x*轴上占据一个单位。
- en: Multiple bar charts
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多条形图
- en: 'In trying to visualize data, stacking a number of bars enables one to further
    understand how one piece of data or variable varies compared to another:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试可视化数据时，堆叠多个条使人能够进一步了解一条数据或变量相对于另一条数据或变量的变化：
- en: '[PRE42]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `y` values for the first batch of data are `[8., 57., 22., 10.]`. The second
    batch is `[16., 7., 32., 40.]`. When the bars are plotted, 8 and 16 will occupy
    the same `x` position, side by side.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 第一批数据的`y`值为`[8., 57., 22., 10.]`。第二批数据为`[16., 7., 32., 40.]`。当条形图绘制时，8和16将占据相同的`x`位置，侧边相邻。
- en: '`x_values = np.arange(4)` generates the array with values `[0, 1, 2, 3]`. The
    first set of bars are drawn first at position `x_values + 0.30`. Thus, the first
    x values will be plotted at `0.00, 1.00, 2.00 and 3.00`.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`x_values = np.arange(4)`生成值为`[0, 1, 2, 3]`的数组。第一组条形图首先绘制在位置`x_values + 0.30`。因此，第一个x值将被绘制在`0.00,
    1.00, 2.00和3.00`。'
- en: 'The second batch of `x_values` will be plotted at `0.30, 1.30, 2.30` and `3.30`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组`x_values`将被绘制在`0.30, 1.30, 2.30`和`3.30`：
- en: '![](Images/d0624b77-b67d-470b-96fb-22a604eafad6.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/d0624b77-b67d-470b-96fb-22a604eafad6.png)'
- en: Box plot
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 箱线图
- en: The box plot is used to visualize the median value and low and high ranges of
    a distribution. It is also referred to as a box and whisker plot.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图用于可视化分布的中位数值和低高范围。它也被称为箱线图。
- en: Let's chart a simple box plot.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制一个简单的箱线图。
- en: 'We begin by generating `50` numbers from a normal distribution. These are then
    passed to `plt.boxplot(data)` to be charted:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先生成`50`个来自正态分布的数字。然后将它们传递给`plt.boxplot(data)`进行绘图：
- en: '[PRE43]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The following diagram is what is produced:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是产生的：
- en: '![](Images/05876ad6-cc46-4141-bfa8-bb3b119b6c0e.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05876ad6-cc46-4141-bfa8-bb3b119b6c0e.png)'
- en: A few comments on the preceding diagram—the features of the box plot include
    a box spanning the interquartile range, which measures the dispersion; the outer
    fringes of the data are denoted by the whiskers attached to the central box; the
    red line represents the median.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面的图表，一些注释——箱线图的特点包括跨越四分位距的箱子，用于测量离散度；数据的外围由连接到中心箱子的须表示；红线代表中位数。
- en: The box plot is useful to easily identify the outliers in a dataset, as well
    as determining in which direction a dataset may be skewed.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 箱线图可用于轻松识别数据集中的异常值，以及确定数据集可能偏向的方向。
- en: Pie chart
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 饼图
- en: 'The pie chart interprets and visually represents the data as if to fit into
    a circle. The individual data points are expressed as sectors of a circle that
    add up to 360 degrees. This chart is good for displaying categorical data and
    summaries too:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 饼图解释和直观地表示数据，就像适合放在圆圈里一样。个别数据点被表示为圆圈的扇形，总和为360度。这种图表适合显示分类数据和总结：
- en: '[PRE44]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The sectors in the graph are labeled with the strings in the labels array:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中的扇形用标签数组中的字符串标记：
- en: '![](Images/17ea1d44-5589-427c-8c5c-0d37c801d374.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/17ea1d44-5589-427c-8c5c-0d37c801d374.png)'
- en: Bubble chart
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 气泡图
- en: 'Another variant of the scatter plot is the bubble chart. In a scatter plot,
    we only plot the `x` and `y` points of the data. Bubble charts add another dimension
    by illustrating the size of the points. This third dimension may represent sizes
    of markets or even profits:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图的另一种变体是气泡图。在散点图中，我们只绘制数据的`x`和`y`点。气泡图通过展示点的大小添加了另一个维度。这第三个维度可以表示市场的规模甚至利润：
- en: '[PRE45]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: With the `n` variable, we specify the number of randomly generated `x` and `y`
    values. This same number is used to determine the random colors for our `x` and
    `y` coordinates. Random bubble sizes are determined by `area = np.pi * (60 * np.random.rand(n))**2`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`n`变量，我们指定了随机生成的`x`和`y`值的数量。这个数字也用于确定我们的`x`和`y`坐标的随机颜色。随机气泡大小由`area = np.pi
    * (60 * np.random.rand(n))**2`确定。
- en: 'The following diagram shows this bubble chart:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了这个气泡图：
- en: '![](Images/9b77b68c-6fed-44e9-93f5-c9f23357954a.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9b77b68c-6fed-44e9-93f5-c9f23357954a.png)'
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have explored how data and algorithms come together to aid
    machine learning. Making sense of huge amounts of data is made possible by first
    pruning our data through data cleaning techniques and scaling and normalization
    processes. Feeding this data to specialized learning algorithms, we are able to
    predict the categories of unseen data based on the patterns learned by the algorithm
    from the data. We also discussed the basics of machine learning algorithms.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了数据和算法如何结合起来帮助机器学习。通过数据清洗技术和缩放和归一化过程，我们首先对大量数据进行了整理。将这些数据输入到专门的学习算法中，我们能够根据算法从数据中学到的模式来预测未知数据的类别。我们还讨论了机器学习算法的基础知识。
- en: We explained supervised and unsupervised machine learning algorithms in detail
    with the naive bayes and k-means clustering algorithms. We also provided the implementation
    of these algorithms using the `scikit-learn` Python-based machine learning library. Finally,
    some important visualization techniques were discussed, as charting and plotting
    the condensed data helps you to better understand and make insightful discoveries.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们详细解释了监督和无监督的机器学习算法，使用朴素贝叶斯和k均值聚类算法。我们还使用基于Python的`scikit-learn`机器学习库提供了这些算法的实现。最后，我们讨论了一些重要的可视化技术，因为对压缩数据进行图表化和绘图有助于更好地理解和做出有见地的发现。
- en: I hope you had a good experience with this book and that it helps in your future
    endeavors with data structures and Python 3.7!
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您在阅读本书时有一个愉快的体验，并且它能够帮助您在未来的数据结构和Python 3.7的学习中取得成功！
