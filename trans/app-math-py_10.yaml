- en: Miscellaneous Topics
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 其他主题
- en: In this chapter, we will look at several topics that don't fit within the categories
    that we discussed in the previous chapters of this book. Most of these topics
    are concerned with different ways to facilitate computing and otherwise optimize
    the execution of our code. Others concern working with specific kinds of data
    or file formats.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论一些在本书前几章中没有涉及的主题。这些主题大多涉及不同的计算方式以及优化代码执行的其他方式。其他主题涉及处理特定类型的数据或文件格式。
- en: In the first two recipes, we will cover packages that help keep track of units
    and uncertainties in calculations. These are very important for calculations that
    concern data that have a direct physical application. In the next recipe, we will
    look at loading and storing data from NetCDF files. NetCDF is a file format usually
    used for storing weather and climate data. (NetCDF stands for **network common
    data form**.) In the fourth recipe, we'll discuss working with geographical data,
    such as data that might be associated with weather or climate data. After that,
    we'll discuss how we can run Jupyter notebooks from the terminal without having
    to start up an interactive session. The next two recipes deal with validating
    data and working with data streamed from a Kafka server. Our final two recipes
    deal with two different ways we can accelerate our code using tools such as Cython
    and Dask.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个内容中，我们将介绍帮助跟踪计算中的单位和不确定性的软件包。这些对于涉及具有直接物理应用的数据的计算非常重要。在下一个内容中，我们将讨论如何从NetCDF文件加载和存储数据。NetCDF通常用于存储天气和气候数据的文件格式。（NetCDF代表**网络通用数据格式**。）在第四个内容中，我们将讨论处理地理数据，例如可能与天气或气候数据相关的数据。之后，我们将讨论如何可以在不必启动交互式会话的情况下从终端运行Jupyter笔记本。接下来的两个内容涉及验证数据和处理从Kafka服务器流式传输的数据。我们最后两个内容涉及两种不同的方式，即使用诸如Cython和Dask等工具来加速我们的代码。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Keeping track of units with Pint
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Pint跟踪单位
- en: Accounting for uncertainties in calculations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在计算中考虑不确定性
- en: Loading and storing data from NetCDF files
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从NetCDF文件加载和存储数据
- en: Working with geographical data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理地理数据
- en: Executing Jupyter notebooks as a script
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Jupyter笔记本作为脚本执行
- en: Validating data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证数据
- en: Working with data streams
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理数据流
- en: Accelerating code with Cython
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Cython加速代码
- en: Distributing computation with Dask
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Dask进行分布式计算
- en: Let's get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires many different packages due to the nature of the recipes
    it contains. The list of packages we need is as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本章包含的内容的性质，需要许多不同的软件包。我们需要的软件包列表如下：
- en: Pint
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pint
- en: uncertainties
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不确定性
- en: NetCDF4
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NetCDF4
- en: xarray
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: xarray
- en: GeoPandas
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GeoPandas
- en: Geoplot
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geoplot
- en: Papermill
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papermill
- en: Cerberus
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cerberus
- en: Faust
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Faust
- en: Cython
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cython
- en: Dask
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dask
- en: 'All of these packages can be installed using your favorite package manager,
    such as `pip`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些软件包都可以使用您喜欢的软件包管理器（如`pip`）进行安装：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To install the Dask package, we need to install the various extras associated
    with the package. We can do this using the following `pip` command in the terminal:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Dask软件包，我们需要安装与软件包相关的各种额外功能。我们可以在终端中使用以下`pip`命令来执行此操作：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In addition to these Python packages, we will also need to install some supporting
    software. For the *Working with geographical data* recipe, the GeoPandas and Geoplot
    libraries have numerous lower-level dependencies that might need to be installed
    separately. Detailed instructions are given in the GeoPandas package documentation
    at [https://geopandas.org/install.html](https://geopandas.org/install.html).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些Python软件包，我们还需要安装一些支持软件。对于*处理地理数据*的内容，GeoPandas和Geoplot库可能需要单独安装许多低级依赖项。详细说明在GeoPandas软件包文档中给出，网址为[https://geopandas.org/install.html](https://geopandas.org/install.html)。
- en: For the *Working with streaming data* recipe, we will need to install the Kafka
    server. Detailed instructions on how to install and run a Kafka server can be
    found on the Apache Kafka documentation pages at [https://kafka.apache.org/quickstart](https://kafka.apache.org/quickstart).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*处理数据流*的内容，我们需要安装Kafka服务器。如何安装和运行Kafka服务器的详细说明可以在Apache Kafka文档页面上找到，网址为[https://kafka.apache.org/quickstart](https://kafka.apache.org/quickstart)。
- en: For the *Accelerating code with Cython* recipe, we will need to have a C compiler
    installed. Instructions on how to obtain the **GNU C compiler** (**GCC**) are
    given in the Cython documentation at [https://cython.readthedocs.io/en/latest/src/quickstart/install.html](https://cython.readthedocs.io/en/latest/src/quickstart/install.html).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*Cython加速代码*的内容，我们需要安装C编译器。如何获取**GNU C编译器**（**GCC**）的说明在Cython文档中给出，网址为[https://cython.readthedocs.io/en/latest/src/quickstart/install.html](https://cython.readthedocs.io/en/latest/src/quickstart/install.html)。
- en: The code for this chapter can be found in the `Chapter 10` folder of the GitHub
    repository at [https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2010](https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2010).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在GitHub存储库的`Chapter 10`文件夹中找到，网址为[https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2010](https://github.com/PacktPublishing/Applying-Math-with-Python/tree/master/Chapter%2010)。
- en: 'Check out the following video to see the Code in Action: [https://bit.ly/2ZMjQVw](https://bit.ly/2ZMjQVw).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际操作：[https://bit.ly/2ZMjQVw](https://bit.ly/2ZMjQVw)。
- en: Keeping track of units with Pint
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Pint跟踪单位
- en: Correctly keeping track of units in calculations can be very difficult, particularly
    if there are places where different units can be used. For example, it is very
    easy to forget to convert between different units – feet/inches into meters –
    or metric prefixes – converting 1 km into 1,000 m, for instance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算中正确跟踪单位可能非常困难，特别是在可以使用不同单位的地方。例如，很容易忘记在不同单位之间进行转换 – 英尺/英寸转换成米 – 或者公制前缀 –
    比如将1千米转换成1,000米。
- en: In this recipe, we'll learn how to use the Pint package to keep track of units
    of measurement in calculations.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个内容中，我们将学习如何使用Pint软件包来跟踪计算中的测量单位。
- en: Getting ready
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, we need the Pint package, which can be imported as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们需要Pint包，可以按如下方式导入：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: How to do it...
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The following steps show you how to use the Pint package to keep track of units
    in calculations:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤向您展示了如何使用Pint包在计算中跟踪单位：
- en: 'First, we need to create a `UnitRegistry` object:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个`UnitRegistry`对象：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To create a quantity with a unit, we multiply the number by the appropriate
    attribute of the registry object:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建带有单位的数量，我们将数字乘以注册对象的适当属性：
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can change the units of the quantity using one of the available conversion
    methods:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用其中一种可用的转换方法更改数量的单位：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output of these `print` statements is as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些`print`语句的输出如下：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We wrap a routine to make it expect an argument in seconds and output a result
    in meters:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们包装一个例程，使其期望以秒为参数并输出以米为结果：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, when we call the `calc_depth` routine with a minute unit, it is automatically
    converted into seconds for the calculation:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，当我们使用分钟单位调用`calc_depth`例程时，它会自动转换为秒进行计算：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The Pint package provides a wrapper class for numerical types that adds unit
    metadata to the type. This wrapper type implements all the standard arithmetic
    operations and keeps track of the units throughout these calculations. For example,
    when we divide a length unit by a time unit, we will get a speed unit. This means
    that you can use Pint to make sure the units are correct after a complex calculation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Pint包为数字类型提供了一个包装类，为类型添加了单位元数据。这个包装类型实现了所有标准的算术运算，并在这些计算过程中跟踪单位。例如，当我们将长度单位除以时间单位时，我们将得到速度单位。这意味着您可以使用Pint来确保在复杂计算后单位是正确的。
- en: The `UnitRegistry` object keeps track of all the units that are present in the
    session and handles things such as conversion between different unit types. It
    also maintains a reference system of measurements, which in this recipe is the
    standard international system with meters, kilograms, and seconds as base units,
    denoted `mks`.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`UnitRegistry`对象跟踪会话中存在的所有单位，并处理不同单位类型之间的转换等问题。它还维护一个度量参考系统，在这个示例中是标准国际系统，以米、千克和秒作为基本单位，表示为`mks`。'
- en: The `wrap` functionality allows us to declare the input and output units of
    a routine, which allows Pint to do automatic unit conversions for the input function
    – in this recipe, we converted from minutes into seconds. Trying to call a wrapped
    function with a quantity that does not have an associated unit, or an incompatible
    unit, will raise an exception. This allows runtime validation of parameters and
    automatic conversion into the correct units for a routine.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`wrap`功能允许我们声明例程的输入和输出单位，这允许Pint对输入函数进行自动单位转换-在这个示例中，我们将分钟转换为秒。尝试使用没有关联单位或不兼容单位的数量调用包装函数将引发异常。这允许对参数进行运行时验证，并自动转换为例程的正确单位。'
- en: There's more...
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The Pint package comes with a large list of preprogrammed units of measurement
    that cover most globally used systems. Units can be defined at runtime or loaded
    from a file. This means that you can define custom units or systems of units that
    are specific to the application that you are working with.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Pint包带有一个大型的预设测量单位列表，涵盖了大多数全球使用的系统。单位可以在运行时定义或从文件加载。这意味着您可以定义特定于您正在使用的应用程序的自定义单位或单位系统。
- en: Units can also be used within different contexts, which allows for easy conversion
    between different unit types that would ordinarily be unrelated. This can save
    a lot of time in situations where you need to move between units fluidly at multiple
    points in a calculation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 单位也可以在不同的上下文中使用，这允许在不同单位类型之间轻松转换，这些单位类型通常是不相关的。这可以在需要在计算的多个点之间流畅地移动单位的情况下节省大量时间。
- en: Accounting for uncertainty in calculations
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在计算中考虑不确定性
- en: Most measuring devices are not 100% accurate and instead are accurate up to
    a certain amount, usually somewhere between 0 and 10%. For instance, a thermometer
    might be accurate to 1%, while a pair of digital calipers might be accurate up
    to 0.1%. The true value in both of these cases is unlikely to be exactly the reported
    value, although it will be fairly close. Keeping track of the uncertainty in a
    value is difficult, especially when you have multiple different uncertainties
    combined in different ways. Rather than keeping track of this by hand, it is much
    better to use a consistent library to do this for you. This is what the `uncertainties`
    package does.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数测量设备并不是100%准确的，通常只能准确到一定程度，通常在0到10%之间。例如，温度计可能准确到1%，而一对数字卡尺可能准确到0.1%。在这两种情况下，报告的数值不太可能是真实值，尽管它会非常接近。跟踪数值的不确定性是困难的，特别是当您有多种不同的不确定性以不同的方式组合在一起时。与其手动跟踪这些，最好使用一个一致的库来为您完成。这就是`uncertainties`包的作用。
- en: In this recipe, we will learn how to quantify the uncertainty of variables and
    see how these uncertainties propagate through a calculation.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将学习如何量化变量的不确定性，并看到这些不确定性如何通过计算传播。
- en: Getting ready
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, we will need the `uncertainties` package, from which we will
    import the `ufloat` class and the `umath` module:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们将需要`uncertainties`包，我们将从中导入`ufloat`类和`umath`模块：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How to do it...
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The following steps show you how to quantify uncertainty on numerical values
    in calculations:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤向您展示了如何在计算中对数值的不确定性进行量化：
- en: 'First, we create an uncertain float value of `3.0` plus or minus `0.4`:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们创建一个不确定的浮点值为`3.0`加减`0.4`：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we perform a calculation involving this uncertain value to obtain a new
    uncertain value:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们进行涉及这个不确定值的计算，以获得一个新的不确定值：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we create a new uncertain float value and apply the `sqrt` routine from
    the `umath` module in the reverse of the previous calculation:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个新的不确定浮点值，并在与之前计算相反的方向上应用`umath`模块的`sqrt`例程：
- en: '[PRE12]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works...
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `ufloat` class wraps around `float` objects and keeps track of the uncertainty
    throughout calculations. The library makes use of linear error propagation theory,
    which uses derivatives of non-linear functions, to estimate the propagated error
    during calculations. The library also correctly handles correlation so that subtracting
    a value from itself gives 0 with no error.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`ufloat`类包装了`float`对象，并在整个计算过程中跟踪不确定性。该库利用线性误差传播理论，使用非线性函数的导数来估计计算过程中传播的误差。该库还正确处理相关性，因此从自身减去一个值会得到0，没有误差。'
- en: To keep track of uncertainties in standard mathematical functions, you need
    to use the versions that are provided in the `umath` module, rather than those
    defined in the Python Standard Library or in a third-party package such as NumPy.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟踪标准数学函数中的不确定性，您需要使用`umath`模块中提供的版本，而不是Python标准库或第三方包（如NumPy）中定义的版本。
- en: There's more...
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The `uncertainties` package provides support for NumPy, and the Pint package
    mentioned in the previous recipe can be combined with uncertainties to make sure
    that units and error margins are correctly attributed to the final value of a
    calculation. For example, we could compute the units in the calculation from *step
    2* of this recipe, as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`uncertainties`包支持NumPy，并且前面示例中提到的Pint包可以与不确定性结合使用，以确保正确地将单位和误差边界归因于计算的最终值。例如，我们可以从本示例的*步骤2*中计算出计算的单位，如下所示：'
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As expected, the `print` statement on the last line gives us `44+/-12 meter`,
    as we expect.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，最后一行的`print`语句给出了我们预期的`44+/-12米`。
- en: Loading and storing data from NetCDF files
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从NetCDF文件加载和存储数据
- en: Many scientific applications require that we start large quantities of multi-dimensional
    data in a robust format. NetCDF is one example of a format used for data that's
    developed by the weather and climate industry. Unfortunately, the complexity of
    the data means that we can't simply use the utilities from the Pandas package,
    for example, to load this data for analysis. We need the `netcdf4` package to
    be able to read and import the data into Python, but we also need to use `xarray`.
    Unlike the Pandas library, `xarray` can handle higher-dimensional data while still
    providing a Pandas-like interface.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 许多科学应用程序要求我们以稳健的格式开始大量的多维数据。NetCDF是天气和气候行业用于开发数据的格式的一个例子。不幸的是，数据的复杂性意味着我们不能简单地使用Pandas包的实用程序来加载这些数据进行分析。我们需要`netcdf4`包来能够读取和导入数据到Python中，但我们还需要使用`xarray`。与Pandas库不同，`xarray`可以处理更高维度的数据，同时仍提供类似于Pandas的接口。
- en: In this recipe, we will learn how to load data from and store data in NetCDF
    files.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将学习如何从NetCDF文件中加载数据并存储数据。
- en: Getting ready
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'For this recipe, we will need to import the NumPy package as `np`, the Pandas
    package as `pd`, the Matplotlib `pyplot` module as `plt`, and an instance of the
    default random number generator from NumPy:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们需要导入NumPy包作为`np`，Pandas包作为`pd`，Matplotlib `pyplot`模块作为`plt`，以及从NumPy导入默认随机数生成器的实例：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We also need to import the `xarray`package under the alias`xr`. You will also
    need to install the Dask package, as described in the *Technical requirements*
    section, and the NetCDF4 package:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要导入`xarray`包并使用别名`xr`。您还需要安装Dask包，如“技术要求”部分所述，以及NetCDF4包：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We don't need to import either of these packages directly.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要直接导入这两个包。
- en: How to do it...
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作方法...
- en: 'Follow these steps to load and store sample data in a NetCDF file:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤加载和存储样本数据到NetCDF文件中：
- en: 'First, we need to create some random data. This data consists of a range of
    dates, a list of location codes, and randomly generated numbers:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一些随机数据。这些数据包括一系列日期、位置代码列表和随机生成的数字：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, we create an xarray `Dataset` object containing the data. The dates and
    locations are indexes, while the `steps` and `accumulated` variables are the data:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个包含数据的xarray `Dataset`对象。日期和位置是索引，而`steps`和`accumulated`变量是数据：
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output from the `print` statement is shown here:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`print`语句的输出如下所示：'
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, we compute the mean over all the locations at each time index:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们计算每个时间索引处所有位置的平均值：
- en: '[PRE19]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, we plot the mean accumulated values on a new set of axes:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们在新的坐标轴上绘制平均累积值：
- en: '[PRE20]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The resulting plot looks as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的绘图如下所示：
- en: '![](assets/6481c4b7-78d8-474c-b1fe-e2e780d25381.png)Figure 10.1: Plot of accumulated
    means over time'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/6481c4b7-78d8-474c-b1fe-e2e780d25381.png)图10.1：随时间累积平均值的绘图'
- en: 'Save this dataset into a new NetCDF file using the `to_netcdf` method:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`to_netcdf`方法将此数据集保存到新的NetCDF文件中：
- en: '[PRE21]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we can load the newly created NetCDF file using the `load_dataset` routine
    from `xarray`:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`xarray`的`load_dataset`例程加载新创建的NetCDF文件：
- en: '[PRE22]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output of the preceding code is as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码的输出如下所示：
- en: '[PRE23]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: How it works...
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The `xarray` package provides the `DataArray` and`DataSet` classes, which are
    (roughly speaking) multi-dimensional equivalents of the Pandas `Series` and `DataFrame`
    objects. We're using a dataset in this example because each index – a tuple of
    a date and location – has two pieces of data associated with it. Both of these
    objects expose a similar interface to their Pandas equivalents. For example, we
    can compute the mean along one of the axes using the `mean` method. The `DataArray`
    and `DataSet` objects also have a convenience method for converting into a Pandas
    `DataFrame` called `to_dataframe`. We used it in this recipe to convert to a `DataFrame`
    for plotting, which isn't really necessary because `xarray` has plotting features
    built into it.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`xarray`包提供了`DataArray`和`DataSet`类，它们（粗略地说）是Pandas`Series`和`DataFrame`对象的多维等价物。在本例中，我们使用数据集，因为每个索引（日期和位置的元组）都与两个数据相关联。这两个对象都暴露了与它们的Pandas等价物类似的接口。例如，我们可以使用`mean`方法沿着其中一个轴计算平均值。`DataArray`和`DataSet`对象还有一个方便的方法，可以将其转换为Pandas`DataFrame`，称为`to_dataframe`。我们在这个示例中使用它将其转换为`DataFrame`进行绘图，这并不是真正必要的，因为`xarray`内置了绘图功能。'
- en: The real focus of this recipe is on the `to_netcdf` method and the `load_dataset`
    routine. The former stores a `DataSet` in NetCDF format file. This requires the
    NetCDF4 package to be installed as it allows us to access the relevant C library
    for decoding NetCDF formatted files. The `load_dataset` routine is a general-purpose
    routine for loading data into a `DataSet` object from various file formats, including
    NetCDF (again, this requires the NetCDF4 package to be installed).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方的真正重点是`to_netcdf`方法和`load_dataset`例程。前者将`DataSet`存储在NetCDF格式文件中。这需要安装NetCDF4包，因为它允许我们访问相关的C库来解码NetCDF格式的文件。`load_dataset`例程是一个通用的例程，用于从各种文件格式（包括NetCDF，这同样需要安装NetCDF4包）将数据加载到`DataSet`对象中。
- en: There's more...
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The `xarray` package has support for a number of data formats in addition to
    NetCDF, such as OPeNDAP, Pickle, GRIB, and other formats that are supported by
    Pandas.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`xarray`包支持除NetCDF之外的许多数据格式，如OPeNDAP、Pickle、GRIB和Pandas支持的其他格式。'
- en: Working with geographical data
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理地理数据
- en: Many applications involve working with geographical data. For example, when
    tracking global weather, we might want to plot the temperature as measured by
    various sensors around the world at their position on a map. For this, we can
    use the GeoPandas package and the Geoplot package, both of which allow us to manipulate,
    analyze, and visualize geographical data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 许多应用涉及处理地理数据。例如，当跟踪全球天气时，我们可能希望在地图上以各种传感器在世界各地的位置测量的温度为例进行绘图。为此，我们可以使用GeoPandas包和Geoplot包，这两个包都允许我们操纵、分析和可视化地理数据。
- en: In this recipe, we will use the GeoPandas and Geoplot packages to load and visualize
    some sample geographical data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用GeoPandas和Geoplot包来加载和可视化一些样本地理数据。
- en: Getting ready
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, we will need the GeoPandas package, the Geoplot package, and
    the Matplotlib `pyplot` package imported as `plt`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个配方，我们需要GeoPandas包，Geoplot包和Matplotlib的`pyplot`包作为`plt`导入：
- en: '[PRE24]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: How to do it...
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Follow these steps to create a simple plot of the capital cities plotted on
    a map of the world using sample data:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤，使用样本数据在世界地图上创建首都城市的简单绘图：
- en: 'First, we need to load the sample data from the GeoPandas package, which contains
    the world geometry information:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要从GeoPandas包中加载样本数据，其中包含世界地理信息：
- en: '[PRE25]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we need to load the data containing the name and position of each of
    the capital cities of the world:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要加载包含世界各个首都城市名称和位置的数据：
- en: '[PRE26]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, we can create a new figure and plot the outline of the world geometry
    using the `polyplot` routine:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以创建一个新的图形，并使用`polyplot`例程绘制世界地理的轮廓：
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Finally, we use the `pointplot` routine to add the positions of the capital
    cities on top of the world map. We also set the axes limits to make the whole
    world visible:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用`pointplot`例程在世界地图上添加首都城市的位置。我们还设置轴限制，以使整个世界可见：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The resulting plot of the positions of the capital cities of the world looks
    as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 结果绘制的世界各国首都城市的位置如下：
- en: '![](assets/c3ed4017-aab6-4ab8-9c90-1225fd886f1b.png)Figure 10.2: Plot of the
    world''s capital cities on a map'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/c3ed4017-aab6-4ab8-9c90-1225fd886f1b.png)图10.2：世界首都城市在地图上的绘图'
- en: How it works...
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The GeoPandas package is an extension of Pandas that works with geographical
    data, while the Geoplot package is an extension of Matplotlib that's used to plot
    geographical data. The GeoPandas package comes with a selection of sample datasets
    that we used in this recipe. `naturalearth_lowres` contains geometric figures
    that describe the boundaries of countries in the world. This data is not very
    high resolution, as signified by its name, which means that some of the finer
    details of geographical features might not be present on the map. (Some small
    islands are not shown at all.) `naturalearth_cities` contains the names and locations
    of the capital cities of the world. We're using the `datasets.get_path` routine
    to retrieve the path for these datasets in the package data directory. The `read_file`
    routine imports the data into the Python session.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: GeoPandas包是Pandas的扩展，用于处理地理数据，而Geoplot包是Matplotlib的扩展，用于绘制地理数据。GeoPandas包带有一些我们在这个配方中使用的样本数据集。`naturalearth_lowres`包含描述世界各国边界的几何图形。这些数据不是非常高分辨率，正如其名称所示，这意味着地理特征的一些细节可能在地图上不存在（一些小岛根本没有显示）。`naturalearth_cities`包含世界各国首都城市的名称和位置。我们使用`datasets.get_path`例程来检索包数据目录中这些数据集的路径。`read_file`例程将数据导入Python会话。
- en: The Geoplot package provides some additional plotting routines specifically
    for plotting geographical data. The `polyplot` routine plots polygonal data from
    a GeoPandas DataFrame, which might describe the geographical boundaries of a country.
    The `pointplot` routine plots discrete points on a set of axes from a GeoPandas
    DataFrame, which in this case describe the position of capital cities.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Geoplot包提供了一些专门用于绘制地理数据的附加绘图例程。`polyplot`例程从GeoPandas DataFrame绘制多边形数据，该数据可能描述一个国家的地理边界。`pointplot`例程从GeoPandas
    DataFrame在一组轴上绘制离散点，这种情况下描述了首都城市的位置。
- en: Executing a Jupyter notebook as a script
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Jupyter笔记本作为脚本执行
- en: Jupyter notebooks are a popular medium for writing Python code for scientific
    and data-based applications. A Jupyter notebook is really a sequence of blocks
    that are stored in a file in **JavaScript Object Notation** (**JSON**) with the
    `ipynb` extension. Each block can be one of several different types, such as code
    or markdown. These notebooks are typically accessed through a web application
    that interprets the blocks and executes the code in a background kernel that then
    returns the results to the web application. This is great if you are working on
    a personal PC, but what if you want to run the code contained within a notebook
    remotely on a server? In this case, it might not even be possible to access the
    web interface provided by the Jupyter notebook software. The papermill package
    allows us to parameterize and execute notebooks from the command line.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter笔记本是用于编写科学和数据应用的Python代码的流行媒介。 Jupyter笔记本实际上是一个以**JavaScript对象表示**（**JSON**）格式存储在带有`ipynb`扩展名的文件中的块序列。每个块可以是多种不同类型之一，例如代码或标记。这些笔记本通常通过解释块并在后台内核中执行代码然后将结果返回给Web应用程序的Web应用程序访问。如果您在个人PC上工作，这很棒，但是如果您想在服务器上远程运行笔记本中包含的代码怎么办？在这种情况下，甚至可能无法访问Jupyter笔记本软件提供的Web界面。papermill软件包允许我们从命令行参数化和执行笔记本。
- en: In this recipe, we'll learn how to execute a Jupyter notebook from the command
    line using papermill.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将学习如何使用papermill从命令行执行Jupyter笔记本。
- en: Getting ready
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, we will need to have the papermill package installed, and also
    have a sample Jupyter notebook in the current directory. We will use the `sample.ipynb`
    notebook file stored in the code repository for this chapter.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们需要安装papermill软件包，并且当前目录中需要有一个示例Jupyter笔记本。我们将使用本章的代码存储库中存储的`sample.ipynb`笔记本文件。
- en: How to do it...
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Follow these steps to use the papermill command-line interface to execute a
    Jupyter notebook remotely:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用papermill命令行界面远程执行Jupyter笔记本：
- en: 'First, we open the sample notebook, `sample.ipynb`, from the code repository
    for this chapter. The notebook contains three code cells that hold the following
    code:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们从本章的代码存储库中打开样本笔记本`sample.ipynb`。笔记本包含三个代码单元格，其中包含以下代码：
- en: '[PRE29]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we open the folder containing the Jupyter notebook in the terminal and
    use the following command:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在终端中打开包含Jupyter笔记本的文件夹并使用以下命令：
- en: '[PRE30]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, we open the output file, `output.ipynb`, which should now contain the
    notebook that''s been updated with the result of the executed code. The scatter
    plot that''s generated in the final block is shown here:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们打开输出文件`output.ipynb`，该文件现在应该包含已更新为执行代码结果的笔记本。在最终块中生成的散点图如下所示：
- en: '![](assets/05f0392f-a1b4-4448-b26a-2e3fb8d57bb7.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/05f0392f-a1b4-4448-b26a-2e3fb8d57bb7.png)'
- en: 'Figure 10.3: Scatter plot of the random data that was generated inside a Jupyter
    notebook, executed remotely using papermill'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：在远程使用papermill执行的Jupyter笔记本中生成的随机数据的散点图
- en: How it works...
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The papermill package provides a simple command-line interface that interprets
    and then executes a Jupyter notebook and then stores the results in a new notebook
    file. In this recipe, we gave the first argument – the input notebook file –`sample.ipynb`
    and the second argument – the output notebook file –`output.ipynb`. The tool then
    executes the code contained in the notebook and produces the output. The notebook's
    file format keeps track of the results of the last run, so these results are added
    to the output notebook and stored at the desired location. In this recipe, this
    is a simple local file, but papermill can also store to a cloud location such
    as **Amazon Web Services** (**AWS**) S3 storage or Azure data storage.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: papermill软件包提供了一个简单的命令行界面，用于解释和执行Jupyter笔记本，然后将结果存储在新的笔记本文件中。在本教程中，我们提供了第一个参数
    - 输入笔记本文件 - `sample.ipynb`和第二个参数 - 输出笔记本文件 - `output.ipynb`。然后工具执行笔记本中包含的代码并生成输出。笔记本文件格式跟踪上次运行的结果，因此这些结果将添加到输出笔记本并存储在所需的位置。在本教程中，这是一个简单的本地文件，但是papermill也可以存储到云位置，例如**Amazon
    Web Services**（**AWS**）S3存储或Azure数据存储。
- en: 'In *step 2,* we added the `--kernel python3` option when using the papermill
    command-line interface. This option allows us to specify the kernel that is used
    to execute the Jupyter notebook. This might be necessary to prevent errors if
    papermill tries to execute the notebook with a different kernel than the one used
    to write the notebook. A list of available kernels can be found by using the following
    command in the terminal:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤2*中，我们在使用papermill命令行界面时添加了`--kernel python3`选项。此选项允许我们指定用于执行Jupyter笔记本的内核。如果papermill尝试使用与用于编写笔记本的内核不同的内核执行笔记本，则可能需要这样做以防止错误。可以使用以下命令在终端中找到可用内核的列表：
- en: '[PRE31]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: If you get an error when executing a notebook, you could try changing to a different
    kernel.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在执行笔记本时出现错误，您可以尝试切换到不同的内核。
- en: There's more...
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Papermill also has a Python interface so that you can execute notebooks from
    within a Python application. This might be useful for building web applications
    that need to be able to perform long-running calculations on external hardware
    and where the results need to be stored in the cloud. It also has the ability
    to provide parameters to a notebook. To do this, we need to create a block in
    the notebook marked with the parameters tag with the default values. Updated parameters
    can then be provided through the command-line interface using the `-p` flag, followed
    by the name of the argument and the value.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: Papermill还具有Python接口，因此您可以从Python应用程序内执行笔记本。这对于构建需要能够在外部硬件上执行长时间计算并且结果需要存储在云中的Web应用程序可能很有用。它还具有向笔记本提供参数的能力。为此，我们需要在笔记本中创建一个标有默认值的参数标记的块。然后可以通过命令行界面使用`-p`标志提供更新的参数，后跟参数的名称和值。
- en: Validating data
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证数据
- en: Data is often presented in a raw form and might contain anomalies or incorrect
    or malformed data, which will obviously present a problem for later processing
    and analysis. It is usually a good idea to build a validation step into a processing
    pipeline. Fortunately, the Cerberus package provides a lightweight and easy to
    use validation tool for Python.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通常以原始形式呈现，可能包含异常或不正确或格式不正确的数据，这显然会给后续处理和分析带来问题。通常最好在处理管道中构建验证步骤。幸运的是，Cerberus包为Python提供了一个轻量级且易于使用的验证工具。
- en: For validation, we have to define a *schema*, which is a technical description
    of what the data should look like and the checks that should be performed on the
    data. For example, we can check the type and place bounds of the maximum and minimum
    values. Cerberus validators can also perform type conversions during the validation
    step, which allows us to plug data loaded directly from CSV files into the validator.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对于验证，我们必须定义一个*模式*，这是关于数据应该如何以及应该对数据执行哪些检查的技术描述。例如，我们可以检查类型并设置最大和最小值的边界。Cerberus验证器还可以在验证步骤中执行类型转换，这使我们可以将直接从CSV文件加载的数据插入验证器中。
- en: In this recipe, we will learn how to use Cerberus to validate data loaded from
    a CSV file.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将学习如何使用Cerberus验证从CSV文件加载的数据。
- en: Getting ready
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, we need to import the `csv` module from the Python Standard
    Library, as well as the Cerberus package:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们需要从Python标准库中导入`csv`模块，以及Cerberus包：
- en: '[PRE32]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We will also need the `sample.csv` file from the code repository for this chapter.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要这一章的代码库中的`sample.csv`文件。
- en: How to do it...
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In the following steps, we will validate a set of data that''s been loaded
    from CSV using the Cerberus package:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，我们将使用Cerberus包从CSV中加载的一组数据进行验证：
- en: 'First, we need to build a schema that describes the data we expect. To do this,
    we must define a simple schema for floating-point numbers:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要构建描述我们期望的数据的模式。为此，我们必须为浮点数定义一个简单的模式：
- en: '[PRE33]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we build the schema for individual items. These will be the rows of our
    data:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们为单个项目构建模式。这些将是我们数据的行：
- en: '[PRE34]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, we can define the schema for the whole document, which will contain a
    list of items:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以定义整个文档的模式，其中将包含一系列项目：
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, we create a `Validator` object with the schema we just defined:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用刚刚定义的模式创建一个`Validator`对象：
- en: '[PRE36]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Then, we load the data using a `DictReader` from the `csv` module:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用`csv`模块中的`DictReader`加载数据：
- en: '[PRE37]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Next, we use the `validate` method on the `Validator` to validate the document:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`Validator`上的`validate`方法来验证文档：
- en: '[PRE38]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, we retrieve the errors from the validation process from the `Validator`
    object:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们从`Validator`对象中检索验证过程中的错误：
- en: '[PRE39]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, we can print any error messages that appeared:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以打印出任何出现的错误消息：
- en: '[PRE40]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output of the error messages is as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 错误消息的输出如下：
- en: '[PRE41]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: How it works...
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The schema that we created is a technical description of all the criteria that
    we need to check against our data. This will usually be defined as a dictionary
    with the name of the item as the key and a dictionary of properties, such as the
    type or bounds on the value in a dictionary, as the value. For example, in *step
    1*, we defined a schema for floating-point numbers that limits the numbers so
    that they're between the values of -1 and 1\. Note that we include the `coerce`
    key, which specifies the type that the value should be converted into during the
    validation. This allows us to pass in data that's been loaded from a CSV document,
    which contains only strings, without having to worry about its type.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的模式是对我们需要根据数据检查的所有标准的技术描述。这通常被定义为一个字典，其中项目的名称作为键，属性字典作为值，例如字典中的值的类型或值的边界。例如，在*步骤1*中，我们为浮点数定义了一个模式，限制了数字的范围，使其在-1和1之间。请注意，我们包括`coerce`键，该键指定在验证期间应将值转换为的类型。这允许我们传入从CSV文档中加载的数据，其中只包含字符串，而不必担心其类型。
- en: The `Validator` object takes care of parsing documents so that they're validated
    and checking the data they contain against all the criteria described by the schema.
    In this recipe, we provided the schema to the `Validator` object when it was created.
    However, we could also pass the schema into the `validate` method as a second
    argument. The errors are stored in a nested dictionary that mirrors the structure
    of the document.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`Validator`对象负责解析文档，以便对其进行验证，并根据模式描述的所有标准检查它们包含的数据。在这个示例中，我们在创建`Validator`对象时向其提供了模式。但是，我们也可以将模式作为第二个参数传递给`validate`方法。错误存储在一个嵌套字典中，其结构与文档的结构相似。'
- en: Working with data streams
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理数据流
- en: Some data is received in a constant stream from various sources. For example,
    we might have a situation where multiple temperature probes are reporting values
    at set intervals via a Kafka server. Kafka is a streaming data message broker
    that passes messages to different processing agents based on topics.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据是从各种来源以恒定流的形式接收的。例如，我们可能会遇到多个温度探头通过Kafka服务器定期报告值的情况。Kafka是一个流数据消息代理，根据主题将消息传递给不同的处理代理。
- en: Processing streaming data is the perfect application for asynchronous Python.
    This allows us to process larger quantities of data concurrently, which could
    be very important in applications. Of course, we can't directly perform long-running
    analysis on this data in an asynchronous context, since this will interfere with
    the execution of the event loop.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 处理流数据是异步Python的完美应用。这使我们能够同时处理更大量的数据，这在应用程序中可能非常重要。当然，在异步上下文中我们不能直接对这些数据进行长时间的分析，因为这会干扰事件循环的执行。
- en: For working with Kafka streams using Python's asynchronous programming features,
    we can use the Faust package. This package allows us to define asynchronous functions
    that will act as processing agents or services that can process or otherwise interact
    with a stream of data from a Kafka server.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python的异步编程功能处理Kafka流时，我们可以使用Faust包。该包允许我们定义异步函数，这些函数将充当处理代理或服务，可以处理或以其他方式与来自Kafka服务器的数据流进行交互。
- en: In this recipe, we will learn how to use the Faust package to process a stream
    of data from a Kafka server.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将学习如何使用Faust包来处理来自Kafka服务器的数据流。
- en: Getting ready
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Unlike most of the recipes in this book, this recipe cannot be run in a Jupyter
    notebook since we will run the resulting app from the command line.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中大多数食谱不同，由于我们将从命令行运行生成的应用程序，因此无法在Jupyter笔记本中运行此食谱。
- en: 'For this recipe, we will need to import the Faust package:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，我们需要导入Faust包：
- en: '[PRE42]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We will also need an instance of the default random number generator from the
    NumPy package:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要从NumPy包中运行默认随机数生成器的实例：
- en: '[PRE43]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We will also need to run an instance of a Kafka service on our local machine
    so that our Faust application can interact with the message broker.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要在本地机器上运行Kafka服务的实例，以便我们的Faust应用程序可以与消息代理进行交互。
- en: 'Once you have downloaded Kafka and decompressed the downloaded source, navigate
    to the folder that the Kafka application can be found in. Open this folder in
    the terminal. Start the ZooKeeper server using the following command for Linux
    or Mac:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您下载了Kafka并解压了下载的源代码，就导航到Kafka应用程序所在的文件夹。在终端中打开此文件夹。使用以下命令启动ZooKeeper服务器（适用于Linux或Mac）：
- en: '[PRE44]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'If you''re on Windows, use the following command instead:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用Windows，改用以下命令：
- en: '[PRE45]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Then, in a new terminal, launch the Kafka server using the following command
    for Linux or Mac:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在一个新的终端中，使用以下命令启动Kafka服务器（适用于Linux或Mac）：
- en: '[PRE46]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If you''re on Windows, use the following command instead:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用Windows，改用以下命令：
- en: '[PRE47]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: In each terminal, you should see some logging information that will indicate
    that the server is running.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个终端中，您应该看到一些日志信息，指示服务器正在运行。
- en: How to do it...
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'Follow these steps to create a Faust app that will read (and write) data to
    a Kafka server and do some simple processing:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤创建一个Faust应用程序，该应用程序将读取（和写入）数据到Kafka服务器并进行一些简单的处理：
- en: 'First, we need to create a Faust `App` instance that will act as the interface
    between Python and the Kafka server:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个Faust`App`实例，它将充当Python和Kafka服务器之间的接口：
- en: '[PRE48]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Next, we will create a record type that mimics the data we expect from the
    server:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个记录类型，模拟我们从服务器期望的数据：
- en: '[PRE49]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Now, we''ll add a topic to the Faust `App` object that sets the value type
    to the `Record` class that we just defined:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将向Faust`App`对象添加一个主题，将值类型设置为我们刚刚定义的`Record`类：
- en: '[PRE50]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, we define an agent, which is an asynchronous function wrapped in the `agent`
    decorator on the `App` object:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们定义一个代理，这是一个包装在`App`对象上的`agent`装饰器的异步函数：
- en: '[PRE51]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Next, we define two source functions that will publish records to the Kafka
    server on the sample topic we set up. These are asynchronous functions wrapped
    in the `timer` decorator with an appropriate interval set:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义两个源函数，将记录发布到我们设置的样本主题的Kafka服务器上。这些是异步函数，包装在`timer`装饰器中，并设置适当的间隔：
- en: '[PRE52]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'At the bottom of the file, we start the application''s `main` function:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在文件底部，我们启动应用程序的`main`函数：
- en: '[PRE53]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Now, in a new terminal, we can use the following command to start a worker
    for the application (assuming our application is stored in `working-with-data-streams.py`):'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在一个新的终端中，我们可以使用以下命令启动应用程序的工作进程（假设我们的应用程序存储在`working-with-data-streams.py`中）：
- en: '[PRE54]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'At this stage, you should see some output that''s been generated by the agent
    printed into the terminal, as shown here:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您应该看到代理生成的一些输出被打印到终端中，如下所示：
- en: '[PRE55]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: This will be below some application information that's been generated by Faust.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是由Faust生成的一些应用程序信息的下方。
- en: Press *Ctrl* + *C* to close the worker and make sure to close both the Kafka
    server and the Zookeeper server in the same way.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按下*Ctrl* + *C*关闭工作进程，并确保以相同的方式关闭Kafka服务器和Zookeeper服务器。
- en: How it works...
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This is a very basic example of a Faust application. Ordinarily, we wouldn't
    generate the records and send them through the Kafka server and process them within
    the same app. However, this is fine for the purposes of this demonstration. In
    a production environment, we'd probably connect to a remote Kafka server that
    is connected to multiple sources and publishing to multiple different topics simultaneously.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Faust应用程序的一个非常基本的示例。通常，我们不会生成记录并通过Kafka服务器发送它们，并在同一个应用程序中处理它们。但是，这对于本演示来说是可以的。在生产环境中，我们可能会连接到远程Kafka服务器，该服务器连接到多个来源并同时发布到多个不同的主题。
- en: The Faust app controls the interaction between the Python code and the Kafka
    server. We use the `agent` decorator to add a function to process information
    published to a particular channel. This asynchronous function will be executed
    each time new data is pushed to the sample topic. In this recipe, the agent that
    we defined simply prints the information contained within the `Record` objects
    into the terminal.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Faust应用程序控制Python代码与Kafka服务器之间的交互。我们使用`agent`装饰器添加一个函数来处理发布到特定通道的信息。每当新数据被推送到样本主题时，将执行此异步函数。在这个食谱中，我们定义的代理只是将`Record`对象中包含的信息打印到终端中。
- en: The `timer` decorator defines a service that regularly performs some action
    at a specified interval. In our case, the timer sends a message to the Kafka server
    through the `App` object. These messages are then pushed to the agent for processing.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '`timer`装饰器定义了一个服务，定期在指定的间隔执行某些操作。在我们的情况下，计时器通过`App`对象向Kafka服务器发送消息。然后将这些消息推送给代理进行处理。'
- en: The Faust command-line interface is used to start a worker process running the
    application. These workers are what actually perform the processing in reaction
    to events on the Kafka server or locally in the process, such as the timer services
    defined in this recipe. Larger applications might use several worker processes
    in order to cope with vast quantities of data.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Faust命令行界面用于启动运行应用程序的工作进程。这些工作进程实际上是在Kafka服务器上或本地进程中对事件做出反应的处理者，例如本示例中定义的定时器服务。较大的应用程序可能会使用多个工作进程来处理大量数据。
- en: See also
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 此外
- en: 'The Faust documentation provides far more details about the capabilities of
    Faust, along with various alternatives to Faust: [https://faust.readthedocs.io/en/latest/](https://faust.readthedocs.io/en/latest/).'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Faust文档提供了有关Faust功能的更多详细信息，以及Faust的各种替代方案：[https://faust.readthedocs.io/en/latest/](https://faust.readthedocs.io/en/latest/)。
- en: 'More information about Kafka can be found on the Apache Kafka website: [https://kafka.apache.org/](https://kafka.apache.org/).'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Kafka的更多信息可以在Apache Kafka网站上找到：[https://kafka.apache.org/](https://kafka.apache.org/)。
- en: Accelerating code with Cython
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Cython加速代码
- en: Python is often criticized for being a slow programming language – a statement
    that is endlessly debatable. Many of these criticisms can be addressed by using
    a high-performance compiled library with a Python interface – such as the scientific
    Python stack – to greatly improve performance. However, there are some situations
    where it is difficult to avoid the fact that Python is not a compiled language.
    One way to improve performance in these (fairly rare) situations is to write a
    C extension (or even rewrite the code entirely in C) to speed up the critical
    parts. This will certainly make the code run faster, but it might make it more
    difficult to maintain the package. Instead, we can use Cython, which is an extension
    of the Python language that is transpiled into C and compiled for great performance
    improvements.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: Python经常因为速度慢而受到批评——这是一个无休止的争论。使用具有Python接口的高性能编译库（例如科学Python堆栈）可以解决许多这些批评，从而大大提高性能。然而，在某些情况下，很难避免Python不是编译语言的事实。在这些（相当罕见的）情况下，改善性能的一种方法是编写C扩展（甚至完全重写代码为C）以加速关键部分。这肯定会使代码运行更快，但可能会使维护软件包变得更加困难。相反，我们可以使用Cython，这是Python语言的扩展，可以转换为C并编译以获得更好的性能改进。
- en: 'For example, we can consider some code that''s used to generate an image of
    the Mandelbrot set. For comparison, the pure Python code – which we assume is
    our starting point – is as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以考虑一些用于生成Mandelbrot集图像的代码。为了比较，我们假设纯Python代码——我们假设这是我们的起点——如下所示：
- en: '[PRE56]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The reason why this code is relatively slow in pure Python is fairly obvious:
    the nested loops. For demonstration purposes, let''s assume that we can''t vectorize
    this code using NumPy. A little preliminary testing shows that using these functions
    to generate the Mandelbrot set using 320 × 240 points and 255 steps takes approximately
    6.3 seconds. Your times may vary, depending on your system.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 纯Python中这段代码相对较慢的原因是相当明显的：嵌套循环。为了演示目的，让我们假设我们无法使用NumPy对这段代码进行矢量化。一些初步测试显示，使用这些函数生成Mandelbrot集的320×240点和255步大约需要6.3秒。您的时间可能会有所不同，这取决于您的系统。
- en: In this recipe, we will use Cython to greatly improve the performance of the
    preceding code in order to generate an image of the Mandelbrot set.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用Cython大大提高前面代码的性能，以生成Mandelbrot集图像。
- en: Getting ready
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: For this recipe, we will need the NumPy package and the Cython package to be
    installed. You will also need a C compiler such as GCC installed on your system.
    For example, on Windows, you can obtain a version of GCC by installing MinGW.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们需要安装NumPy包和Cython包。您还需要在系统上安装GCC等C编译器。例如，在Windows上，您可以通过安装MinGW来获取GCC的版本。
- en: How to do it...
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤
- en: 'Follow these steps to use Cython to greatly improve the performance of the
    code for generating an image of the Mandelbrot set:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用Cython大大提高生成Mandelbrot集图像的代码性能：
- en: 'Start a new file called `cython_mandel.pyx` in the `mandelbrot` folder. In
    this file, we will add some simple imports and type definitions:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`mandelbrot`文件夹中创建一个名为`cython_mandel.pyx`的新文件。在这个文件中，我们将添加一些简单的导入和类型定义：
- en: '[PRE57]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Next, we define a new version of the `in_mandel` routine using the Cython syntax.
    We add some declarations to the first few lines of this routine:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用Cython语法定义`in_mandel`例程的新版本。我们在这个例程的前几行添加了一些声明：
- en: '[PRE58]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The rest of the function is identical to the Python version of the function:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 函数的其余部分与Python版本的函数相同：
- en: '[PRE59]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Next, we define a new version of the `compute_mandel` function. We add two
    decorators to this function from the Cython package:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义`compute_mandel`函数的新版本。我们向这个函数添加了Cython包的两个装饰器：
- en: '[PRE60]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Then, we define the constants, just as we did in the original routine:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们像在原始例程中一样定义常量：
- en: '[PRE61]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'We use the `linspace` and `empty` routines from the NumPy package in exactly
    the same way as in the Python version. The only addition here is that we declare
    the `i` and `j` variables, which are of the `Int` type:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用NumPy包中的`linspace`和`empty`例程的方式与Python版本完全相同。这里唯一的添加是我们声明了`i`和`j`变量，它们是`Int`类型的：
- en: '[PRE62]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The remainder of the definition is exactly the same as in the Python version:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义的其余部分与Python版本完全相同：
- en: '[PRE63]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Next, we create a new file called `setup.py` in the `mandelbrot` folder and
    add the following imports to the top of this file:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在`mandelbrot`文件夹中创建一个名为`setup.py`的新文件，并将以下导入添加到此文件的顶部：
- en: '[PRE64]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'After that, we define an extension module with the source pointing to the original
    `python_mandel.py` file. Set the name of this module to `hybrid_mandel`:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们使用指向原始`python_mandel.py`文件的源定义一个扩展模块。将此模块的名称设置为`hybrid_mandel`：
- en: '[PRE65]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Now, we define a second extension module with the source set as the `cython_mandel.pyx`
    file that we just created:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们定义第二个扩展模块，将源设置为刚刚创建的`cython_mandel.pyx`文件：
- en: '[PRE66]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Next, we add both these extension modules to a list and call the `setup` routine
    to register these modules:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将这两个扩展模块添加到列表中，并调用`setup`例程来注册这些模块：
- en: '[PRE67]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Create a new empty file called `__init__.py` in the `mandelbrot` folder to make
    this into a package that can be imported in Python.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`mandelbrot`文件夹中创建一个名为`__init__.py`的新空文件，以便将其转换为可以在Python中导入的包。
- en: 'Open the terminal inside the `mandelbrot` folder and use the following command
    to build the Cython extension modules:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`mandelbrot`文件夹中打开终端，并使用以下命令构建Cython扩展模块：
- en: '[PRE68]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Now, start a new file called `run.py` and add the following import statements:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，开始一个名为`run.py`的新文件，并添加以下导入语句：
- en: '[PRE69]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Import the various `compute_mandel` routines from each of the modules we have
    defined: `python_mandel` for the original; `hybrid_mandel` for the Cythonized
    Python code; and `cython_mandel` for the compiled pure Cython code:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们定义的每个模块中导入各种`compute_mandel`例程：原始的`python_mandel`；Cython化的Python代码`hybrid_mandel`；以及编译的纯Cython代码`cython_mandel`：
- en: '[PRE70]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Define a simple timer decorator that we will use to test the performance of
    the routines:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个简单的计时器装饰器，我们将用它来测试例程的性能：
- en: '[PRE71]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Apply the `timer` decorator to each of the imported routines, and define some
    constants for testing:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`timer`装饰器应用于每个导入的例程，并定义一些用于测试的常量：
- en: '[PRE72]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Run each of the decorated routines with the constants we set previously. Record
    the output of the final call (the Cython version) in the `vals` variable:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用我们之前设置的常量运行每个装饰的例程。将最终调用（Cython版本）的输出记录在`vals`变量中：
- en: '[PRE73]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Finally, plot the output of the Cython version to check that the routine computes
    the Mandelbrot set correctly:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，绘制Cython版本的输出，以检查例程是否正确计算了Mandelbrot集：
- en: '[PRE74]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Running the `run.py` file will print the execution time of each of the routines
    to the terminal, as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`run.py`文件将在终端打印每个例程的执行时间，如下所示：
- en: '[PRE75]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The plot of the Mandelbrot set can be seen in the following image:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: Mandelbrot集的绘图可以在以下图像中看到：
- en: '![](assets/c53ef857-15af-45ab-9dc1-6cd07339285a.png)Figure 10.4: Image of the
    Mandelbrot set computed using Cython code'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/c53ef857-15af-45ab-9dc1-6cd07339285a.png)图10.4：使用Cython代码计算的Mandelbrot集的图像'
- en: This is what we expect for the Mandelbrot set.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们对Mandelbrot集的期望。
- en: How it works...
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: There is a lot happening in this recipe, so let's start by explaining the overall
    process. Cython takes code that is written in an extension of the Python language
    and compiles it into C code, which is then used to produce a C extension library
    that can be imported into a Python session. In fact, you can even use Cython to
    compile ordinary Python code directly to an extension, although the results are
    not as good as when using the modified language. The first few steps in this recipe
    define the new version of the Python code in the modified language (saved as a
    `.pyx` file), which includes type information in addition to the regular Python
    code. In order to build the C extension using Cython, we need to define a setup
    file, and then we create a file that we run to produce the results.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中发生了很多事情，所以让我们从解释整个过程开始。Cython接受用Python语言的扩展编写的代码，并将其编译成C代码，然后用于生成可以导入Python会话的C扩展库。实际上，您甚至可以使用Cython直接将普通Python代码编译为扩展，尽管结果不如使用修改后的语言好。在这个示例中的前几个步骤中，我们在修改后的语言中定义了Python代码的新版本（保存为`.pyx`文件），其中包括类型信息以及常规Python代码。为了使用Cython构建C扩展，我们需要定义一个设置文件，然后创建一个文件来生成结果。
- en: The final compiled version of the Cython code runs considerably faster than
    its Python equivalent. The Cython compiled Python code (hybrid, as we called it
    in this recipe) performs slightly better than the pure Python code. This is because
    the produced Cython code still has to work with Python objects with all of their
    caveats. By adding the typing information to the Python code, in the `.pyx` file,
    we start to see major improvements to performance. This is because the `in_mandel`
    function is now effectively defined as a C-level function that has no interaction
    with Python objects, and instead operates on primitive data types.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: Cython代码的最终编译版本比其Python等效代码运行速度快得多。Cython编译的Python代码（在本示例中称为混合代码）的性能略优于纯Python代码。这是因为生成的Cython代码仍然必须处理带有所有注意事项的Python对象。通过在`.pyx`文件中向Python代码添加类型信息，我们开始看到性能的重大改进。这是因为`in_mandel`函数现在有效地被定义为一个C级别函数，它不与Python对象交互，而是操作原始数据类型。
- en: There are some small, but very important differences, between the Cython code
    and the Python equivalent. In *step 1*, you can see that we imported the NumPy
    package as usual but that we also used the `cimport` keyword to bring some C-level
    definitions into the scope. In *step 2*, we used the `cdef` keyword instead of
    the `def` keyword when we defined the `in_mandel` routine. This means that the
    `in_mandel` routine is defined as a C-level function that cannot be used from
    the Python level, which saves a significant amount of overhead when calling this
    function (which happens a lot).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: Cython代码和Python等效代码之间存在一些小但非常重要的区别。在*步骤1*中，您可以看到我们像往常一样导入了NumPy包，但我们还使用了`cimport`关键字将一些C级别的定义引入了作用域。在*步骤2*中，我们在定义`in_mandel`例程时使用了`cdef`关键字而不是`def`关键字。这意味着`in_mandel`例程被定义为一个C级别函数，不能从Python级别使用，这在调用这个函数时（这经常发生）节省了大量开销。
- en: The only other real differences regarding the definition of this function are
    the inclusion of some type declarations in the signature and in the first few
    lines of the function. The two decorators we applied here disable the checking
    of bounds when accessing elements from a list (array). The `boundscheck` decorator
    disables checking if the index is valid (between 0 and the size of the array),
    while the `wraparound` decorator disables the negative indexing. Both of these
    give a modest improvement to speed during execution, although they disable some
    of the safety features built into Python. In this recipe, it is OK to disable
    these checks because we are using a loop over the valid indices of the array.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个函数定义的唯一其他真正的区别是在签名和函数的前几行中包含了一些类型声明。我们在这里应用的两个装饰器禁用了访问列表（数组）元素时的边界检查。`boundscheck`装饰器禁用了检查索引是否有效（在0和数组大小之间），而`wraparound`装饰器禁用了负索引。尽管它们禁用了Python内置的一些安全功能，但这两个装饰器在执行过程中都会对速度产生适度的改进。在这个示例中，禁用这些检查是可以的，因为我们正在使用循环遍历数组的有效索引。
- en: The setup file is where we tell Python (and therefore Cython) how to build the
    C extension. The `cythonize` routine from Cython is the key here as it triggers
    the Cython build process. In *steps 9* and *10,* we defined extension modules
    using the `Extension` class from `setuptools` so that we could define some extra
    details for the build; specifically, we set an environment variable for the NumPy
    compilation and added the `include` files for the NumPy C headers. This is done
    via the `define_macros` keyword argument for the `Extension` class. The terminal
    command we used in *step 13* uses `setuptools` to build the Cython extensions,
    and the addition of the `--inplace` flat means that the compiled libraries will
    be added to the current directory, rather than being placed in a centralized location.
    This is good for development.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 设置文件是我们告诉Python（因此也是Cython）如何构建C扩展的地方。Cython中的`cythonize`例程在这里起着关键作用，因为它触发了Cython构建过程。在*步骤9*和*10*中，我们使用`setuptools`中的`Extension`类定义了扩展模块，以便我们可以为构建定义一些额外的细节；具体来说，我们为NumPy编译设置了一个环境变量，并添加了NumPy
    C头文件的`include`文件。这是通过`Extension`类的`define_macros`关键字参数完成的。我们在*步骤13*中使用`setuptools`命令来构建Cython扩展，并且添加了`--inplace`选项，这意味着编译后的库将被添加到当前目录，而不是放在一个集中的位置。这对开发来说是很好的。
- en: 'The run script is fairly simple: import the routines from each of the defined
    modules – two of these are actually C extension modules – and time their execution.
    We have to be a little creative with the import aliases and routine names to avoid
    collisions.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本相当简单：从每个定义的模块中导入例程 - 其中两个实际上是C扩展模块 - 并计算它们的执行时间。我们必须在导入别名和例程名称上有一些创造性，以避免冲突。
- en: There's more...
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Cython is a powerful tool for improving the performance of some aspects of your
    code. However, you must always be careful to spend your time wisely while optimizing
    code. Using a profile such as the cProfiler that is provided in the Python Standard
    Library can be used to find the places where performance bottlenecks occur in
    your code. In this recipe, it was fairly obvious where the performance bottleneck
    occurs. Cython is a good remedy to the problem in this case because it involves
    repetitive calls to a function inside a (double) `for` loop. However, it is not
    a universal fix for performance issues and, more often than not, the performance
    of code can be greatly improved by refactoring it so that it makes use of high-performance
    libraries.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: Cython是改进代码性能的强大工具。然而，在优化代码时，您必须始终谨慎地花费时间。使用像Python标准库中提供的cProfiler这样的性能分析工具可以用来找到代码中性能瓶颈出现的地方。在这个示例中，性能瓶颈出现的地方是相当明显的。在这种情况下，Cython是解决问题的良药，因为它涉及对（双重）`for`循环内的函数进行重复调用。然而，它并不是解决性能问题的通用方法，往往情况下，通过重构代码以利用高性能库，可以大大提高代码的性能。
- en: Cython is well integrated with Jupyter notebooks and can be used seamlessly
    in the code blocks of a notebook. Cython is also included in the Anaconda distribution
    of Python, so no additional setup is required for using Cython with Jupyter notebooks
    when it's been installed using the Anaconda distribution.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Cython与Jupyter笔记本集成良好，并且可以无缝地在笔记本的代码块中使用。Cython也包含在Python的Anaconda发行版中，因此在使用Anaconda发行版安装了Cython后，就无需额外设置即可在Jupyter笔记本中使用Cython。
- en: There are alternatives to Cython when it comes to producing compiled code from
    Python. For example, the NumBa package ([http://numba.pydata.org/](http://numba.pydata.org/))
    provides a **just in time** (**JIT**) compiler that optimizes Python code at runtime
    by simply placing a decorator on specific functions. NumBa is designed to work
    with NumPy and other scientific Python libraries and can also be used to leverage
    GPUs to accelerate code.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在从Python生成编译代码时，Cython并不是唯一的选择。例如，NumBa包（[http://numba.pydata.org/](http://numba.pydata.org/)）提供了一个**即时**（**JIT**）编译器，通过简单地在特定函数上放置装饰器来优化Python代码的运行时。NumBa旨在与NumPy和其他科学Python库一起使用，并且还可以用于利用GPU加速代码。
- en: Distributing computing with Dask
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Dask进行分布式计算
- en: Dask is a library that's used for distributing computing across multiple threads,
    processes, or even computers in order to effectively perform computation at a
    huge scale. This can greatly improve performance and throughput, even if you are
    working on a single laptop computer. Dask provides replacements for most of the
    data structures from the Python scientific stack, such as NumPy arrays and Pandas
    DataFrames. These replacements have very similar interfaces, but under the hood,
    they are built for distributed computing so that they can be shared between multiple
    threads, processes, or computers. In many cases, switching to Dask is as simple
    as changing the `import` statement, and possibly adding a couple of extra method
    calls to start concurrent computations.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: Dask是一个用于在多个线程、进程或甚至计算机之间进行分布式计算的库，以有效地进行大规模计算。即使您只是在一台笔记本电脑上工作，这也可以极大地提高性能和吞吐量。Dask提供了Python科学堆栈中大多数数据结构的替代品，如NumPy数组和Pandas
    DataFrames。这些替代品具有非常相似的接口，但在内部，它们是为分布式计算而构建的，以便它们可以在多个线程、进程或计算机之间共享。在许多情况下，切换到Dask就像改变`import`语句一样简单，可能还需要添加一些额外的方法调用来启动并发计算。
- en: In this recipe, we will learn how to use Dask to do some simple computations
    on a DataFrame.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将学习如何使用Dask对DataFrame进行一些简单的计算。
- en: Getting ready
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'For this recipe, we will need to import the `dataframe` module from the Dask
    package. Following the convention set out in the Dask documentation, we will import
    this module under the alias `dd`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，我们需要从Dask包中导入`dataframe`模块。按照Dask文档中的约定，我们将使用别名`dd`导入此模块：
- en: '[PRE76]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: We will also need the `sample.csv` file from the code repository for this chapter.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要这一章的代码库中的`sample.csv`文件。
- en: How to do it...
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Follow these steps to use Dask to perform some computations on a DataFrame
    object:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用Dask对DataFrame对象执行一些计算：
- en: 'First, we need to load the data from `sample.csv` into a Dask `DataFrame`:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要将数据从`sample.csv`加载到Dask的`DataFrame`中：
- en: '[PRE77]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Next, we perform a standard calculation on the columns of the DataFrame:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们对DataFrame的列执行标准计算：
- en: '[PRE78]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Unlike with Pandas DataFrames, the result is not a new DataFrame. The `print`
    statement gives us the following information:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 与Pandas DataFrames不同，结果不是一个新的DataFrame。`print`语句给了我们以下信息：
- en: '[PRE79]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'To actually get the result, we need to use the `compute` method:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要实际获得结果，我们需要使用`compute`方法：
- en: '[PRE80]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The result is now shown as expected:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 结果现在如预期所示：
- en: '[PRE81]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'We compute the means of the final two columns in exactly the same way we would
    with a Pandas DataFrame, but we need to add a call to the `compute` method to
    execute the calculation:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算最后两列的均值的方式与Pandas DataFrame完全相同，但我们需要添加一个调用`compute`方法来执行计算：
- en: '[PRE82]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The result, as printed, is exactly as we expect it to be:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 打印的结果与我们的预期完全一致：
- en: '[PRE83]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: How it works...
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Dask builds a *task graph* for the computation, which describes the relationships
    between the various operations and calculations that need to be performed on the
    collection of data. This breaks down the steps of the calculation so that calculations
    can be done in the right order across the different workers. This task graph is
    then passed into a scheduler that sends the actual tasks to the workers for execution.
    Dask comes with several different schedulers: synchronous, threaded, multiprocessing,
    and distributed. The type of scheduler can be chosen in the call to the `compute`
    method or set globally. Dask will choose a sensible default if one is not given.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: Dask为计算构建了一个*任务图*，描述了需要对数据集合执行的各种操作和计算之间的关系。这样可以将计算步骤分解，以便可以按正确的顺序在不同的工作器之间进行计算。然后将此任务图传递给调度程序，调度程序将实际任务发送给工作器执行。Dask配备了几种不同的调度程序：同步、线程、多进程和分布式。可以在`compute`方法的调用中选择调度程序的类型，或者全局设置。如果没有给出一个合理的默认值，Dask会选择一个合理的默认值。
- en: The synchronous, threaded, and multiprocessing schedulers work on a single machine,
    while the distributed scheduler is for working with a cluster. Dask allows you
    to change between schedulers in a relatively transparent way, although for small
    tasks, you might not get any performance benefits because of the overhead of setting
    up more complicated schedulers.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 同步、线程和多进程调度程序在单台机器上工作，而分布式调度程序用于与集群一起工作。Dask允许您以相对透明的方式在调度程序之间切换，尽管对于小任务，您可能不会因为设置更复杂的调度程序而获得任何性能优势。
- en: The `compute` method is the key to this recipe. The methods that would ordinarily
    perform the computation on Pandas DataFrames now just set up a computation that
    is to be executed through the Dask scheduler. The computation isn't started until
    the `compute` method is called. This is similar to the way that a `Future` is
    returned as a proxy for the result of an asynchronous function call, which isn't
    fulfilled until the computation is complete.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '`compute`方法是这个示例的关键。通常会在Pandas DataFrames上执行计算的方法现在只是设置了一个通过Dask调度程序执行的计算。直到调用`compute`方法之前，计算才会开始。这类似于`Future`作为异步函数调用结果的代理返回，直到计算完成才会实现。'
- en: There's more...
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Dask provides interfaces for NumPy arrays, as well as the DataFrames shown in
    this recipe. There is also a machine learning interface called `dask_ml` that
    exposes similar capabilities to the scikit-learn package. Some external packages,
    such as `xarray`, also have a Dask interface. Dask can also work with GPUs to
    further accelerate computations and load data from remote sources, which is useful
    if the computation is distributed across a cluster.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: Dask提供了NumPy数组的接口，以及本示例中显示的DataFrames。还有一个名为`dask_ml`的机器学习接口，它提供了类似于scikit-learn包的功能。一些外部包，如`xarray`，也有Dask接口。Dask还可以与GPU一起工作，以进一步加速计算并从远程源加载数据，这在计算分布在集群中时非常有用。
