- en: Heterogeneous Computing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异构计算
- en: This chapter will help us to explore the **Graphics Processing Unit** (**GPU**)programming
    techniques through the Python language. The continuous evolution of GPUs is revealing
    how these architectures can bring great benefits to performing complex calculations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将帮助我们通过Python语言探索**图形处理单元**（**GPU**）编程技术。GPU的不断演进揭示了这些架构如何为执行复杂计算带来巨大好处。
- en: GPUs certainly cannot replace CPUs. However, they are a well-structured and
    heterogeneous code that is able to exploit the strengths of both types of processors
    that can, in fact, bring considerable advantages.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: GPU当然不能取代CPU。然而，它们是一个结构良好的异构代码，能够利用两种类型处理器的优势，事实上，可以带来相当大的优势。
- en: We will examine the main development environments for heterogeneous programming,
    namely, the **PyCUDA** and **Numba** environments for **Compute Unified Device
    Architecture** (**CUDA**) and **PyOpenCL** environments, which are for**Open Computing
    Language** (**OpenCL**) frameworks in their Python version.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将研究异构编程的主要开发环境，即**PyCUDA**和**Numba**环境，用于**CUDA**和**PyOpenCL**环境，它们是Python版本的**OpenCL**框架。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Understanding heterogeneous computing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解异构计算
- en: Understanding the GPU architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解GPU架构
- en: Understanding GPU programming
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解GPU编程
- en: Dealing with PyCUDA
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理PyCUDA
- en: Heterogeneous programming with PyCUDA
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyCUDA进行异构编程
- en: Implementing memory management with PyCUDA
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyCUDA实现内存管理
- en: Introducing PyOpenCL
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍PyOpenCL
- en: Building applications with PyOpenCL
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyOpenCL构建应用程序
- en: Element-wise expressions with PyOpenCL
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyOpenCL进行逐元素表达
- en: Evaluating PyOpenCL applications
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估PyOpenCL应用程序
- en: GPU programming with Numba
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Numba进行GPU编程
- en: Let's start with understanding heterogeneous computing in detail.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从详细了解异构计算开始。
- en: Understanding heterogeneous computing
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解异构计算
- en: Over the years, the search for better performance for increasingly complex calculations
    has led to the adoption of new techniques in the use of computers. One of these
    techniques is called *heterogeneous computing*, which aims to cooperate with different
    (or heterogeneous) processors in such a way as to have advantages (in particular)
    in terms of temporal computational efficiency.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，对越来越复杂计算的更好性能的追求导致了在计算机使用方面采用新技术。其中之一称为*异构计算*，旨在以一种有利于时间计算效率的方式与不同（或异构）处理器合作。
- en: In this context, the processor on which the main program is run (generally the
    CPU) is called the *h**ost*, while the coprocessors (for example, the GPUs) are
    called *d**evices*. The latter are generally physically separated from the host and
    manage their own memory space, which is also separated from the host's memory.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，主程序运行的处理器（通常是CPU）被称为“主机”，而协处理器（例如GPU）被称为“设备”。后者通常与主机物理上分离，并管理自己的内存空间，这也与主机的内存分开。
- en: In particular, following significant market demand, the GPU has evolved into
    a highly parallel processor, transforming the GPU from devices for graphics rendering to
    devices for parallelizable and computationally intensive general-purpose calculations.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，受到市场需求的影响，GPU已经演变成高度并行的处理器，将GPU从图形渲染设备转变为可并行化和计算密集型的通用计算设备。
- en: In fact, the use of GPU for tasks other than rendering graphics on the screen
    is called heterogeneous computing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，除了在屏幕上渲染图形之外，使用GPU进行其他任务被称为异构计算。
- en: Finally, the task of good GPU programming is to make the most of the great level
    of parallelism and mathematical capabilities offered by the graphics card, minimizing
    all the disadvantages presented by it, such as the delay of the physical connection
    between the host and device.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，良好的GPU编程任务是充分利用图形卡提供的高级并行性和数学能力，并尽量减少它所带来的所有缺点，例如主机和设备之间的物理连接延迟。
- en: Understanding the GPU architecture
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解GPU架构
- en: A GPU is a specialized CPU/core for vector processing of graphical data to render
    images from polygonal primitives. The task of a good GPU program is to make the
    most of the great level of parallelism and mathematical capabilities offered by
    the graphics card and minimize all the disadvantages presented by it, such as
    the delay in the physical connection between the host and device.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: GPU是用于矢量处理图形数据以从多边形基元渲染图像的专用CPU/核心。良好的GPU程序的任务是充分利用图形卡提供的高级并行性和数学能力，并尽量减少它所带来的所有缺点，例如主机和设备之间的物理连接延迟。
- en: GPUs are characterized by a highly parallel structure that allows you to manipulate
    large datasets in an efficient manner. This feature is combined with rapid improvements
    in hardware performance programs, bringing the attention of the scientific world
    to the possibility of using GPUs for purposes other than just rendering images.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: GPU具有高度并行的结构，可以以高效的方式处理大型数据集。这一特性与硬件性能程序的快速改进相结合，引起了科学界对使用GPU进行除了渲染图像之外的其他用途的关注。
- en: 'A GPU (refer to the following diagram) is composed of several processing units
    called **Streaming Multiprocessors **(**SMs**), which represent the first logic
    level of parallelism. In fact, each SM works simultaneously and independently
    from the others:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: GPU（参见下图）由称为**流多处理器**（**SMs**）的多个处理单元组成，代表了并行逻辑的第一级别。事实上，每个SM同时独立地工作：
- en: '![](assets/12715105-d093-49e4-8e05-cdb976bc755c.png)GPU architecture'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/12715105-d093-49e4-8e05-cdb976bc755c.png)GPU架构'
- en: Each SM is divided into a group of **Streaming Processors** (**SPs**), which
    have a core that can run a thread sequentially. The SP represents the smallest
    unit of execution logic and the level of finer parallelism.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 每个SM被分成一组**流处理器**（**SPs**），具有可以顺序运行线程的核心。SP代表执行逻辑的最小单位和更细粒度的并行级别。
- en: In order to best program this type of architecture, we need to introduce GPU
    programming, which is described in the next section.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最好地编程这种类型的架构，我们需要介绍GPU编程，这将在下一节中描述。
- en: Understanding GPU programming
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解GPU编程
- en: GPUs have become increasingly programmable. In fact, their set of instructions
    has been extended to allow the execution of a greater number of tasks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: GPU已经变得越来越可编程。事实上，它们的指令集已经扩展，允许执行更多的任务。
- en: Today, on a GPU, it is possible to execute classic CPU programming instructions,
    such as cycles and conditions, memory access, and floating-point calculations.
    The two major discrete video card manufacturers—**NVIDIA** and **AMD**—have developed
    their GPU architectures, providing developers with related development environments
    that allow programming in different programming languages, including Python.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，在GPU上，可以执行经典的CPU编程指令，如循环和条件，内存访问和浮点计算。两个主要的独立显卡制造商——**NVIDIA**和**AMD**——已经开发了他们的GPU架构，为开发人员提供了相关的开发环境，允许使用不同的编程语言，包括Python进行编程。
- en: At present, developers have valuable tools for programming software that uses
    GPUs in contexts that aren't purely graphics-related. Among the main development
    environments for heterogeneous computing, we have CUDA and OpenCL.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，开发人员在非纯粹与图形相关的环境中编程使用GPU的软件时，有宝贵的工具。在异构计算的主要开发环境中，我们有CUDA和OpenCL。
- en: Let's now have a look at them in detail.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们详细看一下它们。
- en: CUDA
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA
- en: CUDA is a proprietary hardware architecture of NVIDIA, which also gives its
    name to the related development environment. Currently, CUDA has a pool of hundreds
    of thousands of active developers, which demonstrates the growing interest that
    is developing around this technology in the parallel programming environment.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA是NVIDIA的专有硬件架构，也是相关开发环境的名称。目前，CUDA拥有数十万活跃开发人员，这表明在并行编程环境中对这项技术的兴趣正在增长。
- en: 'CUDA offers extensions for the most commonly used programming languages, including
    Python. The most well known CUDA Python extensions are as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA为最常用的编程语言提供扩展，包括Python。最知名的CUDA Python扩展如下：
- en: PyCUDA ([https://mathema.tician.de/software/PyCUDA/](https://mathema.tician.de/software/pycuda/))
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyCUDA ([https://mathema.tician.de/software/PyCUDA/](https://mathema.tician.de/software/pycuda/))
- en: Numba ([http://numba.pydata.org](http://numba.pydata.org))
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Numba ([http://numba.pydata.org](http://numba.pydata.org))
- en: We'll use these extensions in the coming sections.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中使用这些扩展。
- en: OpenCL
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL
- en: The second protagonist in parallel computing is OpenCL, which (unlike its NVIDIA
    counterpart) is open standard and can be used not only with GPUs of different
    manufacturers but also with microprocessors of different types.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算中的第二个主角是OpenCL，与其NVIDIA对应物不同，它是开放标准，不仅可以与不同制造商的GPU一起使用，还可以与不同类型的微处理器一起使用。
- en: However, OpenCL is a more complete and versatile solution as it does not boast
    the maturity and simplicity of use that CUDA has.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，OpenCL是一个更完整和多功能的解决方案，因为它没有CUDA的成熟和简单易用。
- en: The OpenCL Python extension is PyOpenCL ([https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/)).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL Python扩展是PyOpenCL ([https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/))。
- en: In the following sections, the CUDA and OpenCL programming models will be analyzed
    in their Python extension and will be accompanied by some interesting application
    examples.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，将分析CUDA和OpenCL编程模型及其Python扩展，并附带一些有趣的应用示例。
- en: Dealing with PyCUDA
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理PyCUDA
- en: PyCUDA is a binding library that provides access to CUDA's Python API by Andreas
    Klöckner. The main features include automatic cleanup, which is tied to an object's
    lifetime, thus preventing leaks, convenient abstraction over modules and buffers,
    full access to the driver, and built-in error handling. It is also very light.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA是Andreas Klöckner提供的一个绑定库，通过它可以访问CUDA的Python API。其主要特点包括自动清理，与对象的生命周期相关联，从而防止泄漏，对模块和缓冲区的方便抽象，对驱动程序的完全访问以及内置的错误处理。它也非常轻巧。
- en: The project is open source under the MIT license, the documentation is very
    clear, and many different sources found online can provide help and support. The
    main purpose of PyCUDA is to let a developer invoke CUDA with minimal abstraction
    from Python, and it also supports CUDA metaprogramming and templatization.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目是根据MIT许可证开源的，文档非常清晰，而且在线可以找到许多不同的来源来提供帮助和支持。PyCUDA的主要目的是让开发人员以最小的抽象从Python调用CUDA，并支持CUDA元编程和模板化。
- en: Getting ready
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Please follow the instructions on the Andreas Klöckner home page ([https://mathema.tician.de/software/pycuda/](https://mathema.tician.de/software/pycuda/))
    to install PyCUDA.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照Andreas Klöckner主页上的说明([https://mathema.tician.de/software/pycuda/](https://mathema.tician.de/software/pycuda/))安装PyCUDA。
- en: 'The next programming example has a dual function:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个编程示例具有双重功能：
- en: The first is to verify that PyCUDA is properly installed.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一步是验证PyCUDA是否正确安装。
- en: The second is to read and to print the characteristics of the GPU cards.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二步是读取并打印GPU卡的特性。
- en: How to do it...
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到...
- en: 'Let''s look at the steps, as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照以下步骤进行：
- en: 'With the first instruction, we import the Python driver (that is, `pycuda.driver`)
    to the CUDA library installed on our PC:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过第一条指令，我们导入了Python驱动程序（即`pycuda.driver`）到我们PC上安装的CUDA库：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Initialize CUDA. Note also that the following instruction must be called before
    any other instruction in the `pycuda.driver` module:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化CUDA。还要注意，在`pycuda.driver`模块中的任何其他指令之前必须调用以下指令：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Enumerate the number of GPU cards on the PC:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 枚举PC上的GPU卡数量：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For each of the GPU cards present, print the model name, the computing capability,
    and the total amount of memory on the device in kilobytes:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个存在的GPU卡，打印设备的型号名称、计算能力和设备上的总内存量（以千字节为单位）：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The execution is pretty simple. In the first line of code, `pycuda.driver`
    is imported and then initialized:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 执行非常简单。在第一行代码中，导入并初始化了`pycuda.driver`：
- en: '[PRE4]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `pycuda.driver` module exposes the driver level to the programming interface
    of CUDA, which is more flexible than the CUDA C runtime-level programming interface,
    and it has a few features that are not present in the runtime.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`pycuda.driver`模块公开了CUDA编程接口的驱动级别，比CUDA C运行时级别的编程接口更灵活，并且具有一些运行时中不存在的功能。'
- en: 'Then, it cycles into the `drv.Device.count()` function and, for each GPU card,
    the name of the card and its main characteristics (computing capability and total
    memory) are printed:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它循环进入`drv.Device.count()`函数，并且对于每个GPU卡，都会打印出卡的名称和其主要特征（计算能力和总内存）：
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Execute the following code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下代码：
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'When you''ve done so, the installed GPU will be shown on the screen, as in
    the following example:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，安装的GPU将显示在屏幕上，如下例所示：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There's more...
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The CUDA programming model (and consequently PyCUDA, which is a Python wrapper)
    is implemented through specific extensions to the standard library of the C language.
    These extensions have been created just like function calls in the standard C
    library, allowing a simple approach to a heterogeneous programming model that
    includes the host and device code. The management of the two logical parts is
    done by the `nvcc` compiler.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA编程模型（因此也包括Python包装器PyCUDA）是通过对C语言标准库的特定扩展来实现的。这些扩展就像在标准C库中的函数调用一样创建，允许简单地处理包括主机和设备代码在内的异构编程模型。这两个逻辑部分的管理由`nvcc`编译器完成。
- en: 'Here is a brief description of how this works:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是其简要描述：
- en: '*Separate* device code from the host code.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将*设备代码与主机代码分开。'
- en: '*Invoke* a default compiler (for example, GCC) to compile the host code.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*调用*默认编译器（例如GCC）来编译主机代码。'
- en: '*Build* the device code in binary form (`.cubin` objects) or in assembly form
    (`PTX` objects):'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*构建*设备代码为二进制形式（`.cubin`对象）或汇编形式（`PTX`对象）：'
- en: '![](assets/6c16c259-1075-4eb4-bf70-ad0b6ac78a12.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6c16c259-1075-4eb4-bf70-ad0b6ac78a12.png)'
- en: PyCUDA execution model
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA执行模型
- en: All the preceding steps are performed by PyCUDA during execution, with an increase
    in the application loading time compared to a CUDA application.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA在执行期间执行所有前述步骤，与CUDA应用程序相比，这会增加应用程序的加载时间。
- en: See also
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'The CUDA programming guide is available here: [https://docs.nvidia.com/CUDA/CUDA-c-programming-guide/](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA编程指南可在此处找到：[https://docs.nvidia.com/CUDA/CUDA-c-programming-guide/](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
- en: The PyCUDA documentation is available here: [https://documen.tician.de/PyCUDA/](https://documen.tician.de/pycuda/)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyCUDA文档可在此处找到：[https://documen.tician.de/PyCUDA/](https://documen.tician.de/pycuda/)
- en: Heterogeneous programming with PyCUDA
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyCUDA进行异构编程
- en: The CUDA programming model (and, hence, that of PyCUDA) is designed for the
    joint execution of a software application on a CPU and GPU, in order to perform
    the sequential parts of the application on the CPU and those that can be parallelized
    on the GPU. Unfortunately, the computer is not smart enough to understand how
    to distribute the code autonomously, so it is up to the developer to indicate
    which parts should be run by the CPU and by the GPU.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA编程模型（因此也包括PyCUDA的编程模型）旨在在CPU和GPU上共同执行软件应用程序，以便在CPU上执行应用程序的顺序部分，并在GPU上执行可以并行化的部分。不幸的是，计算机并不足够聪明，无法自主地理解如何分配代码，因此开发人员需要指示哪些部分应由CPU和GPU运行。
- en: In fact, a CUDA application is composed of serial components, which are executed
    by the system CPU or host, or by parallel components called kernels, which are
    executed by the GPU or by the device instead.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，CUDA应用程序由串行组件和并行组件（称为内核）组成，串行组件由系统CPU或主机执行，而并行组件由GPU或设备执行。
- en: A kernel is defined as a *grid* and can, in turn, be decomposed into blocks
    that are sequentially assigned to the various multiprocessors, thus implementing*coarse-grained
    parallelism*. Inside the blocks, there is the fundamental computational unit,
    the thread, with a very *fine parallel granularity*. A thread can belong to only
    one block and is identified by a unique index for the whole kernel. For convenience,
    there is the possibility of using two-dimensional indexes for blocks and three-dimensional
    indexes for threads. The kernels are executed sequentially between them. Blocks
    and threads, on the other hand, are executed in parallel. The number of threads
    running (in parallel) depends on their organization in blocks and on their requests
    in terms of resources, with respect to the resources available in the device.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 内核被定义为*网格*，反过来可以分解为顺序分配给各个多处理器的块，从而实现*粗粒度并行*。在块内部，有一个基本的计算单元，线程，具有非常*细粒度的并行性*。一个线程只能属于一个块，并且由整个内核的唯一索引标识。为了方便起见，可以使用二维索引来表示块，三维索引来表示线程。内核之间是顺序执行的。另一方面，块和线程是并行执行的。运行的线程数量（并行）取决于它们在块中的组织以及它们对资源的请求，与设备中可用的资源相比。
- en: To visualize the concepts expressed previously, please refer to (*Figure 5*)
    at [https://sites.google.com/site/computationvisualization/programming/cuda/article1](https://sites.google.com/site/computationvisualization/programming/cuda/article1).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要可视化先前表达的概念，请参考[https://sites.google.com/site/computationvisualization/programming/cuda/article1](https://sites.google.com/site/computationvisualization/programming/cuda/article1)中的（*图5*）。
- en: The blocks are designed to guarantee scalability. In fact, if you have an architecture
    with two multiprocessors and another with four, then, a GPU application can be
    performed on both architectures, obviously with different times and levels of
    parallelism.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 块的设计旨在保证可伸缩性。事实上，如果您有一个具有两个多处理器的架构和另一个具有四个多处理器的架构，那么GPU应用程序可以在两个架构上执行，显然具有不同的时间和并行级别。
- en: 'The execution of a heterogeneous program according to the PyCUDA programming
    model is thus structured as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 根据PyCUDA编程模型执行异构程序的结构如下：
- en: '*Allocate* memoryon the host.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*在*主机上分配内存。'
- en: '*Transfer* data from the hostmemory to the device memory.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将*数据从主机内存传输到设备内存。'
- en: '*Run* the device through the invocation of the kernel functions.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*通过调用内核函数*运行设备。'
- en: '*Transfer* the results from the device memory to the host memory.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将结果从设备内存传输到主机内存。'
- en: '*Release* the memory allocated on the device.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*释放*在设备上分配的内存。'
- en: 'The following diagram shows the execution flow of a program according to the
    PyCUDA programming model:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了根据PyCUDA编程模型的程序执行流程：
- en: '![](assets/d58c37c0-992d-4f12-b1e3-b152038611bc.png)PyCUDA programming model'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/d58c37c0-992d-4f12-b1e3-b152038611bc.png)PyCUDA编程模型'
- en: In the next example, we will go through a concrete example of the programming
    methodology to follow in order to build PyCUDA applications.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个例子中，我们将通过一个具体的编程方法来构建PyCUDA应用程序。
- en: How to do it...
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'In order to show the PyCUDA programming model, we consider the task of having
    to double all the elements of a 5 × 5 matrix:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示PyCUDA编程模型，我们考虑需要将5×5矩阵的所有元素加倍的任务：
- en: 'We import the libraries needed for the task we want to perform:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入了执行所需的库：
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `numpy` library, which we imported, allows us to construct the input to
    our problem, that is, a 5 × 5 matrix whose values are chosen randomly:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入的`numpy`库允许我们构建问题的输入，即一个5×5矩阵，其值是随机选择的：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The matrix, thus built, must be copied from the memory of the host to the memory
    of the device. For this, we allocate a memory space (`a*_*gpu`) on the device that
    is necessary to contain matrix `a`. For this purpose, we use the `mem_alloc` function,
    which has the allocated memory space as its subject. In particular, the number
    of bytes of matrix `a`, as expressed by the `a.nbytes` parameter, is as follows:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，构建的矩阵必须从主机内存复制到设备内存。为此，我们在设备上分配了一个内存空间（`a*_*gpu`），用于包含矩阵`a`。为此，我们使用了`mem_alloc`函数，其主题是分配的内存空间。特别是，由`a.nbytes`参数表示的矩阵`a`的字节数如下：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After that, we can transfer the matrix from the host to the memory area, created
    specifically on the device by using the `memcpy_htod` function:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们可以使用`memcpy_htod`函数将矩阵从主机传输到设备上专门创建的内存区域：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Inside the device, the `doubleMatrix` kernel function will operate. Its purpose
    will be to multiply each element of the input matrix by `2`. As you can see, the
    syntax of the `doubleMatrix` function is C-like, while the `SourceModule` statement
    is a real directive for the NVIDIA compiler (the `nvcc`compiler), which creates
    a module that, in this case, consists of the `doubleMatrix` function only:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在设备内部，`doubleMatrix`内核函数将运行。它的目的是将输入矩阵的每个元素乘以`2`。正如你所看到的，`doubleMatrix`函数的语法类似于C语言，而`SourceModule`语句是NVIDIA编译器（`nvcc`编译器）的真正指令，它创建了一个模块，这个模块只包含`doubleMatrix`函数：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the `func` parameter, we identify the `doubleMatrix` function, which is
    contained in the`mod` module:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过`func`参数，我们识别了`mod`模块中包含的`doubleMatrix`函数：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, we run the kernel function. In order to successfully execute a kernel
    function on the device, the CUDA user must specify the input for the kernel and
    the size of the execution thread block. In the following case, the input is the
    `a_gpu` matrix that was previously copied to the device, while the dimension of
    the thread block is`(5,5,1)`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们运行内核函数。为了成功地在设备上执行内核函数，CUDA用户必须指定内核的输入和执行线程块的大小。在下面的情况中，输入是先前复制到设备上的`a_gpu`矩阵，而线程块的维度是`(5,5,1)`：
- en: '[PRE14]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Therefore, we allocate an area of memory of size equal to that of the input
    matrix `a`:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们分配了一个大小等于输入矩阵`a`的内存区域：
- en: '[PRE15]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, we copy the contents of the memory area allocated to the device—that
    is, the `a_gpu` matrix—to the previously defined memory area, `a_doubled`:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将分配给设备的内存区域`a_gpu`的内容复制到先前定义的内存区域`a_doubled`中：
- en: '[PRE16]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, we print the contents of the input matrix `a` and the output matrix
    in order to verify the quality of the implementation:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们打印输入矩阵`a`的内容和输出矩阵，以验证实现的质量：
- en: '[PRE17]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How it works...
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s start with looking at which libraries are imported for this example:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看一下为这个例子导入了哪些库：
- en: '[PRE18]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In particular, the `autoinit` import automatically identifies which GPU on our
    system is available for execution, while `SourceModule` is the directive for the
    compiler of NVIDIA (`nvcc`) that allows us to identify the objects that must be
    compiled and uploaded to the device.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，`autoinit`导入自动识别我们系统上可用于执行的GPU，而`SourceModule`是NVIDIA编译器（`nvcc`）的指令，允许我们识别必须编译并上传到设备的对象。
- en: 'Then, we build the 5 × 5 input matrix by using the `numpy` library:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`numpy`库构建了5×5输入矩阵：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In this case, the elements in the matrix are converted to single-precision
    mode (since the graphics card on which this example is executed only supports
    single precision):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，矩阵中的元素被转换为单精度模式（因为执行此示例的图形卡仅支持单精度）：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, we copy the array from the host to the device, using the following two
    operations:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数组从主机复制到设备，使用以下两个操作：
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that the device and host memory may never communicate during the execution
    of a kernel function. For this reason, in order to parallel execute the kernel
    function on the device, all input data relating to the kernel function must also
    be present in the memory of the device.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在执行内核函数期间，设备和主机内存可能永远不会进行通信。因此，为了在设备上并行执行内核函数，与内核函数相关的所有输入数据也必须存在于设备的内存中。
- en: It should also be noted that the `a_gpu` matrix is linearized, that is, it is
    one-dimensional, and therefore we must manage it as such.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 还应该注意，`a_gpu`矩阵是线性化的，即是一维的，因此我们必须对其进行管理。
- en: Moreover, all these operations do not require kernel invocation. This means
    that they are made directly by the host.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，所有这些操作都不需要内核调用。这意味着它们是由主机直接执行的。
- en: 'The `SourceModule` entity allows the definition of the`doubleMatrix` kernel
    function. `__global__`, which is an `nvcc` directive, indicates that the `doubleMatrix`
    function will be processed by the device:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`SourceModule`实体允许定义`doubleMatrix`内核函数。`__global__`是`nvcc`指令，表示`doubleMatrix`函数将由设备处理：'
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s consider the kernel''s body. The `idx` parameter is the matrix index,
    which is identified by the `threadIdx.x` and `threadIdx.y` thread coordinates:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑内核的主体。`idx`参数是矩阵索引，由`threadIdx.x`和`threadIdx.y`线程坐标标识：
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, `mod.get_function("doubleMatrix")` returns an identifier to the `func`
    parameter:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`mod.get_function("doubleMatrix")`返回`func`参数的标识符：
- en: '[PRE24]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In order to execute the kernel, we need to configure the execution context.
    This means setting the three-dimensional structure of the threads that belong
    to the block grid by using the block parameter inside the `func` call:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行内核，我们需要配置执行上下文。这意味着通过在`func`调用内部使用块参数来设置属于块网格的线程的三维结构：
- en: '[PRE25]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`block = (5, 5, 1)` tells us that we are calling a kernel function with the
    `a_gpu` linearized input matrix and a single thread block of size `5` (that is,`5`
    threads) in the *x*-direction, `*5*` threads in the *y*-direction, and 1 thread
    in the *z*-direction, which makes *16* threads in total. Note that each thread
    executes the same kernel code (25 threads in total).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`block = (5, 5, 1)`告诉我们，我们正在调用一个具有`a_gpu`线性化输入矩阵和大小为`5`的单个线程块的内核函数（即在*x*方向上`*5*`个线程，在*y*方向上`*5*`个线程，在*z*方向上1个线程，总共*16*个线程）。请注意，每个线程执行相同的内核代码（总共25个线程）。'
- en: 'After the computation in the GPU device, we use an array to store the results:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPU设备中计算后，我们使用数组来存储结果：
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To run the example, type the following on Command Prompt:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行示例，请在命令提示符上键入以下内容：
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output should be like this:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该是这样的：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: There's more...
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The key feature of CUDA that makes this programming model substantially different
    from other parallel models (normally used on CPUs) is that in order to be efficient,
    it requires thousands of threads to be active. This is made possible by the typical
    structure of GPUs, which use light threads and also allow the creation and modification
    of execution contexts in a very fast and efficient way.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使得CUDA的关键特性与其他并行模型（通常在CPU上使用）根本不同的是，为了高效，它需要成千上万的线程处于活动状态。这是由GPU的典型结构实现的，它使用轻量级线程，并且还允许非常快速和高效地创建和修改执行上下文。
- en: Note that the scheduling of threads is directly linked to the GPU architecture
    and its intrinsic parallelism. In fact, a block of threads is assigned to a single
    SM. Here, the threads are further divided into groups, called warps. The threads
    that belong to the same warp are managed by the *warp scheduler*. To take full
    advantage of the inherent parallelism of the SM, the threads of the same warp
    must execute the same instruction. If this condition does not occur, then we speak
    of *threads divergence.*
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，线程的调度直接与GPU架构及其固有的并行性相关联。事实上，一块线程分配给一个单个SM。在这里，线程进一步分成称为warp的组。属于同一warp的线程由*warp调度程序*管理。为了充分利用SM的固有并行性，同一warp的线程必须执行相同的指令。如果不满足这个条件，我们就称为*线程分歧*。
- en: See also
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'The complete tutorial on using PyCUDA is available at the following site: [https://documen.tician.de/pycuda/tutorial.html](https://documen.tician.de/pycuda/tutorial.html).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关使用PyCUDA的完整教程，请访问以下网站：[https://documen.tician.de/pycuda/tutorial.html](https://documen.tician.de/pycuda/tutorial.html)。
- en: 'To install PyCUDA on Windows 10, take a look at the following link: [https://github.com/kdkoadd/Win10-PyCUDA-Install](https://github.com/kdkoadd/Win10-PyCUDA-Install).'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Windows 10上安装PyCUDA，请查看以下链接：[https://github.com/kdkoadd/Win10-PyCUDA-Install](https://github.com/kdkoadd/Win10-PyCUDA-Install)。
- en: Implementing memory management with PyCUDA
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyCUDA实现内存管理
- en: 'PyCUDA programs should respect the rules dictated by the structure and the
    internal organization of SM that impose constraints on thread performances. In
    fact, the knowledge and the correct use of various types of memory that the GPU
    makes available are fundamental in order to achieve maximum efficiency. In those
    GPU cards, enabled for CUDA use, there are four types of memory, which are as
    follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA程序应遵守由SM的结构和内部组织所规定的对线程性能的限制。事实上，GPU提供的各种类型的内存的知识和正确使用对于实现最大效率至关重要。在那些启用了CUDA使用的GPU卡中，有四种类型的内存，如下所示：
- en: '**Registers**: Each thread is assigned a memory register which only the assigned
    thread can access, even if the threads belong to the same block.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**寄存器**：每个线程被分配一个内存寄存器，只有分配的线程才能访问，即使线程属于同一块。'
- en: '**Shared memory**: Each block has its own shared memory between the threads
    that belong to it. Even this memory is extremely fast.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**共享内存**：每个块都有自己的共享内存，线程属于它。即使这个内存也非常快。'
- en: '**Constant memory**: All threads in a grid have constant access to the memory,
    but can only be accessed in reading. The data present in it persists for the entire
    duration of the application.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常量内存**：网格中的所有线程都可以常量访问内存，但只能读取。其中的数据在整个应用程序的持续时间内存在。'
- en: '**Global memory**: All the threads of the grid, and therefore all the kernels,
    have access to the global memory. Moreover, data persistence is exactly like a
    constant memory:'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局内存**：网格中的所有线程，因此所有内核都可以访问全局内存。此外，数据的持久性与常量内存完全相同：'
- en: '![](assets/b43f49cb-fad9-4e64-8752-610540f62d30.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b43f49cb-fad9-4e64-8752-610540f62d30.png)'
- en: GPU memory model
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: GPU内存模型
- en: Getting ready
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: For best performance, a PyCUDA program must, therefore, make the most of every
    type of memory. In particular, it must make the most of shared memory, minimizing
    access to memory on a global level.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得最佳性能，PyCUDA程序必须充分利用每种类型的内存。特别是，它必须充分利用共享内存，最小化对全局内存的访问。
- en: To do this, the problem domain is typically subdivided so that a single block
    of threads is able to execute its processing in a closed subset of data. In this
    way, the threads operating on the single block will all work together on the same
    shared memory area, optimizing access.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，问题域通常被细分，以便一个线程块能够在一个封闭的数据子集中执行其处理。这样，操作单个块的线程将共同在同一个共享内存区域上工作，优化访问。
- en: 'The basic steps for each thread are as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 每个线程的基本步骤如下：
- en: '*Load* data from global memory to shared memory.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*从全局内存加载数据到共享内存。'
- en: '*Synchronize* all threads of the block so that everyone can read safety positions
    and shared memory filled by other threads.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*同步*块的所有线程，以便每个人都可以安全地读取其他线程填充的位置和共享内存。'
- en: '*Process* the data of the shared memory. Making a new synchronization is necessary
    to ensure that the shared memory has been updated with the results.'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*处理*共享内存的数据。进行新的同步是必要的，以确保共享内存已经更新了结果。'
- en: '*Write* the results in global memory.'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将*结果写入全局内存。'
- en: To clarify this approach, in the following section, we will present an example
    based on the calculation of the product of two matrices.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了澄清这种方法，在接下来的部分中，我们将介绍一个基于计算两个矩阵乘积的示例。
- en: How to do it...
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The following code fragment shows the calculation of the product of two matrices,
    *M×N*, in the standard method, which is based on a sequential approach. Each element
    of the output matrix, `P`, is obtained by taking a row element from matrix `M`,
    and a column element from matrix `N`:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段显示了在标准方法中计算两个矩阵*M×N*的乘积，这是基于顺序方法的。输出矩阵`P`的每个元素都是通过从矩阵`M`中取一个行元素和从矩阵`N`中取一个列元素得到的：
- en: '[PRE29]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In this case, if each thread had been given the task of calculating each element
    of the matrix, then access to the memory would have dominated the execution time
    of the algorithm.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，如果每个线程都被赋予计算矩阵的每个元素的任务，那么对内存的访问将主导算法的执行时间。
- en: 'What we can do is rely on a block of threads to calculate one output submatrix
    at a time. In this way, the threads that access the same memory block cooperate
    to optimize accesses, thereby minimizing the total calculation time:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以依靠一个线程块来计算一个输出子矩阵。这样，访问相同内存块的线程合作优化访问，从而最小化总计算时间：
- en: 'The first step is to load all the necessary modules to implement the algorithm:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是加载实现算法所需的所有模块：
- en: '[PRE30]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, initialize the GPU device:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，初始化GPU设备：
- en: '[PRE31]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We implement `kernel_code_template`, which implements the product of two matrices
    that are respectively indicated with `a` and `b`, while the resulting matrix is
    indicated with the parameter `c`. Note that the `MATRIX_SIZE` parameter will be
    defined in the next step:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实现了`kernel_code_template`，它实现了两个矩阵的乘积，分别用`a`和`b`表示，而结果矩阵用参数`c`表示。注意，`MATRIX_SIZE`参数将在下一步中定义：
- en: '[PRE32]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following parameter will be used to set the dimensions of the matrices.
    In this case, the size is 5 × 5:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下参数将用于设置矩阵的维度。在这种情况下，大小为5×5：
- en: '[PRE33]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We define the two input matrices, `a_cpu`and `b_cpu`, that will contain random
    floating-point values:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义两个输入矩阵，`a_cpu`和`b_cpu`，它们将包含随机浮点值：
- en: '[PRE34]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then, we calculate the product of the two matrices, `a` and `b`, on the host
    device:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在主机设备上计算两个矩阵`a`和`b`的乘积：
- en: '[PRE35]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We allocate memory areas on the device (GPU), equal in size to the input matrices:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在设备（GPU）上分配了与输入矩阵大小相同的内存区域：
- en: '[PRE36]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We allocate a memory area on the GPU, equal in size to the output matrix resulting
    from the product of the two matrices. In this case, the resulting matrix, `c_gpu`,
    will have a size of 5 × 5:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在GPU上分配了一个内存区域，大小与两个矩阵的乘积得到的输出矩阵相同。在这种情况下，得到的矩阵`c_gpu`的大小为5×5：
- en: '[PRE37]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following `kernel_code` redefines `kernel_code_template`, but with the
    `matrix_size` parameter set:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下的`kernel_code`重新定义了`kernel_code_template`，但设置了`matrix_size`参数：
- en: '[PRE38]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The `SourceModule` directive tells `nvcc` (*NVIDIA CUDA Compiler)* that it
    will have to create a module—that is, a collection of functions—containing the previously
    defined `kernel_code`:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SourceModule`指令告诉`nvcc`（*NVIDIA CUDA Compiler*）它将需要创建一个模块，其中包含先前定义的`kernel_code`：'
- en: '[PRE39]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, we take the `MatrixMulKernel` functionfrom the module, `mod`, to which
    we give the name `matrixmul`:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们从模块`mod`中取出`MatrixMulKernel`函数，给它起名为`matrixmul`：
- en: '[PRE40]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We execute the product between two matrices, `a_gpu` and `b_gpu`, resulting
    in the `c_gpu` matrix. The size of the thread block is defined as `MATRIX_SIZE,
    MATRIX_SIZE, 1`:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们执行两个矩阵`a_gpu`和`b_gpu`之间的乘积，得到`c_gpu`矩阵。线程块的大小被定义为`MATRIX_SIZE, MATRIX_SIZE,
    1`：
- en: '[PRE41]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Print the input matrices:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印输入矩阵：
- en: '[PRE42]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'To check the validity of the calculation performed on the GPU, we compare the
    results of the two implementations, which are the one performed on the host device
    (CPU) and the one performed on the device (GPU). To do this, we use the `numpy
    allclose` directive, which verifies that two element-wise arrays are equal within
    a tolerance equal to `1e-05`:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了检查在GPU上执行的计算的有效性，我们比较了两种实现的结果，一种是在主机设备（CPU）上执行的，另一种是在设备（GPU）上执行的。为此，我们使用了`numpy
    allclose`指令，它验证了两个逐元素数组在容差为`1e-05`的情况下是否相等：
- en: '[PRE43]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: How it works...
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s consider the PyCUDA programming workflow. Let''s prepare the input matrix,
    the output matrix, and where to store the results:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑PyCUDA编程工作流程。准备输入矩阵、输出矩阵以及存储结果的位置：
- en: '[PRE44]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then, we transfer these matrices to the GPU device by using the `gpuarray.to_gpu()`
    PyCUDA function:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`gpuarray.to_gpu()` PyCUDA函数将这些矩阵传输到GPU设备：
- en: '[PRE45]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The core of the algorithm is the following kernel function. Let''s remark that
    the `__global__` keyword specifies that this function is a kernel function, which
    means that it will be executed by the device (GPU) following a call from the host
    code (CPU):'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的核心是以下的核函数。需要指出的是，`__global__`关键字指定这个函数是一个核函数，这意味着它将由设备（GPU）执行，而这是在主机代码（CPU）调用后执行的：
- en: '[PRE46]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '`threadIdx.x` and `threadIdy.y` are coordinates that allow the identification
    of the threads in the grid of two-dimensional blocks. Note that the threads within
    the grid block execute the same kernel code but on different pieces of data. If
    we compare the parallel version with the sequential one, then we immediately notice
    that the cycle indexes, *i* and *j*, have been replaced by the `threadIdx.x` and
    `threadIdx.y` indexes.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`threadIdx.x`和`threadIdy.y`是坐标，允许在二维块网格中识别线程。请注意，网格块内的线程执行相同的内核代码，但是在不同的数据片段上。如果我们将并行版本与顺序版本进行比较，那么我们立即注意到循环索引*i*和*j*已被`threadIdx.x`和`threadIdx.y`索引所取代。'
- en: This means that in the parallel version, we will have only one iteration of
    the cycle. In fact, the `MatrixMulKernel` kernel will be executed on a grid of
    dimensions of 5 × 5 parallel threads.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在并行版本中，我们只会有一个循环迭代。实际上，`MatrixMulKernel`内核将在一个5×5并行线程的网格上执行。
- en: 'This condition is expressed in the following diagram:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这个条件在下图中表示：
- en: '![](assets/65aa99d1-d699-4329-883c-543cb7ef15de.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/65aa99d1-d699-4329-883c-543cb7ef15de.png)'
- en: Grid and block of thread organization for the example
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 示例的网格和线程块组织
- en: 'Then, we verify the product computation just by comparing the two resulting
    matrices:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过比较两个结果矩阵来验证产品计算：
- en: '[PRE47]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE48]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: There's more...
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The data allocated in shared memory has limited visibility in the single-threaded
    block. It is easy to see that the PyCUDA programming model adapts to specific
    classes of applications.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在单线程块中，共享内存中分配的数据的可见性有限。很容易看出，PyCUDA编程模型适用于特定类别的应用程序。
- en: In particular, the features that these applications must present concern the
    presence of many mathematical operations, with a high degree of data parallelism
    (that is, the same sequence of operations being repeated on large amounts of data).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是这些应用程序必须具备的特征涉及到许多数学运算，具有高度的数据并行性（即在大量数据上重复相同操作的序列）。
- en: 'The application fields that possess these characteristics all belong to the
    following sciences: cryptography, computational chemistry, and image and signal
    analysis.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 具有这些特征的应用领域都属于以下科学领域：密码学、计算化学以及图像和信号分析。
- en: See also
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: More examples of using PyCUDA can be found at [https://github.com/zamorays/miniCursoPycuda](https://github.com/zamorays/miniCursoPycuda).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在以下链接找到更多使用PyCUDA的示例：[https://github.com/zamorays/miniCursoPycuda](https://github.com/zamorays/miniCursoPycuda)。
- en: Introducing PyOpenCL
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍PyOpenCL
- en: PyOpenCL is a sister project to PyCUDA. It is a binding library that provides
    full access to OpenCL's API from Python and is also by Andreas Klöckner. It features
    many of the same concepts as PyCUDA, including cleanup for out-of-scope objects,
    partial abstraction over data structures, and error handling, all with minimal
    overhead. The project is available under the MIT license; its documentation is
    very good and plenty of guides and tutorials can be found online.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL是PyCUDA的姊妹项目。它是一个绑定库，可以从Python完全访问OpenCL的API，也是由Andreas Klöckner开发的。它具有许多与PyCUDA相同的概念，包括对超出范围对象的清理、对数据结构的部分抽象和错误处理，而且开销很小。该项目在MIT许可下可用；其文档非常好，网上可以找到大量指南和教程。
- en: The main focus of PyOpenCL is to provide a lightweight connection between Python
    and OpenCL, but it also includes support for templates and metaprograms. The flow
    of a PyOpenCL program is almost exactly the same as a C or C++ program for OpenCL.
    The host program prepares the call of the device program, launches it, and then
    waits for the result.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL的主要重点是提供Python和OpenCL之间的轻量级连接，但它还包括对模板和元程序的支持。PyOpenCL程序的流程几乎与OpenCL的C或C++程序完全相同。主机程序准备调用设备程序，启动它，然后等待结果。
- en: Getting ready
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The main reference for the PyOpenCL installation is the Andreas Klöckner home
    page: [https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/).'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL安装的主要参考资料是Andreas Klöckner的主页：[https://mathema.tician.de/software/pyopencl/](https://mathema.tician.de/software/pyopencl/)。
- en: 'If you are using Anaconda, then it is advisable to perform the following steps:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用Anaconda，则建议执行以下步骤：
- en: Install the latest Anaconda distribution with Python 3.7 from the following
    link: [https://www.anaconda.com/distribution/#download-section](https://www.anaconda.com/distribution/#download-section). For
    this section, the Anaconda 2019.07 for Windows Installer has been installed.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下链接安装最新的Anaconda发行版，其中包括Python 3.7：[https://www.anaconda.com/distribution/#download-section](https://www.anaconda.com/distribution/#download-section)。对于本节，已安装了Windows
    Installer的Anaconda 2019.07。
- en: 'Get the PyOpenCL prebuilt binaryfrom Christoph Gohlke from this link: [https://www.lfd.uci.edu/~gohlke/pythonlibs/](https://www.lfd.uci.edu/~gohlke/pythonlibs/).
    Select the right combination of OS and CPython versions. Here, we use `pyopencl-2019.1+cl12-cp37-cp37m-win_amd64.whl`.'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从此链接获取PyOpenCL预构建二进制文件，链接为：[https://www.lfd.uci.edu/~gohlke/pythonlibs/](https://www.lfd.uci.edu/~gohlke/pythonlibs/)。选择正确的OS和CPython版本组合。在这里，我们使用`pyopencl-2019.1+cl12-cp37-cp37m-win_amd64.whl`。
- en: 'Use `pip` to install the previous package. Simply type this in your Anaconda
    Prompt:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pip`来安装之前的软件包。只需在Anaconda Prompt中输入以下内容：
- en: '[PRE49]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '`<directory>` is the folder where the PyOpenCL package is located.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '`<directory>`是PyOpenCL软件包所在的文件夹。'
- en: 'Moreover, the following notation indicates that we are operating on the Anaconda
    Prompt:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下符号表示我们正在使用Anaconda Prompt：
- en: '[PRE50]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: How to do it...
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤如下...
- en: In the following example, we will use a function of PyOpenCL that allows us
    to enumerate the features of the GPU on which it will operate.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将使用PyOpenCL的一个函数来列举它将运行的GPU的特性。
- en: 'The code we implement is very simple and logical:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现的代码非常简单和逻辑：
- en: 'In the first step, we import the `pyopencl` library:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，我们导入`pyopencl`库：
- en: '[PRE51]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We build a function whose output will provide us with the characteristics of
    the GPU hardware in use:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们构建一个函数，其输出将为我们提供正在使用的GPU硬件的特征：
- en: '[PRE52]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'So, we implement the `main` function, which calls thepreviously implemented `print_device_info` function:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们实现了`main`函数，该函数调用了先前实现的`print_device_info`函数：
- en: '[PRE53]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: How it works...
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The following command is used to import the `pyopencl` library:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于导入`pyopencl`库：
- en: '[PRE54]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'This allows us to use the **`get_platforms` **method, which returns a list
    of platform instances, that is, a list of devices in the system:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们可以使用**`get_platforms`**方法，该方法返回一个平台实例列表，即系统中设备的列表：
- en: '[PRE55]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Then, for each device found, the following main features are shown:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于找到的每个设备，显示以下主要特性：
- en: Name and device type
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称和设备类型
- en: Max clock speed
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大时钟速度
- en: Compute units
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算单元
- en: Local/constant/global memory
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地/常量/全局内存
- en: 'The output for this example is as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的输出如下：
- en: '[PRE56]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: There's more...
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: OpenCL is currently managed by the Khronos Group, a non-profit consortium of
    companies that collaborate in defining the specifications of this (and many other)
    standards and compliance parameters for the creation of OpenCL-specific drivers for
    each type of platform.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL目前由Khronos Group管理，这是一个非营利性公司联盟，他们合作定义了这个（以及许多其他）标准的规范和符合参数，用于为每种类型的平台创建特定于OpenCL的驱动程序。
- en: 'These drivers also provide functions for compiling programs that are written
    in the kernel language: these are converted into programs in some form of intermediate
    language that is usually vendor-specific, and then executed on the reference architectures.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这些驱动程序还提供了用于编译使用内核语言编写的程序的函数：这些函数被转换为通常是特定于供应商的某种形式的中间语言中的程序，然后在参考架构上执行。
- en: 'More info on OpenCL can be found at the following link: [https://www.khronos.org/registry/OpenCL/](https://www.khronos.org/registry/OpenCL/).'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 有关OpenCL的更多信息可以在以下链接找到：[https://www.khronos.org/registry/OpenCL/](https://www.khronos.org/registry/OpenCL/)。
- en: See also
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: 'PyOpenCL documentation is available here: [https://documen.tician.de/pyopencl/](https://documen.tician.de/pyopencl/).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyOpenCL文档可在此处找到：[https://documen.tician.de/pyopencl/](https://documen.tician.de/pyopencl/)。
- en: 'One of the best introductions to PyOpenCL, even if somewhat dated, can be found
    at the following link: [http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614](http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614).'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyOpenCL的最佳介绍之一，即使有点过时，可以在以下链接找到：[http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614](http://www.drdobbs.com/open-source/easy-opencl-with-python/240162614)。
- en: Building applications with PyOpenCL
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyOpenCL构建应用程序
- en: The first step in the construction of a program for PyOpenCL is the coding of
    the host application. This is performed on the CPU and has the task of managing
    the possible execution of the kernel on the GPU card (that is, the device).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 为PyOpenCL构建程序的第一步是编写主机应用程序。这是在CPU上执行的，其任务是管理可能在GPU卡（即设备）上执行内核。
- en: A *kernel* is a basic unit of executable code, similar to a C function. It can
    be data-parallel or task-parallel. However, the cornerstone of PyOpenCL is the
    exploitation of parallelism.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '*内核*是可执行代码的基本单位，类似于C函数。它可以是数据并行或任务并行。然而，PyOpenCL的基石是利用并行性。'
- en: A fundamental concept is a *program*, which is a collection of kernels and other
    functions, analogous to dynamic libraries. So, we can group instructions in a
    kernel and group different kernels into a program.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本概念是*程序*，它是一组内核和其他函数，类似于动态库。因此，我们可以将内核中的指令分组，并将不同的内核分组到一个程序中。
- en: Programs can be called from applications. We have the execution queues that
    indicate the order in which the kernels are executed. However, in some cases,
    these can be launched without following the original order.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 程序可以从应用程序中调用。我们有执行队列，指示内核执行的顺序。但是，在某些情况下，这些可以在不遵循原始顺序的情况下启动。
- en: 'We can finally list the fundamental elements for developing an application
    with PyOpenCL:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以列出使用PyOpenCL开发应用程序的基本元素：
- en: '**Device**: This identifies the hardware in which the kernel code is to be
    executed. Note that the PyOpenCL application can be run on both CPU and GPU boards
    (as well as PyCUDA) but also on embedded devices such as**Field-Programmable Gate
    Arrays**(**FPGAs**).'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设备**：这标识了内核代码要在其中执行的硬件。请注意，PyOpenCL应用程序可以在CPU和GPU板上运行（以及PyCUDA），还可以在嵌入式设备（如**可编程门阵列**（**FPGAs**））上运行。'
- en: '**Program**: This is a group of kernels that has the task of selecting which
    kernel must be run on the device.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**程序**：这是一组内核，其任务是选择在设备上运行哪个内核。'
- en: '**Kernel**: Thisis the code to execute on the device. A kernel is a C-like
    function, which means it can be compiled on any device that supports PyOpenCL
    drivers.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内核**：这是要在设备上执行的代码。内核是类似C的函数，这意味着它可以在支持PyOpenCL驱动程序的任何设备上编译。'
- en: '**Command queue**: This orders the execution of kernels on the device.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命令队列**：这在设备上对内核的执行进行排序。'
- en: '**Context**: This is a group of devices that allows devices to receive kernels
    and transfer data.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**：这是一组设备，允许设备接收内核并传输数据。'
- en: 'The following diagram shows how this data structure can work in a host application:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了此数据结构如何在主机应用程序中工作：
- en: '![](assets/60b38941-28e9-4b2f-a920-d59c4f426b1e.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/60b38941-28e9-4b2f-a920-d59c4f426b1e.png)'
- en: PyOpenCL programming model
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: PyOpenCL编程模型
- en: Again, we observe that a program can contain more functions to run on the device
    and that each kernel encapsulates only a single function from the program.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们观察到一个程序可以包含更多的函数在设备上运行，并且每个内核仅封装了程序中的单个函数。
- en: How to do it...
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'In the following example, we show the basic steps to build an application with
    PyOpenCL: the task to be performed is the sum of two vectors. In order to have
    a readable output, we''ll consider two vectors that each have 100 elements: each
    *i-th* element of the resulting vector will be equal to the sum of the *i-th*
    element of**`vector_a`**, plus the *i-th* element of **`vector_b`**:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们展示了使用PyOpenCL构建应用程序的基本步骤：要执行的任务是两个向量的求和。为了有一个可读的输出，我们将考虑每个具有100个元素的两个向量：结果向量的每个第i个元素将等于**`vector_a`**的第i个元素加上**`vector_b`**的第i个元素的和：
- en: 'Let''s start by importing all the necessary libraries:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入所有必要的库开始：
- en: '[PRE57]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We define the size of the vectors to be added, as follows:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义要相加的向量的大小，如下所示：
- en: '[PRE58]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Here, the input vectors, `vector_a` and `vector_b`, are defined:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，定义了输入向量`vector_a`和`vector_b`：
- en: '[PRE59]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'In sequence, we define **`platform`**, **`device`**, **`context`**, and **`queue`**:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们定义**`platform`**、**`device`**、**`context`**和**`queue`**：
- en: '[PRE60]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now, it''s time to organize the memory areas that will contain the input vectors:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候组织将包含输入向量的内存区域了：
- en: '[PRE61]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, we build the application kernel by using the `Program` method:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用`Program`方法构建应用程序内核：
- en: '[PRE62]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Then, we allocate the memory of the resulting matrix:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们分配了结果矩阵的内存：
- en: '[PRE63]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Then, we call the kernel function:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们调用内核函数：
- en: '[PRE64]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The memory space used to store the result is allocated in the host memory area
    *(*`res_np`*)*:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用于存储结果的内存空间在主机内存区域中分配（`res_np`）：
- en: '[PRE65]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Copy the result of the computation into the memory area created:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将计算结果复制到创建的内存区域中：
- en: '[PRE66]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, we print the results:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们打印结果：
- en: '[PRE67]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Then, we perform a simple check in order to verify that the sum operation is
    correct:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们进行了简单的检查，以验证求和操作是否正确：
- en: '[PRE68]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: How it works...
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the following lines, after the relevant import, we define the input vectors*:*
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几行中，在相关的导入之后，我们定义输入向量*：*
- en: '[PRE69]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Each vector contains 100 integer items, which are randomly selected through
    the `numpy` function:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 每个向量包含100个整数项，这些项是通过`numpy`函数随机选择的：
- en: '[PRE70]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Then, we select the platform to achieve the computation by using the `get_platform()` method:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`get_platform()`方法选择平台来进行计算：
- en: '[PRE71]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Then, select the corresponding device. Here, `platform.get_devices()[0]` corresponds
    to the Intel(R) HD Graphics 5500 graphics card:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，选择相应的设备。这里，`platform.get_devices()[0]`对应于Intel(R) HD Graphics 5500显卡：
- en: '[PRE72]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'In the following steps, the context and the queue are defined; PyOpenCL provides
    the method context (device selected) and queue (context selected):'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，定义了上下文和队列；PyOpenCL提供了上下文（选择的设备）和队列（选择的上下文）的方法：
- en: '[PRE73]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'In order to perform the computation in the selected device, the input vector
    is copied to the device''s memory:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在所选设备中执行计算，将输入向量复制到设备的内存中：
- en: '[PRE74]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Then, we prepare the buffer for the resulting vector:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们为结果向量准备缓冲区：
- en: '[PRE75]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Here, the kernel code is defined:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，定义了内核代码：
- en: '[PRE76]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '`vectorSum` is the name of the kernel, and the parameter list defines the data
    types of the input arguments and output data type (both are integer vectors).
    Inside the kernel body, the sum of two vectors is defined in the following steps:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '`vectorSum`是内核的名称，参数列表定义了输入参数和输出数据类型的数据类型（都是整数向量）。在内核主体内，两个向量的和定义如下步骤：'
- en: '*Initialize* the vector''s index: `int gid = get_global_id(0)`.'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*初始化*向量的索引：`int gid = get_global_id(0)`。'
- en: '*Sum* the vector''s components: `res_g[gid] = a_g[gid] + b_g[gid]`.'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*求和*向量的分量：`res_g[gid] = a_g[gid] + b_g[gid]`。'
- en: In OpenCL (hence, in PyOpenCL), the buffers are attached to a context ([https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context](https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context)),
    which are moved to a device once the buffer is used on that device.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在OpenCL（因此在PyOpenCL中），缓冲区附加到上下文（[https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context](https://documen.tician.de/pyopencl/runtime.html#pyopencl.Context)），一旦缓冲区在设备上使用，就会移动到设备上。
- en: 'Finally, we execute `vectorSum` in the device:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在设备中执行`vectorSum`：
- en: '[PRE77]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'To check the result, we use the `assert` statement. This tests the result and
    triggers an error if the condition is false:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查结果，我们使用`assert`语句。这会测试结果，并在条件为假时触发错误：
- en: '[PRE78]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The output should be as follows:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应该如下所示：
- en: '[PRE79]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: There's more...
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In this section, we have seen that the PyOpenCL execution model, like PyCUDA,
    involves a host processor that manages one or more heterogeneous devices. In particular,
    each PyOpenCL command is sent to the devices from the host in the form of source
    code that is defined through the kernel function.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经看到PyOpenCL执行模型，就像PyCUDA一样，涉及一个管理一个或多个异构设备的主机处理器。特别是，每个PyOpenCL命令以源代码的形式从主机发送到设备，该源代码是通过内核函数定义的。
- en: The source code is then loaded into a program object for the reference architecture,
    the program is compiled into the reference architecture, and the kernel object that
    is relative to the program is created.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将源代码加载到参考架构的程序对象中，将程序编译成参考架构，并创建与程序相关的内核对象。
- en: A kernel object can be executed in a variable number of workgroups, creating
    an *n*-dimensional computation matrix that allows it to effectively subdivide
    the workload for a problem in *n*-dimensions (1, 2, or 3) in each workgroup. In
    turn, they are composed of a number of work items that work in parallel.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 内核对象可以在可变数量的工作组中执行，创建一个*n*维计算矩阵，使其能够有效地将问题的工作负载在*n*维（1、2或3）中进行有效划分。这些工作组又由多个并行工作项组成。
- en: Balancing the workload for each workgroup based on the parallel computing capability
    of a device is one of the critical parameters for achieving good application performance.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 根据设备的并行计算能力平衡每个工作组的工作负载是实现良好应用程序性能的关键参数之一。
- en: A wrong balancing of the workload, together with the specific characteristics
    of each device (such as transfer latency, throughput, and bandwidth), can lead
    to a substantial loss of performance or compromise the portability of the code
    when executed without considering any system of dynamic acquisition of information
    in terms of device calculation capacities.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载的错误平衡，以及每个设备的特定特性（如传输延迟、吞吐量和带宽），可能会导致性能的大幅损失，或者在执行时没有考虑任何动态获取设备计算能力信息的系统时，会损害代码的可移植性。
- en: However, the accurate use of these technologies allows us to reach high levels
    of performance by combining the results of the calculation of different computational
    units.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，准确使用这些技术可以通过结合不同计算单元的计算结果来达到高水平的性能。
- en: See also
  id: totrans-345
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: More on PyOpenCL programming can be found at [https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html](https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html).
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 有关PyOpenCL编程的更多信息，请访问[https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html](https://pydanny-event-notes.readthedocs.io/en/latest/PyConPL2012/async_via_pyopencl.html)。
- en: Element-wise expressions with PyOpenCL
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyOpenCL进行逐元素表达式
- en: The element-wise functionality allows us to evaluate kernels on complex expressions
    (which are made of more operands) into a single computational pass.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 逐元素功能允许我们在单个计算步骤中对复杂表达式（由更多操作数组成）进行评估。
- en: Getting started
  id: totrans-349
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门指南
- en: The `ElementwiseKernel (context, argument, operation, name, optional_parameters)` method is
    implemented in PyOpenCL to handle element-wise expressions.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '`ElementwiseKernel(context, argument, operation, name, optional_parameters)`方法在PyOpenCL中实现以处理逐元素表达式。'
- en: 'The main parameters are as follows:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 主要参数如下：
- en: '`context` is the device or the group of devices to which the element-wise operation
    will be executed.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`context`是将执行逐元素操作的设备或设备组。'
- en: '`argument` is a C-like argument list of all the parameters involved in the
    computation.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`argument`是计算中涉及的所有参数的类似C的参数列表。'
- en: '`operation` is a string that represents the operation to perform on the argument
    list.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`operation`是表示要在参数列表上执行的操作的字符串。'
- en: '`name` is the kernel''s name that is associated with`Elementwisekernel`.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`是与`Elementwisekernel`关联的内核名称。'
- en: '`optional_parameters` is not important in this recipe.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optional_parameters`在此示例中并不重要。'
- en: How to do it...
  id: totrans-357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'Here, we consider the task of adding two integer vectors again:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们考虑再次添加两个整数向量的任务：
- en: 'Start importing the relevant libraries:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始导入相关库：
- en: '[PRE80]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Define the context element (`context`) and the command queue (`queue`) :'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义上下文元素（`context`）和命令队列（`queue`）：
- en: '[PRE81]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Here, we set the vector dimension and the space allocation for the input and
    output vectors:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们设置了输入和输出向量的向量维度和空间分配：
- en: '[PRE82]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'We set `elementwiseSum` as the application of `ElementwiseKernel`, and then
    set it to a set of arguments that define the operations to be applied to the input
    vectors:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`elementwiseSum`设置为`ElementwiseKernel`的应用程序，然后将其设置为一组定义要应用于输入向量的操作的参数：
- en: '[PRE83]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Finally, we print the result:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们打印结果：
- en: '[PRE84]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: How it works...
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In the first lines of the script, we import all the requested modules.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 在脚本的前几行中，我们导入了所有请求的模块。
- en: 'In order to initialize the context, we use the `cl.create_some_context()` method.
    This asks the user which context must be used to perform the calculation:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 为了初始化上下文，我们使用`cl.create_some_context()`方法。这会询问用户必须使用哪个上下文来执行计算：
- en: '[PRE85]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Then, we need to instantiate the queue that will receive `ElementwiseKernel`:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要实例化将接收`ElementwiseKernel`的队列：
- en: '[PRE86]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Input and output vectors are instantiated. The input vectors, `vector_a` and
    `vector_b`, are integer vectors of random values obtained using the `random.randint`
    NumPy function. These vectors are then copied into the device by using the PyOpenCL
    statement:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 输入和输出向量被实例化。输入向量`vector_a`和`vector_b`是使用`random.randint` NumPy函数获得的随机值的整数向量。然后使用PyOpenCL语句将这些向量复制到设备中：
- en: '[PRE87]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'In `ElementwiseKernel`, an object is created:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ElementwiseKernel`中，创建了一个对象：
- en: '[PRE88]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Note that all the arguments are in the form of a string formatted as a C argument
    list (they are all integers). The operation is a C-like code snippet that carries
    out the operation, that is, the sum of the input vector elements. The name of
    the function with which the kernel will be compiled is `sum`.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所有参数都以C参数列表的形式的字符串格式化（它们都是整数）。操作是类似C的代码片段，执行操作，即输入向量元素的和。将用于编译内核的函数的名称是`sum`。
- en: 'Finally, we call the `elementwiseSum` function with the arguments defined previously:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用之前定义的参数调用`elementwiseSum`函数：
- en: '[PRE89]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The example ends by printing the input vectors and the result obtained. The
    output looks like this:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 示例最后通过打印输入向量和获得的结果结束。输出如下所示：
- en: '[PRE90]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: There's more...
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'PyCUDA also has element-wise functionality:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: PyCUDA也具有逐元素功能：
- en: '[PRE91]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'This feature has pretty much the same arguments as the function built for PyOpenCL,
    except for the context parameter. The same example this section, which is implemented
    through PyCUDA, has the following listing:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能与为PyOpenCL构建的函数几乎具有相同的参数，除了上下文参数。通过PyCUDA实现的本节中的相同示例具有以下列表：
- en: '[PRE92]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: See also
  id: totrans-389
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In the following link, you'll find interesting examples of PyOpenCL applications: [https://github.com/romanarranz/PyOpenCL](https://github.com/romanarranz/PyOpenCL).
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下链接中，您将找到PyOpenCL应用程序的有趣示例：[https://github.com/romanarranz/PyOpenCL](https://github.com/romanarranz/PyOpenCL)。
- en: Evaluating PyOpenCL applications
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估PyOpenCL应用程序
- en: In this section, we are doing a comparative test of performance between CPU
    and GPU by using the PyOpenCL library.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用PyOpenCL库对CPU和GPU之间的性能进行比较测试。
- en: In fact, before studying the performance of the algorithms to be implemented,
    it is also important to understand the computational advantages offered by the
    computing platform you have.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，在研究要实现的算法的性能之前，了解所拥有的计算平台所提供的计算优势也是很重要的。
- en: Getting started
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门指南
- en: The specific characteristics of a computing system interfere with the computational
    time, and hence they represent an aspect of primary importance.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 计算系统的特定特征会干扰计算时间，因此它们代表了一个非常重要的方面。
- en: 'In the following example, we will perform a test in order to monitor performance
    on such a system:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将进行一项测试，以便监视系统的性能：
- en: 'GPU: GeForce 840 M'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU：GeForce 840 M
- en: 'CPU: Intel Core i7 – 2.40 GHz'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU：Intel Core i7 – 2.40 GHz
- en: 'RAM: 8 GB'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAM：8 GB
- en: How to do it...
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: In the following test, the calculation time of a mathematical operation, as
    the sum of two vectors with floating-point elements, will be evaluated and compared.
    To make the comparison, the same operation will be performed on two separate functions.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下测试中，将评估并比较数学运算的计算时间，例如两个具有浮点元素的向量的求和。为了进行比较，将在两个单独的函数上执行相同的操作。
- en: The first function is computed by the CPU only, while the second function is
    written by using the PyOpenCL library to use the GPU card. The test is performed
    on vectors with a size of 10,000 elements.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个函数仅由CPU计算，而第二个函数是通过使用PyOpenCL库编写的，以使用GPU卡。测试是在大小为10,000个元素的向量上执行的。
- en: 'Here is the code:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是代码：
- en: 'Import the relevant libraries. Note the import of the `time` library to calculate
    the computation times, and the `linalg` library, which is a tool of linear algebra
    tools of the `numpy` library:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关库。注意导入`time`库以计算计算时间，以及`linalg`库，它是`numpy`库的线性代数工具：
- en: '[PRE93]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'Then, we define the input vectors. They both contain `10000` random elements
    of floating-point numbers:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义输入向量。它们都包含`10000`个浮点数的随机元素：
- en: '[PRE94]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'The following function computes the sum of the two vectors working on the CPU
    (host):'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下函数计算两个向量在CPU（主机）上的和：
- en: '[PRE95]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The following function computes the sum of the two vectors working on the GPU
    (device):'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下函数计算两个向量在GPU（设备）上的和：
- en: '[PRE96]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Within the `test_gpu_vector_sum` function, we prepare the memory buffers to
    contain the input vectors and the output vector:'
  id: totrans-412
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`test_gpu_vector_sum`函数中，我们准备内存缓冲区来包含输入向量和输出向量：
- en: '[PRE97]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Still, within the `test_gpu_vector_sum` function, we define the kernel that
    will computerize the sum of the two vectors on the device:'
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，在`test_gpu_vector_sum`函数中，我们定义了将在设备上计算两个向量的和的内核：
- en: '[PRE98]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Then, we reset the `gpu_start_time` variable before starting the calculation.
    After this, we calculate the sum of two vectors and then we evaluate the calculation
    time:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在开始计算之前，我们重置`gpu_start_time`变量。之后，我们计算两个向量的和，然后评估计算时间：
- en: '[PRE99]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Finally, we perform the test, recalling the two functions defined previously:'
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们执行测试，调用之前定义的两个函数：
- en: '[PRE100]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: How it works...
  id: totrans-420
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: As explained previously, the test consists of executing the calculation task,
    both on the CPU via the `test_cpu_vector_sum` function, and then on the GPU via
    the `test_gpu_vector_sum` function.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，测试包括在CPU上通过`test_cpu_vector_sum`函数执行计算任务，然后通过`test_gpu_vector_sum`函数在GPU上执行。
- en: Both functions report the execution time.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 两个函数都报告执行时间。
- en: 'Regarding the testing function on the CPU, `test_cpu_vector_sum`, it consists
    of a double calculation loop on `10000` vector elements:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在CPU上进行测试的函数`test_cpu_vector_sum`，它由对`10000`个向量元素进行双重计算循环组成：
- en: '[PRE101]'
  id: totrans-424
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'The total CPU time is the difference between the following:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 总CPU时间是以下时间之间的差异：
- en: '[PRE102]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'As for the `test_gpu_vector_sum` function, you can see the following by looking
    at the execution kernel:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 至于`test_gpu_vector_sum`函数，通过查看执行内核，可以看到以下内容：
- en: '[PRE103]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: The sum of the two vectors is performed through a single calculation loop.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量的和是通过单个计算循环执行的。
- en: 'The result, as can be imagined, is a substantial reduction in the execution
    time for the `test_gpu_vector_sum` function:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，可以想象，是对`test_gpu_vector_sum`函数执行时间的实质性减少：
- en: '[PRE104]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: Even if the test is not computationally expansive, it provides useful indications
    of the potential of a GPU card.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 即使测试不具有计算上的广泛性，它也提供了有关GPU卡潜力的有用指示。
- en: There's more...
  id: totrans-433
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: OpenCL is a standardized cross-platform API for developing applications that
    exploit parallel computing in heterogeneous systems. The similarities with CUDA
    are remarkable, including everything from the memory hierarchy to the direct correspondence
    between threads and work items.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCL是一个标准化的跨平台API，用于开发利用异构系统中的并行计算的应用程序。与CUDA的相似之处令人瞩目，包括从内存层次结构到线程和工作项之间的直接对应关系。
- en: Even at the programming level, there are many similar aspects and extensions
    with the same functionality.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在编程层面，也有许多相似的方面和具有相同功能的扩展。
- en: However, OpenCL has a much more complex device management model due to its ability
    to support a wide variety of hardware. On the other hand, OpenCL is designed to
    have code portability between products from different manufacturers.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于OpenCL能够支持各种硬件，它具有更复杂的设备管理模型。另一方面，OpenCL旨在实现不同制造商产品之间的代码可移植性。
- en: CUDA, thanks to its greater maturity and dedicated hardware, offers simplified
    device management and higher-level APIs that make it preferable, but only if you
    are dealing with specific architectures (that is, NVIDIA graphic cards).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA由于其更高的成熟度和专用硬件，提供了简化的设备管理和更高级别的API，使其更可取，但前提是您正在处理特定的架构（即NVIDIA显卡）。
- en: The pros and cons of the CUDA and OpenCL libraries, as well as the PyCUDA and
    PyOpenCL libraries, are explained in the following sections.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: CUDA和OpenCL库以及PyCUDA和PyOpenCL库的优缺点在以下部分中进行了解释。
- en: Pros of OpenCL and PyOpenCL
  id: totrans-439
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL和PyOpenCL的优点
- en: 'The pros are as follows:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 优点如下：
- en: They allow the use of heterogeneous systems with different types of microprocessors.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们允许在不同类型的微处理器的异构系统中使用。
- en: The same code runs on different systems.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相同的代码在不同的系统上运行。
- en: Cons of OpenCL and PyOpenCL
  id: totrans-443
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCL和PyOpenCL的缺点
- en: 'The cons are as follows:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点如下：
- en: Complex device management
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂的设备管理
- en: APIs not fully stable
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: APIs不够稳定
- en: Pros of CUDA and PyCUDA
  id: totrans-447
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA和PyCUDA的优点
- en: 'The pros are as follows:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 优点如下：
- en: APIs with very high abstraction levels
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有非常高抽象级别的APIs
- en: Extensions for many programming languages
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多编程语言的扩展
- en: Huge documentation and a very large community
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 庞大的文档和非常庞大的社区
- en: Cons of CUDA and PyCUDA
  id: totrans-452
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CUDA和PyCUDA的缺点
- en: 'The cons are as follows:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点如下：
- en: Supports only the latest NVIDIA GPUs as devices
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅支持最新的NVIDIA GPU作为设备
- en: Reduces heterogeneity to CPUs and GPUs
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少了对CPU和GPU的异构性
- en: See also
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Andreas Klöckner has made a series of lectures on GPU programming with PyCuda
    and PyOpenCL available at [https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/](https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/)
    and [https://www.youtube.com/results?search_query=pyopenCL+and+pycuda](https://www.youtube.com/results?search_query=pyopenCL+and+pycuda).
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: Andreas Klöckner在[https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/](https://www.bu.edu/pasi/courses/gpu-programming-with-pyopencl-and-pycuda/)和[https://www.youtube.com/results?search_query=pyopenCL+and+pycuda](https://www.youtube.com/results?search_query=pyopenCL+and+pycuda)上提供了一系列关于PyCuda和PyOpenCL的GPU编程讲座。
- en: GPU programming with Numba
  id: totrans-458
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Numba进行GPU编程
- en: Numba is a Python compiler that provides CUDA-based APIs. It has been designed
    primarily for numerical computing tasks, just like the NumPy library. In particular,
    the `numba` library manages and processes the array data types provided by NumPy.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: Numba是一个提供基于CUDA的API的Python编译器。它主要设计用于数值计算任务，就像NumPy库一样。特别是，`numba`库管理和处理NumPy提供的数组数据类型。
- en: In fact, the exploitation of data parallelism, which is inherent in numerical
    computation involving arrays, is a natural choice for GPU accelerators.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，利用数据并行性，这是涉及数组的数值计算中固有的选择，对于GPU加速器来说是一个自然的选择。
- en: The Numba compiler works by specifying the signature types (or decorators) for
    Python functions and enabling the compilation at runtime (this type of compilation
    is also called *Just In Time*).
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: Numba编译器通过为Python函数指定签名类型（或装饰器）并在运行时启用编译来工作（这种类型的编译也称为*即时编译*）。
- en: 'The most important decorators are as follows:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的装饰器如下：
- en: '`jit`: This allows the developer to write CUDA-like functions. When encountered,
    the compiler translates the code under the decorator into the pseudo-assembly
    PTX language, so that it can be executed by the GPU.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jit`：这允许开发人员编写类似CUDA的函数。当遇到时，编译器将装饰器下的代码翻译成伪汇编PTX语言，以便GPU执行。'
- en: '`autojit`: This annotates a function for a *deferred compilation* procedure,
    which means that the function with this signature is compiled exactly once.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autojit`：这为*延迟编译*过程注释了一个函数，这意味着具有此签名的函数只编译一次。'
- en: '`vectorize`: This creates a so-called** NumPy Universal Function** (**ufunc**)
    that takes a function and executes it in parallel with vector arguments.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vectorize`：这创建了一个所谓的**NumPy通用函数**（**ufunc**），它接受一个函数并使用矢量参数并行执行它。'
- en: '`guvectorize`: This builds a so-called **NumPy Generalized Universal Function**
    (**gufunc**). A `gufunc` object may operate on entire sub-arrays.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`guvectorize`：这构建了所谓的**NumPy广义通用函数**（**gufunc**）。`gufunc`对象可以操作整个子数组。'
- en: Getting ready
  id: totrans-467
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Numba (release 0.45) is compatible with Python 2.7 and 3.5 or later, as well
    as NumPy versions 1.7 to 1.16.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: Numba（版本0.45）兼容Python 2.7和3.5或更高版本，以及NumPy版本1.7到1.16。
- en: 'To install `numba`, it is recommended as per `pyopencl` to use the Anaconda
    framework, so, from the Anaconda Prompt, just type the following:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`numba`，建议使用Anaconda框架，因此，只需从Anaconda Prompt中输入以下内容：
- en: '[PRE105]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'In addition, to use the full potential of `numba`, the `cudatoolkit` library
    must be installed:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了充分利用`numba`，必须安装`cudatoolkit`库：
- en: '[PRE106]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: After that, it's possible to verify whether the CUDA library and GPU are properly
    detected.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，可以验证CUDA库和GPU是否被正确检测到。
- en: 'Open the Python interpreter from the Anaconda Prompt:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 从Anaconda Prompt打开Python解释器：
- en: '[PRE107]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'The first test entails checking whether the CUDA library (`cudatoolkit`) is
    properly installed:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个测试涉及检查CUDA库（`cudatoolkit`）是否正确安装：
- en: '[PRE108]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'The following output shows the quality of the installation, where all the checks
    returned a positive result:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示了安装的质量，其中所有检查都返回了积极的结果：
- en: '[PRE109]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'In the second test, we verify the presence of a graphics card:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次测试中，我们验证了显卡的存在：
- en: '[PRE110]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'The output shows the graphic card found and whether it is supported:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示找到的显卡以及是否支持它：
- en: '[PRE111]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: How to do it...
  id: totrans-484
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: In this example, we provide a demonstration of the Numba compiler using the `@guvectorize` annotation.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用`@guvectorize`注释演示了Numba编译器的使用。
- en: 'The task to execute is matrix multiplication:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行的任务是矩阵乘法：
- en: 'Import `guvectorize` from the `numba` library and the `numpy` module:'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`numba`库和`numpy`模块导入`guvectorize`：
- en: '[PRE112]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Using the `@guvectorize` decorator, we define the `matmul` function, which
    will perform the matrix multiplication task:'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`@guvectorize`装饰器，我们定义了`matmul`函数，它将执行矩阵乘法任务：
- en: '[PRE113]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'The input matrices are 10 × 10 in size, while the elements are integers:'
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入矩阵的大小为10×10，元素为整数：
- en: '[PRE114]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Finally, we call the `matmul` function on the previously defined input matrices:'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们在之前定义的输入矩阵上调用`matmul`函数：
- en: '[PRE115]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'We print the input matrices and the resulting matrix:'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们打印输入矩阵和结果矩阵：
- en: '[PRE116]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: How it works...
  id: totrans-497
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The `@guvectorize` decorator works on array arguments, taking four arguments in
    order to specify the `gufunc` signature:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '`@guvectorize`装饰器适用于数组参数，按顺序使用四个参数来指定`gufunc`签名：'
- en: The first three arguments specify the types of data to be managed and arrays
    of integers: `void(int64[:,:], int64[:,:], int64[:,:])`.
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前三个参数指定要管理的数据类型和整数数组：`void(int64[:,:], int64[:,:], int64[:,:])`。
- en: The last argument of `@guvectorize` specifies how to manipulate the matrix dimensions: `(m,n),(n,p)->(m,p)`.
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@guvectorize`的最后一个参数指定如何操作矩阵维度：`(m,n),(n,p)->(m,p)`。'
- en: Then, the matrix multiplication operation is defined, where `A` and `B` are
    the input matrices and `C` is the output matrix: *A(m,n)* B(n,p) = C(m,p)*, where *m*, *n*,
    and *p* are the matrix dimensions.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，定义了矩阵乘法操作，其中`A`和`B`是输入矩阵，`C`是输出矩阵：*A(m,n)* B(n,p) = C(m,p)*，其中*m*、*n*和*p*是矩阵维度。
- en: 'The matrix product is performed through three `for` loops along with the matrix
    indices:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘积是通过三个`for`循环以及矩阵索引执行的：
- en: '[PRE117]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'The `randint` NumPy function is used here to build the input matrices of 10
    × 10 dimensions:'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用`randint` NumPy函数构建了10×10维度的输入矩阵：
- en: '[PRE118]'
  id: totrans-505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Finally, the `matmul` function is called with these matrices as arguments,
    and the resultant `C` matrix is printed out:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用这些矩阵作为参数调用 `matmul` 函数，并打印出结果矩阵 `C`：
- en: '[PRE119]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'To execute this example, type the following:'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行此示例，请键入以下内容：
- en: '[PRE120]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'The result shows the two matrices given as input and the matrix resulting from
    their product:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示了输入的两个矩阵以及它们的乘积得到的矩阵：
- en: '[PRE121]'
  id: totrans-511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: There's more...
  id: totrans-512
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Writing an algorithm for a reduction operation using PyCUDA can be quite complex.
    For this purpose, Numba provides the `@reduce` decorator for converting simple
    binary operations into *reduction kernels*.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyCUDA 编写缩减操作的算法可能非常复杂。为此，Numba 提供了 `@reduce` 装饰器，用于将简单的二进制操作转换为*缩减内核*。
- en: 'Reduction operations reduce a set of values to a single value. A typical example
    of a reduction operation is to calculate the sum of all the elements of an array.
    As an example, consider the following array of elements: 1, 2, 3, 4, 5, 6, 7,
    8.'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 缩减操作将一组值缩减为单个值。缩减操作的典型示例是计算数组所有元素的总和。例如，考虑以下元素数组：1, 2, 3, 4, 5, 6, 7, 8。
- en: 'The sequential algorithm operates in the way shown in the diagram, that is,
    adding the elements of the array one after the other:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序算法按照图表中显示的方式运行，即一个接一个地添加数组的元素：
- en: '![](assets/7e5ea317-7653-4c24-96f3-8ea106d866df.png)'
  id: totrans-516
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7e5ea317-7653-4c24-96f3-8ea106d866df.png)'
- en: Sequential sum
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序求和
- en: 'A parallel algorithm operates according to the following schema:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 并行算法按照以下模式运行：
- en: '![](assets/3704575d-6b42-4dc7-b4f9-01093cb44870.png)'
  id: totrans-519
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3704575d-6b42-4dc7-b4f9-01093cb44870.png)'
- en: Parallel sum
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 并行求和
- en: It is clear that the latter has the advantage of shorter execution time.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，后者具有更短的执行时间优势。
- en: 'By using Numba and the `@reduce` decorator, we can write an algorithm, in a
    few lines of code, for the parallel sum on an array of integers ranging from 1
    to 10,000:'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 Numba 和 `@reduce` 装饰器，我们可以编写一个算法，用几行代码对从 1 到 10,000 的整数数组进行并行求和：
- en: '[PRE122]'
  id: totrans-523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'The previous example can be performed by typing the following command:'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过输入以下命令执行前面的示例：
- en: '[PRE123]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'The following result is provided:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 提供以下结果：
- en: '[PRE124]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: See also
  id: totrans-528
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参阅
- en: In the following repository, you can find many examples of Numba: [https://github.com/numba/numba-examples](https://github.com/numba/numba-examples). 
    An interesting introduction to Numba and CUDA programming can be found at [https://nyu-cds.github.io/python-numba/05-cuda/](https://nyu-cds.github.io/python-numba/).
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下存储库中，您可以找到许多 Numba 的示例：[https://github.com/numba/numba-examples](https://github.com/numba/numba-examples)。您可以在[https://nyu-cds.github.io/python-numba/05-cuda/](https://nyu-cds.github.io/python-numba/05-cuda/)找到有关
    Numba 和 CUDA 编程的有趣介绍。
