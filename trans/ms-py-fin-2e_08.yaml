- en: Statistical Analysis of Time Series Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据的统计分析
- en: In financial portfolios, the returns on their constituent assets depend on a
    number of factors, such as macroeconomic and microeconomical conditions, and various
    financial variables. As the number of factors increases, so does the complexity
    involved in modeling portfolio behavior. Given that computing resources are finite,
    coupled with time constraints, performing an extra computation for a new factor
    only increases the bottleneck on portfolio modeling calculations. A linear technique
    for dimensionality reduction is **Principal Component Analysis** (**PCA**). As
    its name suggests, PCA breaks down the movement of portfolio asset prices into
    its principal components, or common factors, for further statistical analysis.
    Common factors that don't explain much of the movement of the portfolio assets
    receive less weighting in their factors and are usually ignored. By keeping the
    most useful factors, portfolio analysis can be greatly simplified without compromising
    on computational time and space costs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融投资组合中，其组成资产的回报取决于许多因素，如宏观和微观经济条件以及各种金融变量。随着因素数量的增加，建模投资组合行为所涉及的复杂性也在增加。鉴于计算资源是有限的，再加上时间限制，为新因素进行额外计算只会增加投资组合建模计算的瓶颈。一种用于降维的线性技术是主成分分析（PCA）。正如其名称所示，PCA将投资组合资产价格的变动分解为其主要成分或共同因素，以进行进一步的统计分析。不能解释投资组合资产变动很多的共同因素在其因素中获得较少的权重，并且通常被忽略。通过保留最有用的因素，可以大大简化投资组合分析，而不会影响计算时间和空间成本。
- en: In statistical analysis of time series data, it is important for the data to
    be stationary in order to avoid spurious regression. Non-stationary data may be
    generated by an underlying process that is affected by a trend, a seasonal effect,
    presence of a unit root, or a combination of all three. The statistical properties
    of non-stationary data, such as mean and variance, changes over time. Non-stationary
    data needs to be transformed into stationary data for statistical analysis to
    produce consistent and reliable results. This can be achieved by removing the
    trend and seasonality components. Stationary data can thereafter be used for prediction
    or forecasting.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列数据的统计分析中，数据保持平稳对于避免虚假回归是很重要的。非平稳数据可能由受趋势影响的基础过程、季节效应、单位根的存在或三者的组合产生。非平稳数据的统计特性，如均值和方差，会随时间变化。非平稳数据需要转换为平稳数据，以便进行统计分析以产生一致和可靠的结果。这可以通过去除趋势和季节性成分来实现。然后可以使用平稳数据进行预测或预测。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Performing PCA on the Dow and its 30 components
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对道琼斯及其30个成分进行主成分分析
- en: Reconstructing the Dow index
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重建道琼斯指数
- en: Understanding the difference between stationary and non-stationary data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解平稳和非平稳数据之间的区别
- en: Checking data for stationarity
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查数据的平稳性
- en: Types of stationary and non-stationary processes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平稳和非平稳过程的类型
- en: Using the Augmented Dickey-Fuller Test to test the presence of a unit root
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用增广迪基-富勒检验来检验单位根的存在
- en: Making stationary data by detrending, differencing, and seasonal decomposing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过去趋势化、差分和季节性分解制作平稳数据
- en: Using an Autoregressive Integrated Moving Average for time series prediction
    and forecasting
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自回归积分移动平均法进行时间序列预测和预测
- en: The Dow Jones industrial average and its 30 components
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 道琼斯工业平均指数及其30个成分
- en: The **Dow Jones Industrial Average** (**DJIA**) is a stock market index that
    comprises the 30 largest US companies. Commonly known as the **Dow**, it is owned
    by S&P Dow Jones Indices LLC and computed on a price-weighted basis (see [https://us.spindices.com/index-family/us-equity/dow-jones-averages](https://us.spindices.com/index-family/us-equity/dow-jones-averages)
    for more information on the Dow).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 道琼斯工业平均指数（DJIA）是由30家最大的美国公司组成的股票市场指数。通常被称为道琼斯，它由S＆P道琼斯指数有限责任公司拥有，并以价格加权的方式计算（有关道琼斯的更多信息，请参见[https://us.spindices.com/index-family/us-equity/dow-jones-averages](https://us.spindices.com/index-family/us-equity/dow-jones-averages)）。
- en: This section involves downloading the datasets of Dow and its components into
    `pandas` DataFrame objects for use in later sections of this chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涉及将道琼斯及其成分的数据集下载到`pandas` DataFrame对象中，以供本章后续部分使用。
- en: Downloading Dow component datasets from Quandl
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Quandl下载道琼斯成分数据集
- en: 'The following code retrieves the Dow component datasets from Quandl. The data
    provider that we will be using is WIKI Prices, a community formed by members of
    the public and that provides datasets free of charge back to the public. Such
    data isn''t free from errors, so please use them with caution. At the time of
    writing, this data feed is no longer supported actively by the Quandl community,
    though past datasets are still available for use. We will download historical
    daily closing prices for 2017:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码从Quandl检索道琼斯成分数据集。我们将使用的数据提供者是WIKI Prices，这是一个由公众成员组成的社区，向公众免费提供数据集。这些数据并非没有错误，因此请谨慎使用。在撰写本文时，该数据源不再受到Quandl社区的积极支持，尽管过去的数据集仍可供使用。我们将下载2017年的历史每日收盘价：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `wiki_symbols` variable contains a list of Quandl codes that we use for
    downloading. Notice that in the parameter arguments of `quandl.get()`, we specified
    `column_index=11`. This tells Quandl to download only the 11th column of each
    dataset, which coincides with the adjusted daily closing prices. The datasets
    are downloaded into our `df_components` variable as a single `pandas` DataFrame
    object.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`wiki_symbols`变量包含我们用于下载的Quandl代码列表。请注意，在`quandl.get()`的参数中，我们指定了`column_index=11`。这告诉Quandl仅下载每个数据集的第11列，这与调整后的每日收盘价相符。数据集以单个`pandas`
    DataFrame对象的形式下载到我们的`df_components`变量中。'
- en: 'Let''s normalize our dataset before using it for analysis:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在分析之前对数据集进行归一化处理：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you inspect every value in this data feed, you will notice `NaN` values,
    or missing data. Since we are using data that is error-prone, and for quick studies
    of PCA, we can temporarily fill in these unknown variables by propagating previous
    observed values. The `fillna(method='ffill')` method helps to do this and stores
    the result in the `filled_df_components` variable.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您检查这个数据源中的每个值，您会注意到`NaN`值或缺失数据。由于我们使用的是容易出错的数据，并且为了快速研究PCA，我们可以通过传播先前观察到的值临时填充这些未知变量。`fillna(method='ffill')`方法有助于执行此操作，并将结果存储在`filled_df_components`变量中。
- en: An additional step in normalizing is to resample the time series at regular
    intervals and match it up exactly with our Dow time series dataset, which we will
    be downloading later. The `daily_df_components` variable stores the result from
    resampling the time series on a daily basis, and any missing values during resampling
    are propagated using the forward fill method. And finally, to account for incomplete
    starting data, we will simply perform a backfill of values with `fillna(method='bfill')`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化的另一个步骤是以固定间隔重新取样时间序列，并将其与我们稍后将要下载的道琼斯时间序列数据集完全匹配。`daily_df_components`变量存储了按日重新取样时间序列的结果，重新取样期间的任何缺失值都使用向前填充方法传播。最后，为了解决起始数据不完整的问题，我们将简单地使用`fillna(method='bfill')`对值进行回填。
- en: For the purpose of PCA demonstration, we have to make do with free, low-quality
    datasets. If you require high quality datasets, consider subscribing to a data
    publisher.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示PCA的目的，我们必须使用免费的低质量数据集。如果您需要高质量的数据集，请考虑订阅数据发布商。
- en: Quandl doesn't provide free datasets on the DJIA. In the next section, we will
    explore another data provider named Alpha Vantage as an alternative method of
    downloading datasets.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Quandl不提供道琼斯工业平均指数的免费数据集。在下一节中，我们将探索另一个名为Alpha Vantage的数据提供商，作为下载数据集的替代方法。
- en: About Alpha Vantage
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于Alpha Vantage
- en: Alpha Vantage ([https://www.alphavantage.co](https://www.alphavantage.co)) is
    a data provider that provides real-time and historical data on equities, foreign
    exchange, and cryptocurrencies. Similar to Quandl, you can obtain a Python wrapper
    for the Alpha Vantage REST API interface and download free datasets directly into
    a `pandas` DataFrame.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Alpha Vantage ([https://www.alphavantage.co](https://www.alphavantage.co))是一个数据提供商，提供股票、外汇和加密货币的实时和历史数据。与Quandl类似，您可以获得Alpha
    Vantage REST API接口的Python包装器，并直接将免费数据集下载到`pandas` DataFrame中。
- en: Obtaining an Alpha Vantage API key
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取Alpha Vantage API密钥
- en: 'From your web browser, visit [https://www.alphavantage.co](https://www.alphavantage.co),
    and click **Get your free API Key today** from the home page. You will be brought
    to a registration page. Fill in basic information about yourself and submit the
    form. Your API key will be shown in the same page. Copy this API key for use in
    the next section:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从您的网络浏览器访问[https://www.alphavantage.co](https://www.alphavantage.co)，并从主页点击**立即获取您的免费API密钥**。您将被带到注册页面。填写关于您自己的基本信息并提交表单。您的API密钥将显示在同一页。复制此API密钥以在下一节中使用：
- en: '![](Images/2c9fad0e-8f40-4aeb-b4ce-4bfba2f743a4.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/2c9fad0e-8f40-4aeb-b4ce-4bfba2f743a4.png)'
- en: Installing the Alpha Vantage Python wrapper
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Alpha Vantage Python包装器
- en: 'From your terminal window, type the following command to install the Python
    module for Alpha Vantage:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从您的终端窗口，输入以下命令以安装Alpha Vantage的Python模块：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Downloading the DJIA dataset from Alpha Vantage
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Alpha Vantage下载道琼斯数据集
- en: 'The following code connects to Alpha Vantage and downloads the Dow dataset,
    with the ticker code `^DJI`. Replace the value of the constant variable, `ALPHA_VANTAGE_API_KEY`,
    with your own API key:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码连接到Alpha Vantage并下载道琼斯数据集，股票代码为`^DJI`。用您自己的API密钥替换常量变量`ALPHA_VANTAGE_API_KEY`的值：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `TimeSeries` class of the `alpha_vantage.timeseries` module is instantiated
    with the API key and specifies that datasets are automatically downloaded as `pandas`
    DataFrame objects. The `get_daily_adjusted()` method with the `outputsize='full'`
    parameter downloads the entire available daily adjusted prices for the given ticker
    symbol in the `df` variable as a `DataFrame` object.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`alpha_vantage.timeseries`模块的`TimeSeries`类是用API密钥实例化的，并指定数据集自动下载为`pandas` DataFrame对象。`get_daily_adjusted()`方法使用`outputsize=''full''`参数下载给定股票符号的整个可用每日调整价格，并将其存储在`df`变量中作为`DataFrame`对象。'
- en: 'Let''s inspect this DataFrame with the `info()` command:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`info()`命令检查一下这个DataFrame：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The Dow dataset that we downloaded from Alpha Vantage gives us the full time
    series data from the most recent available trading date, all the way back to the
    year 2000\. It contains several columns that give us additional information.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从Alpha Vantage下载的道琼斯数据集提供了从最近可用交易日期一直回到2000年的完整时间序列数据。它包含几列给我们额外的信息。
- en: 'Let''s also inspect the indexes of this DataFrame:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也检查一下这个DataFrame的索引：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The outputs suggests that the index values are made up of an object of string
    type. Let''s convert this DataFrame into something suitable for our analysis:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出表明索引值由字符串类型的对象组成。让我们将这个DataFrame转换为适合我们分析的形式：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we are taking the adjusted closing prices of Dow Jones for the year of
    2017, resampled on a daily basis. The resulting DataFrame object is stored in
    `djia_2017`, which we can use for applying PCA.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在获取2017年道琼斯的调整收盘价，按日重新取样。结果的DataFrame对象存储在`djia_2017`中，我们可以用它来应用PCA。
- en: Applying a kernel PCA
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用核PCA
- en: In this section, we will perform kernel PCA to find eigenvectors and eigenvalues
    so that we can reconstruct the Dow index.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将执行核PCA以找到特征向量和特征值，以便我们可以重建道琼斯指数。
- en: Finding eigenvectors and eigenvalues
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找特征向量和特征值
- en: 'We can perform a kernel PCA using the `KernelPCA` class of the `sklearn.decomposition`
    module in Python. The default kernel method is linear. The dataset that''s used
    in PCA is required to be normalized, which we can perform with z-scoring. The
    following code do this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Python的`sklearn.decomposition`模块的`KernelPCA`类执行核PCA。默认的核方法是线性的。在PCA中使用的数据集需要被标准化，我们可以使用z-scoring来实现。以下代码执行此操作：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `fn_z_score` variable is an inline function to perform z-scoring on a `pandas`
    DataFrame, which is applied with the `apply()` method. These normalized datasets
    can be fitted into a kernel PCA with the `fit()` method. The fitted results of
    the daily Dow component prices are stored in the `fitted_pca` variable, which
    is of the same `KernelPCA` object.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`fn_z_score`变量是一个内联函数，用于对`pandas` DataFrame执行z得分，该函数使用`apply()`方法应用。这些归一化的数据集可以使用`fit()`方法拟合到核PCA中。每日道琼斯成分价格的拟合结果存储在`fitted_pca`变量中，该变量是相同的`KernelPCA`对象。'
- en: Two main outputs of PCA are eigenvectors and eigenvalues. **Eigenvectors** are
    vectors containing the direction of the principal component line, which doesn't
    change when a linear transformation is applied. **Eigenvalues** are scalar values
    indicating the amount of variance of the data in a direction with respect to a
    particular eigenvector. In fact, the eigenvector with the highest eigenvalue forms
    the principal component.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: PCA的两个主要输出是特征向量和特征值。**特征向量**是包含主成分线方向的向量，当应用线性变换时不会改变。**特征值**是标量值，指示数据在特定特征向量方向上的方差量。实际上，具有最高特征值的特征向量形成主成分。
- en: 'The `alphas_` and `lambdas_` attributes of the `KernelPCA` object return the
    eigenvectors and eigenvalues of the centered kernel matrix dataset, respectively.
    When we plot the eigenvalues, we get the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`KernelPCA`对象的`alphas_`和`lambdas_`属性返回中心化核矩阵数据集的特征向量和特征值。当我们绘制特征值时，我们得到以下结果：'
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We should then get the following output:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们应该得到以下输出：
- en: '![](Images/1db86b3d-e5bc-44d2-91f2-8557034eac96.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/1db86b3d-e5bc-44d2-91f2-8557034eac96.png)'
- en: 'We can see that the first few eigenvalues explain much of the variances in
    the data, and become more negligent further down the components. Taking the first
    five eigenvalues, let''s see how much explanation each of these eigenvalues gives
    us by obtaining their weighted average values:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，前几个特征值解释了数据中的大部分方差，并且在后面的成分中变得更加忽略。获取前五个特征值，让我们看看每个特征值给我们提供了多少解释：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can see that the first component explains 65% of the variance of the data,
    the second component explains 14%, and so on. Taking the sum of these values,
    we get the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，第一个成分解释了数据方差的65%，第二个成分解释了14%，依此类推。将这些值相加，我们得到以下结果：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The first five eigenvalues would explain 92% of the variance in the dataset.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 前五个特征值将解释数据集方差的92%。
- en: Reconstructing the Dow index with PCA
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PCA重建道琼斯指数
- en: 'By default, the `KernelPCA` is instantiated with the `n_components=None` parameter,
    which constructs a kernel PCA with non-zero components. We can also create a PCA
    index with five components:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`KernelPCA`实例化时使用`n_components=None`参数，这将构建一个具有非零成分的核PCA。我们还可以创建一个具有五个成分的PCA指数：
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: With the `fit()` method, we fitted the normalized dataset using the linear kernel
    PCA function with five components. The `transform()` method transforms the original
    dataset with the kernel PCA. These values are normalized using the weights indicated
    by the eigenvectors, computed with dot matrix multiplication. We then create a
    copy of the Dow time series `pandas` DataFrame with the `copy()` method, and combine
    it with the reconstructed values in the `df_combined` DataFrame.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`fit()`方法，我们使用具有五个成分的线性核PCA函数拟合了归一化数据集。`transform()`方法使用核PCA转换原始数据集。这些值使用由特征向量指示的权重进行归一化，通过点矩阵乘法计算。然后，我们使用`copy()`方法创建了道琼斯时间序列`pandas`
    DataFrame的副本，并将其与`df_combined` DataFrame中的重建值组合在一起。
- en: 'The new DataFrame is normalized by z-scoring, and plotted out to see how well
    the reconstructed PCA index tracks the original Dow movements. This gives us the
    following output:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 新的DataFrame通过z得分进行归一化，并绘制出来，以查看重建的PCA指数跟踪原始道琼斯运动的情况。这给我们以下输出：
- en: '![](Images/eac0f8e9-5056-4623-a021-d4291c231a56.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/eac0f8e9-5056-4623-a021-d4291c231a56.png)'
- en: The preceding graph shows the original Dow index against the reconstructed Dow
    index with five principal components for the year 2017.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图显示了2017年原始道琼斯指数与重建的道琼斯指数相比，使用了五个主成分。
- en: Stationary and non-stationary time series
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平稳和非平稳时间序列
- en: It is important that time series data that's used for statistical analysis is
    stationary in order to perform statistical modeling correctly, as such usages
    may be for prediction and forecasting. This section introduces the concepts of
    stationarity and non-stationarity in time series data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于进行统计分析的时间序列数据，重要的是数据是平稳的，以便正确进行统计建模，因为这样的用途可能是用于预测和预测。本节介绍了时间序列数据中的平稳性和非平稳性的概念。
- en: Stationarity and non-stationarity
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平稳性和非平稳性
- en: In empirical time series studies, price movements are observed to drift toward
    some long-term mean, either upwards or downwards. A stationary time series is
    one whose statistical properties, such as mean, variance, and autocorrelation,
    are constant over time. Conversely, observations on non-stationary time series
    data have their statistical properties change over time, mostly likely due to
    trends, seasonality, presence of a unit root, or a combination of all three.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在经验时间序列研究中，观察到价格变动向某些长期均值漂移，要么向上，要么向下。平稳时间序列是其统计特性（如均值、方差和自相关）随时间保持恒定的时间序列。相反，非平稳时间序列数据的观察结果其统计特性随时间变化，很可能是由于趋势、季节性、存在单位根或三者的组合。
- en: In time series analysis, it is assumed that the data of the underlying process
    is stationary. Otherwise, modeling from non-stationary data may produce unpredictable
    results. This would lead to a condition known as spurious regression. **Spurious
    regression** is a regression that produces misleading statistical evidence of
    relationships between independent non-stationary variables. In order to receive
    consistent and reliable results, non-stationary data needs to be transformed into
    stationary data.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列分析中，假设基础过程的数据是平稳的。否则，对非平稳数据进行建模可能会产生不可预测的结果。这将导致一种称为伪回归的情况。**伪回归**是指产生误导性的统计证据，表明独立的非平稳变量之间存在关系的回归。为了获得一致和可靠的结果，非平稳数据需要转换为平稳数据。
- en: Checking for stationarity
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查平稳性
- en: 'There are a number of ways to check whether time series data is stationary
    or non-stationary:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以检查时间序列数据是平稳还是非平稳：
- en: '**Through visualizations**: You can review a time series graph for obvious
    indication of trends or seasonality.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过可视化**：您可以查看时间序列图，以明显指示趋势或季节性。'
- en: '**Through statistical summaries**: You can review the statistical summaries
    of your data significant differences. For example, you can partition your time
    series data and compare the mean and variance of each group.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过统计摘要**：您可以查看数据的统计摘要，寻找显著差异。例如，您可以对时间序列数据进行分组，并比较每组的均值和方差。'
- en: '**Through statistical tests**: You can use statistical tests such as the Augmented
    Dickey-Fuller Test to check if stationarity expectations have been met or violated.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过统计检验**：您可以使用统计检验，如增广迪基-富勒检验，来检查是否满足或违反了平稳性期望。'
- en: Types of non-stationary processes
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非平稳过程的类型
- en: 'The following points help to identify non-stationary behavior in time series
    data for consideration in transforming stationary data:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几点有助于识别时间序列数据中的非平稳行为，以便考虑转换为平稳数据：
- en: '**Pure random walk**: A process with a unit root or a stochastic trend. It
    is a non-mean reverting process with a variance that evolves over time and goes
    to infinity.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**纯随机游走**：具有单位根或随机趋势的过程。这是一个非均值回归的过程，其方差随时间演变并趋于无穷大。'
- en: '**Random walk with drift**: A process with a random walk and a constant drift.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带漂移的随机游走**：具有随机游走和恒定漂移的过程。'
- en: '**Deterministic trend**: A process with a mean that grows around a fixed trend,
    which is constant and independent of time.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确定性趋势**：均值围绕着固定的趋势增长的过程，该趋势是恒定的且与时间无关。'
- en: '**Random walk with drift and deterministic trend**: A process combining a random
    walk with a drift component, and a deterministic trend.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带漂移和确定性趋势的随机游走**：将随机游走与漂移分量和确定性趋势结合的过程。'
- en: Types of stationary processes
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平稳过程的类型
- en: 'These are a number of definitions of stationarity that you may come across
    in time series studies:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是时间序列研究中可能遇到的平稳性定义：
- en: '**Stationary process**: A process that generates a stationary series of observations.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平稳过程**：生成平稳观测序列的过程。'
- en: '**Trend stationary**: A process that does not exhibit a trend.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**趋势平稳**：不呈现趋势的过程。'
- en: '**Seasonal stationary**: A process that does not exhibit seasonality.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**季节性平稳**：不呈现季节性的过程。'
- en: '**Strictly stationary**: Also known as **strongly stationary**. A process whose
    unconditional joint probability distribution of random variables does not change
    when shifted in time (or along the *x *axis).'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**严格平稳**：也称为**强平稳**。当随机变量的无条件联合概率分布在时间（或*x*轴上）移动时不发生变化的过程。'
- en: '**Weakly stationary**: Also known as **covariance-stationary**, or **second-order
    stationary**. A process whose mean, variance, and correlation of random variables
    doesn''t change when shifted in time.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弱平稳**：也称为**协方差平稳**或**二阶平稳**。当随机变量的均值、方差和相关性在时间移动时不发生变化的过程。'
- en: The Augmented Dickey-Fuller Test
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增广迪基-富勒检验
- en: An **Augmented Dickey-Fuller Test** (**ADF**) is a type of statistical test
    that determines whether a unit root is present in time series data. Unit roots
    can cause unpredictable results in time series analysis. A null hypothesis is
    formed on the unit root test to determine how strongly time series data is affected
    by a trend. By accepting the null hypothesis, we accept the evidence that the
    time series data is non-stationary. By rejecting the null hypothesis, or accepting
    the alternative hypothesis, we accept the evidence that the time series data is
    generated by a stationary process. This process is also known as **trend-stationary.**
    Values of the ADF test statistic are negative. Lower values of ADF indicates stronger
    rejection of the null hypothesis.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**增广迪基-富勒检验**（**ADF**）是一种统计检验，用于确定时间序列数据中是否存在单位根。单位根可能会导致时间序列分析中的不可预测结果。对单位根检验形成零假设，以确定时间序列数据受趋势影响的程度。通过接受零假设，我们接受时间序列数据是非平稳的证据。通过拒绝零假设，或接受备择假设，我们接受时间序列数据是由平稳过程生成的证据。这个过程也被称为**趋势平稳**。增广迪基-富勒检验统计量的值为负数。较低的ADF值表示更强烈地拒绝零假设。'
- en: 'Here are some basic autoregression models for use in ADF testing:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用于ADF测试的一些基本自回归模型：
- en: 'No constant and no trend:'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有常数和趋势：
- en: '![](Images/2177ca63-55d4-40b3-93ae-80a298b53df9.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/2177ca63-55d4-40b3-93ae-80a298b53df9.png)'
- en: 'A constant without a trend:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有常数和趋势：
- en: '![](Images/77f7073a-b720-45a8-b4ca-ab166a427590.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/77f7073a-b720-45a8-b4ca-ab166a427590.png)'
- en: 'With a constant and trend:'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有常数和趋势：
- en: '![](Images/c05c5f00-9d72-463e-ba26-7018a93c8faa.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/c05c5f00-9d72-463e-ba26-7018a93c8faa.png)'
- en: Here, *α* is the drift constant, *β* is the coefficient on a time trend, *γ*
    is the coefficient of our hypothesis, *p* is the lag order of the first-differences
    autoregressive process, and *ϵ[t]* is an independent and identically distributed
    residual term. When *α=0* and *β=0*, the model is a random walk process. When
    *β=0*, the model is a random walk with a drift process. The length of the lag
    *p* is to be chosen so that the residuals are not serially correlated. Some approaches
    for examining the information criteria for choosing lags are by minimizing the
    **Akaike information criterion** (**AIC**), the **Bayesian information criterion**
    (**BIC**), and the **Hannan-Quinn information criterion**.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*α*是漂移常数，*β*是时间趋势的系数，*γ*是我们的假设系数，*p*是一阶差分自回归过程的滞后阶数，*ϵ[t]*是独立同分布的残差项。当*α=0*和*β=0*时，模型是一个随机游走过程。当*β=0*时，模型是一个带漂移的随机游走过程。滞后阶数*p*的选择应使得残差不具有序列相关性。一些选择滞后阶数的信息准则的方法包括最小化**阿卡信息准则**（**AIC**）、**贝叶斯信息准则**（**BIC**）和**汉南-奎恩信息准则**。
- en: 'The hypothesis can then be formulated as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以将假设表述如下：
- en: 'Null hypothesis, *H[0]*: If failed to be rejected, it suggests that the time
    series contains a unit root and is non-stationary'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零假设，*H[0]*：如果未能被拒绝，表明时间序列包含单位根并且是非平稳的
- en: 'Alternate hypothesis, *H[1]*: If *H[0]* is rejected, it suggests that the time
    series does not contain a unit root and is stationary'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备择假设，*H[1]*：如果拒绝*H[0]*，则表明时间序列不包含单位根并且是平稳的
- en: 'To accept or reject the null hypothesis, we use the p-value. We reject the
    null hypothesis if the p-value falls below a threshold value such as 5% or even
    1%. We can fail to reject the null hypothesis if the p-value is above this threshold
    value and consider the time series as non-stationary. In other words, if our threshold
    value is 5%, or 0.05, note the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了接受或拒绝零假设，我们使用p值。如果p值低于5%甚至1%的阈值，我们拒绝零假设。如果p值高于此阈值，我们可能未能拒绝零假设，并将时间序列视为非平稳的。换句话说，如果我们的阈值为5%或0.05，请注意以下内容：
- en: 'p-value > 0.05: We fail to reject the null hypothesis *H[0]* and conclude that
    the data has a unit root and is non-stationary'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: p值> 0.05：我们未能拒绝零假设*H[0]*，并得出结论，数据具有单位根并且是非平稳的
- en: 'p-value ≤ 0.05: We reject the null hypothesis *H[0]* and conclude that the
    data has a unit root and is non-stationary'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: p值≤0.05：我们拒绝零假设*H[0]*，并得出结论，数据具有单位根并且是非平稳的
- en: The `statsmodels` library provides the `adfuller()` function that implements
    this test.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels`库提供了实现此测试的`adfuller()`函数。'
- en: Analyzing a time series with trends
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析具有趋势的时间序列
- en: 'Let''s examine a time series dataset. Take, for example, the prices of gold
    futures traded on the CME. On Quandl, the gold futures continuous contract is
    available for download with the following code: `CHRIS/CME_GC1`. This data is
    curated by the Wiki Continuous Futures community group, taking into account the
    front month contracts only. The sixth column of the dataset contains the settlement
    prices. The following code downloads the dataset from the year 2000 onward:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一个时间序列数据集。例如，考虑在芝加哥商品交易所交易的黄金期货价格。在Quandl上，可以通过以下代码下载黄金期货连续合约：`CHRIS/CME_GC1`。这些数据由维基连续期货社区小组策划，仅考虑了最近的合约。数据集的第六列包含了结算价格。以下代码从2000年开始下载数据集：
- en: '[PRE12]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Examine the head of the dataset using the following command:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令检查数据集的头部：
- en: '[PRE13]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We get the following table:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下表格：
- en: '| **Settle** | **Date** |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| **Settle** | **Date** |'
- en: '| --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **2000-01-31** | 283.2 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **2000-01-31** | 283.2 |'
- en: '| **2000-02-29** | 294.2 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| **2000-02-29** | 294.2 |'
- en: '| **2000-03-31** | 278.4 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| **2000-03-31** | 278.4 |'
- en: '| **2000-04-30** | 274.7 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| **2000-04-30** | 274.7 |'
- en: '| **2000-05-31** | 271.7 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **2000-05-31** | 271.7 |'
- en: 'Compute the rolling mean and standard deviation into the `df_mean` and `df_std`
    variables, respectively, with a window period of one year:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 将滚动均值和标准差计算到`df_mean`和`df_std`变量中，窗口期为一年：
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The `resample()` method helps to ensure that the data is smoothed out on a monthly
    basis, and the `ffill()` method forward fills any missing values.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`resample()`方法有助于确保数据在月度基础上平滑，并且`ffill()`方法向前填充任何缺失值。'
- en: A list of useful common time series frequencies for specifying the `resample()`
    method can be found at [http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases](http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)[.](http://pandas.pydata.org/pandas-docs/stable/timeseries.offset-aliases)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html](http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)找到用于指定`resample()`方法的常见有用时间序列频率列表[.](http://pandas.pydata.org/pandas-docs/stable/timeseries.offset-aliases)
- en: 'Let''s visualize the plot of the rolling mean against the original time series:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化滚动均值与原始时间序列的图表：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We obtain the following output:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得以下输出：
- en: '![](Images/a4bbffb4-80d2-45a3-9f5a-aa1ddb4c9b54.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/a4bbffb4-80d2-45a3-9f5a-aa1ddb4c9b54.png)'
- en: 'Visualizing the rolling standard deviation separately, we get the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 将滚动标准差可视化分开，我们得到以下结果：
- en: '[PRE16]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We obtain the following output:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得以下输出：
- en: '![](Images/0d2dd772-94e7-47dd-a254-4e0613a566e6.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/0d2dd772-94e7-47dd-a254-4e0613a566e6.png)'
- en: 'Using the `statsmodels` module, perform an ADF unit root test on our dataset
    with the `adfuller()` method:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`statsmodels`模块，用`adfuller()`方法对我们的数据集进行ADF单位根检验：
- en: '[PRE17]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `adfuller()` method returns a tuple of seven values. Particularly, we are
    interested in the first, second, and fifth values, which give us the test statistic,
    `p-value`, and a dictionary of critical values, respectively.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`adfuller()`方法返回一个包含七个值的元组。特别地，我们对第一个、第二个和第五个值感兴趣，它们分别给出了检验统计量、`p值`和临界值字典。'
- en: Observe from the plots that the mean and standard deviations swing over time,
    with the mean exhibiting an overall upward trend. The ADF test statistic value
    is more than the critical values (especially at 5%), and the `p-value` is more
    than 0.05\. With these, we cannot reject the null hypothesis that there is a unit
    root and consider that our data is non-stationary.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以观察到，均值和标准差随时间波动，均值呈现总体上升趋势。ADF检验统计值大于临界值（特别是在5%时），`p-value`大于0.05。基于这些结果，我们无法拒绝存在单位根的原假设，并认为我们的数据是非平稳的。
- en: Making a time series stationary
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使时间序列平稳
- en: A non-stationary time series data is likely to be affected by a trend or seasonality.
    Trending time series data has a mean that is not constant over time. Data that
    is affected by seasonality have variations at specific intervals in time. In making
    a time series data stationary, the trend and seasonality effects have to be removed.
    Detrending, differencing, and decomposition are such methods. The resulting stationary
    data is then suitable for statistical forecasting.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 非平稳时间序列数据可能受到趋势或季节性的影响。趋势性时间序列数据的均值随时间不断变化。受季节性影响的数据在特定时间间隔内有变化。在使时间序列数据平稳时，必须去除趋势和季节性影响。去趋势、差分和分解就是这样的方法。然后得到的平稳数据适合进行统计预测。
- en: Let's look at all three methods in detail.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看所有三种方法。
- en: Detrending
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 去趋势
- en: The process of removing a trend line from a non-stationary data is known as
    **detrending**. This involves a transformation step that normalizes large values
    into smaller ones. Examples could be a logarithmic function, a square root function,
    or even a cube root. A further step is to subtract the transformation from the
    moving average.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从非平稳数据中去除趋势线的过程称为**去趋势**。这涉及一个将大值归一化为小值的转换步骤。例如可以是对数函数、平方根函数，甚至是立方根。进一步的步骤是从移动平均值中减去转换值。
- en: 'Let''s perform detrending on the same dataset, `df_settle`, with logarithmic
    transformation and subtracting from the moving average of two periods, as given
    in the following Python code:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对相同的数据集`df_settle`执行去趋势，使用对数变换并从两个周期的移动平均值中减去，如下Python代码所示：
- en: '[PRE18]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `df_log` variable is our transformed `pandas` DataFrame by logarithmic function
    using the `numpy` module, and the `df_detrend` variable contains the detrended
    data. We plot this detrended data to visualize its mean and standard deviation
    over a rolling one-year period.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`df_log`变量是我们使用`numpy`模块的对数函数转换的`pandas` DataFrame，`df_detrend`变量包含去趋势数据。我们绘制这些去趋势数据，以可视化其在滚动一年期间的均值和标准差。'
- en: 'We get the following output:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](Images/10d6a205-d53e-4b5f-8c88-92be573fdd6f.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/10d6a205-d53e-4b5f-8c88-92be573fdd6f.png)'
- en: Observe that the mean and standard deviation do not exhibit a long-term trend.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 观察到均值和标准差没有表现出长期趋势。
- en: 'Looking at the ADF test statistic for the detrended data, we get the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 观察去趋势数据的ADF检验统计量，我们得到以下结果：
- en: '[PRE19]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `p-value` for this detrended data is less than 0.05\. Our ADF test statistic
    is lower than all the critical values. We can reject the null hypothesis and say
    that this data is stationary.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个去趋势数据的`p-value`小于0.05。我们的ADF检验统计量低于所有临界值。我们可以拒绝原假设，并说这个数据是平稳的。
- en: Removing trend by differencing
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过差分去除趋势
- en: 'Differencing involves the difference of time series values with a time lag.
    The first-order difference of the time series is given by the following formula:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 差分涉及将时间序列值与时间滞后进行差分。时间序列的一阶差分由以下公式给出：
- en: '![](Images/99483d9c-05ff-42c5-9824-a96edcbd8c2b.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/99483d9c-05ff-42c5-9824-a96edcbd8c2b.png)'
- en: 'We can reuse the `df_log` variable in the previous section as our logarithmic
    transformed time series, and utilize the `diff()` and `shift()` methods of NumPy
    modules in our differencing, with the following code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重复使用前一节中的`df_log`变量作为我们的对数转换时间序列，并利用NumPy模块的`diff()`和`shift()`方法进行差分，代码如下：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The parameter of `diff()` given as `periods=3` indicates that the dataset is
    shifted by three periods in calculating the differences.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`diff()`的参数`periods=3`表示在计算差异时数据集向后移动三个周期。'
- en: 'This provides the following output:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了以下输出：
- en: '![](Images/145641ad-aa7f-495f-aace-58872e076217.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/145641ad-aa7f-495f-aace-58872e076217.png)'
- en: Observe from the plots that the rolling mean and standard deviation tend to
    change very little over time.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以观察到，滚动均值和标准差随时间变化很少。
- en: 'Looking at our ADF test statistic, we get the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 观察我们的ADF检验统计量，我们得到以下结果：
- en: '[PRE21]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: From the ADF test, the `p-value` for this data is less than 0.05\. Our ADF test
    statistic is lower than the 5% critical value, indicating a 95% confidence level
    that this data is stationary. We can reject the null hypothesis and say that this
    data is stationary.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从ADF检验中，此数据的`p-value`小于0.05。我们的ADF检验统计量低于5%的临界值，表明此数据在95%的置信水平下是平稳的。我们可以拒绝原假设，并说这个数据是平稳的。
- en: Seasonal decomposing
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 季节性分解
- en: Decomposing involves modeling both the trend and seasonality, and then removing
    them. We can use the `statsmodel.tsa.seasonal` module to model a non-stationary
    time series dataset using moving averages and remove its trend and seasonal components.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 分解涉及对趋势和季节性进行建模，然后将它们移除。我们可以使用`statsmodel.tsa.seasonal`模块来使用移动平均模型非平稳时间序列数据，并移除其趋势和季节性成分。
- en: 'By reusing our `df_log` variable containing the logarithm of our dataset from
    the previous section, we get the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重复使用包含先前部分数据集对数的`df_log`变量，我们得到以下结果：
- en: '[PRE22]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `seasonal_decompose()` method of `statsmodels.tsa.seasonal` requires a parameter,
    `freq`, which is an integer value specifying the number of periods per seasonal
    cycle. Since we are using monthly data, we expect 12 periods in a seasonal year.
    The method returns an object with three attributes, mainly the trend and seasonal
    components, as well as the final `pandas` series data with its trend and seasonal
    components removed.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels.tsa.seasonal`的`seasonal_decompose()`方法需要一个参数`freq`，它是一个整数值，指定每个季节周期的周期数。由于我们使用的是月度数据，我们期望每个季节年有12个周期。该方法返回一个对象，主要包括趋势和季节分量，以及最终的`pandas`系列数据，其趋势和季节分量已被移除。'
- en: More information on the `seasonal_decompose()` method of the `statsmodels.tsa.seasonal`
    module can be found at [https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`statsmodels.tsa.seasonal`模块的`seasonal_decompose()`方法的更多信息可以在[https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html)找到。
- en: 'Let''s visualize the different plots by running the following Python code:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下Python代码来可视化不同的图表：
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We get the following graphs:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下图表：
- en: '![](Images/77071b95-4137-43ff-8101-d2b84ffb6c09.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/77071b95-4137-43ff-8101-d2b84ffb6c09.png)'
- en: 'Here, we can see the individual trend and seasonality components being removed
    from the dataset and plotted, and the residuals plotted at the bottom. Let''s
    visualize the statistical properties of our residuals:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到单独的趋势和季节分量从数据集中被移除并绘制，残差在底部绘制。让我们可视化一下我们的残差的统计特性：
- en: '[PRE24]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We get the following graph:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下图表：
- en: '![](Images/9ff7a79e-3d33-4822-9285-692d0f87b6a2.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9ff7a79e-3d33-4822-9285-692d0f87b6a2.png)'
- en: Observe from the plots that the rolling mean and standard deviation tend to
    change very little over time.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中观察到，滚动均值和标准差随时间变化很少。
- en: 'By checking our residual data for stationarity, we get the following:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查我们的残差数据的平稳性，我们得到以下结果：
- en: '[PRE25]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: From the ADF test, the `p-value` for this data is less than 0.05\. Our ADF test
    statistic is lower than all the critical values. We can reject the null hypothesis
    and say that this data is stationary.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 从ADF测试中，这些数据的`p-value`小于0.05。我们的ADF测试统计量低于所有临界值。我们可以拒绝零假设，并说这些数据是平稳的。
- en: Drawbacks of ADF testing
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ADF测试的缺点
- en: 'Here are some considerations when using ADF tests for reliable checking of
    non-stationary data:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用ADF测试可靠检查非平稳数据时，有一些考虑事项：
- en: The ADF test do not truly tell apart between pure and non-unit root generating
    processes. In long-term moving average processes, the ADF tests becomes biased
    in rejecting the null hypothesis. Other stationarity testing methods such as the
    **Kwiatkowski–Phillips–Schmidt–Shin** (**KPSS**) tests and the **Phillips-Perron**
    test take a different approach in treating the presence of unit roots.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ADF测试不能真正区分纯单元根生成过程和非单元根生成过程。在长期移动平均过程中，ADF测试在拒绝零假设方面存在偏差。其他检验平稳性的方法，如**Kwiatkowski–Phillips–Schmidt–Shin**（**KPSS**）检验和**Phillips-Perron**检验，采用了不同的方法来处理单位根的存在。
- en: There is no fixed methodology in determining the lag length *p*. If *p* is too
    small, the remaining serial correlation in the errors may affect the size of the
    test. If *p* is too large, the power of the test will deteriorate. Additional
    consideration is to be given for this lag order.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在确定滞后长度*p*时没有固定的方法。如果*p*太小，剩余误差中的序列相关性可能会影响检验的大小。如果*p*太大，检验的能力将会下降。对于这个滞后阶数，还需要进行额外的考虑。
- en: As deterministic terms are added to the test regressions, the power of unit
    root tests diminishes.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着确定性项被添加到测试回归中，单位根测试的能力减弱。
- en: Forecasting and predicting a time series
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列的预测和预测
- en: In the previous section, we identified non-stationarity in time series data
    and discussed techniques for making time series data stationary. With stationary
    data, we can proceed to perform statistical modeling such as prediction and forecasting.
    Prediction involves generating best estimates of in-sample data. Forecasting involves
    generating best estimates of out-of-sample data. Predicting future values is based
    on previously observed values. One such commonly used method is the Autoregressive
    Integrated Moving Average.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们确定了时间序列数据中的非平稳性，并讨论了使时间序列数据平稳的技术。有了平稳的数据，我们可以进行统计建模，如预测和预测。预测涉及生成样本内数据的最佳估计。预测涉及生成样本外数据的最佳估计。预测未来值是基于先前观察到的值。其中一个常用的方法是自回归积分移动平均法。
- en: About the Autoregressive Integrated Moving Average
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于自回归积分移动平均
- en: 'The **Autoregressive Integrated Moving Average** (**ARIMA**) is a forecasting
    model for stationary time series based on linear regression. As its name suggests,
    it is based on three components:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**自回归积分移动平均**（**ARIMA**）是基于线性回归的平稳时间序列的预测模型。顾名思义，它基于三个组件：'
- en: '**Autoregression** (**AR**): A model that uses the dependency between an observation
    and its lagged values'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自回归**（**AR**）：使用观察和滞后值之间的依赖关系的模型'
- en: '**Integrated** (**I**): The use of differencing an observation with an observation
    from a previous time stamp in making the time series stationary'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**积分**（**I**）：使用差分观察和以前时间戳的观察来使时间序列平稳'
- en: '**Moving average** (**MA**): A model that uses the dependency between an observed
    error term and a combination of previous error terms, *e*[*t*]'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动平均**（**MA**）：使用观察误差项和先前误差项的组合之间的依赖关系的模型，*e*[*t*]'
- en: 'ARIMA models are referenced by the notation *ARIMA(p, d, q)*, which corresponds
    to the parameters of the three components. Non-seasonal ARIMA models can be specified
    by changing the values of *p*, *d*, and *q*, as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ARIMA模型的标记是*ARIMA(p, d, q)*，对应于三个组件的参数。可以通过改变*p*、*d*和*q*的值来指定非季节性ARIMA模型，如下所示：
- en: '**ARIMA**(***p*,0,0**): First-order autoregressive model, notated by *AR(p)*.
    *p* is the lag order, indicating the number of lagged observations in the model.
    For example, *ARIMA(2,0,0)* is *AR(2)* and represented as follows:'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ARIMA**(***p*,0,0**): 一阶自回归模型，用*AR(p)*表示。*p*是滞后阶数，表示模型中滞后观察值的数量。例如，*ARIMA(2,0,0)*是*AR(2)*，表示如下：'
- en: '![](Images/9517941c-16d9-4dfa-9022-9112151baa9c.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9517941c-16d9-4dfa-9022-9112151baa9c.png)'
- en: Here, *ϕ[1]* and *ϕ[2]* are parameters for the model.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*ϕ[1]*和*ϕ[2]*是模型的参数。
- en: '**ARIMA**(**0,*d*,0**): First degree of differencing in the integrated component,
    also known as random walk, notated by *I(d)*. *d* is the degree of differencing,
    indicating the number of times the data have had past values subtracted. For example,
    *ARIMA(0,1,0)* is *I(1)* and represented as follows:'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ARIMA**(**0,*d*,0**): 整合分量中的一阶差分，也称为随机游走，用*I(d)*表示。*d*是差分的程度，表示数据被减去过去值的次数。例如，*ARIMA(0,1,0)*是*I(1)*，表示如下：'
- en: '![](Images/2f918895-6293-475c-bbae-ede1814afb27.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/2f918895-6293-475c-bbae-ede1814afb27.png)'
- en: Here, *μ* is the mean of the seasonal difference.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*μ*是季节差分的均值。
- en: '**ARIMA(0,0,*q*)**: Moving average component, notated by *MA(q)*. The order
    *q* determines the number of terms to be included in the model:'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ARIMA(0,0,*q*)**：移动平均分量，用*MA(q)*表示。阶数*q*决定了模型中要包括的项数：'
- en: '![](Images/9624d155-da2e-4709-99bc-0b0798ca96ac.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9624d155-da2e-4709-99bc-0b0798ca96ac.png)'
- en: Finding model parameters by grid search
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过网格搜索找到模型参数
- en: A grid search, also known as the hyperparameter optimization method, can be
    used to iteratively explore different combinations of parameters for fitting our
    ARIMA model. We can fit a seasonal ARIMA model with the `SARIMAX()` function of
    the `statsmodels` module in each iteration, returning an object of the `MLEResults`
    class. The `MLEResults` object holds an `aic` attribute for returning the AIC value.
    The model with the lowest AIC value gives us the best-fitting model that determines
    our parameters of *p*, *d*, and *q*. More information on SARIMAX can be found
    at [https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索，也称为超参数优化方法，可用于迭代地探索不同的参数组合，以拟合我们的ARIMA模型。我们可以在每次迭代中使用`statsmodels`模块的`SARIMAX()`函数拟合季节性ARIMA模型，返回一个`MLEResults`类的对象。`MLEResults`对象具有一个`aic`属性，用于返回AIC值。具有最低AIC值的模型为我们提供了最佳拟合模型，确定了我们的*p*、*d*和*q*参数。有关SARIMAX的更多信息，请访问[https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html)。
- en: 'We define the grid search procedure as the `arima_grid_search()` function,
    as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将网格搜索过程定义为`arima_grid_search()`函数，如下所示：
- en: '[PRE26]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Our variable, `df_settle`, holds the monthly prices of the futures data that
    we downloaded in the previous section. In the **SARIMAX (seasonal autoregressive
    integrated moving average with exogenous regressors model)** function, we provided
    the `seasonal_order` parameter, which is the *ARIMA(p,d,q,s)* seasonal component,
    where *s* is the number of periods in a season of the dataset. Since we are using
    monthly data, we use 12 periods to define a seasonal pattern. The `enforce_stationarity=False`
    parameter doesn't transform the AR parameters to enforce stationarity in the AR
    component of the model. The `enforce_invertibility=False` parameter doesn't transform
    MA parameters to enforce invertibility in the MA component of the model. The `disp=False`
    parameter suppresses output information when fitting our models.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的变量`df_settle`保存了我们在上一节中下载的期货数据的月度价格。在**SARIMAX（具有外生回归器的季节性自回归整合移动平均模型）**函数中，我们提供了`seasonal_order`参数，这是*ARIMA(p,d,q,s)*季节性分量，其中*s*是数据集中一个季节的周期数。由于我们使用的是月度数据，我们使用12个周期来定义季节模式。`enforce_stationarity=False`参数不会将AR参数转换为强制模型的AR分量。`enforce_invertibility=False`参数不会将MA参数转换为强制模型的MA分量。`disp=False`参数在拟合模型时抑制输出信息。
- en: 'With the grid function defined, we can now call this with our monthly data
    and print out the model parameters with the lowest AIC value:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了网格函数后，我们现在可以使用我们的月度数据调用它，并打印出具有最低AIC值的模型参数：
- en: '[PRE27]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: An `ARIMA(0,1,1,12)` seasonal component model would give us the lowest AIC value
    at 2149.636\. We shall use these parameters to fit our SARIMAX model in the next
    section.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`ARIMA(0,1,1,12)`季节性分量模型将在2149.636的AIC值处得到最低值。我们将使用这些参数在下一节中拟合我们的SARIMAX模型。'
- en: Fitting the SARIMAX model
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合SARIMAX模型
- en: 'Having obtained the optimal model parameters, inspect the model properties
    using the `summary()` method on the fitted results to view detailed statistical
    information:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 获得最佳模型参数后，使用`summary()`方法检查拟合结果的模型属性，以查看详细的统计信息：
- en: '[PRE28]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This gives us the following output:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '[PRE29]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'It is important to run model diagnostics to investigate that model assumptions
    haven''t been violated:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要运行模型诊断，以调查模型假设是否被违反：
- en: '[PRE30]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We get the following output:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](Images/f01811a8-00c5-4d0a-989c-50686fddabf5.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/f01811a8-00c5-4d0a-989c-50686fddabf5.png)'
- en: 'The top-right plot shows the **kernel density estimate** (**KDE**) of the standardized
    residuals, which suggests the errors are Gaussian with a mean close to zero. Let''s
    see a more accurate statistic of the residuals:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 右上角的图显示了标准化残差的**核密度估计**（**KDE**），这表明误差服从均值接近于零的高斯分布。让我们看一下残差的更准确的统计信息：
- en: '[PRE31]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: From the description of the residuals, the non-zero mean suggests that the prediction
    may be biased positively.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 从残差的描述中，非零均值表明预测可能存在正向偏差。
- en: Predicting and forecasting the SARIMAX model
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测和预测SARIMAX模型
- en: 'The `model_results` variable is a `SARIMAXResults` object of the `statsmodel`
    module, representing the output of the SARIMAX model. It contains a `get_prediction()`
    method for performing in-sample prediction and out-of-sample forecasting. It also
    contains a `conf_int()` method, which returns the confidence intervals of the
    predictions, both lower- and upper-bounded, of the fitted parameters, which is
    at a 95% confidence interval by default. Let''s apply these methods:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_results`变量是`statsmodel`模块的`SARIMAXResults`对象，代表SARIMAX模型的输出。它包含一个`get_prediction()`方法，用于执行样本内预测和样本外预测。它还包含一个`conf_int()`方法，返回预测的置信区间，包括拟合参数的下限和上限，默认情况下为95%置信区间。让我们应用这些方法：'
- en: '[PRE32]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `start` parameter in the `get_prediction()` method indicates we are performing
    an in-sample prediction of the most recent five years' prices. At the same time,
    with the `end` parameter, we are performing an out-of-sample forecast of the next
    five months.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_prediction()`方法中的`start`参数表示我们正在对最近五年的价格进行样本内预测。同时，使用`end`参数，我们正在对接下来的五个月进行样本外预测。'
- en: 'By inspecting the top three forecasted confidence interval values, we get the
    following:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查前三个预测的置信区间值，我们得到以下结果：
- en: '[PRE33]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s plot the predicted and forecasted prices against our original dataset,
    from the year 2008 onwards:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将预测和预测的价格与我们的原始数据集从2008年开始进行对比：
- en: '[PRE34]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This gives us the following output:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们以下输出：
- en: '![](Images/25f3ccd6-0eb0-42c6-b52f-d37861e4be7c.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/25f3ccd6-0eb0-42c6-b52f-d37861e4be7c.png)'
- en: The solid line plot shows the observed values, while the dotted lines plot the
    five-year rolling predictions trailing closely and bounded by the confidence intervals
    in the shaded area. Observe that as the next five-month forecast goes into the
    future, and the confidence interval widens to reflect the loss of certainty in
    the outlook.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 实线图显示了观察值，而虚线图显示了五年滚动预测，紧密跟随并受到阴影区域内的置信区间的限制。请注意，随着接下来五个月的预测进入未来，置信区间扩大以反映对前景的不确定性。
- en: Summary
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we were introduced to PCA as a dimension reduction technique
    in portfolio modeling. By breaking down the movement of asset prices of a portfolio
    into its principal components, or common factors, the most useful factors can
    be kept, and portfolio analysis can be greatly simplified without compromising
    on computational time and space complexity. In applying PCA to the Dow and its
    thirty components using the `KernelPCA` function of the `sklearn.decomposition`
    module, we obtained eigenvectors and eigenvalues, which we used to reconstruct
    the Dow with five components.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了PCA作为投资组合建模中的降维技术。通过将投资组合资产价格的波动分解为其主要成分或共同因素，可以保留最有用的因素，并且可以大大简化投资组合分析，而不会影响计算时间和空间复杂性。通过使用`sklearn.decomposition`模块的`KernelPCA`函数将PCA应用于道琼指数及其30个成分，我们获得了特征向量和特征值，用于用五个成分重构道琼指数。
- en: In the statistical analysis of time series data, the data is considered as either
    stationary or non-stationary. Stationary time series data is data whose statistical
    properties are constant over time. Non-stationary time series data has its statistical
    properties change over time, most likely due to trends, seasonality, presence
    of a unit root, or a combination of all three. Modeling from non-stationary data
    may produce spurious regression. In order to receive consistent and reliable results,
    non-stationary data needs to be transformed into stationary data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列数据的统计分析中，数据被视为平稳或非平稳。平稳的时间序列数据是其统计特性随时间保持不变的数据。非平稳的时间序列数据其统计特性随时间变化，很可能是由于趋势、季节性、存在单位根或三者的组合。从非平稳数据建模可能产生虚假回归。为了获得一致和可靠的结果，非平稳数据需要转换为平稳数据。
- en: We used statistical tests such as the ADF to check whether stationary expectations
    are met or violated. The `adfuller` method of the `statsmodels.tsa.stattools`
    module provides the test statistic, p-value, and critical values, from which we
    can fail to reject the null hypothesis that the data has a unit root and is non-stationary.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用统计检验，如ADF，来检查是否满足或违反了平稳性期望。`statsmodels.tsa.stattools`模块的`adfuller`方法提供了检验统计量、p值和临界值，从中我们可以拒绝零假设，即数据具有单位根且是非平稳的。
- en: We transformed non-stationary data into stationary data by detrending, differencing,
    and seasonal decomposition. By using ARIMA, we fitted models using the `SARIMAX`
    function of the `statsmodels.tsa.statespace.sarimax` module to find suitable model
    parameters that give the lowest AIC value through an iterative grid search procedure.
    The fitted results are used for prediction and forecasting.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过去趋势化、差分和季节性分解将非平稳数据转换为平稳数据。通过使用ARIMA，我们使用`statsmodels.tsa.statespace.sarimax`模块的`SARIMAX`函数拟合模型，以找到通过迭代网格搜索过程给出最低AIC值的合适模型参数。拟合结果用于预测和预测。
- en: In the next chapter, we will perform interactive financial analytics with the
    VIX.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将使用VIX进行交互式金融分析。
