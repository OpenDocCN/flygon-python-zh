["```py\n          python3.8 -m pip install pandas bokeh\n\n```", "```py\nimport pandas as pd\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\ndiff_data = rng.normal(0, 1, size=100)\ncumulative = np.add.accumulate(diff_data)\n```", "```py\ndata_series = pd.Series(diff_data)\nprint(data_series)\n```", "```py\ndata_frame = pd.DataFrame({\n   \"diffs\": data_series,\n    \"cumulative\": cumulative\n}) \n```", "```py\nprint(data_frame)\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345) # seed for example\n```", "```py\ndiffs = rng.normal(0, 1, size=100)\ncumulative = np.add.accumulate(diffs)\n\ndata_frame = pd.DataFrame({\n    \"diffs\": diffs, \n    \"cumulative\": cumulative\n})\nprint(data_frame)\n```", "```py\ndata_frame.to_csv(\"sample.csv\", index=False)\n```", "```py\ndf = pd.read_csv(\"sample.csv\", index_col=False)\nprint(df)\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\nthree = rng.uniform(-0.2, 1.0, size=100)\nthree[three < 0] = np.nan\n\ndata_frame = pd.DataFrame({\n    \"one\": rng.random(size=100),\n    \"two\": np.add.accumulate(rng.normal(0, 1, size=100)),\n    \"three\": three\n})\n```", "```py\ndata_frame[\"four\"] = data_frame[\"one\"] > 0.5\n```", "```py\ndef transform_function(row):\n    if row[\"four\"]:\n        return 0.5*row[\"two\"]\n    return row[\"one\"]*row[\"two\"]\n```", "```py\ndata_frame[\"five\"] = data_frame.apply(transform_function, axis=1)\nprint(data_frame)\n```", "```py\ndf = data_frame.dropna()\nprint(df)\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\ndiffs = rng.standard_normal(size=100)\nwalk = np.add.accumulate(diffs)\ndf = pd.DataFrame({\n    \"diffs\": diffs,\n    \"walk\": walk\n})\n```", "```py\nfig, (ax1, ax2) = plt.subplots(1, 2, tight_layout=True)\n```", "```py\ndf[\"walk\"].plot(ax=ax1, title=\"Random walk\")\nax1.set_xlabel(\"Index\")\nax1.set_ylabel(\"Value\")\n```", "```py\ndf[\"diffs\"].plot(kind=\"hist\", ax=ax2, title=\"Histogram of diffs\")\nax2.set_xlabel(\"Difference\")\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\nuniform = rng.uniform(1, 5, size=100)\nnormal = rng.normal(1, 2.5, size=100)\nbimodal = np.concatenate([rng.normal(0, 1, size=50), \n    rng.normal(6, 1, size=50)])\ndf = pd.DataFrame({\n    \"uniform\": uniform, \n    \"normal\": normal, \n    \"bimodal\": bimodal\n})\n```", "```py\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, tight_layout=True)\n\ndf[\"uniform\"].plot(kind=\"hist\", title=\"Uniform\", ax=ax1)\ndf[\"normal\"].plot(kind=\"hist\", title=\"Normal\", ax=ax2)\ndf[\"bimodal\"].plot(kind=\"hist\", title=\"Bimodal\", ax=ax3, bins=20)\n```", "```py\ndescriptive = df.describe()\n```", "```py\ndescriptive.loc[\"kurtosis\"] = df.kurtosis()\nprint(descriptive)\n#             uniform     normal    bimodal\n# count    100.000000 100.000000 100.000000\n# mean       2.813878   1.087146   2.977682\n# std        1.093795   2.435806   3.102760\n# min        1.020089  -5.806040  -2.298388\n# 25%        1.966120  -0.498995   0.069838\n# 50%        2.599687   1.162897   3.100215\n# 75%        3.674468   2.904759   5.877905\n# max        4.891319   6.375775   8.471313\n# kurtosis  -1.055983   0.061679  -1.604305\n```", "```py\nuniform_mean = descriptive.loc[\"mean\", \"uniform\"]\nnormal_mean = descriptive.loc[\"mean\", \"normal\"]\nbimodal_mean = descriptive.loc[\"mean\", \"bimodal\"]\nax1.vlines(uniform_mean, 0, 20)\nax2.vlines(uniform_mean, 0, 25)\nax3.vlines(uniform_mean, 0, 20)\n```", "```py\nfrom scipy import stats\n```", "```py\nsample_data = pd.Series(\n    [172.3, 171.3, 164.7, 162.9, 172.5, 176.3, 174.8, 171.9, \n     176.8, 167.8, 164.5, 179.7, 157.8, 170.6, 189.9, 185\\. , \n     172.7, 165.5, 174.5, 171.5]\n)\n```", "```py\nsample_mean = sample_data.mean()\nsample_std = sample_data.std()\nprint(f\"Mean {sample_mean}, st. dev {sample_std}\")\n# Mean 172.15, st. dev 7.473778724383846\n```", "```py\nN = sample_data.count()\nstd_err = sample_std/math.sqrt(N)\n```", "```py\ncv_95, cv_99 = stats.t.ppf([0.975, 0.995], df=N-1)\n```", "```py\npm_95 = cv_95*std_err\nconf_interval_95 = [sample_mean - pm_95, sample_mean + pm_95]\npm_99 = cv_99*std_err\nconf_interval_99 = [sample_mean - pm_99, sample_mean + pm_99]\n\nprint(\"95% confidence\", conf_interval_95)\n# 95% confidence [168.65216388659374, 175.64783611340627]\nprint(\"99% confidence\", conf_interval_99)\n# 99% confidence [167.36884119608774, 176.93115880391227]\n```", "```py\nfrom scipy import stats\n```", "```py\nsample = pd.Series([\n    2.4, 2.4, 2.9, 2.6, 1.8, 2.7, 2.6, 2.4, 2.8, 2.4, 2.4,\n    2.4, 2.7, 2.7, 2.3, 2.4, 2.4, 3.2, 2.2, 2.5, 2.1, 1.8,\n    2.9, 2.5, 2.5, 3.2, 2\\. , 2.3, 3\\. , 1.5, 3.1, 2.5, 3.1,\n    2.4, 3\\. , 2.5, 2.7, 2.1, 2.3, 2.2, 2.5, 2.6, 2.5, 2.8,\n    2.5, 2.9, 2.1, 2.8, 2.1, 2.3\n])\n```", "```py\nmu0 = 2.0\nsignificance = 0.05\n```", "```py\nt_statistic, p_value = stats.ttest_1samp(sample, mu0)\nprint(f\"t stat: {t_statistic}, p value: {p_value}\")\n# t stat: 9.752368720068665, p value: 4.596949515944238e-13\n```", "```py\nif p_value <= significance:\n    print(\"Reject H0 in favour of H1: mu != 2.0\")\nelse:\n    print(\"Accept H0: mu = 2.0\")\n# Reject H0 in favour of H1: mu != 2.0\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\ncurrent = rng.normal(4.0, 2.0, size=40)\nprocess_a = rng.normal(6.2, 2.0, size=25)\nprocess_b = rng.normal(4.5, 2.0, size=64)\n```", "```py\nsignificance = 0.05\n```", "```py\nF_stat, p_value = stats.f_oneway(current, process_a, process_b)\nprint(f\"F stat: {F_stat}, p value: {p_value}\")\n# F stat: 9.949052026027028, p value: 9.732322721019206e-05\n```", "```py\nif p_value <= significance:\n    print(\"Reject H0: there is a difference between means\")\nelse:\n    print(\"Accept H0: all means equal\")\n# Reject H0: there is a difference between means\n```", "```py\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\nsample_A = rng.uniform(2.5, 4.5, size=22)\nsample_B = rng.uniform(3.0, 4.4, size=25)\nsample_C = rng.uniform(3.0, 4.4, size=30)\n```", "```py\nsignificance = 0.05\n```", "```py\nstatistic, p_value = stats.kruskal(sample_A, sample_B, sample_C)\nprint(f\"Statistic: {statistic}, p value: {p_value}\")\n# Statistic: 5.09365664638392, p value: 0.07832970895845669\n```", "```py\nif p_value <= significance:\n    print(\"Accept H0: all medians equal\")\nelse:\n    print(\"There are differences between population medians\")\n# There are differences between population medians\n```", "```py\n_, p_A_B = stats.ranksums(sample_A, sample_B)\n_, p_A_C = stats.ranksums(sample_A, sample_C)\n_, p_B_C = stats.ranksums(sample_B, sample_C)\n```", "```py\nif p_A_B > significance:\n    print(\"Significant differences between A and B, p value\", \n        p_A_B)\n# Significant differences between A and B, p value\n     0.08808151166219029\n\nif p_A_C > significance:\n    print(\"Significant differences between A and C, p value\",\n        p_A_C)\n# Significant differences between A and C, p value \n     0.4257804790323789\n\nif p_B_C > significance:\n    print(\"Significant differences between B and C, p value\",\n        p_B_C) \nelse:\n    print(\"No significant differences between B and C, p value\",\n        p_B_C)\n# No significant differences between B and C, p value\n     0.037610047044153536\n\n```", "```py\nfrom bokeh import plotting as bk\nfrom numpy.random import default_rng\nrng = default_rng(12345)\n```", "```py\ndate_range = pd.date_range(\"2020-01-01\", periods=50)\ndata = np.add.accumulate(rng.normal(0, 3, size=50))\nseries = pd.Series(data, index=date_range)\n```", "```py\nbk.output_file(\"sample.html\")\n```", "```py\nfig = bk.figure(title=\"Time series data\", \n                x_axis_label=\"date\",\n                x_axis_type=\"datetime\",\n                y_axis_label=\"value\")\n```", "```py\nfig.line(date_range, series)\n```", "```py\nbk.show(fig)\n```"]