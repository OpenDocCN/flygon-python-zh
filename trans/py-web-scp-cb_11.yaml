- en: Making the Scraper as a Service Real
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使Scraper成为一个真正的服务
- en: 'In this chapter, we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Creating and configuring an Elastic Cloud trial account
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和配置Elastic Cloud试用账户
- en: Accessing the Elastic Cloud cluster with curl
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用curl访问Elastic Cloud集群
- en: Connecting to the Elastic Cloud cluster with Python
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python连接Elastic Cloud集群
- en: Performing an Elasticsearch query with the Python API
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python API执行Elasticsearch查询
- en: Using Elasticsearch to query for jobs with specific skills
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Elasticsearch查询具有特定技能的工作
- en: Modifying the API to search for jobs by skill
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改API以按技能搜索工作
- en: Storing configuration in the environment
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将配置存储在环境中
- en: Creating an AWS IAM user and a key pair for ECS
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为ECS创建AWS IAM用户和密钥对
- en: Configuring Docker to authenticate with ECR
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Docker以与ECR进行身份验证
- en: Pushing containers into ECR
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将容器推送到ECR
- en: Creating an ECS cluster
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建ECS集群
- en: Creating a task to run our containers
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建任务来运行我们的容器
- en: Starting and accessing the containers in AWS
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在AWS中启动和访问容器
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In this chapter, we will first add a feature to search job listings using Elasticsearch
    and extend the API for this capability. Then will move Elasticsearch functions
    to Elastic Cloud, a first step in cloud-enabling our cloud based scraper.  Then,
    we will move our Docker containers to Amazon **Elastic Container Repository**
    (**ECR**), and finally run our containers (and scraper) in Amazon **Elastic Container
    Service** (**ECS**).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先添加一个功能，使用Elasticsearch搜索工作列表，并扩展API以实现此功能。然后将Elasticsearch功能移至Elastic
    Cloud，这是将我们的基于云的Scraper云化的第一步。然后，我们将将我们的Docker容器移至Amazon Elastic Container Repository（ECR），最后在Amazon
    Elastic Container Service（ECS）中运行我们的容器（和Scraper）。
- en: Creating and configuring an Elastic Cloud trial account
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和配置Elastic Cloud试用账户
- en: In this recipe we will create and configure an Elastic Cloud trial account so
    that we can use Elasticsearch as a hosted service.  Elastic Cloud is a cloud service
    offered by the creators of Elasticsearch, and provides a completely managed implementation
    of Elasticsearch.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将创建和配置一个Elastic Cloud试用账户，以便我们可以将Elasticsearch作为托管服务使用。Elastic Cloud是Elasticsearch创建者提供的云服务，提供了完全托管的Elasticsearch实现。
- en: While we have examined putting Elasticsearch in a Docker container, actually
    running a container with Elasticsearch within AWS is very difficult due to a number
    of memory requirements and other system configurations that are complicated to
    get working within ECS.  Therefore, for a cloud solution, we will use Elastic
    Cloud.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们已经研究了将Elasticsearch放入Docker容器中，但在AWS中实际运行带有Elasticsearch的容器非常困难，因为存在许多内存要求和其他系统配置，这些配置在ECS中很难实现。因此，对于云解决方案，我们将使用Elastic
    Cloud。
- en: How to do it
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We''ll proceed with the recipe as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下步骤进行：
- en: 'Open your browser and navigate to [https://www.elastic.co/cloud/as-a-service/signup](https://www.elastic.co/cloud/as-a-service/signup).
    You will see a page similar to the following:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开浏览器，转到[https://www.elastic.co/cloud/as-a-service/signup](https://www.elastic.co/cloud/as-a-service/signup)。您将看到一个类似以下内容的页面：
- en: '![](assets/db8027f8-ba93-421c-a026-fb2cedd5ddcb.png)The Elastic Cloud signup
    page'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/db8027f8-ba93-421c-a026-fb2cedd5ddcb.png)Elastic Cloud注册页面'
- en: 'Enter your email and press the Start Free Trial button.  When the email arrives,
    verify yourself.  You will be taken to a page to create your cluster:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入您的电子邮件并点击“开始免费试用”按钮。当邮件到达时，请进行验证。您将被带到一个页面来创建您的集群：
- en: '![](assets/c08434c1-5481-4c1f-8582-674152731121.png)Cluster creation page'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/c08434c1-5481-4c1f-8582-674152731121.png)集群创建页面'
- en: 'I''ll be using AWS (not Google) in the Oregon (us-west-2) region in other examples,
    so I''ll pick both of those  for this cluster.  You can pick a cloud and region
    that works for you.  You can leave the other options as it is, and just press
    create.  You will then be presented with your username and password.  Jot those
    down. The following screenshot gives an idea of how it displays the username and
    password:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在其他示例中，我将使用AWS（而不是Google）在俄勒冈州（us-west-2）地区，所以我将为这个集群选择这两个选项。您可以选择适合您的云和地区。您可以将其他选项保持不变，然后只需按“创建”。然后您将看到您的用户名和密码。记下来。以下屏幕截图给出了它如何显示用户名和密码：
- en: '![](assets/c8d98099-d766-43d2-9825-62dc4ddd9b9c.png)The credentials info for
    the Elastic Cloud accountWe won''t use the Cloud ID in any recipes.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/c8d98099-d766-43d2-9825-62dc4ddd9b9c.png)Elastic Cloud账户的凭据信息我们不会在任何示例中使用Cloud
    ID。'
- en: 'Next, you will be presented with your endpoints.  The Elasticsearch URL is
    what''s important to us:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您将看到您的端点。对我们来说，Elasticsearch URL很重要：
- en: '![](assets/054dab3f-ed34-43a7-9cab-099198e4bc8a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/054dab3f-ed34-43a7-9cab-099198e4bc8a.png)'
- en: And that's it - you are ready to go (at least for 14 days)!
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就是这样 - 你已经准备好了（至少可以使用14天）！
- en: Accessing the Elastic Cloud cluster with curl
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用curl访问Elastic Cloud集群
- en: Elasticsearch is fundamentally accessed via a REST API.  Elastic Cloud is no
    different and is actually an identical API.  We just need to be able to know how
    to construct the URL properly to connect.  Let's look at that.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch基本上是通过REST API访问的。Elastic Cloud也是一样的，实际上是相同的API。我们只需要知道如何正确构建URL以进行连接。让我们来看看。
- en: How to do it
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下步骤进行：
- en: 'When you signed up for Elastic Cloud, you were given various endpoints and
    variables, such as username and password.  The URL was similar to the following:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当您注册Elastic Cloud时，您会获得各种端点和变量，例如用户名和密码。URL类似于以下内容：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Depending on the cloud and region, the rest of the domain name, as well as the
    port, may differ.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 根据云和地区，域名的其余部分以及端口可能会有所不同。
- en: 'We''ll use a slight variant of the following URL to communicate and authenticate
    with Elastic Cloud:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用以下URL的略微变体来与Elastic Cloud进行通信和身份验证：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Currently, mine is (it will be disabled by the time you read this):'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目前，我的URL是（在您阅读此内容时将被禁用）：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Basic authentication and connectivity can be checked with curl:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用curl检查基本身份验证和连接：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And we are up and talking!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以开始交谈了！
- en: Connecting to the Elastic Cloud cluster with Python
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python连接Elastic Cloud集群
- en: Now let's look at how to connect to Elastic Cloud using the Elasticsearch Python
    library.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用Elasticsearch Python库连接到Elastic Cloud。
- en: Getting ready
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The code for this recipe is in the `11/01/elasticcloud_starwars.py` script. 
    This script will scrape Star Wars character data from the swapi.co API/website
    and put it into the Elastic Cloud.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的代码位于`11/01/elasticcloud_starwars.py`脚本中。此脚本将从swapi.co API/网站中获取Star Wars角色数据，并将其放入Elastic
    Cloud中。
- en: How to do it
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'Execute the file as a Python script:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文件作为Python脚本执行：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will loop through up to 20 characters and drop them into the `sw` index
    with a document type of `people`.  The code is straightforward (replace the URL
    with yours):'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将循环遍历最多20个字符，并将它们放入`sw`索引中，文档类型为`people`。代码很简单（用您的URL替换URL）：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The connection is made using the URL with the username and password added to
    it.  The data is pulled from swapi.co using a GET request and then with a call
    to `.index()` on the Elasticsearch object.  You''ll see output similar to the
    following:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接是使用URL进行的，用户名和密码添加到其中。数据是使用GET请求从swapi.co中提取的，然后使用Elasticsearch对象上的`.index()`调用。您将看到类似以下的输出：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There's more...
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'When you signed up for Elastic Cloud, you were also given a URL to Kibana. 
    Kibana is a powerful graphical frontend to Elasticsearch:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当您注册Elastic Cloud时，您还会获得一个指向Kibana的URL。Kibana是Elasticsearch的强大图形前端：
- en: 'Open the URL in your browser.  You''ll see see a login page:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在浏览器中打开URL。您将看到一个登录页面：
- en: '![](assets/8cba8c2e-8870-4c2c-a721-4a1787387ad8.png)The Kibana login page'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/8cba8c2e-8870-4c2c-a721-4a1787387ad8.png)Kibana登录页面'
- en: 'Enter your username and password and you''ll be taken to the main dashboard:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入您的用户名和密码，然后您将进入主仪表板：
- en: '![](assets/6aff28f8-f90a-4018-a809-990fceae344a.png)Creating an index pattern'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/6aff28f8-f90a-4018-a809-990fceae344a.png)创建索引模式'
- en: 'We''re being asked to create an index pattern for the one index that was created
    by our app: sw.  In the index pattern textbox, enter `sw*` and then press Next
    step.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们被要求为我们的应用程序创建一个索引模式：sw创建的一个索引。在索引模式文本框中，输入`sw*`，然后按下下一步。
- en: 'We''ll be asked to select a time filter field name.  Select I don''t want to
    use the Time Filter and press the Create Index Pattern button. A few moments later,
    you will see a confirmation of the index that was created:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将被要求选择时间过滤器字段名称。选择I don't want to use the Time Filter，然后按下Create Index Pattern按钮。几秒钟后，您将看到创建的索引的确认：
- en: '![](assets/951c8ef3-95f8-454a-b76c-7315b6f68b47.png)The index that was created'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/951c8ef3-95f8-454a-b76c-7315b6f68b47.png)创建的索引'
- en: 'Now click the Discover menu item, and you''ll be taken to the interactive data
    explorer, where you will see the data we just entered:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在点击Discover菜单项，您将进入交互式数据浏览器，在那里您将看到我们刚刚输入的数据：
- en: '![](assets/3c49c59b-7f1d-4f48-b3bc-081f342a95b8.png)The data added to our index'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/3c49c59b-7f1d-4f48-b3bc-081f342a95b8.png)添加到我们的索引的数据'
- en: Here you can navigate through the data and see just how effectively Elasticsearch
    stored and organized this data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以浏览数据，看看Elasticsearch如何有效地存储和组织这些数据。
- en: Performing an Elasticsearch query with the Python API
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python API执行Elasticsearch查询
- en: Now let's look at how we can search Elasticsearch using the Elasticsearch Python
    library.  We will perform a simple search on the Star Wars index.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用Elasticsearch Python库搜索Elasticsearch。我们将在Star Wars索引上执行简单的搜索。
- en: Getting ready
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Make sure to modify the connection URL in the samples to your URL.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在示例中修改连接URL为您的URL。
- en: How to do it
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'The code for the search is in the `11/02/search_starwars_by_haircolor.py` script,
    and can be run by simply executing the script.  This is a fairly simple search
    to find the characters whose hair color is `blond`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索的代码在`11/02/search_starwars_by_haircolor.py`脚本中，只需执行该脚本即可运行。这是一个相当简单的搜索，用于查找头发颜色为`blond`的角色：
- en: 'The main portion of the code is:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码的主要部分是：
- en: '[PRE7]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A search is performed by constructing a dictionary that expresses an Elasticsearch
    DSL query.  In this case, our query asks for all documents where the `"hair_color"`
    property is `"blond"`.  This object is then passed as the body parameter of the
    `.search` method.  The result of this method is a diction describing what was
    found (or not).  In this case:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过构建表达Elasticsearch DSL查询的字典来执行搜索。在这种情况下，我们的查询要求所有文档的`"hair_color"`属性为`"blond"`。然后将此对象作为`.search`方法的body参数传递。此方法的结果是描述找到的内容（或未找到的内容）的字典。在这种情况下：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The results give us some metadata about the search execution and then the results
    in the `hits` property.  Each hit returns the actual document as well as the index
    name, document type, document ID, and a score.  The score is a lucene calculation
    of the relevance of the document to the search query.  While this query uses an
    exact match of a property to a value, you can see that these two documents still
    have different scores.  I'm not sure why in this case, but searching can also
    be less exact and based on various built-in heuristics to find items "like" a
    certain sentence, that is, such as when you enter text into a Google search box.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 结果为我们提供了有关搜索执行的一些元数据，然后是`hits`属性中的结果。每个命中都会返回实际文档以及索引名称、文档类型、文档ID和分数。分数是文档与搜索查询相关性的lucene计算。虽然此查询使用属性与值的精确匹配，但您可以看到这两个文档仍然具有不同的分数。我不确定为什么在这种情况下，但搜索也可以不太精确，并基于各种内置启发式来查找“类似”某个句子的项目，也就是说，例如当您在Google搜索框中输入文本时。
- en: There's more...
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The Elasticsearch search DSL, and the search engine itself, is very powerful
    and expressive.  We'll only look at this example and one more in the next recipe,
    so we don't go into it in much detail.  To find out more about the DSL, you can
    start with the official documentation at [https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch搜索DSL和搜索引擎本身非常强大和富有表现力。我们只会在下一个配方中查看这个例子和另一个例子，所以我们不会详细介绍。要了解更多关于DSL的信息，您可以从官方文档开始[https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)。
- en: Using Elasticsearch to query for jobs with specific skills
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Elasticsearch查询具有特定技能的工作
- en: In this recipe, we move back to using the crawler that we created to scrape
    and store job listings from StackOverflow in Elasticsearch.  We then extend this
    capability to query Elasticsearch to find job listings that contain one or more
    specified skills.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们回到使用我们创建的爬虫从StackOverflow中爬取和存储工作列表到Elasticsearch。然后，我们扩展这个功能，查询Elasticsearch以找到包含一个或多个指定技能的工作列表。
- en: Getting ready
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The example we will use is coded to use a local Elastic Cloud engine and not
    a local Elasticsearch engine.  You can change that if you want.  For now, we will
    perform this process within a single python script that is run locally and not
    inside a container or behind an API.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个本地Elastic Cloud引擎而不是本地Elasticsearch引擎。如果您愿意，您可以更改。现在，我们将在一个本地运行的Python脚本中执行此过程，而不是在容器内或在API后面执行。
- en: How to do it
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'We proceed with the recipe as follows:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'The code for the recipe is in the `11/03/search_jobs_by_skills.py` file:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该配方的代码位于`11/03/search_jobs_by_skills.py`文件中。
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The first part of this code defines four job listings to be put into Elasticsearch,
    if they already are not available.  It iterates through this job's ID, and if
    not already available, retrieves them and puts them in Elasticsearch.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的第一部分定义了四个工作列表，如果它们尚不可用，则将它们放入Elasticsearch中。它遍历了这个工作的ID，如果尚未可用，则检索它们并将它们放入Elasticsearch中。
- en: The remainder of this defines a query to be executed against Elasticsearch,
    and follows the same pattern for executing the search. The only difference is
    in the definition of the search criteria.  Ultimately, we want to match a list
    of job skills to those in the job listings.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 其余部分定义了要针对Elasticsearch执行的查询，并遵循相同的模式来执行搜索。唯一的区别在于搜索条件的定义。最终，我们希望将一系列工作技能与工作列表中的技能进行匹配。
- en: This query simply matches a single skill to those in the skills field in our
    job listings documents. The sample specifies that we want to match to the JSON.skills
    property in the target documents. The skills in those documents are just beneath
    the root of the document, so in this syntax we preface it with JSON.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询只是将单个技能与我们的工作列表文档中的技能字段进行匹配。示例指定我们要匹配目标文档中的JSON.skills属性。这些文档中的技能就在文档的根部下面，所以在这个语法中我们用JSON作为前缀。
- en: This property in Elasticsearch is an array, and the query value we have will
    match the document if any of the values in that property array are `"c#"`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch中的这个属性是一个数组，我们的查询值将匹配该属性数组中的任何一个值为`"c#"`的文档。
- en: 'Running this search with just those four documents in Elasticsearch results
    in the following (the output here just shows the results and not the complete
    contents of the four documents returned):'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Elasticsearch中只使用这四个文档运行此搜索将产生以下结果（这里的输出只显示结果，而不是返回的四个文档的完整内容）：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Each of the jobs placed in Elasticsearch has C# for a skill (I randomly picked
    these documents, so this is a little bit of a coincidence).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 放入Elasticsearch的每个工作都有C#作为技能（我随机选择了这些文档，所以这有点巧合）。
- en: 'The results of these searches return the entire contents of each of the documents
    that are identified.  If we don''t want the entire document returned for each
    hit, we can change the query to make this happen. Let''s modify the query to only
    return the ID in the hits. Change the `search_definition` variable to the following:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些搜索的结果返回了每个被识别的文档的全部内容。如果我们不希望每次命中都返回整个文档，我们可以更改查询以实现这一点。让我们修改查询，只返回命中的ID。将`search_definition`变量更改为以下内容：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Including the `"_source"` property tells Elasticsearch to return the specified
    document properties in the result.  Executing this query results in the following
    output:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 包括`"_source"`属性告诉Elasticsearch在结果中返回指定的文档属性。执行此查询将产生以下输出：
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Each of the hits now only returns the ID property of the document. This will
    help control the size of the result if there are a lot of hits.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每个命中只返回文档的ID属性。如果有很多命中，这将有助于控制结果的大小。
- en: 'Let''s get to the ultimate goal of this recipe, identifying documents that
    have multiple skills.  This is actually a very simple change to `search_defintion`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来到这个配方的最终目标，识别具有多种技能的文档。这实际上是对`search_defintion`进行了一个非常简单的更改：
- en: '[PRE13]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This states that we only want documents where the skills contain both `"c#"`
    and `"sql"`.  The result from running the script is then the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这说明我们只想要包含`"c#"`和`"sql"`两个技能的文档。然后运行脚本的结果如下：
- en: '[PRE14]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The result set is now cut down to two hits, and if you check, these are the
    only two with those values in the skills.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 结果集现在减少到两个命中，如果您检查，这些是唯一具有这些技能值的两个。
- en: Modifying the API to search for jobs by skill
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修改API以按技能搜索工作
- en: In this recipe, we will modify our existing API to add a method to enable searching
    for jobs with a set of skills.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将修改我们现有的API，添加一个方法来搜索具有一组技能的工作。
- en: How to do it
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: We will be extending the API code.  We will make two fundamental changes to
    the implementation of the API.  The first is that we will add an additional Flask-RESTful 
    API implementation for the search capability, and the second is that we will make
    addresses for both Elasticsearch and our own microservice configurable by environment
    variables.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将扩展API代码。 我们将对API的实现进行两个基本更改。 第一个是我们将为搜索功能添加一个额外的Flask-RESTful API实现，第二个是我们将Elasticsearch和我们自己的微服务的地址都可通过环境变量进行配置。
- en: 'The API implementation is in `11/04_scraper_api.py`.   By default, the implementation
    attempts to connect to Elasticsearch on the local system.  If you are using Elastic
    Cloud, make sure to change the URL (and make sure you have documents in the index):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: API实现在`11/04_scraper_api.py`中。 默认情况下，该实现尝试连接到本地系统上的Elasticsearch。 如果您正在使用Elastic
    Cloud，请确保更改URL（并确保索引中有文档）：
- en: 'The API can be started by simply executing the script:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以通过简单执行脚本来启动API：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To make a search request, we make a POST to the `/joblistings/search` endpoint,
    passing data in the form of `"skills=<skills separated with a space>"`.  The following
    performs a search for jobs with C# and SQL:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要进行搜索请求，我们可以向`/joblistings/search`端点进行POST，以`"skills=<用空格分隔的技能>"`的形式传递数据。 以下是使用C#和SQL进行作业搜索的示例：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: And we get the results that we saw in the previous recipe.  We've now made our
    search capabilities accessible over the internet with REST!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了在上一个食谱中看到的结果。 现在我们已经通过互联网实现了我们的搜索功能！
- en: How it works
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理
- en: 'This works by adding another Flask-RESTful class implementation:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过添加另一个Flask-RESTful类实现来实现：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This class implements a post method as a resource mapped to `/joblistings/search`. 
    The reason for the POST operation is that we are passing a string consisting of
    multiple words.  While this could be URL-encoded in a GET operation, a POST allows
    us to pass this in as a keyed value.  And while we only have the one key, skills,
    future expansion to other keys to support other search parameters can be simply
    added.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类实现了一个post方法，作为映射到`/joblistings/search`的资源。 进行POST操作的原因是我们传递了一个由多个单词组成的字符串。
    虽然这可以在GET操作中进行URL编码，但POST允许我们将其作为键值传递。 虽然我们只有一个键，即skills，但未来扩展到其他键以支持其他搜索参数可以简单地添加。
- en: There's more...
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The decision to perform the search from within the API implementation is one
    that should be considered as a system evolves.  It is my opinion, and just mine
    (but I think others would agree), that like how the API calls a microservice for
    the actual scraping, it should also call a microservice that handles the search
    (and that microservice would then interface with Elasticsearch).  This would also
    be the case for storing the document returned from the scraping microservice,
    as well as accessing Elasticsearch to check for a cached document.  But for our
    purposes here, we'll try and keep it simple.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 从API实现中执行搜索的决定是应该在系统发展时考虑的。 这是我的观点，仅仅是我的观点（但我认为其他人会同意），就像API调用实际的爬取微服务一样，它也应该调用一个处理搜索的微服务（然后该微服务将与Elasticsearch进行接口）。
    这也适用于存储从爬取微服务返回的文档，以及访问Elasticsearch以检查缓存文档。 但出于我们在这里的目的，我们将尽量保持简单。
- en: Storing configuration in the environment
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在环境中存储配置
- en: This recipe points out a change made in the code of the API in the previous
    recipe to support one of the *factors* of a **12-Factor** application.  A 12-Factor
    app is defined as an app that is designed to be run as a software as a service. 
    We have been moving our scraper in this direction for a while now, breaking it
    into components that can be run independently, as scripts, or in containers, and
    as we will see soon, in the cloud.  You can learn all about 12-Factor apps at [https://12factor.net/](https://12factor.net/).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱指出了在上一个食谱中对API代码进行的更改，以支持**12-Factor**应用程序的一个*因素*。 12-Factor应用程序被定义为设计为软件即服务运行的应用程序。
    我们已经在这个方向上移动了一段时间的爬虫，将其分解为可以独立运行的组件，作为脚本或容器运行，并且很快我们将看到，作为云中的组件。 您可以在[https://12factor.net/](https://12factor.net/)上了解有关12-Factor应用程序的所有信息。
- en: Factor-3 states that we should pass in configuration to our application through
    environment variables.  While we definitely don't want to hardcode things, such
    as URLs, to external services, it also isn't best practice to use configuration
    files.  When deploying to various environments, such as containers or the cloud,
    a config file will often get fixed in an image and not be able to be changed on-demand
    as the application is dynamically deployed to different environments.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Factor-3指出我们应该通过环境变量将配置传递给我们的应用程序。 虽然我们绝对不希望硬编码诸如外部服务的URL之类的东西，但使用配置文件也不是最佳实践。
    在部署到各种环境（如容器或云）时，配置文件通常会固定在镜像中，并且无法根据应用程序动态部署到不同环境而随需求更改。
- en: The best way to fix this is to always look in environment variables for configuration
    settings that can change based on how the application is run.  Most tools for
    running 12-Factor apps allow the setting of environment variables based on how
    and where the environment decides the app should be run.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 修复此问题的最佳方法是始终查找环境变量中的配置设置，这些设置可以根据应用程序的运行方式而改变。 大多数用于运行12-Factor应用程序的工具允许根据环境决定应用程序应该在何处以及如何运行来设置环境变量。
- en: How to do it
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点
- en: 'In our job listings implementation, we used the following code to determine
    the host for Elasticsearch:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的工作列表实现中，我们使用以下代码来确定Elasticsearch的主机：
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It's a straightforward and simple thing to do, but it's very important for making
    our app incredibly portable to different environments.  This defaults to using
    localhost, but lets us define a different host with the `ES_HOST` environment
    variable.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单直接的操作，但对于使我们的应用程序在不同环境中具有极高的可移植性非常重要。 默认情况下使用localhost，但让我们使用`ES_HOST`环境变量定义不同的主机。
- en: 'The implementation of the skills search also makes a similar change to allow
    us to change a default of localhost for our scraping microservice:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 技能搜索的实现也进行了类似的更改，以允许我们更改我们的爬虫微服务的本地主机的默认值：
- en: '[PRE19]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We will see Factor-3 in use in the upcoming recipes, as we move this code to
    AWS's Elastic Container Service.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的教程中看到 Factor-3 的使用，当我们将这段代码移到 AWS 的弹性容器服务时。
- en: Creating an AWS IAM user and a key pair for ECS
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建用于 ECS 的 AWS IAM 用户和密钥对
- en: In this recipe, we will create an Identity and Access Management (IAM) user
    account to allow us to access the AWS Elastic Container Service (ECS).  We need
    this as we are going to package our scraper and API up in Docker containers (we've
    done this already), but now we are going to move these containers into and run
    them from AWS ECS, making our scraper a true cloud service.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将创建一个身份和访问管理（IAM）用户账户，以允许我们访问 AWS 弹性容器服务（ECS）。我们需要这个，因为我们将把我们的爬虫和 API
    打包到 Docker 容器中（我们已经做过了），但现在我们将把这些容器移到 AWS ECS 并在那里运行它们，使我们的爬虫成为一个真正的云服务。
- en: Getting ready
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: This assumes that you have already created an AWS account, which we used earlier
    in the book when we looked at SQS and S3.  You don't need a different account,
    but we need to create a non-root user that has permissions to use ECS.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这假设你已经创建了一个 AWS 账户，我们在之前的章节中使用过它，当我们查看 SQS 和 S3 时。你不需要另一个账户，但我们需要创建一个非根用户，该用户具有使用
    ECS 的权限。
- en: How to do it
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤
- en: Instructions for creating an IAM user with ECS permissions and a key pair can
    be found at [https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何创建具有 ECS 权限和密钥对的 IAM 用户的说明可以在[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/get-set-up-for-amazon-ecs.html)找到。
- en: There are a lot of instructions on this page, such as setting up a VPC and security
    groups.  Just focus now on creating the user, assigning permissions, and creating
    the key pair.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这个页面上有很多说明，比如设置 VPC 和安全组。现在只关注创建用户、分配权限和创建密钥对。
- en: 'One thing I want to highlight are the permissions for the IAM account you create. 
    There are detailed instructions on doing this at [https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html). 
    I''ve seen this not done properly.  Just make sure that when you examine the permissions
    for the user you just created that the following permissions are assigned:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我想要强调的一件事是你创建的 IAM 账户的权限。在[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html)上有关于如何做这个的详细说明。我曾经见过这样的操作没有做好。只需确保当你检查刚刚创建的用户的权限时，以下权限已经被分配：
- en: '![](assets/f67ea806-ca40-49f7-a2f1-fd561116c372.png)AWS IAM credentials'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/f67ea806-ca40-49f7-a2f1-fd561116c372.png)AWS IAM 凭证'
- en: I attached these directly to the account I use for ECS instead of through the
    group.  If this isn't assigned, you will get cryptic authentication errors when
    pushing containers to ECR.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我直接将这些附加到我用于 ECS 的账户上，而不是通过组。如果没有分配这些，当推送容器到 ECR 时会出现加密的身份验证错误。
- en: 'One more thing: we will need the access key ID and the associated secret key. 
    This will be presented to you during the creation of the user.  If you didn''t
    record it, you can create another one in the security credentials tab of the user''s
    account page:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一件事：我们需要访问密钥 ID 和相关的密钥。这将在创建用户时呈现给你。如果你没有记录下来，你可以在用户账户页面的安全凭证选项卡中创建另一个：
- en: '![](assets/9fa87343-5f4c-439a-abc8-f79339dfcd9b.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9fa87343-5f4c-439a-abc8-f79339dfcd9b.png)'
- en: Note that you can't get the secret for an already existing access key ID.  You
    will have to make another.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，无法获取已存在的访问密钥 ID 的密钥。你需要创建另一个。
- en: Configuring Docker to authenticate with ECR
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置 Docker 以便与 ECR 进行身份验证
- en: In this recipe, we will configure docker to be able to push our containers to
    the Elastic Container Repository (ECR).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将配置 Docker 以便能够将我们的容器推送到弹性容器仓库（ECR）。
- en: Getting ready
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: A key element of Docker is docker container repositories.  We have previously
    used Docker Hub to pull containers.  But we can also push our containers to Docker
    Hub, or any Docker-compatible container repository, such as ECR. But this is not
    without its troubles. The docker CLI does not naturally know how to authenticate
    with ECR, so we have to jump through a few hoops to get it to work.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 的一个关键元素是 Docker 容器仓库。我们之前使用 Docker Hub 来拉取容器。但我们也可以将我们的容器推送到 Docker Hub，或者任何兼容
    Docker 的容器仓库，比如 ECR。但这并不是没有问题的。docker CLI 并不自然地知道如何与 ECR 进行身份验证，所以我们需要做一些额外的工作来让它能够工作。
- en: 'Make sure that the AWS command line tools are installed.  These are required
    to get Docker authenticated to work with ECR.  Good instructions are found at [https://docs.aws.amazon.com/cli/latest/userguide/installing.html](https://docs.aws.amazon.com/cli/latest/userguide/installing.html).  Once
    the install is verified, you will need to configure the CLI to use the account
    created in the previous recipe.  This can be done using the `aws configure` command,
    which will prompt you for four items:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 确保安装了 AWS 命令行工具。这些工具是必需的，用于让 Docker 能够与 ECR 进行身份验证。在[https://docs.aws.amazon.com/cli/latest/userguide/installing.html](https://docs.aws.amazon.com/cli/latest/userguide/installing.html)上有很好的说明。安装验证通过后，你需要配置
    CLI 以使用前面教程中创建的账户。这可以通过`aws configure`命令来完成，该命令会提示你输入四个项目：
- en: '[PRE20]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Swap the keys to be the ones you retrieved earlier, and set your default region
    and data type.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 将密钥替换为之前检索到的密钥，并设置默认区域和数据类型。
- en: How to do it
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤
- en: 'We proceed with the recipe as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行教程：
- en: 'Execute the following command. This returns a command to authenticate Docker
    with ECR:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令。这将返回一个命令，用于对接 Docker 和 ECR 进行身份验证：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This output is a command that you need to execute to get your docker CLI to
    authenticate with ECR!  This secret is only valid for a few hours (twelve I believe). 
    You can copy all this from the where it starts with `docker login` through the
    end of the URL at the end of the secret.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出是一个命令，你需要执行它来让你的 docker CLI 与 ECR 进行身份验证！这个密钥只在几个小时内有效（我相信是十二小时）。你可以从`docker
    login`开始的位置复制所有内容，一直到密钥末尾的 URL。
- en: 'On a Mac (and Linux), I generally shorten this to the following:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Mac（和Linux）上，我通常简化为以下步骤：
- en: '[PRE22]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Much easier. At this point, we can use the docker command to push containers
    to ECR.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 更容易。在这一点上，我们可以使用docker命令将容器推送到ECR。
- en: This is an area where I've seen a couple of problems.  I've found the URL at
    the end of the secret can still be the root user and not the user you created
    for ECR (this login HAS to be for that user).  If that is the case, later commands
    will get weird authentication issues.  The fix is to delete all the AWS CLI configuration
    files and reconfigure.  This fix doesn't always work. Sometimes, I've had to use
    a fresh system/VM, go through the AWS CLI install/ config, and then generate this
    secret to get it to work.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我见过的一些问题的地方。我发现密钥末尾的URL可能仍然是根用户，而不是您为ECR创建的用户（此登录必须是该用户）。如果是这种情况，后续命令将出现奇怪的身份验证问题。解决方法是删除所有AWS
    CLI配置文件并重新配置。这种解决方法并不总是有效。有时候，我不得不使用一个全新的系统/虚拟机，通过AWS CLI安装/配置，然后生成这个密钥才能使其工作。
- en: Pushing containers into ECR
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将容器推送到ECR
- en: In this recipe we will rebuild our API and microservice containers and push
    them to ECR.  We will also push a RabbitMQ container to ECR.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将重建我们的API和微服务容器，并将它们推送到ECR。我们还将RabbitMQ容器推送到ECR。
- en: Getting ready
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Bear with this, as this can get tricky. In addition to our container images,
    we also need to push our RabbitMQ container to ECR. ECS doesn't talk to Docker
    Hub and and can't pull that image. it would be immensely convenient, but at the
    same time it's probably also a security issue.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 请耐心等待，因为这可能会变得棘手。除了我们的容器镜像之外，我们还需要将RabbitMQ容器推送到ECR。ECS无法与Docker Hub通信，也无法拉取该镜像。这将非常方便，但同时也可能是一个安全问题。
- en: Pushing these containers to ECR from a home internet connection can take a long
    time. I create a Linux image in EC2 in the same region as my ECR, pulled down
    the code from github, build the containers on that EC2 system, and then push to
    ECR.  The push takes a matter of minutes, if not seconds.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 从家庭互联网连接推送这些容器到ECR可能需要很长时间。我在EC2中创建了一个与我的ECR相同地区的Linux镜像，从github上拉取了代码，在那台EC2系统上构建了容器，然后推送到ECR。如果不是几秒钟的话，推送只需要几分钟。
- en: First, let's rebuild our API and microservice containers on our local system. 
    I've included the Python files, two docker files, and a configuration file for
    the microservice  in the `11/05` recipe folder.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们在本地系统上重建我们的API和微服务容器。我已经在`11/05`食谱文件夹中包含了Python文件、两个docker文件和微服务的配置文件。
- en: 'Let''s start with the build of the API container:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从构建API容器开始：
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This docker file is similar to the previous API Docker file with the modification
    to copy files from the `11/05` folder.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这个docker文件与之前的API Docker文件类似，只是修改了从`11/05`文件夹复制文件的部分。
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then build the container for the scraper microservice:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然后构建scraper微服务的容器：
- en: '[PRE25]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This Dockerfile is slightly different from the one for the microservice.  Its
    contents are the following:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这个Dockerfile与微服务的Dockerfile略有不同。它的内容如下：
- en: '[PRE26]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Now we are ready to work with configuring ECR to store our containers for use
    by ECS.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好配置ECR来存储我们的容器，供ECS使用。
- en: We now run the microservice using python and not with the "nameko run" command. 
    This is due to an issue with sequencing the launch of containers in ECS.  The
    "nameko run" command does not perform well if the RabbitMQ server is not already
    running, which is not guaranteed in ECS.  So, we start this with python.  Because
    of this, the implementation has a startup that essentially copies the code for
    "nameko run" and wraps it with a while loop and exception handlers as it retries
    connections until the container is stopped.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用python而不是“nameko run”命令来运行微服务。这是由于ECS中容器启动顺序的问题。如果RabbitMQ服务器尚未运行，“nameko
    run”命令的性能不佳，而在ECS中无法保证RabbitMQ服务器已经运行。因此，我们使用python启动。因此，该实现具有一个启动，基本上是复制“nameko
    run”的代码，并用while循环和异常处理程序包装它，直到容器停止。
- en: How to do it
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作
- en: 'We proceed with the recipe as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'When signed in to the account that we created for ECS, we get access to the
    Elastic Container Repository.  This service can hold our containers for use by
    ECS.  There are a number of AWS CLI commands that you can use to work with ECR. 
    Let''s start with the following that lists the existing repositories:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到我们为ECS创建的帐户后，我们可以访问弹性容器仓库。这项服务可以保存我们的容器供ECS使用。有许多AWS CLI命令可以用来处理ECR。让我们从列出现有仓库的以下命令开始：
- en: '[PRE27]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Right now we don''t have any repositories, so let''s create some.  We will
    create three repositories, one for each of the different containers: scraper-rest-api,
    scraper-microservice, and one for a RabbitMQ container, which we will call `rabbitmq`. 
    Each repository maps to one container by its name, but can have multiple tags
    (up to 1,000 different versions/tags for each). Let''s create the three repositories:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们还没有任何仓库，让我们创建一些。我们将创建三个仓库，分别用于不同的容器：scraper-rest-api、scraper-microservice，以及一个RabbitMQ容器，我们将其命名为`rabbitmq`。每个仓库都映射到一个容器，但可以有多个标签（每个最多有1,000个不同的版本/标签）。让我们创建这三个仓库：
- en: '[PRE28]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note the data returned.  We will need the repository URL for each in the following
    step(s).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意返回的数据。我们需要在接下来的步骤中使用每个仓库的URL。
- en: 'We need to *tag* our local container images so their docker knows that when
    we *push* them, they should go to a specific repository in our ECR.  At this point,
    you should have the following images in docker:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要*标记*我们的本地容器镜像，以便它们的docker知道当我们*推送*它们时，它们应该去我们ECR中的特定仓库。此时，您的docker中应该有以下镜像：
- en: '[PRE29]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Tag using the `<image-id> <ECR-repository-uri>` docker tag.  Let''s tag all
    three (we don''t need to do the python image):'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`<image-id> <ECR-repository-uri>` docker tag进行标记。让我们标记所有三个（我们不需要对python镜像进行操作）：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The list of docker images now shows the tagged images along with the originals:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在的docker镜像列表中显示了标记的镜像以及原始镜像：
- en: '[PRE31]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now we finally push the images into ECR:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们最终将镜像推送到ECR：
- en: '[PRE32]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now check that the images made it to the repository  The following shows this
    for `scraper-rest-api`:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在检查镜像是否已经到达仓库。以下是`scraper-rest-api`的情况：
- en: '[PRE33]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: With our containers now stored in ECR, we can go on and create a cluster to
    run our containers.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的容器已经存储在ECR中，我们可以继续创建一个集群来运行我们的容器。
- en: Creating an ECS cluster
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个ECS集群
- en: Elastic Container Service (ECS) is an AWS service that runs your Docker containers
    in the cloud.  There is a lot of power (and detail) in using ECS.  We will look
    at a simple deployment that runs our containers on a single EC2 virtual machine. 
    Our goal is to get our scraper to the cloud.  Extensive detail on using ECS to
    scale out the scraper is for another time (and book).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 弹性容器服务（ECS）是AWS在云中运行Docker容器的服务。使用ECS有很多强大的功能（和细节）。我们将看一个简单的部署，它在单个EC2虚拟机上运行我们的容器。我们的目标是将我们的爬虫放到云中。关于使用ECS扩展爬虫的详细信息将在另一个时间（和书籍）中介绍。
- en: How to do it
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到
- en: We start by creating an ECR cluster using the AWS CLI.  The we will create one
    EC2 virtual machine in the cluster to run our containers.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用AWS CLI创建一个ECR集群。然后我们将在集群中创建一个EC2虚拟机来运行我们的容器。
- en: I've included a shell file, in the `11/06` folder, names `create-cluster-complete.sh`,
    which runs through all of these commands in one run.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我在`11/06`文件夹中包含了一个shell文件，名为`create-cluster-complete.sh`，它可以一次运行所有这些命令。
- en: 'There are number of steps to getting this configured but they are all fairly
    simple.  Let''s walk through them:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多步骤需要进行配置，但它们都相当简单。让我们一起走过它们：
- en: 'The following creates an ECR cluster named scraper-cluster:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下创建了一个名为scraper-cluster的ECR集群：
- en: '[PRE34]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Wow, that was easy!  Well, there's a bit of detail to take care of yet.  At
    this point, we don't have any EC2 instances to run the containers.  We also need
    to set up key pairs, security groups, IAM policies, phew!  It seems like a lot,
    but we'll get through it quickly and easily.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，这太容易了！嗯，还有一些细节要处理。在这一点上，我们没有任何EC2实例来运行容器。我们还需要设置密钥对、安全组、IAM策略，哎呀！看起来很多，但我们将很快、很容易地完成它。
- en: 'Create a key pair. Every EC2 instance needs one to launch, and it is needed
    to remote into the instance (if you want to).  The following creates a key pair,
    puts it in a local file, and then confirms with AWS that it was created:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个密钥对。每个EC2实例都需要一个密钥对来启动，并且需要远程连接到实例（如果您想要的话）。以下是创建一个密钥对，将其放入本地文件，然后与AWS确认它已创建：
- en: '[PRE35]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now we create security groups.  A security group allows us to open ports to
    the cluster instance from the Internet, and hence allows us to access the apps
    running in our containers.  We will create a security group with ports 22 (ssh)
    and 80 (http), and the two ports for RabbitMQ (5672 and 15672) opened.  We need
    80 open to talk to the REST API (we''ll map 80 to the 8080 containers in the next
    recipe).  We don''t need 15672 and 5672 open, but they help with debugging the
    process by allowing you to connect into RabbitMQ from outside AWS. The following
    four commands create the security group and the rules in that group:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们创建安全组。安全组允许我们从互联网打开端口到集群实例，因此允许我们访问运行在我们的容器中的应用程序。我们将创建一个安全组，其中包括端口22（ssh）和80（http），以及RabbitMQ的两个端口（5672和15672）被打开。我们需要打开80端口以与REST
    API进行通信（我们将在下一个步骤中将80映射到8080容器）。我们不需要打开15672和5672端口，但它们有助于通过允许您从AWS外部连接到RabbitMQ来调试该过程。以下四个命令创建了安全组和该组中的规则：
- en: '[PRE36]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: You can confirm the contents of the security group using the aws ec2 describe-security-groups
    --group-names ScraperClusterSG command. This will output a JSON representation
    of the group.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用aws ec2 describe-security-groups --group-names ScraperClusterSG命令确认安全组的内容。这将输出该组的JSON表示。
- en: 'To launch an EC2 instance into an ECS cluster, it needs to have an IAM policy
    put in place to allow it to connect.  It also needs to have various abilities
    with ECR, such as pulling containers.  These are defined in the two files included
    in the recipe directory, `ecsPolicy.json` and `rolePolicy.json`. The following
    commands will register these policies with IAM (output is omitted):'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要将EC2实例启动到ECS集群中，需要放置一个IAM策略，以允许它进行连接。它还需要具有与ECR相关的各种能力，例如拉取容器。这些定义在配方目录中包含的两个文件`ecsPolicy.json`和`rolePolicy.json`中。以下命令将这些策略注册到IAM（输出被省略）：
- en: '[PRE37]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We need to do one more thing before we launch the instance.  We need to have
    a file to pass user data to the instance that tells the instance which cluster
    to connect to. If we don't do this, it will connect to a cluster named `default`
    instead of `scraper-cluster`.  This file is `userData.txt` in the recipe directory. 
    There is no real action here as I provided the file.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动实例之前，我们需要做一件事。我们需要有一个文件将用户数据传递给实例，告诉实例连接到哪个集群。如果我们不这样做，它将连接到名为`default`而不是`scraper-cluster`的集群。这个文件是`userData.txt`在配方目录中。这里没有真正的操作，因为我提供了这个文件。
- en: 'New we launch an instance in our cluster.  We need to use an ECS-optimized
    AMI or create an AMI with the ECS container agent.  We will use a prebuilt AMI
    with this agent.  The following kicks off the instance:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们在集群中启动一个实例。我们需要使用一个经过优化的ECS AMI或创建一个带有ECS容器代理的AMI。我们将使用一个带有此代理的预构建AMI。以下是启动实例的步骤：
- en: '[PRE38]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This will spit out a bit of JSON describing your instance.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出描述您的实例的一些JSON。
- en: 'After a few minutes, you can check that this instance is running in the container:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 几分钟后，您可以检查此实例是否在容器中运行：
- en: '[PRE39]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Awesome!  Now we need to define tasks to run on the container instances.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！现在我们需要定义要在容器实例上运行的任务。
- en: This is an m4.large instance.  It's a bit larger than the t2.micro that fits
    within the free-tier.  So, make sure you don't leave this running if you want
    to keep things cheap.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个m4.large实例。它比适用于免费层的t2.micro大一点。因此，如果您想保持成本低廉，请确保不要让它长时间运行。
- en: Creating a task to run our containers
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个运行我们的容器的任务
- en: In this recipe, we will create an ECS task.  A task tells the ECR cluster manager
    which containers to run. A task is a description of which containers in ECR  to
    run and the parameters required for each.  The task description will feel a lot
    like that which we have done with Docker Compose.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个步骤中，我们将创建一个ECS任务。任务告诉ECR集群管理器要运行哪些容器。任务是对要在ECR中运行的容器以及每个容器所需的参数的描述。任务描述会让我们联想到我们使用Docker
    Compose所做的事情。
- en: Getting ready
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The task definition can be built with the GUI or started by submitting a task
    definition JSON file.  We will use the latter technique and examine the structure
    of the file, `td.json`, which describes how to run our containers together.  This
    file is in the `11/07` recipe folder.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 任务定义可以使用GUI构建，也可以通过提交任务定义JSON文件来启动。我们将使用后一种技术，并检查文件`td.json`的结构，该文件描述了如何一起运行我们的容器。此文件位于`11/07`配方文件夹中。
- en: How to do it
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作步骤
- en: 'The following command registers the task with ECS:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将任务注册到ECS：
- en: '[PRE40]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The output is the definition as filled out by ECS and acknowledges receipt of
    the task definition.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是由ECS填写的任务定义，并确认接收到任务定义。
- en: How it works
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: The task definition consists of two primary sections.  The first gives some
    general information about the tasks as a whole, such as how much memory and CPU
    is allowed for the containers as a whole.  It then consists of a section that
    defines the three containers we will run.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 任务定义由两个主要部分组成。第一部分提供有关整体任务的一些一般信息，例如为整个容器允许多少内存和CPU。然后它包括一个定义我们将运行的三个容器的部分。
- en: 'The file begins with a few lines that define the overall settings:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 文件以定义整体设置的几行开头：
- en: '[PRE41]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The actual name of the task is defined by the `"family"` property.  We state
    the our containers require EC2 (tasks can be run without EC2 - ours needs it).
    Then we state that we want to constrain the entire task to the specified amount
    of CPU and memory, and we are not attaching any volumes.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 任务的实际名称由`“family”`属性定义。我们声明我们的容器需要EC2（任务可以在没有EC2的情况下运行-我们的任务需要它）。然后我们声明我们希望将整个任务限制为指定的CPU和内存量，并且我们不附加任何卷。
- en: 'Now let''s look at the section where the containers are defined.  It starts
    with the following:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下定义容器的部分。它以以下内容开始：
- en: '[PRE42]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now let''s examine each container definition.  The following is the definition
    for the `rabbitmq` container:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们逐个检查每个容器的定义。以下是`rabbitmq`容器的定义：
- en: '[PRE43]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The first line defines the name of the container, and this name also participates
    in DNS resolution of the name of this container by the API and scraper containers. 
    The image tag defines the ECR repository URI to pull for the container.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行定义了容器的名称，此名称还参与API和scraper容器通过DNS解析此容器的名称。图像标签定义了要为容器拉取的ECR存储库URI。
- en: Make sure to change the image URL for this and the other two containers to that
    of your repositories.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将此容器和其他两个容器的图像URL更改为您的存储库的图像URL。
- en: Next are a definition of maximum CPU (0 is unlimited) and memory to be allowed
    for this container. The port mapping defines the mappings between the container
    host (the EC2 instance we created in the cluster) and the container.  We map the
    two RabbitMQ ports.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是定义允许为此容器分配的最大CPU（0表示无限）和内存。端口映射定义了容器主机（我们在集群中创建的EC2实例）和容器之间的映射。我们映射了两个RabbitMQ端口。
- en: The essential tag states that this container must remain running.  If it fails,
    the entire task will be stopped.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 基本标签表示此容器必须保持运行。如果失败，整个任务将被停止。
- en: 'The next container defined is the scraper microservice:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来定义的容器是scraper微服务：
- en: '[PRE44]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This differs in that it has an environment variable and links defined.  The
    environment variable is the URL for the `rabbitmq` container.  ECS will ensure
    that the environment variable is set to this value within this container (implementing
    Factor-3).  While this is the same URL as when we ran this locally on docker compose,
    it could be a different URL if the `rabbitmq` container was named differently
    or on another cluster.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这与具有环境变量和链接定义的不同。环境变量是`rabbitmq`容器的URL。ECS将确保在此容器中将环境变量设置为此值（实现Factor-3）。虽然这与我们在本地使用docker
    compose运行时的URL相同，但如果`rabbitmq`容器的名称不同或在另一个集群上，它可能是不同的URL。
- en: The links settings needs a little explanation.  Links are a deprecated feature
    of Docker but still used in ECS.  They are required in ECS to have the container
    resolve DNS names for other containers in the same cluster network.  This tells
    ECS that when this container tries to resolve the `rabbitmq` hostname (as defined
    in the environment variable), it should return the IP address assigned to that
    container.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 链接设置需要一点解释。链接是Docker的一个已弃用功能，但在ECS中仍在使用。在ECS中，它们是必需的，以便容器解析同一集群网络中其他容器的DNS名称。这告诉ECS，当此容器尝试解析`rabbitmq`主机名（如环境变量中定义的那样）时，它应返回分配给该容器的IP地址。
- en: 'The remainder of the file defines the API container:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的其余部分定义了API容器：
- en: '[PRE45]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: In this definition, we define the port mapping to allow HTTP into the container,
    and set the environment variables for the API to use to talk to Elastic Cloud
    and the `rabbitmq` server (which passed the requests to the `scraper-microservice`
    container).  This also defines a link to `rabbitmq` as that needs to also be resolved.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在此定义中，我们定义了端口映射以允许HTTP进入容器，并设置了API用于与Elastic Cloud和`rabbitmq`服务器通信的环境变量（该服务器将请求传递给`scraper-microservice`容器）。这还定义了对`rabbitmq`的链接，因为也需要解析。
- en: Starting and accessing the containers in AWS
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在AWS中启动和访问容器
- en: In this recipe, we will start our scraper as a service by telling ECS to run
    our task definition.  Then we will check hat it is running by issuing a curl to
    get contents of a job listing.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在此配方中，我们将通过告知ECS运行我们的任务定义来将我们的scraper作为服务启动。然后，我们将通过发出curl来检查它是否正在运行，以获取作业列表的内容。
- en: Getting ready
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: We need to do one quick thing before running the task.  Tasks in ECS go through
    revisions.  Each time you register a task definition with the same name ("family"),
    ECS defines a new revision number.  You can run any of the revisions.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行任务之前，我们需要做一件事。ECS中的任务经历多次修订。每次您使用相同名称（“family”）注册任务定义时，ECS都会定义一个新的修订号。您可以运行任何修订版本。
- en: 'To run the most recent one, we need to list the task definitions for that family
    and find the most recent revision number.  The following lists all of the task
    definitions in the cluster.  At this point we only have one:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行最新的版本，我们需要列出该family的任务定义，并找到最新的修订号。以下列出了集群中的所有任务定义。此时我们只有一个：
- en: '[PRE46]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Notice my revision number is at 17.  While this is my only currently registered
    version of this task, I have registered (and unregistered) 16 previous revisions.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我的修订号是17。虽然这是我当前唯一注册的此任务的版本，但我已经注册（和注销）了16个之前的修订版本。
- en: How to do it
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做
- en: 'We proceed with the recipe as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照以下步骤进行：
- en: 'Now we can run our task. We do this with the following command:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以运行我们的任务。我们可以使用以下命令来完成这个操作：
- en: '[PRE47]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The output gives us a current status of the task.  The very first time this
    is run, it will take a little time to get going, as the containers are being copied
    over to the EC2 instance.  The main culprit of that delayu is the `scraper-microservice`
    container with all of the NLTK data.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 输出给我们提供了任务的当前状态。第一次运行时，它需要一些时间来启动，因为容器正在复制到EC2实例上。造成延迟的主要原因是带有所有NLTK数据的`scraper-microservice`容器。
- en: 'You can check the status of the task with the following command:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用以下命令检查任务的状态：
- en: '[PRE48]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: You will need to change the task GUID to match guid in the `"taskArn"` property
    of the output from running the task.  When all the containers are running, we
    are ready to test the API.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要更改任务GUID以匹配从运行任务的输出的`"taskArn"`属性中获取的GUID。当所有容器都在运行时，我们就可以测试API了。
- en: 'To call our service, we will need to find the IP address or DNS name for our
    cluster instance. you can get this from the output when we created the cluster,
    through the portal, or with the following commands.  First, describe the cluster
    instances:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用我们的服务，我们需要找到集群实例的IP地址或DNS名称。您可以从我们创建集群时的输出中获取这些信息，也可以通过门户或以下命令获取。首先，描述集群实例：
- en: '[PRE49]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'With the GUID for our EC2 instance, we can query its info and pull the EC2
    instance ID with the following:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们EC2实例的GUID，我们可以查询其信息并使用以下命令获取EC2实例ID：
- en: '[PRE50]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'With that instance ID, we can get the DNS name:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有了那个实例ID，我们可以获取DNS名称：
- en: '[PRE51]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'And with that DNS name, we can make a curl to get a job listing:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有了那个DNS名称，我们可以使用curl来获取作业列表：
- en: '[PRE52]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: And we get the following familiar result!
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们得到了以下熟悉的结果！
- en: '[PRE53]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Our scraper is now running in the cloud!
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的爬虫现在正在云端运行！
- en: There's more...
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Our scraper is running on an `m4.large` instance, so we would like to shut it
    down to we don't exceed our free-tier usage.  This is a two-step process. First,
    the EC2 instances in the cluster need to be terminated, and the cluster deleted. 
    Note that deleting the cluster DOES NOT terminate the EC2 instances.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的爬虫正在一个`m4.large`实例上运行，所以我们想要关闭它，以免超出免费使用额度。这是一个两步过程。首先，需要终止集群中的EC2实例，然后删除集群。请注意，删除集群不会终止EC2实例。
- en: 'We can terminate the EC2 instance using the following (and the instance ID
    we just got from interrogating the cluster):'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令终止EC2实例（以及我们刚刚从集群询问中获取的实例ID）：
- en: '[PRE54]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'And the cluster can be deleted with:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 集群可以使用以下命令删除：
- en: '[PRE55]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
