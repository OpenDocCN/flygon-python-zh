["```py\npip install unicodecsv==0.14.1\n```", "```py\nfrom __future__ import print_function\nfrom argparse import ArgumentParser\nimport datetime\nimport os\nimport struct\n\nfrom utility.pytskutil import TSKUtil\nimport unicodecsv as csv\n```", "```py\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument('EVIDENCE_FILE', help=\"Path to evidence file\")\n    parser.add_argument('IMAGE_TYPE', help=\"Evidence file format\",\n                        choices=('ewf', 'raw'))\n    parser.add_argument('CSV_REPORT', help=\"Path to CSV report\")\n    args = parser.parse_args()\n    main(args.EVIDENCE_FILE, args.IMAGE_TYPE, args.CSV_REPORT)\n```", "```py\ndef main(evidence, image_type, report_file):\n    tsk_util = TSKUtil(evidence, image_type)\n\n    dollar_i_files = tsk_util.recurse_files(\"$I\", path='/$Recycle.bin',\n                                            logic=\"startswith\")\n\n    if dollar_i_files is not None:\n        processed_files = process_dollar_i(tsk_util, dollar_i_files)\n\n        write_csv(report_file,\n                  ['file_path', 'file_size', 'deleted_time',\n                   'dollar_i_file', 'dollar_r_file', 'is_directory'],\n                  processed_files)\n    else:\n        print(\"No $I files found\")\n```", "```py\ndef process_dollar_i(tsk_util, dollar_i_files):\n    processed_files = []\n    for dollar_i in dollar_i_files:\n        # Interpret file metadata\n        file_attribs = read_dollar_i(dollar_i[2])\n        if file_attribs is None:\n            continue # Invalid $I file\n        file_attribs['dollar_i_file'] = os.path.join(\n            '/$Recycle.bin', dollar_i[1][1:])\n```", "```py\n        # Get the $R file\n        recycle_file_path = os.path.join(\n            '/$Recycle.bin',\n            dollar_i[1].rsplit(\"/\", 1)[0][1:]\n        )\n        dollar_r_files = tsk_util.recurse_files(\n            \"$R\" + dollar_i[0][2:],\n            path=recycle_file_path, logic=\"startswith\"\n        )\n```", "```py\n        if dollar_r_files is None:\n            dollar_r_dir = os.path.join(recycle_file_path,\n                                        \"$R\" + dollar_i[0][2:])\n            dollar_r_dirs = tsk_util.query_directory(dollar_r_dir)\n            if dollar_r_dirs is None:\n                file_attribs['dollar_r_file'] = \"Not Found\"\n                file_attribs['is_directory'] = 'Unknown'\n            else:\n                file_attribs['dollar_r_file'] = dollar_r_dir\n                file_attribs['is_directory'] = True\n```", "```py\n        else:\n            dollar_r = [os.path.join(recycle_file_path, r[1][1:])\n                        for r in dollar_r_files]\n            file_attribs['dollar_r_file'] = \";\".join(dollar_r)\n            file_attribs['is_directory'] = False\n```", "```py\n        processed_files.append(file_attribs)\n    return processed_files\n```", "```py\ndef read_dollar_i(file_obj):\n    if file_obj.read_random(0, 8) != '\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00':\n        return None # Invalid file\n```", "```py\n    raw_file_size = struct.unpack('<q', file_obj.read_random(8, 8))\n    raw_deleted_time = struct.unpack('<q', file_obj.read_random(16, 8))\n    raw_file_path = file_obj.read_random(24, 520)\n```", "```py\n    file_size = sizeof_fmt(raw_file_size[0])\n    deleted_time = parse_windows_filetime(raw_deleted_time[0])\n    file_path = raw_file_path.decode(\"utf16\").strip(\"\\x00\")\n    return {'file_size': file_size, 'file_path': file_path,\n            'deleted_time': deleted_time}\n```", "```py\ndef sizeof_fmt(num, suffix='B'):\n    # From https://stackoverflow.com/a/1094933/3194812\n    for unit in ['', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi']:\n        if abs(num) < 1024.0:\n            return \"%3.1f%s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n```", "```py\ndef parse_windows_filetime(date_value):\n    microseconds = float(date_value) / 10\n    ts = datetime.datetime(1601, 1, 1) + datetime.timedelta(\n        microseconds=microseconds)\n    return ts.strftime('%Y-%m-%d %H:%M:%S.%f')\n```", "```py\ndef write_csv(outfile, fieldnames, data):\n    with open(outfile, 'wb') as open_outfile:\n        csvfile = csv.DictWriter(open_outfile, fieldnames)\n        csvfile.writeheader()\n        csvfile.writerows(data)\n```", "```py\npip install olefile==0.44\n```", "```py\nfrom __future__ import print_function\nfrom argparse import ArgumentParser\nimport unicodecsv as csv\nimport os\nimport StringIO\n\nfrom utility.pytskutil import TSKUtil\nimport olefile\n```", "```py\nREPORT_COLS = ['note_id', 'created', 'modified', 'note_text', 'note_file']\n```", "```py\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument('EVIDENCE_FILE', help=\"Path to evidence file\")\n    parser.add_argument('IMAGE_TYPE', help=\"Evidence file format\",\n                        choices=('ewf', 'raw'))\n    parser.add_argument('REPORT_FOLDER', help=\"Path to report folder\")\n    args = parser.parse_args()\n    main(args.EVIDENCE_FILE, args.IMAGE_TYPE, args.REPORT_FOLDER)\n```", "```py\ndef main(evidence, image_type, report_folder):\n    tsk_util = TSKUtil(evidence, image_type)\n    note_files = tsk_util.recurse_files('StickyNotes.snt', '/Users',\n                                        'equals')\n```", "```py\n    report_details = []\n    for note_file in note_files:\n        user_dir = note_file[1].split(\"/\")[1]\n        file_like_obj = create_file_like_obj(note_file[2])\n        note_data = parse_snt_file(file_like_obj)\n        if note_data is None:\n            continue\n        write_note_rtf(note_data, os.path.join(report_folder, user_dir))\n        report_details += prep_note_report(note_data, REPORT_COLS,\n                                           \"/Users\" + note_file[1])\n    write_csv(os.path.join(report_folder, 'sticky_notes.csv'), REPORT_COLS,\n              report_details)\n```", "```py\ndef create_file_like_obj(note_file):\n    file_size = note_file.info.meta.size\n    file_content = note_file.read_random(0, file_size)\n    return StringIO.StringIO(file_content)\n```", "```py\ndef parse_snt_file(snt_file):\n    if not olefile.isOleFile(snt_file):\n        print(\"This is not an OLE file\")\n        return None\n    ole = olefile.OleFileIO(snt_file)\n    note = {}\n    for stream in ole.listdir():\n        if stream[0].count(\"-\") == 3:\n            if stream[0] not in note:\n                note[stream[0]] = {\n                    # Read timestamps\n                    \"created\": ole.getctime(stream[0]),\n                    \"modified\": ole.getmtime(stream[0])\n                }\n\n            content = None\n            if stream[1] == '0':\n                # Parse RTF text\n                content = ole.openstream(stream).read()\n            elif stream[1] == '3':\n                # Parse UTF text\n                content = ole.openstream(stream).read().decode(\"utf-16\")\n\n            if content:\n                note[stream[0]][stream[1]] = content\n\n    return note\n```", "```py\ndef write_note_rtf(note_data, report_folder):\n    if not os.path.exists(report_folder):\n        os.makedirs(report_folder)\n    for note_id, stream_data in note_data.items():\n        fname = os.path.join(report_folder, note_id + \".rtf\")\n        with open(fname, 'w') as open_file:\n            open_file.write(stream_data['0'])\n```", "```py\ndef prep_note_report(note_data, report_cols, note_file):\n    report_details = []\n    for note_id, stream_data in note_data.items():\n        report_details.append({\n            \"note_id\": note_id,\n            \"created\": stream_data['created'],\n            \"modified\": stream_data['modified'],\n            \"note_text\": stream_data['3'].strip(\"\\x00\"),\n            \"note_file\": note_file\n        })\n    return report_details\n```", "```py\ndef write_csv(outfile, fieldnames, data):\n    with open(outfile, 'wb') as open_outfile:\n        csvfile = csv.DictWriter(open_outfile, fieldnames)\n        csvfile.writeheader()\n        csvfile.writerows(data)\n```", "```py\npip install python-registry==1.0.4\n```", "```py\nfrom __future__ import print_function\nfrom argparse import ArgumentParser\nimport datetime\nimport StringIO\nimport struct\n\nfrom utility.pytskutil import TSKUtil\nfrom Registry import Registry\n```", "```py\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument('EVIDENCE_FILE', help=\"Path to evidence file\")\n    parser.add_argument('IMAGE_TYPE', help=\"Evidence file format\",\n                        choices=('ewf', 'raw'))\n    args = parser.parse_args()\n    main(args.EVIDENCE_FILE, args.IMAGE_TYPE)\n```", "```py\ndef main(evidence, image_type):\n    tsk_util = TSKUtil(evidence, image_type)\n    tsk_system_hive = tsk_util.recurse_files(\n        'system', '/Windows/system32/config', 'equals')\n    tsk_software_hive = tsk_util.recurse_files(\n        'software', '/Windows/system32/config', 'equals')\n\n    system_hive = open_file_as_reg(tsk_system_hive[0][2])\n    software_hive = open_file_as_reg(tsk_software_hive[0][2])\n\n    process_system_hive(system_hive)\n    process_software_hive(software_hive)\n```", "```py\ndef open_file_as_reg(reg_file):\n    file_size = reg_file.info.meta.size\n    file_content = reg_file.read_random(0, file_size)\n    file_like_obj = StringIO.StringIO(file_content)\n    return Registry.Registry(file_like_obj)\n```", "```py\ndef process_system_hive(hive):\n    root = hive.root()\n    current_control_set = root.find_key(\"Select\").value(\"Current\").value()\n    control_set = root.find_key(\"ControlSet{:03d}\".format(\n        current_control_set))\n```", "```py\n    raw_shutdown_time = struct.unpack(\n        '<Q', control_set.find_key(\"Control\").find_key(\"Windows\").value(\n            \"ShutdownTime\").value()\n    )\n    shutdown_time = parse_windows_filetime(raw_shutdown_time[0])\n    print(\"Last Shutdown Time: {}\".format(shutdown_time))\n```", "```py\n    time_zone = control_set.find_key(\"Control\").find_key(\n        \"TimeZoneInformation\").value(\"TimeZoneKeyName\").value()\n    print(\"Machine Time Zone: {}\".format(time_zone))\n```", "```py\n    computer_name = control_set.find_key(\n        \"Control\").find_key(\"ComputerName\").find_key(\n            \"ComputerName\").value(\"ComputerName\").value()\n    print(\"Machine Name: {}\".format(computer_name))\n```", "```py\n    last_access = control_set.find_key(\"Control\").find_key(\n        \"FileSystem\").value(\"NtfsDisableLastAccessUpdate\").value()\n    last_access = \"Disabled\" if last_access == 1 else \"enabled\"\n    print(\"Last Access Updates: {}\".format(last_access))\n```", "```py\ndef parse_windows_filetime(date_value):\n    microseconds = float(date_value) / 10\n    ts = datetime.datetime(1601, 1, 1) + datetime.timedelta(\n        microseconds=microseconds)\n    return ts.strftime('%Y-%m-%d %H:%M:%S.%f')\n\ndef parse_unix_epoch(date_value):\n    ts = datetime.datetime.fromtimestamp(date_value)\n    return ts.strftime('%Y-%m-%d %H:%M:%S.%f')\n```", "```py\ndef process_software_hive(hive):\n    root = hive.root()\n    nt_curr_ver = root.find_key(\"Microsoft\").find_key(\n        \"Windows NT\").find_key(\"CurrentVersion\")\n\n    print(\"Product name: {}\".format(nt_curr_ver.value(\n        \"ProductName\").value()))\n    print(\"CSD Version: {}\".format(nt_curr_ver.value(\n        \"CSDVersion\").value()))\n    print(\"Current Build: {}\".format(nt_curr_ver.value(\n        \"CurrentBuild\").value()))\n    print(\"Registered Owner: {}\".format(nt_curr_ver.value(\n        \"RegisteredOwner\").value()))\n    print(\"Registered Org: {}\".format(nt_curr_ver.value(\n        \"RegisteredOrganization\").value()))\n\n    raw_install_date = nt_curr_ver.value(\"InstallDate\").value()\n    install_date = parse_unix_epoch(raw_install_date)\n    print(\"Installation Date: {}\".format(install_date))\n```", "```py\npip install jinja2==2.9.6\n```", "```py\nfrom __future__ import print_function\nfrom argparse import ArgumentParser\nimport os\nimport StringIO\nimport struct\n\nfrom utility.pytskutil import TSKUtil\nfrom Registry import Registry\nimport jinja2\n```", "```py\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument('EVIDENCE_FILE',\n                        help=\"Path to evidence file\")\n    parser.add_argument('IMAGE_TYPE',\n                        help=\"Evidence file format\",\n                        choices=('ewf', 'raw'))\n    parser.add_argument('REPORT',\n                        help=\"Path to report file\")\n    args = parser.parse_args()\n    main(args.EVIDENCE_FILE, args.IMAGE_TYPE, args.REPORT)\n```", "```py\ndef main(evidence, image_type, report):\n    tsk_util = TSKUtil(evidence, image_type)\n    tsk_ntuser_hives = tsk_util.recurse_files('ntuser.dat',\n                                              '/Users', 'equals')\n\n    nt_rec = {\n        'wordwheel': {'data': [], 'title': 'WordWheel Query'},\n        'typed_path': {'data': [], 'title': 'Typed Paths'},\n        'run_mru': {'data': [], 'title': 'Run MRU'}\n    }\n    for ntuser in tsk_ntuser_hives:\n        uname = ntuser[1].split(\"/\")[1]\n```", "```py\n        open_ntuser = open_file_as_reg(ntuser[2])\n        try:\n            explorer_key = open_ntuser.root().find_key(\n                \"Software\").find_key(\"Microsoft\").find_key(\n                    \"Windows\").find_key(\"CurrentVersion\").find_key(\n                        \"Explorer\")\n        except Registry.RegistryKeyNotFoundException:\n            continue # Required registry key not found for user\n```", "```py\n        nt_rec['wordwheel']['data'] += parse_wordwheel(\n            explorer_key, uname)\n        nt_rec['typed_path']['data'] += parse_typed_paths(\n            explorer_key, uname)\n        nt_rec['run_mru']['data'] += parse_run_mru(\n            explorer_key, uname)\n```", "```py\n    nt_rec['wordwheel']['headers'] = \\\n        nt_rec['wordwheel']['data'][0].keys()\n\n    nt_rec['typed_path']['headers'] = \\\n        nt_rec['typed_path']['data'][0].keys()\n\n    nt_rec['run_mru']['headers'] = \\\n        nt_rec['run_mru']['data'][0].keys()\n```", "```py\n    write_html(report, nt_rec)\n```", "```py\ndef open_file_as_reg(reg_file):\n    file_size = reg_file.info.meta.size\n    file_content = reg_file.read_random(0, file_size)\n    file_like_obj = StringIO.StringIO(file_content)\n    return Registry.Registry(file_like_obj)\n```", "```py\ndef parse_wordwheel(explorer_key, username):\n    try:\n        wwq = explorer_key.find_key(\"WordWheelQuery\")\n    except Registry.RegistryKeyNotFoundException:\n        return []\n```", "```py\n    mru_list = wwq.value(\"MRUListEx\").value()\n    mru_order = []\n    for i in xrange(0, len(mru_list), 2):\n        order_val = struct.unpack('h', mru_list[i:i + 2])[0]\n        if order_val in mru_order and order_val in (0, -1):\n            break\n        else:\n            mru_order.append(order_val)\n```", "```py\n    search_list = []\n    for count, val in enumerate(mru_order):\n        ts = \"N/A\"\n        if count == 0:\n            ts = wwq.timestamp()\n```", "```py\n        search_list.append({\n            'timestamp': ts,\n            'username': username,\n            'order': count,\n            'value_name': str(val),\n            'search': wwq.value(str(val)).value().decode(\n                \"UTF-16\").strip(\"\\x00\")\n        })\n    return search_list\n```", "```py\ndef parse_typed_paths(explorer_key, username):\n    try:\n        typed_paths = explorer_key.find_key(\"TypedPaths\")\n    except Registry.RegistryKeyNotFoundException:\n        return []\n```", "```py\n    typed_path_details = []\n    for val in typed_paths.values():\n        typed_path_details.append({\n            \"username\": username,\n            \"value_name\": val.name(),\n            \"path\": val.value()\n        })\n    return typed_path_details\n```", "```py\ndef parse_run_mru(explorer_key, username):\n    try:\n        run_mru = explorer_key.find_key(\"RunMRU\")\n    except Registry.RegistryKeyNotFoundException:\n        return []\n```", "```py\n    if len(run_mru.values()) == 0:\n        return []\n```", "```py\n    mru_list = run_mru.value(\"MRUList\").value()\n    mru_order = []\n    for i in mru_list:\n        mru_order.append(i)\n```", "```py\n    mru_details = []\n    for count, val in enumerate(mru_order):\n        ts = \"N/A\"\n        if count == 0:\n            ts = run_mru.timestamp()\n        mru_details.append({\n            \"username\": username,\n            \"timestamp\": ts,\n            \"order\": count,\n            \"value_name\": val,\n            \"run_statement\": run_mru.value(val).value()\n        })\n\n    return mru_details\n```", "```py\ndef write_html(outfile, data_dict):\n    cwd = os.path.dirname(os.path.abspath(__file__))\n    env = jinja2.Environment(loader=jinja2.FileSystemLoader(cwd))\n```", "```py\n    template = env.get_template(\"user_activity.html\")\n    rendering = template.render(nt_data=data_dict)\n    with open(outfile, 'w') as open_outfile:\n        open_outfile.write(rendering)\n```", "```py\n<html> \n<head>...</head> \n<body> \n    <div class=\"container\"> \n        {% for nt_content in nt_data.values() %} \n            <h2>{{ nt_content['title'] }}</h2> \n```", "```py\n            <table class=\"table table-hover table-condensed\"> \n                <tr> \n                    {% for header in nt_content['headers'] %} \n                        <th>{{ header }}</th> \n                    {% endfor %} \n                <tr/> \n```", "```py\n                {% for entry in nt_content['data'] %} \n                    <tr> \n                        {% for header in nt_content['headers'] %} \n                            <td>{{ entry[header] }}</td> \n                        {% endfor %} \n                    </tr> \n```", "```py\n                {% endfor %} \n            </table> \n            <br /> \n            <hr /> \n            <br /> \n        {% endfor %} \n    </div> \n</body> \n</html> \n```", "```py\n./synclibs.sh\n./autogen.sh\nsudo python setup.py install\n```", "```py\nfrom __future__ import print_function\nfrom argparse import ArgumentParser\nimport csv\nimport StringIO\n\nfrom utility.pytskutil import TSKUtil\nimport pylnk\n```", "```py\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument('EVIDENCE_FILE', help=\"Path to evidence file\")\n    parser.add_argument('IMAGE_TYPE', help=\"Evidence file format\",\n                        choices=('ewf', 'raw'))\n    parser.add_argument('CSV_REPORT', help=\"Path to CSV report\")\n    args = parser.parse_args()\n    main(args.EVIDENCE_FILE, args.IMAGE_TYPE, args.CSV_REPORT)\n```", "```py\ndef main(evidence, image_type, report):\n    tsk_util = TSKUtil(evidence, image_type)\n    lnk_files = tsk_util.recurse_files(\"lnk\", path=\"/\", logic=\"endswith\")\n    if lnk_files is None:\n        print(\"No lnk files found\")\n        exit(0)\n\n    columns = [\n        'command_line_arguments', 'description', 'drive_serial_number',\n        'drive_type', 'file_access_time', 'file_attribute_flags',\n        'file_creation_time', 'file_modification_time', 'file_size',\n        'environmental_variables_location', 'volume_label',\n        'machine_identifier', 'local_path', 'network_path',\n        'relative_path', 'working_directory'\n    ]\n```", "```py\n    parsed_lnks = []\n    for entry in lnk_files:\n        lnk = open_file_as_lnk(entry[2])\n        lnk_data = {'lnk_path': entry[1], 'lnk_name': entry[0]}\n        for col in columns:\n            lnk_data[col] = getattr(lnk, col, \"N/A\")\n        lnk.close()\n        parsed_lnks.append(lnk_data)\n\n    write_csv(report, columns + ['lnk_path', 'lnk_name'], parsed_lnks)\n```", "```py\ndef open_file_as_lnk(lnk_file):\n    file_size = lnk_file.info.meta.size\n    file_content = lnk_file.read_random(0, file_size)\n    file_like_obj = StringIO.StringIO(file_content)\n    lnk = pylnk.file()\n    lnk.open_file_object(file_like_obj)\n    return lnk\n```", "```py\ndef write_csv(outfile, fieldnames, data):\n    with open(outfile, 'wb') as open_outfile:\n        csvfile = csv.DictWriter(open_outfile, fieldnames)\n        csvfile.writeheader()\n        csvfile.writerows(data)\n```", "```py\n./synclibs.sh\n./autogen.sh\nsudo python setup.py install \n```", "```py\nfrom __future__ import print_function\nfrom argparse import ArgumentParser\nimport unicodecsv as csv\nimport datetime\nimport StringIO\nimport struct\n\nfrom utility.pytskutil import TSKUtil\nimport pyesedb\n\nCOL_TYPES = pyesedb.column_types\n```", "```py\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument('EVIDENCE_FILE', help=\"Path to evidence file\")\n    parser.add_argument('IMAGE_TYPE', help=\"Evidence file format\",\n                        choices=('ewf', 'raw'))\n    parser.add_argument('CSV_REPORT', help=\"Path to CSV report\")\n    args = parser.parse_args()\n    main(args.EVIDENCE_FILE, args.IMAGE_TYPE, args.CSV_REPORT)\n```", "```py\ndef main(evidence, image_type, report):\n    tsk_util = TSKUtil(evidence, image_type)\n    esedb_files = tsk_util.recurse_files(\n        \"Windows.edb\",\n        path=\"/ProgramData/Microsoft/Search/Data/Applications/Windows\",\n        logic=\"equals\"\n    )\n    if esedb_files is None:\n        print(\"No Windows.edb file found\")\n        exit(0)\n\n    for entry in esedb_files:\n        ese = open_file_as_esedb(entry[2])\n        if ese is None:\n            continue # Invalid ESEDB\n        report_cols, ese_data = process_windows_search(ese)\n\n    write_csv(report, report_cols, ese_data)\n```", "```py\ndef open_file_as_esedb(esedb):\n    file_size = esedb.info.meta.size\n    file_content = esedb.read_random(0, file_size)\n    file_like_obj = StringIO.StringIO(file_content)\n    esedb = pyesedb.file()\n    try:\n        esedb.open_file_object(file_like_obj)\n    except IOError:\n        return None\n    return esedb\n```", "```py\ndef process_windows_search(ese):\n    report_cols = [\n        (0, \"DocID\"), (286, \"System_KindText\"),\n        (35, \"System_ItemUrl\"), (5, \"System_DateModified\"),\n        (6, \"System_DateCreated\"), (7, \"System_DateAccessed\"),\n        (3, \"System_Size\"), (19, \"System_IsFolder\"),\n        (2, \"System_Search_GatherTime\"), (22, \"System_IsDeleted\"),\n        (61, \"System_FileOwner\"), (31, \"System_ItemPathDisplay\"),\n        (150, \"System_Link_TargetParsingPath\"),\n        (265, \"System_FileExtension\"), (348, \"System_ComputerName\"),\n        (34, \"System_Communication_AccountName\"),\n        (44, \"System_Message_FromName\"),\n        (43, \"System_Message_FromAddress\"), (49, \"System_Message_ToName\"),\n        (47, \"System_Message_ToAddress\"),\n        (62, \"System_Message_SenderName\"),\n        (189, \"System_Message_SenderAddress\"),\n        (52, \"System_Message_DateSent\"),\n        (54, \"System_Message_DateReceived\")\n    ]\n```", "```py\n    table = ese.get_table_by_name(\"SystemIndex_0A\")\n    table_data = []\n    for record in table.records:\n        record_info = {}\n        for col_id, col_name in report_cols:\n            rec_val = record.get_value_data(col_id)\n            col_type = record.get_column_type(col_id)\n```", "```py\n            if col_type in (COL_TYPES.DATE_TIME, COL_TYPES.BINARY_DATA):\n                try:\n                    raw_val = struct.unpack('>q', rec_val)[0]\n                    rec_val = parse_windows_filetime(raw_val)\n                except Exception:\n                    if rec_val is not None:\n                        rec_val = rec_val.encode('hex')\n\n            elif col_type in (COL_TYPES.TEXT, COL_TYPES.LARGE_TEXT):\n                try:\n                    rec_val = record.get_value_data_as_string(col_id)\n                except Exception:\n                    rec_val = rec_val.decode(\"utf-16-be\", \"replace\")\n\n            elif col_type == COL_TYPES.INTEGER_32BIT_SIGNED:\n                rec_val = record.get_value_data_as_integer(col_id)\n\n            elif col_type == COL_TYPES.BOOLEAN:\n                rec_val = rec_val == '\\x01'\n\n            else:\n                if rec_val is not None:\n                    rec_val = rec_val.encode('hex')\n\n            record_info[col_name] = rec_val\n        table_data.append(record_info)\n```", "```py\n    return [x[1] for x in report_cols], table_data\n```", "```py\ndef parse_windows_filetime(date_value):\n    microseconds = float(date_value) / 10\n    ts = datetime.datetime(1601, 1, 1) + datetime.timedelta(\n        microseconds=microseconds)\n    return ts.strftime('%Y-%m-%d %H:%M:%S.%f')\n```", "```py\ndef write_csv(outfile, fieldnames, data):\n    with open(outfile, 'wb') as open_outfile:\n        csvfile = csv.DictWriter(open_outfile, fieldnames)\n        csvfile.writeheader()\n        csvfile.writerows(data)\n```"]