- en: Practical Considerations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际考虑
- en: There are a bunch of algorithms presented in this book that can be used to solve
    real-world problems. This chapter is about some practical considerations the algorithms
    presented in this book.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中介绍的一堆算法可以用于解决现实世界问题。本章是关于本书中介绍的算法的一些实际考虑。
- en: This chapter is organized as follows. We will start with an introduction. Then,
    we will present the important topic of the explainability of an algorithm, which
    is the degree to which the internal mechanics of an algorithm can be explained
    in understandable terms. Then, we will present the ethics of using an algorithm
    and the possibility of creating biases when implementing them. Next, the techniques
    for handling NP-hard problems are discussed. Finally, we will look into factors
    that should be considered before choosing an algorithm.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的组织如下。我们将从介绍开始。然后，我们将介绍算法可解释性的重要主题，即算法内部机制能否以可理解的方式解释的程度。接下来，我们将介绍使用算法的道德和在实施时可能产生偏见的可能性。然后讨论处理NP难问题的技术。最后，我们将探讨在选择算法之前应考虑的因素。
- en: By the end of this chapter, you will have learned about the practical considerations
    that are important to keep in mind when using algorithms.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解在使用算法时需要牢记的实际考虑。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing practical considerations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍实际考虑
- en: The explainability of an algorithm
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的可解释性
- en: Understanding ethics and algorithms
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解伦理和算法
- en: Reducing bias in models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少模型中的偏见
- en: Tackling NP-hard problems
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决NP难问题
- en: When to use algorithms
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时使用算法
- en: Let's start with the introduction,
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从介绍开始，
- en: Introducing practical considerations
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍实际考虑
- en: In addition to designing, developing, and testing an algorithm, in many cases,
    it is important to consider certain practical aspects of starting to rely on a
    machine to solve a real-world problem as this makes the solution more useful.
    For certain algorithms, we may need to consider ways to reliably incorporate new
    important information that is expected to keep changing even after we have deployed
    our algorithm. Will incorporating this new information change the quality of our
    well-tested algorithm in any way? If so, how does our design handle it? And then,
    for some algorithms that use global patterns, we may need to keep an eye on real-time
    parameters that capture changes in the global geopolitical situation. Also, in
    some use cases, we may need to consider regulatory polices enforced at the time
    of use for the solution to be useful.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 除了设计、开发和测试算法外，在许多情况下，考虑开始依赖机器解决现实世界问题的某些实际方面也很重要，因为这会使解决方案更有用。对于某些算法，我们可能需要考虑可靠地整合预计会在部署算法后继续变化的新重要信息的方法。整合这些新信息会以任何方式改变我们经过良好测试的算法的质量吗？如果是，我们的设计如何处理？然后，对于一些使用全局模式的算法，我们可能需要关注捕捉全球地缘政治局势变化的实时参数。此外，在某些用例中，我们可能需要考虑在使用时强制执行的监管政策，以使解决方案有用。
- en: When we are using algorithms to solve a real-world problem, we are, in a way,
    relying on machines for problem solving. Even the most sophisticated algorithms
    are based on simplification and assumptions and cannot handle surprises. We are
    still not even close to fully handing over critical decision making to our own
    designed algorithms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用算法解决现实世界问题时，我们在某种程度上依赖机器进行问题解决。即使是最复杂的算法也是基于简化和假设的，并且无法处理意外情况。我们甚至还远远没有完全将关键决策交给我们设计的算法。
- en: For example, Google's designed recommendation engine algorithms have recently
    faced the European Union's regulatory restrictions due to privacy concerns. These
    algorithms may be some of the most advanced in their field. But if banned, these
    algorithms may actually turn out to be useless as they cannot be used to solve
    the problems they were supposed to tackle.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，谷歌设计的推荐引擎算法最近面临欧盟的监管限制，原因是隐私问题。这些算法可能是其领域中最先进的。但如果被禁止，这些算法实际上可能会变得无用，因为它们无法用于解决它们本应解决的问题。
- en: The truth of the matter is that, unfortunately, the practical considerations
    of an algorithm are still afterthoughts that are not usually considered at the
    initial design phase. For many use cases, once an algorithm is deployed and the
    short-term excitement of providing the solution is over, the practical aspects
    and implications of using an algorithm will be discovered over time and will define
    the success or failure of the project.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，不幸的是，算法的实际考虑仍然是在初始设计阶段通常不考虑的事后想法。对于许多用例来说，一旦算法部署并且提供解决方案的短期激动感过去后，使用算法的实际方面和影响将随着时间的推移被发现，并将定义项目的成功或失败。
- en: Let's look into a practical example where not paying attention to the practical
    consideration failed a high-profile project designed by one of the best IT companies
    in the world.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个实际例子，其中不注意实际考虑导致了一家世界顶尖IT公司设计的备受关注的项目失败。
- en: The sad story of an AI Twitter Bot
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个AI Twitter机器人的悲伤故事
- en: Let's present the classical example of Tay, which was presented as the first-ever
    AI Twitter bot created by Microsoft in 2016\. Being operated by an AI algorithm,
    Tay was supposed to learn from the environment and keep on improving itself. Unfortunately,
    after living in cyberspace for a couple of days, Tay started learning from the
    racism and rudeness of ongoing tweets. It soon started writing offensive tweets
    of its own. Although it exhibited intelligence and quickly learned how to create
    customized tweets based on real-time events, as designed, at the same time, it
    seriously offended people. Microsoft took it offline and tried to re-tool it,
    but that did not work. Microsoft had to eventually kill the project. That was
    the sad end of an ambitious project.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看Tay的经典例子，它是微软于2016年创建的第一个AI Twitter机器人。由AI算法操作，Tay应该从环境中学习并不断改进自己。不幸的是，在网络空间生活了几天后，Tay开始从不断发出的种族主义和粗鲁的推文中学习。它很快开始发表冒犯性的推文。尽管它表现出了智能，并迅速学会根据实时事件创建定制推文，但同时，它严重冒犯了人们。微软将其下线并尝试重新调整，但没有成功。微软最终不得不终止该项目。这是一个雄心勃勃的项目的悲伤结局。
- en: Note that although the intelligence built into it by Microsoft was impressive,
    the company ignored the practical implications of deploying a self-learning Twitter
    bot. The NLP and machine learning algorithms may have been the best in the class
    but due to the obvious shortcomings, it was practically a useless project. Today,
    Tay has become a textbook example of a failure due to ignoring the practical implications
    of allowing algorithms to learn on the fly. The lessons learned by the failure
    of Tay definitely influenced the AI projects of later years. Data scientists also
    started paying more attention to the transparency of algorithms. That brings us
    to the next topic, which explores the need and ways to make algorithms transparent.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管微软内置的智能令人印象深刻，但该公司忽视了部署自学习Twitter机器人的实际影响。NLP和机器学习算法可能是最好的，但由于明显的缺陷，这实际上是一个无用的项目。如今，Tay已成为忽视允许算法在飞行中学习的实际影响而导致失败的典型案例。Tay的失败所带来的教训肯定影响了后来几年的AI项目。数据科学家也开始更加关注算法的透明度。这将引出下一个主题，探讨使算法透明的需求和方法。
- en: The explainability of an algorithm
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法的可解释性
- en: A black box algorithm is one whose logic of is not interpretable by humans either
    due to its complexity or due to its logic being represented in a convoluted manner.
    On the other hand, a white box algorithm is one whose logic is visible and understandable
    for a human. In other words, explainability helps the human brain to understand
    why an algorithm is giving specific results. The degree of explainability is the
    measure to which a particular algorithm is understandable for the human brain.
    Many classes of algorithms, especially those related to machine learning, are
    classified as black box. If the algorithms are used for critical decision-making,
    it may be important to understand the reasons behind the results generated by
    the algorithm. Converting black box algorithms into white box ones also provides
    better insights into the inner workings of the model. An explainable algorithm
    will guide doctors as to which features were actually used to classify patients
    as sick or not. If the doctor has any doubts about the results, they can go back
    and double-check those particular features for accuracy.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 黑匣子算法是指其逻辑由于复杂性或逻辑以混乱的方式表示而无法被人类解释的算法。另一方面，白匣子算法是指其逻辑对人类可见和可理解的算法。换句话说，可解释性帮助人类大脑理解算法为何给出特定结果。可解释性的程度是特定算法对人类大脑可理解的程度。许多类别的算法，特别是与机器学习相关的算法，被归类为黑匣子。如果算法用于关键决策，了解算法产生结果的原因可能很重要。将黑匣子算法转换为白匣子算法还可以更好地了解模型的内部工作。可解释的算法将指导医生哪些特征实际上被用来将患者分类为患病或非患病。如果医生对结果有任何疑问，他们可以回头检查这些特定特征的准确性。
- en: Machine learning algorithms and explainability
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法和可解释性
- en: The explainability of an algorithm has special importance for machine learning
    algorithms. In many applications of machine learning, users are asked to trust
    a model to help them to make decisions. Explainability provides transparency when
    needed in such use cases.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的可解释性对于机器学习算法非常重要。在许多机器学习应用中，用户被要求相信模型能帮助他们做出决策。在这种情况下，可解释性在需要时提供透明度。
- en: Let's look deeper at a specific example. Let's assume that we want to use machine
    learning to predict the prices of houses in the Boston area based on their characteristics.
    Let's also assume that local city regulations will allow us to use machine learning
    algorithms only if we can provide detailed information for the justification of
    any predictions whenever needed. This information is needed for audit purposes
    to make sure that certain segments of the housing market are not artificially
    manipulated. Making our trained model explainable will provide this additional
    information.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入研究一个具体的例子。假设我们想使用机器学习来预测波士顿地区房屋价格，基于它们的特征。还假设当地的城市法规只允许我们使用机器学习算法，只要我们能在需要时提供任何预测的详细信息来进行辩解。这些信息是为了审计目的，以确保房地产市场的某些部分不会被人为操纵。使我们的训练模型可解释将提供这些额外信息。
- en: Let's look into different options that are available for implementing the explainability
    of our trained model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看实现我们训练模型可解释性的不同选项。
- en: Presenting strategies for explainability
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供可解释性策略
- en: 'For machine learning, there are fundamentally two strategies to provide explainability
    to algorithms:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于机器学习，基本上有两种策略可以为算法提供可解释性：
- en: '**A global explainability strategy:**  This is to provide the details of the
    formulation of a model as a whole.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全球可解释性策略：这是为了提供模型整体的制定细节。
- en: '**A local explainability strategy:**  This is to provide the rationale for
    one or more individual predictions made by our trained model.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部可解释性策略：** 这是为我们训练模型所做的一个或多个个体预测提供理由。'
- en: For global explainability, we have techniques such as **Testing with Concept
    Activation Vectors** (**TCAV**), which is used for providing explainability for
    image classification models. TCAV depends on calculating directional derivatives
    to quantify the degree of the relationship between a user-defined concept and
    the classification of pictures. For example, it will quantify how sensitive a
    prediction of classifying a person as male is to the presence of facial hair in
    the picture. There are other global explainability strategies such as **partial
    dependence plots** and calculating the **permutation importance**, which can help
    to explain the formulations in our trained model. Both global and local explainability
    strategies can either be model-specific or model-agnostic. Model-specific strategies
    apply to certain types of models, whereas model-agnostic strategies can be applied
    to a wide variety of models.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于全局可解释性，我们有诸如**概念激活向量测试**（**TCAV**）之类的技术，用于为图像分类模型提供可解释性。TCAV依赖于计算方向导数来量化用户定义的概念与图片分类之间的关系程度。例如，它将量化将一个人分类为男性的预测对图片中面部毛发的敏感程度。还有其他全局可解释性策略，如**部分依赖图**和计算**排列重要性**，可以帮助解释我们训练模型中的公式。全局和局部可解释性策略都可以是特定于模型的或模型不可知的。特定于模型的策略适用于某些类型的模型，而模型不可知的策略可以应用于各种模型。
- en: 'The following diagram summarizes the different strategies available for machine
    learning explainability:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表总结了机器学习可解释性的不同策略：
- en: '![](assets/508ea77c-e398-4c0a-a06d-d872d52423d3.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/508ea77c-e398-4c0a-a06d-d872d52423d3.png)'
- en: Now, let's look at how we can implement explainability using one of these strategies.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用这些策略之一来实施可解释性。
- en: Implementing explainability
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施可解释性
- en: '**Local Interpretable Model-Agnostic Explanations** (**LIME**) is a model-agnostic
    approach that can explain individual predictions made by a trained model. Being
    model-agnostic, it can explain the predictions of most types of trained  machine
    learning models.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**局部可解释模型不可知解释**（**LIME**）是一种模型不可知的方法，可以解释训练模型所做的个体预测。作为模型不可知，它可以解释大多数类型的训练机器学习模型的预测。'
- en: LIME explains decisions by inducing small changes to the input for each instance.
    It can gather the effects on the local decision boundary for that instance. It
    iterates over the loop to provide details for each variable. Looking at the output,
    we can see which variable has the most influence on that instance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LIME通过对每个实例的输入进行微小更改来解释决策。它可以收集该实例的局部决策边界的影响。它迭代循环以提供每个变量的详细信息。通过查看输出，我们可以看到哪个变量对该实例的影响最大。
- en: 'Let''s see how we can use LIME to make the individual predictions of our house
    price model  explainable:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用LIME使我们的房价模型的个体预测变得可解释：
- en: 'If you have never used LIME before, you need to install the package using `pip`:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您以前从未使用过LIME，您需要使用`pip`安装该软件包：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, let''s import the Python packages that we need:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，让我们导入我们需要的Python软件包：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will train a model that can predict housing prices in a particular city.
    For that we will first import the dataset that is stored in the `housing.pkl`
    file. Then, we will explore the features it has:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将训练一个能够预测特定城市房价的模型。为此，我们将首先导入存储在`housing.pkl`文件中的数据集。然后，我们将探索它具有的功能：
- en: '![](assets/df39d111-43cb-4129-90b9-61e991744bd4.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/df39d111-43cb-4129-90b9-61e991744bd4.png)'
- en: Based on these features we need to predict the price of a home.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些功能，我们需要预测房屋的价格。
- en: 'Now, let''s train the model. We will be using a random forest regressor to
    train the model. First we divide the data into testing and training partitions
    and then we using it to train the model:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们训练模型。我们将使用随机森林回归器来训练模型。首先，我们将数据分为测试和训练分区，然后使用它来训练模型：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, let us identify the category columns:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们识别类别列：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, let''s instantiate the LIME explainer with the required configuration
    parameters. Note that we are specifying that our label is `''price''`, representing
    the prices of houses in Boston:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用所需的配置参数实例化LIME解释器。请注意，我们正在指定我们的标签是`'price'`，表示波士顿房屋的价格：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let us try to look into the details of predictions. For that first let us import
    the pyplot as the plotter from matplotlib
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试查看预测的详细信息。首先让我们从matplotlib中导入绘图器。
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As the LIME explainer works on individual predictions, we need to choose the
    predictions we want to analyze. We have asked the explainer for its justification
    of the predictions indexed as `1` and `35`:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于LIME解释器适用于个体预测，我们需要选择要分析的预测。我们已要求解释器解释索引为`1`和`35`的预测的理由：
- en: '![](assets/68e5f21f-d5d7-4bd4-bd7a-4e78b13b8c87.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/68e5f21f-d5d7-4bd4-bd7a-4e78b13b8c87.png)'
- en: 'Let''s try to analyze the preceding explanation by LIME, which tells us the
    following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试分析LIME的上述解释，它告诉我们以下内容：
- en: '**The list of features used in the individual predictions**: They are indicated
    on the *y*-axis in the preceding screenshot.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个体预测中使用的功能列表：它们在前面的截图中显示在*y*轴上。
- en: '**The relative importance of the features in determining the decision**: The
    larger the bar line, the greater the importance is. The value of the number is
    on the *x*-axis.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策中功能的相对重要性：** 条形的长度越长，重要性越大。数字的值在*x*轴上。'
- en: '**The positive or negative influence of each of the input features on the label**:
    Red bars show a negative influence and green bars show the positive influence
    of a particular feature.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**每个输入功能对标签的正面或负面影响：** 红色条表示负面影响，绿色条表示特定功能的正面影响。'
- en: Understanding ethics and algorithms
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解伦理和算法
- en: The formulation of patterns through algorithms may directly or indirectly result
    in unethical decision making. While designing algorithms, it is difficult to foresee
    the full scope of the potential ethical implications, especially for large-scale
    algorithms, where more than one user may be involved in the design. This makes
    it even more difficult to analyze the effects of human subjectivity.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过算法制定模式可能会直接或间接导致不道德的决策。在设计算法时，很难预见潜在的道德影响的全部范围，特别是对于大规模算法，其中可能涉及多个用户。这使得分析人类主观性的影响变得更加困难。
- en: More and more companies are making the ethical analysis of an algorithm part
    of its design. But the truth is that the problems may not become apparent until
    we find a problematic use case.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越多的公司将算法的道德分析作为其设计的一部分。但事实是，问题可能直到我们发现一个有问题的用例才会变得明显。
- en: Problems with learning algorithms
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习算法存在的问题
- en: Algorithms capable of fine-tuning themselves according to changing data patterns
    are called **learning** **algorithms**. They are in learning mode in real time,
    but this real-time learning capability may have ethical implications. This creates
    the possibility that their learning could result in decisions that may have problems
    from an ethical point of view.  As they are created to be in a continuous evolutionary
    phase, it is almost impossible  to continuously perform an ethical analysis of
    them.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 能够根据不断变化的数据模式进行自我调整的算法被称为**学习算法**。它们处于实时学习模式，但这种实时学习能力可能具有道德影响。这可能导致它们的学习结果在道德上存在问题。由于它们被创建为处于持续进化阶段，几乎不可能对它们进行持续的道德分析。
- en: As the complexity of algorithms grows, it is becoming more and more difficult
    to fully understand their long-term implications for individuals and groups within
    society.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 随着算法复杂性的增加，要完全理解它们对社会中个人和群体的长期影响变得越来越困难。
- en: Understanding ethical considerations
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解道德考虑
- en: Algorithmic solutions are mathematical formulations without hearts. It is the
    responsibility of the people responsible for developing algorithms to ensure that
    they conform to ethical sensitivities around the problem we are trying to solve.
    These ethical considerations of algorithms depend on the type of the algorithm.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 算法解决方案是没有感情的数学公式。负责开发算法的人有责任确保它们符合我们试图解决的问题周围的道德敏感性。这些算法的道德考虑取决于算法的类型。
- en: 'For example, let''s look into the following algorithms and their ethical considerations.
    Some examples of powerful algorithms for which careful ethical considerations
    are needed are as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看以下算法及其道德考虑。一些需要仔细考虑道德问题的强大算法的例子如下：
- en: Classification algorithms, when used on society, determine how individuals and
    groups are shaped and managed.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类算法在社会上的使用决定了个人和群体的塑造和管理方式。
- en: Algorithms, when used in recommendation engines,  can match resumes to job seekers,
    both individuals and groups.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在推荐引擎中使用算法时，可以将简历与求职者（个人和群体）进行匹配。
- en: Data mining algorithms are used to mine information from users and are provided
    to decision-makers and governments.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据挖掘算法用于从用户那里挖掘信息，并提供给决策者和政府。
- en: Machine learning algorithms are starting to be used by governments to grant
    or deny visas to applicants.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 政府开始使用机器学习算法来决定是否向申请人发放签证。
- en: Hence, the ethical consideration, of algorithms will depend on the use case
    and the entities they directly or indirectly affect. Careful analysis is needed
    from an ethical point of view before starting to use an algorithm for critical
    decision-making. In the upcoming sections, we shall see the factors that we should
    keep in mind while performing a careful analysis of algorithms.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，算法的道德考虑将取决于使用情况以及它们直接或间接影响的实体。在开始使用算法进行关键决策之前，需要从道德角度进行仔细分析。在接下来的部分中，我们将看到在进行算法的仔细分析时应该牢记的因素。
- en: Inconclusive evidence
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不确定的证据
- en: The data that is used to train a machine learning algorithm may not have conclusive
    evidence. For example, in clinical trials, the effectiveness of a drug may not
    be proven due to the limited available  evidence. Similarly, there may be limited
    inconclusive evidence that a certain postal code in a certain city is more likely
    to be involved in fraud. We should be careful when we are  judging our decision-making
    based on the mathematical patterns found through algorithms using this limited
    data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练机器学习算法的数据可能没有确凿的证据。例如，在临床试验中，由于有限的可用证据，一种药物的有效性可能无法得到证实。同样，可能存在有限的不确定证据表明某个城市的某个邮政编码更有可能涉及欺诈。我们在基于通过这些有限数据找到的数学模式做出决策时应该谨慎。
- en: Decisions that are based on inconclusive evidence are prone to lead to unjustified
    actions.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 基于不确定的证据做出的决定很可能导致不合理的行为。
- en: Traceability
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可追溯性
- en: The disconnection between the training phase and the testing phase in machine
    learning algorithms means that if there is some harm caused by an algorithm, it
    is very hard to trace and debug. Also, when a problem is found in an algorithm,
    it is difficult to actually determine the people who were affected by it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法在训练阶段和测试阶段之间的脱节意味着如果算法造成了一些伤害，很难追踪和调试。此外，当发现算法中存在问题时，很难确定受到影响的人。
- en: Misguided evidence
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 误导的证据
- en: Algorithms are data-driven formulations. The  **Garbage-in, Garbage-out** (**GIGO**)
    principle means that results from algorithms can only be as reliable as the data
    on which they are based. If there are biases in the data, they will be reflected
    in the algorithms as well.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 算法是数据驱动的公式。**垃圾进，垃圾出**（**GIGO**）原则意味着算法的结果只能像其基础数据一样可靠。如果数据中存在偏见，它们也会反映在算法中。
- en: Unfair outcomes
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不公平的结果
- en: The use of algorithms may result in harming vulnerable communities and groups
    that are already at a disadvantage.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的使用可能会对已处于不利地位的脆弱社区和群体造成伤害。
- en: Additionally, the use of algorithms to distribute research funding has been
    proven on more than one occasion to be biased toward the male population. Algorithms
    used for granting immigration are sometimes unintentionally biased toward vulnerable
    population groups.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，已经证明使用算法分配研究资金在多个场合上对男性人口存在偏见。用于授予移民的算法有时会无意中对脆弱人口群体存在偏见。
- en: Despite using high-quality data and complex mathematical formulations, if the
    result is an unfair outcome, the whole effort may bring more harm than benefit.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用高质量的数据和复杂的数学公式，如果结果是不公平的，那么整个努力可能会带来更多的伤害而不是好处。
- en: Reducing bias in models
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减少模型中的偏见
- en: In the current world, there are known, well-documented general biases based
    on gender, race, and sexual orientation. It means that the data we collect is
    expected to exhibit those biases unless we are dealing with an environment where
    an effort has been made to remove these biases before collecting the data.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前世界中，基于性别、种族和性取向已知的、有充分记录的一般偏见。这意味着我们收集的数据预计会展现出这些偏见，除非我们处理的是一个在收集数据之前已经努力消除这些偏见的环境。
- en: 'All bias in algorithms is,  directly or indirectly, due to human bias. Human
    bias can be reflected either in data used by the algorithm or in the formulation
    of the algorithm itself. For a typical machine learning project following the  **CRISP-DM**
    (short for **Cross-Industry Standard Process**) lifecycle, which was explained
    in  [Chapter 5](051e9b32-f15f-4e88-a63a-ae3c14696492.xhtml),  *Graph Algorithms*,
    the bias looks like the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 算法中的所有偏见，直接或间接地都是由人类偏见造成的。人类偏见可以体现在算法使用的数据中，也可以体现在算法本身的制定中。对于遵循**CRISP-DM**（**跨行业标准流程**）生命周期的典型机器学习项目，该生命周期在[第5章](051e9b32-f15f-4e88-a63a-ae3c14696492.xhtml)中有解释，*图算法*，偏见看起来像这样：
- en: '![](assets/2ae7ab7a-9d40-4e63-97a0-13ce65e941e8.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2ae7ab7a-9d40-4e63-97a0-13ce65e941e8.png)'
- en: The trickiest part of reducing bias is to first identify and locate unconscious
    bias.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 减少偏见最棘手的部分是首先识别和定位无意识的偏见。
- en: Tackling NP-hard problems
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决NP-hard问题
- en: NP-hard problems were extensively discussed in  [Chapter 4](d8aca545-f465-4ab2-9f26-28e658b90a33.xhtml),
    *Designing Algorithms*. Some NP-hard problems are important and we need to design
    algorithms to solve them.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: NP-hard问题在[第4章](d8aca545-f465-4ab2-9f26-28e658b90a33.xhtml)中得到了广泛讨论，*设计算法*。一些NP-hard问题很重要，我们需要设计算法来解决它们。
- en: 'If finding the solution for an NP-hard problem seems out of reach due to its
    complexity or the limitations of the available resources, we can take one of these
    approaches:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果由于其复杂性或可用资源的限制而发现解决NP-hard问题似乎是不可能的，我们可以采取以下其中一种方法：
- en: Simplifying the problem
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简化问题
- en: Customizing a well-known solution to a similar problem
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定制一个已知解决方案以解决类似问题
- en: Using a probabilistic method
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用概率方法
- en: Let's look into them one by one.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一看看它们。
- en: Simplifying the problem
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简化问题
- en: We can simplify the problem based on certain assumptions. The solved problem
    still gives a solution that is not perfect but is still  insightful and useful.
    For this to work, the chosen assumptions should be as non- restrictive as possible.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以基于某些假设简化问题。解决的问题仍然给出的解决方案并不完美，但仍然具有洞察力和有用。为了使其起作用，所选择的假设应尽可能不受限制。
- en: Example
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: The relationship between features and labels in regression problems is seldom
    perfectly linear. But it may be linear within our usual operating range. Approximating
    the relationship as linear greatly simplifies the algorithm and is extensively
    used. But this also introduces some approximations affecting the accuracy of the
    algorithm. The trade-off between approximations and accuracy should be carefully
    studied and the right balance suitable for the stakeholders should be chosen.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归问题中，特征和标签之间的关系很少是完全线性的。但在我们通常的操作范围内可能是线性的。将关系近似为线性大大简化了算法，并且被广泛使用。但这也引入了一些影响算法准确性的近似。近似和准确性之间的权衡应该被仔细研究，并且应选择适合利益相关者的正确平衡。
- en: Customizing a well-known solution to a similar problem
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定制一个已知解决方案以解决类似问题
- en: If a solution to a similar problem is known, that solution can be used as a
    starting point. It can be customized to solve the problem we were looking for.
    The concept of  **Transfer Learning**  (**TL**) in machine learning is based on
    this principle. The idea is to use the inference of already pre-trained models
    as the starting point for training the algorithm.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已知类似问题的解决方案，那么可以将该解决方案用作起点。它可以定制以解决我们正在寻找的问题。机器学习中的**迁移学习**（**TL**）就是基于这一原则。其思想是使用已经预先训练的模型的推理作为训练算法的起点。
- en: Example
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: Let's assume that we want to train a binary classifier that can differentiate
    between Apple and Windows laptops based on real-time video feed using computer
    vision during corporate training. From the video feed, the first phase of model
    development would be to detect different objects and identify which of the objects
    are laptops. Once done, we can move to the second phase of formulating rules that
    can differentiate between Apple and Windows laptops.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要训练一个二元分类器，它可以基于实时视频流使用计算机视觉在企业培训期间区分苹果和Windows笔记本电脑。从视频流中，模型开发的第一阶段将是检测不同的物体并确定哪些物体是笔记本电脑。一旦完成，我们可以进入第二阶段，制定可以区分苹果和Windows笔记本电脑的规则。
- en: Now, there are already well-trained, well-tested open source models that can
    deal with the first phase of this model training. Why not use them as a starting
    point and use the inference toward the second phase, which is to differentiate
    between Windows and Apple laptops? This will give us a jump start and the solution
    will be less error-prone as phase 1 is already well tested.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，已经有经过良好训练、经过充分测试的开源模型，可以处理这个模型训练的第一阶段。为什么不以它们作为起点，并将推理用于第二阶段，即区分Windows和苹果笔记本电脑？这将使我们有一个快速起步，解决方案在第一阶段已经经过充分测试，因此错误更少。
- en: Using a probabilistic method
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用概率方法
- en: We use a probabilistic method to get a reasonably good solution that is workable,
    but not optimal. When we used decision tree algorithms in  [Chapter 7](e3df232d-9571-4514-a5f1-2789965492e1.xhtml),  *Traditional
    Supervised Learning Algorithms*, to solve the given problem, the solution was
    based on the probabilistic method. We did not prove that it is an optimal solution,
    but it was a reasonably good solution to give us a useful answer to the problem
    that we were trying to solve within the constraints defined in the requirements.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用概率方法来获得一个相当不错的解决方案，但并非最佳解决方案。当我们在[第7章](e3df232d-9571-4514-a5f1-2789965492e1.xhtml)中使用决策树算法来解决给定问题时，解决方案是基于概率方法的。我们没有证明这是一个最佳解决方案，但它是一个相当不错的解决方案，可以为我们在需求定义中规定的约束条件下提供一个有用的答案。
- en: Example
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 例子
- en: Many machine learning algorithms start from a random solution and then iteratively
    improve the solution. The final solution might be efficient but we cannot prove
    that it is the best one. This method is used in complex problems to solve them
    in a reasonable timeframe. That is why, for many machine learning algorithms,
    the only way to get repeatable results is to use the same sequence of random numbers
    by using the same seed.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机器学习算法从一个随机解决方案开始，然后迭代地改进解决方案。最终的解决方案可能是有效的，但我们无法证明它是最好的。这种方法用于解决复杂问题，以在合理的时间范围内解决它们。这就是为什么对于许多机器学习算法来说，获得可重复的结果的唯一方法是使用相同的种子来使用相同的随机数序列。
- en: When to use algorithms
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时使用算法
- en: 'Algorithms are like tools in a practitioner''s toolbox. First, we need to understand
    which tool is the best one to use under the given circumstances. Sometimes, we
    need to ask ourselves whether we even have a solution for the problem we are trying
    to solve and when the right time to deploy our solution is. We need to determine
    whether the use of an algorithm can provide a solution to a real problem that
    is actually useful, rather than the alternative. We need to analyze the effect
    of using the algorithm in terms of three aspects:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 算法就像从业者工具箱中的工具。首先，我们需要了解在给定情况下哪种工具是最好的。有时，我们需要问自己，我们是否有解决问题的解决方案，以及部署解决方案的正确时间是什么。我们需要确定算法的使用是否能够提供一个实际有用的解决方案，而不是其他替代方案。我们需要分析使用算法的效果，从三个方面来看：
- en: '**Cost**: Can use justify the cost related to the effort of implementing the
    algorithm?'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本**：能否证明与实施算法相关的成本？'
- en: '**Time**: Does our solution make the overall process more efficient than simpler
    alternatives?'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间**：我们的解决方案是否比更简单的替代方案使整个过程更有效？'
- en: '**Accuracy**: Does our solution produce more accurate results than simpler
    alternatives?'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性**：我们的解决方案是否比更简单的替代方案产生更准确的结果？'
- en: 'To choose the right algorithm, we need to find the answers to the following
    questions:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择正确的算法，我们需要找到以下问题的答案：
- en: Can we simplify the problem by making assumptions?
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否可以通过做出假设来简化问题？
- en: How will we evaluate our algorithm? What are the key metrics?
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将如何评估我们的算法？关键指标是什么？
- en: How will it be deployed and used?
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将如何部署和使用？
- en: Does it need to be explainable?
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它需要解释吗？
- en: Do we understand the three important non-functional requirements—security, performance,
    and availability?
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否理解了三个重要的非功能性要求-安全性、性能和可用性？
- en: Is there any expected deadline?
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有预期的截止日期？
- en: A practical example – black swan events
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个实际的例子-黑天鹅事件
- en: Algorithms input data, process and formulate it, and solve a problem. What if
    the data gathered is about an extremely impactful and very rare event? How can
    we use algorithms with the data generated by that event and the events that may
    have led to that Big Bang? Let's look into this aspect in this section.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 算法输入数据，处理并制定它，并解决问题。如果收集的数据是关于一个极具影响力且非常罕见的事件，我们如何使用由该事件生成的数据以及可能导致大爆炸的事件？让我们在本节中探讨这个方面。
- en: Such extremely rare events were represented by the *black swan events* metaphor  by
    Nassim Taleb in his book, *Fooled by Randomness*, in 2001\.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 纳西姆·塔勒布在他的2001年的书《被随机愚弄》中用黑天鹅事件的比喻来代表这些极其罕见的事件。
- en: Before black swans were first discovered in the wild, for centuries, they were
    used to represent something that cannot happen. After their discovery, the term
    remained popular but there was a change in what it represents. It now represents
    something so rare that it cannot be predicted.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在黑天鹅首次在野外被发现之前，几个世纪以来，它们被用来代表不可能发生的事情。在它们被发现后，这个术语仍然很受欢迎，但它所代表的含义发生了变化。现在它代表着一些如此罕见以至于无法预测的事情。
- en: Taleb provided these four criteria to classify an event as a black swan event.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 塔勒布提供了将事件分类为黑天鹅事件的四个标准。
- en: Four criteria to classify an event as a black swan event
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将事件分类为黑天鹅事件的四个标准
- en: It is a bit tricky to decide whether a rare event should be classified as a
    black swan event or not. In general, in order to be classified as a black swan,
    it should meet the following four criteria.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 决定罕见事件是否应该被分类为黑天鹅事件有点棘手。一般来说，为了被归类为黑天鹅，它应该符合以下四个标准。
- en: First, once the event has happened, for observers it must be a mind-blowing
    surprise, for example, dropping the atom bomb on Hiroshima.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，一旦事件发生，对观察者来说，它必须是一个令人震惊的惊喜，例如在广岛投下原子弹。
- en: The event should be a blockbuster—a disruptor and a major one, such as the outbreak
    of the Spanish Flu.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 事件应该是一场轰动一时的事件-一场颠覆性的重大事件，比如西班牙流感的爆发。
- en: Once the event has happened and the dust has settled, data scientists who were
    part of the observer group should realize that actually it was not that much of
    a surprise. Observers never paid attention to some important clues. Had they the
    capacity and initiative, the black swan event could have been predicted. For example,
    the Spanish Flu outbreak had some leads that were known to be ignored before it
    became a global outbreak. Also, the Manhattan Project was run for years before
    the atomic bomb was actually dropped on Hiroshima. People in the observer group
    just could not connect the dots.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦事件发生并尘埃落定，作为观察者群体的数据科学家应该意识到实际上这并不是那么令人惊讶。观察者们从未注意到一些重要的线索。如果他们有能力和主动性，黑天鹅事件本来是可以预测的。例如，西班牙流感爆发之前有一些被忽视的线索。此外，曼哈顿计划在原子弹实际投放广岛之前已经运行了多年。观察者群体只是无法将这些线索联系起来。
- en: When it happened, while the observers of the black swan event got the surprise
    of their lifetime, there may be some people for whom it may not have been a surprise
    at all. For example, for scientists working for years to develop the atomic bomb,
    the use of atomic power was never a surprise but an expected event.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当事件发生时，虽然黑天鹅事件的观察者们感到终身的惊讶，但也许有些人对他们来说根本不是什么惊讶。例如，多年来致力于开发原子弹的科学家们，使用原子能从未是一个惊讶，而是一个预期的事件。
- en: Applying algorithms to black swan events
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将算法应用于黑天鹅事件
- en: 'There are majors aspects of black swan events that are related to algorithms:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 黑天鹅事件与算法相关的主要方面有：
- en: There are many sophisticated forecasting algorithms available. But if we hope
    to use standard forecasting techniques to predict a black swan event as a precaution,
    it will not work. Using such forecasting algorithms will only offer false security.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有许多复杂的预测算法可用。但如果我们希望使用标准的预测技术来预测黑天鹅事件作为预防措施，那是行不通的。使用这种预测算法只会提供虚假的安全感。
- en: Once the black swan event has happened, predicting its exact implications on
    broader areas of society including the economy, the public, and governmental issues
    is not usually possible. First, being a rare event, we do not have the right data
    to feed  to the algorithms, and we do not have a grasp of the correlation and
    interactions between broader areas of society that we may have never explored
    and understood.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦黑天鹅事件发生，通常不可能准确预测其对包括经济、公众和政府问题在内的更广泛社会领域的影响。首先，作为一种罕见事件，我们没有正确的数据来供给算法，也没有掌握我们可能从未探索和理解的更广泛社会领域之间的相关性和相互作用。
- en: An important thing to note is that black swan events are not random events.
    We just did not have the capacity to pay attention to the complex events that
    eventually led to these events. This is an area where algorithms can play an important
    role. We should make sure that, in the future, we have a strategy to predict and
    detect these minor events, which combined over time to generate the black swan
    event.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要注意的一点是，黑天鹅事件并不是随机事件。我们只是没有能力关注最终导致这些事件发生的复杂事件。这是算法可以发挥重要作用的领域。我们应该确保在未来有一种策略来预测和检测这些小事件，这些事件随着时间的推移组合在一起产生了黑天鹅事件。
- en: The COVID-19 outbreak of early 2020 is the best example of a black swan event
    of our times.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年初的COVID-19爆发是我们这个时代最好的黑天鹅事件的例子。
- en: The preceding example shows how important it is to first consider and understand
    the details of the problem we are trying to solve and then come up with the areas
    where we can contribute toward a solution by implementing an algorithm-based solution.
    Without a comprehensive analysis, as presented earlier, the use of algorithms
    may only solve part of a complex problem, falling short of expectations.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子显示了首先考虑和理解我们试图解决的问题的细节，然后提出我们可以通过实施基于算法的解决方案来为解决方案做出贡献的重要性。没有全面的分析，如前所述，使用算法可能只能解决复杂问题的一部分，达不到预期。
- en: Summary
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the practical aspects that should be considered
    while designing algorithms. We looked into the concept of algorithmic explainability
    and the various ways we can provide it at different levels. We also looked into
    the potential ethical issues in algorithms. Finally, we described which factors
    to consider while choosing an algorithm.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了在设计算法时应考虑的实际方面。我们探讨了算法可解释性的概念以及我们可以在不同层面提供它的各种方式。我们还研究了算法中潜在的道德问题。最后，我们描述了在选择算法时要考虑的因素。
- en: Algorithms are engines in the new automated world that we are witnessing today.
    It is important to learn about, experiment with, and understand the implications
    of using algorithms. Understanding their strengths and limitations and the ethical
    implications of using algorithms will go a long way in making this world a better
    place to live in. And this book is an effort to achieve this important goal in
    this ever-changing and evolving world.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 算法是我们今天所见证的新自动化世界中的引擎。了解、实验和理解使用算法的影响是很重要的。了解它们的优势和局限性以及使用算法的道德影响将在使这个世界成为一个更好的居住地方方面产生深远影响。这本书正是为了在这个不断变化和发展的世界中实现这一重要目标而做出的努力。
