- en: Machine Learning for Finance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 金融机器学习
- en: Machine learning is being rapidly adopted for a range of applications in the
    financial services industry. The adoption of machine learning in financial services
    has been driven by both supply factors, such as technological advances in data
    storage, algorithms, and computing infrastructure, and by demand factors, such
    as profitability needs, competition with other firms, and supervisory and regulatory
    requirements. Machine learning in finance includes algorithmic trading, portfolio
    management, insurance underwriting, and fraud detection, just to name a few subject
    areas.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习正在迅速被金融服务行业广泛采用。金融服务业对机器学习的采用受到供应因素的推动，如数据存储、算法和计算基础设施的技术进步，以及需求因素的推动，如盈利需求、与其他公司的竞争，以及监管和监督要求。金融中的机器学习包括算法交易、投资组合管理、保险承保和欺诈检测等多个领域。
- en: There are several types of machine learning algorithms, but the two main ones
    that you will commonly come across in machine learning literature are supervised
    and unsupervised machine learning. Our discussion in this chapter focuses on supervised
    learning. Supervised machine learning involves supplying both the input and output
    data to help the machine predict new input data. Supervised machine learning can
    be regression-based or classification-based. Regression-based machine learning
    algorithms predict continuous values, while classification-based machine learning
    algorithms predict a class or label.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种类型的机器学习算法，但在机器学习文献中你通常会遇到的两种主要算法是监督学习和无监督学习。我们本章的讨论重点在监督学习上。监督学习涉及提供输入和输出数据来帮助机器预测新的输入数据。监督学习可以是基于回归或基于分类的。基于回归的机器学习算法预测连续值，而基于分类的机器学习算法预测类别或标签。
- en: 'In this chapter, we will be introduced to machine learning, study its concepts
    and applications in finance, and look at some practical examples for applying
    machine learning to assist in trading decisions. We will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍机器学习，研究其在金融领域的概念和应用，并查看一些应用机器学习来辅助交易决策的实际例子。我们将涵盖以下主题：
- en: Explore the uses of machine learning in finance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索金融中的机器学习应用
- en: Supervised and unsupervised machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习和无监督学习
- en: Classification-based and regression-based machine learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于分类和基于回归的机器学习
- en: Using scikit-learn for implementing machine learning algorithms
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用scikit-learn实现机器学习算法
- en: Applying single-asset regression-based machine learning in predicting prices
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用单资产回归机器学习来预测价格
- en: Understanding risk metrics in measuring regression models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解风险度量标准以衡量回归模型
- en: Applying multi-asset regression-based machine learning in predicting returns
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用多资产回归机器学习来预测回报
- en: Applying classification-based machine learning in predicting trends
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用基于分类的机器学习来预测趋势
- en: Understanding risk metrics in measuring classification models
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解风险度量标准以衡量分类模型
- en: Introduction to machine learning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: Before machine learning algorithms became mature, many software application
    decisions were rule-based, consisting of a bunch of `if` and `else` statements
    to generate the appropriate response in exchange to some input data. A commonly
    cited example is a spam filter function in email inboxes. A mailbox may contain
    blacklisted words defined by a mail server administrator or owner. Incoming emails
    have their contents scanned against blacklisted words, and should the blacklist
    condition hold true, the mail is marked as spammed and sent to the `Junk` folder.
    As the nature of unwanted emails continues to evolve to avoid detection, spam
    filter mechanisms must also continuously update themselves to keep up with doing
    a better job. However, with machine learning, spam filters can automatically learn
    from past email data and, given an incoming email, calculate the possibility of
    classifying whether the new email is spam or not.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习算法成熟之前，许多软件应用决策都是基于规则的，由一堆“if”和“else”语句组成，以生成适当的响应以交换一些输入数据。一个常见的例子是电子邮箱收件箱中的垃圾邮件过滤器功能。邮箱可能包含由邮件服务器管理员或所有者定义的黑名单词。传入的电子邮件内容会被扫描以检查是否包含黑名单词，如果黑名单条件成立，邮件将被标记为垃圾邮件并发送到“垃圾邮件”文件夹。随着不受欢迎的电子邮件的性质不断演变以避免被检测，垃圾邮件过滤机制也必须不断更新自己以做得更好。然而，通过机器学习，垃圾邮件过滤器可以自动从过去的电子邮件数据中学习，并在收到新的电子邮件时计算分类新邮件是否为垃圾邮件的可能性。
- en: The algorithms behind facial recognition and image detection largely work in
    the same way. Digital images stored in bits and bytes are collected, analyzed,
    and classified according to expected responses provided by the owner. This process
    is known as **training**, using a **supervised learning** approach. The trained
    data may subsequently be used for predicting the next set of input data as some
    output response with a certain level of confidence. On the other hand, when the
    training data does not contain the expected response, the machine learning algorithm is
    expected to learn from the training data, and this process is called **unsupervised
    learning**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 面部识别和图像检测背后的算法基本上是相同的。存储在位和字节中的数字图像被收集、分析和分类，根据所有者提供的预期响应。这个过程被称为“训练”，使用“监督学习”方法。经过训练的数据随后可以用于预测下一组输入数据作为某种输出响应，并带有一定的置信水平。另一方面，当训练数据不包含预期的响应时，机器学习算法被期望从训练数据中学习，这个过程被称为“无监督学习”。
- en: Uses of machine learning in finance
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 金融中的机器学习应用
- en: Machine learning is increasingly finding its uses in many areas of finance,
    such as data security, customer service, forecasting, and financial services.
    A number of use cases leverage big data and **artificial intelligence** (**AI**)
    as well; they are not exclusive to machine learning. In this section, we will
    examine some of the ways in which machine learning is transforming the financial
    sector.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在金融领域的许多领域中越来越多地发挥作用，如数据安全、客户服务、预测和金融服务。许多使用案例也利用了大数据和人工智能，它们并不仅限于机器学习。在本节中，我们将探讨机器学习如何改变金融行业的一些方式。
- en: Algorithmic trading
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法交易
- en: Machine learning algorithms study the statistical properties of the prices of
    highly correlated assets, measure their predictive power on historical data during
    backtesting, and forecast prices to within certain accuracy. Machine learning
    trading algorithms may involve the analysis of the order book, market depth and
    volume, news releases, earnings calls, or financial statements, where the analysis
    translates into price movement possibilities and is taken into account for generating
    trading signals.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法研究高度相关资产价格的统计特性，在回测期间测量它们对历史数据的预测能力，并预测价格在一定精度范围内。机器学习交易算法可能涉及对订单簿、市场深度和成交量、新闻发布、盈利电话或财务报表的分析，分析结果转化为价格变动可能性，并纳入生成交易信号的考虑。
- en: Portfolio management
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 投资组合管理
- en: The concept of *robo advisors* has been gaining popularity in recent years to
    act as automated hedge fund managers. They aid with portfolio construction, optimization,
    allocation, and rebalancing, and even suggest to clients the instruments to invest
    in based on their risk tolerance and preferred choice of investment vehicle. These
    advisories serve as a platform for interacting with a digital financial planner,
    providing financial advice and portfolio management.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，“机器顾问”这一概念越来越受欢迎，作为自动化对冲基金经理。它们帮助进行投资组合构建、优化、配置和再平衡，甚至根据客户的风险承受能力和首选投资工具建议客户投资的工具。这些咨询服务作为与数字财务规划师互动的平台，提供财务建议和投资组合管理。
- en: Supervisory and regulatory functions
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监管和监管职能
- en: Financial institutions and regulators are adopting the use of AI and machine
    learning to analyze, identify, and flag suspicious transactions that warrant further
    investigation. Supervisors such as the **Securities and Exchange Commission**
    (**SEC**) take a data-driven approach and employ AI, machine learning, and natural
    language processing to identify behavior that warrants enforcement. Worldwide,
    central authorities are developing machine learning capabilities in regulatory
    functions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 金融机构和监管机构正在采用人工智能和机器学习来分析、识别和标记需要进一步调查的可疑交易。像证券交易委员会这样的监管机构采取数据驱动的方法，利用人工智能、机器学习和自然语言处理来识别需要执法的行为。全球范围内，中央机构正在开发监管职能的机器学习能力。
- en: Insurance and loan underwriting
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保险和贷款承销
- en: Insurance companies actively use AI and machine learning to augment some insurance
    sector functions, improve pricing and marketing of insurance products, and to
    reduce claims processing times and operational costs. In loan underwriting, many
    data points of a single consumer, such as age, income, and credit score, are compared
    against a database of candidates in building credit risk profiles, determining
    credit scores, and calculating the possibility of loan defaults. Such data relies
    on transaction and payment history from financial institutions. However, lenders
    are increasingly turning to social media activities, mobile phone usage, and messaging
    activities to capture a more holistic view of creditworthiness, speed up lending
    decisions, limit incremental risk, and improve the rating accuracy of loans.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 保险公司积极利用人工智能和机器学习来增强一些保险行业的功能，改善保险产品的定价和营销，减少理赔处理时间和运营成本。在贷款承销方面，单个消费者的许多数据点，如年龄、收入和信用评分，与候选人数据库进行比较，以建立信用风险概况，确定信用评分，并计算贷款违约的可能性。这些数据依赖于金融机构的交易和支付历史。然而，放贷人越来越多地转向社交媒体活动、手机使用和消息活动，以捕捉对信用价值的更全面的观点，加快放贷决策，限制增量风险，并提高贷款的评级准确性。
- en: News sentiment analysis
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新闻情绪分析
- en: Natural language processing, a subset of machine learning, may be used to analyze
    alternative data, financial statements, news announcements, and even Twitter feeds,
    in creating investment sentiment indicators used by hedge funds, high-frequency
    trading firms, social trading, and investment platforms for analyzing markets
    in real time. Politicians' speeches, or important new releases, such as those
    made by central banks, are also being analyzed in real time, where each and every
    word is being scrutinized and calculated to predict which asset prices could move
    and by how much. Machine learning will not only understand the movement of stock
    prices and trades, but also understand social media feeds, news trends, and other
    data sources.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理，作为机器学习的一个子集，可以用于分析替代数据、财务报表、新闻公告，甚至是Twitter动态，以创建由对冲基金、高频交易公司、社交交易和投资平台使用的投资情绪指标，用于实时分析市场。政治家的演讲，或者重要的新发布，比如中央银行发布的，也正在实时分析，每个字都在被审查和计算，以预测资产价格可能会如何变动以及变动的幅度。机器学习不仅能理解股价和交易的波动，还能理解社交媒体动态、新闻趋势和其他数据来源。
- en: Machine learning beyond finance
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 金融之外的机器学习
- en: Machine learning is increasingly being employed in areas of facial recognition,
    voice recognition, biometrics, trade settlement, chatbots, sales recommendations,
    content creation, and more. As machine learning algorithms improve and their rate
    of adoption picks up, the list of use cases becomes even longer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习越来越多地应用于面部识别、语音识别、生物识别、贸易结算、聊天机器人、销售推荐、内容创作等领域。随着机器学习算法的改进和采用速度的加快，使用案例的列表变得更加长。
- en: Let's begin our journey in machine learning by understanding some of the terminology
    you will come across in the machine learning literature.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过了解一些术语来开始我们的机器学习之旅，这些术语在机器学习文献中经常出现。
- en: Supervised and unsupervised learning
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督和无监督学习
- en: There are many types of machine learning algorithms, but the two main ones that
    you will commonly come across are supervised and unsupervised machine learning.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多类型的机器学习算法，但你通常会遇到的两种主要类型是监督和无监督机器学习。
- en: Supervised learning
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习
- en: Supervised learning predicts a certain output from given inputs. These pairings
    of input to output data are known as **training data**. The quality of the prediction
    entirely depends on the training data; incorrect training data reduces the effectiveness
    of the machine learning model. An example is a dataset of transactions with labels
    identifying which ones are fraudulent, and which are not. A model can then be
    built to predict whether a new transaction will be fraudulent.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习从给定的输入中预测特定的输出。这些输入到输出数据的配对被称为**训练数据**。预测的质量完全取决于训练数据；不正确的训练数据会降低机器学习模型的有效性。例如，一个带有标签的交易数据集，标识哪些是欺诈交易，哪些不是。然后可以构建模型来预测新交易是否是欺诈交易。
- en: Some common algorithms in supervised learning are logistic regression, the support
    vector machine, and random forests.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习中一些常见的算法包括逻辑回归、支持向量机和随机森林。
- en: Unsupervised learning
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Unsupervised learning builds a model based on given input data that does not
    contain labels, but instead is asked to detect patterns in the data. This may
    involve identifying clusters of observations with similar underlying characteristics.
    Unsupervised learning aims to make accurate predictions to new, never-before-seen
    data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是基于给定的不包含标签的输入数据构建模型，而是要求检测数据中的模式。这可能涉及识别具有相似基本特征的观察值的聚类。无监督学习旨在对新的、以前未见过的数据进行准确预测。
- en: For example, an unsupervised learning model may price illiquid securities by
    looking for a cluster of securities with similar characteristics. Common unsupervised
    learning algorithms include k-means clustering, principal component analysis,
    and autoencoders.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，无监督学习模型可以通过寻找具有相似特征的证券群来定价不流动的证券。常见的无监督学习算法包括k均值聚类、主成分分析和自动编码器。
- en: Classification and regression in supervised machine learning
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督机器学习中的分类和回归
- en: 'There are two major types of supervised machine algorithms, mainly classification
    and regression. Classification machine learning models attempt to predict and
    classify responses from a list of predefined possibilities. These predefined possibilities
    may be binary classification (such as a *Yes* or *No* response to a question:
    *Is this email spam?*) or multi-class classification.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种主要类型的监督机器学习算法，主要是分类和回归。分类机器学习模型试图从预定义的可能性列表中预测和分类响应。这些预定义的可能性可能是二元分类（例如对问题的“是这封电子邮件是垃圾吗？”的*是*或*否*回答）或多类分类。
- en: Regression machine learning models attempt to predict continuous output values.
    For example, predicting housing prices or the temperature expects a continuous
    range of output values. Common forms of regressions are **ordinary least squares**
    (**OLS**) regression, LASSO regression, ridge regression, and elastic net regularization.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 回归机器学习模型试图预测连续的输出值。例如，预测房价或温度都期望连续范围的输出值。常见的回归形式有普通最小二乘（OLS）回归、LASSO回归、岭回归和弹性网络正则化。
- en: Overfitting and underfitting models
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过度拟合和欠拟合模型
- en: Poor performance in machine learning models can be caused by overfitting or
    underfitting. An overfitted machine learning model is one that is trained too
    well with the training data such that it leads to negative performance on new
    data. This occurs when the training data is fitted to every minor variation, including
    noise and random fluctuations. Unsupervised learning algorithms are highly susceptible
    to overfitting, since the model learns from every piece of data, both good and
    bad.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的性能不佳可能是由于过度拟合或欠拟合造成的。过度拟合的机器学习模型是指在训练数据上训练得太好，导致在新数据上表现不佳。这是因为训练数据适应了每一个微小的变化，包括噪音和随机波动。无监督学习算法非常容易过度拟合，因为模型从每个数据中学习，包括好的和坏的。
- en: An underfitted machine learning model gives poor accuracy of prediction. It
    may be caused by too little training data being available to build an accurate
    model, or that the data is not suitable for extracting its underlying trends.
    Underfitting models are easy to detect since they give consistently poor performance.
    To improve such models, provide more training data or use another machine learning
    algorithm.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合的机器学习模型预测准确性差。这可能是由于可用于构建准确模型的训练数据太少，或者数据不适合提取其潜在趋势。欠拟合模型很容易检测，因为它们始终表现不佳。要改进这样的模型，可以提供更多的训练数据或使用另一个机器学习算法。
- en: Feature engineering
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: A feature is an attribute of the data that defines its characteristic. By using
    domain knowledge of the data, features can be created to help machine learning
    algorithms increase their predictive performance. This can be as simple as grouping
    or bucketing related parts of the existing data to form defining features. Even
    removing unwanted features is also feature engineering.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 特征是定义数据特征的属性。通过使用数据的领域知识，可以创建特征来帮助机器学习算法提高其预测性能。这可以是简单的将现有数据的相关部分分组或分桶以形成定义特征。甚至删除不需要的特征也是特征工程。
- en: 'As an example, suppose we have the following time series price data that looks
    like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有以下时间序列价格数据：
- en: '| **No.** | **Date and Time** | **Price** | **Price Action** |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **编号** | **日期和时间** | **价格** | **价格行动** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | 2019-01-02 09:00:01 | 55.00 | UP |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2019-01-02 09:00:01 | 55.00 | 上涨 |'
- en: '| 2 | 2019-01-02 10:03:42 | 45.00 | DOWN |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2019-01-02 10:03:42 | 45.00 | 下跌 |'
- en: '| 3 | 2019-01-02 10:31:23 | 48.00 | UP |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2019-01-02 10:31:23 | 48.00 | 上涨 |'
- en: '| 4 | 2019-01-02 11:14:02 | 33.00 | DOWN |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 2019-01-02 11:14:02 | 33.00 | DOWN |'
- en: 'Grouping the time series into buckets by the hour of the day and taking the
    last price action in each bucket, we end up with a feature like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一天中的小时将时间序列分组，并在每个时间段内采取最后的价格行动，我们得到了这样一个特征：
- en: '| **No.** | **Hour of Day** | **Last Price Action** |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| **No.** | **Hour of Day** | **Last Price Action** |'
- en: '| --- | --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | 9 | UP |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 9 | UP |'
- en: '| 2 | 10 | UP |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 10 | UP |'
- en: '| 3 | 11 | DOWN |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 11 | DOWN |'
- en: 'The process of feature engineering involves these four steps:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程的过程包括以下四个步骤：
- en: Brainstorming features to include in the training model
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构思要包括在训练模型中的特征
- en: Creating those features
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建这些特征
- en: Checking how the features work with the model
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查特征如何与模型配合
- en: Repeating from step 1 until the features work perfectly
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从步骤1重复，直到特征完美工作
- en: There are absolutely no hard and fast rules when it comes to what constitutes
    creating features. Feature engineering is considered more of an art than a science.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建特征方面，没有绝对的硬性规则。特征工程被认为更像是一门艺术而不是科学。
- en: Scikit-learn for machine learning
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于机器学习的Scikit-learn
- en: Scikit-learn is a Python library designed for scientific computing and contains
    a number of state-of-the-art machine learning algorithms for classification, regression,
    clustering, dimensionality reduction, model selection, and preprocessing. Its
    name is derived from the SciPy Toolkit, which is an extension of the SciPy module.
    Comprehensive documentation on scikit-learn can be found at [https://scikit-learn.org](https://scikit-learn.org).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn是一个专为科学计算设计的Python库，包含一些最先进的机器学习算法，用于分类、回归、聚类、降维、模型选择和预处理。其名称源自SciPy工具包，这是SciPy模块的扩展。有关scikit-learn的详细文档可以在[https://scikit-learn.org](https://scikit-learn.org)找到。
- en: SciPy is a collection of Python modules for scientific computing, containing
    a number of core packages, such as NumPy, Matplotlib, IPython, and others.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy是用于科学计算的Python模块集合，包含一些核心包，如NumPy、Matplotlib、IPython等。
- en: 'In this chapter, we will be using scikit-learn''s machine learning algorithms
    to predict securities movements. Scikit-learn require a working installation of
    NumPy and SciPy. Install scikit-learn with the `pip` package manager by using
    the following command:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用scikit-learn的机器学习算法来预测证券的走势。Scikit-learn需要安装NumPy和SciPy。使用以下命令通过`pip`包管理器安装scikit-learn：
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Predicting prices with a single-asset regression model
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用单一资产回归模型预测价格
- en: Pairs trading is a common statistical arbitrage trading strategy employed by
    traders using a pair of co-integrated and highly positively correlated assets,
    though negatively correlated pairs can also be considered.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 配对交易是一种常见的统计套利交易策略，交易者使用一对协整和高度正相关的资产，尽管也可以考虑负相关的配对。
- en: In this section, we will use machine learning to train regression-based models
    using the historical prices of a pair of securities that might be used in pairs
    trading. Given the current price of one security for a particular day, we predict
    the other security's price on a daily basis. The following examples uses the historical
    daily prices of **Goldman Sachs** (**GS**) and **J.P. Morgan** (**JPM**) traded
    on the **New York Stock Exchange** (**NYSE**). We will be predicting prices of
    JPM's stock price for the year 2018.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用机器学习来训练基于回归的模型，使用一对可能用于配对交易的证券的历史价格。给定某一天某一证券的当前价格，我们每天预测另一证券的价格。以下示例使用了**纽约证券交易所**（**NYSE**）上交易的**高盛**（**GS**）和**摩根大通**（**JPM**）的历史每日价格。我们将预测2018年JPM股票价格。
- en: Linear regression by OLS
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过OLS进行线性回归
- en: 'Let''s begin our investigation of regression-based machine learning with a
    simple linear regression model. A straight line is in the following form:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的线性回归模型开始我们的基于回归的机器学习调查。一条直线的形式如下：
- en: '![](Images/f7b4925f-5179-47a2-bf43-8b887bf19c6f.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/f7b4925f-5179-47a2-bf43-8b887bf19c6f.png)'
- en: 'This attempts to fit the data by OLS:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这尝试通过OLS拟合数据：
- en: '*a* is the slope or coefficient'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*a*是斜率或系数'
- en: '*c* is the value of the *y*-intercept'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*c*是*y*截距的值'
- en: '*x* is the input dataset'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x*是输入数据集'
- en: '![](Images/b25ba907-2ae5-48c0-a41b-538f32b462f6.png)is the predicted value
    from the straight line'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](Images/b25ba907-2ae5-48c0-a41b-538f32b462f6.png)是直线的预测值'
- en: 'The coefficients and intercept are determined by minimizing the cost function:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 系数和截距由最小化成本函数确定：
- en: '![](Images/2b7ae4b3-76ee-4adb-8a94-272eef594751.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/2b7ae4b3-76ee-4adb-8a94-272eef594751.png)'
- en: '*y* is the dataset of observed actual values used in performing a straight-line
    fit. In other words, we are performing a least sum of squared errors in finding
    the coefficients *a* and *c*, from which we can predict the current period.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*y*是用于执行直线拟合的观察实际值的数据集。换句话说，我们正在执行最小化平方误差和，以找到系数*a*和*c*，从中我们可以预测当前时期。'
- en: Before developing a model, let's download and prepare the required datasets.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发模型之前，让我们下载并准备所需的数据集。
- en: Preparing the independent and target variables
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备自变量和目标变量
- en: 'Let''s obtain the datasets of GS and JPM prices from Alpha Vantage with the
    following code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下代码从Alpha Vantage获取GS和JPM的价格数据集：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `pandas` DataFrame objects `df_jpm` and `df_gs` contain the downloaded prices
    of JPM and GS respectively. We will be extracting the adjusted closing prices
    from the fifth column of each dataset.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas` DataFrame对象`df_jpm`和`df_gs`包含了JPM和GS的下载价格。我们将从每个数据集的第五列中提取调整后的收盘价。'
- en: 'Let''s prepare our independent variables with the following code:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下代码准备我们的自变量：
- en: '[PRE2]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The adjusted closing prices of GS are extracted to a new DataFrame object, `df_x`.
    Next, obtain our target variables with the following code:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 从GS的调整收盘价中提取到一个新的DataFrame对象`df_x`。接下来，使用以下代码获取我们的目标变量：
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The adjusted closing prices of JPM are extracted to the `jpm_prices` variable as
    a `pandas` Series object. Having prepared our datasets for use in modeling, let's
    proceed to develop the linear regression model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: JPM的调整收盘价被提取到`jpm_prices`变量中，作为一个`pandas` Series对象。准备好我们的数据集以用于建模后，让我们继续开发线性回归模型。
- en: Writing the linear regression model
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写线性回归模型
- en: We will create a class for using a linear regression model to fit and predict
    values. This class also serves as a base class for implementing other models in
    this chapter. The following steps illustrates this process.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个类，用于使用线性回归模型拟合和预测值。这个类还用作在本章中实现其他模型的基类。以下步骤说明了这个过程。
- en: 'Declare a class named `LinearRegressionModel` as follows:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明一个名为`LinearRegressionModel`的类，如下所示：
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the constructor of our new class, we declare a pandas DataFrame called `df_result`
    to store the actual and predicted values for plotting on a chart later on. The `get_model()` method
    returns an instance of the `LinearRegression` class in the `sklearn.linear_model`
    module for fitting and predicting the data. The `set_intercept` parameter is set
    to `True` as the data is not centered (around 0 on the *x*- and *y*-axes, that
    is).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们新类的构造函数中，我们声明了一个名为`df_result`的pandas DataFrame，用于存储之后绘制图表时的实际值和预测值。`get_model()`方法返回`sklearn.linear_model`模块中`LinearRegression`类的一个实例，用于拟合和预测数据。`set_intercept`参数设置为`True`，因为数据没有居中（即在*x*和*y*轴上都围绕0）。
- en: More information about the `LinearRegression` of scikit-learn can be found at [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 有关scikit-learn的`LinearRegression`的更多信息可以在[https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)找到。
- en: The `get_prices_since()` method slices a subset of the supplied dataset with
    the `iloc` command, from the given date index `date_since` and up to a number
    of earlier periods defined by the lookback value.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_prices_since()`方法使用`iloc`命令从给定的日期索引`date_since`开始，获取由`lookback`值定义的较早期间的子集。'
- en: 'Add a method named `learn()` into the `LinearRegressionModel` class, as follows:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`LinearRegressionModel`类中添加一个名为`learn()`的方法，如下所示：
- en: '[PRE5]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `learn()` method serves as the entry point for running the model. It accepts
    the `df` and `ys` parameters as our independent and target variables, `start_date`
    and `end_date` as strings corresponding to the index of the dataset for the period
    we will be predicting, and the `lookback_period` parameter as the number of historical
    data points used for fitting the model in the current period.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`learn()`方法作为运行模型的入口点。它接受`df`和`ys`参数作为我们的自变量和目标变量，`start_date`和`end_date`作为对应于我们将要预测的数据集索引的字符串，以及`lookback_period`参数作为用于拟合当前期间模型的历史数据点的数量。'
- en: The `for` loop simulates a backtest on a daily basis. The call to `get_prices_since()`
    fetches a subset of the dataset for fitting the model on the *x*- and *y*-axes
    with the `fit()` command. The `ravel()` command transforms the given `pandas`
    Series object into a flattened list of target values for fitting the model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`for`循环模拟了每日的回测。调用`get_prices_since()`获取数据集的子集，用于在*x*和*y*轴上拟合模型。`ravel()`命令将给定的`pandas`
    Series对象转换为用于拟合模型的目标值的扁平列表。'
- en: The `x_current` variable represents independent variable values for the specified
    date, fed into the `predict()` method. The predicted output is a `list` object,
    from which we extract the first value. Both the actual and predicted values are
    saved to the `df_result` DataFrame, indexed by the current date as a `pandas`
    object.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`x_current`变量表示指定日期的自变量值，输入到`predict()`方法中。预测的输出是一个`list`对象，我们从中提取第一个值。实际值和预测值都保存到`df_result`
    DataFrame中，由当前日期作为`pandas`对象的索引。'
- en: 'Let''s instantiate this class and run our machine learning model by issuing
    the following commands:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们实例化这个类，并通过以下命令运行我们的机器学习模型：
- en: '[PRE6]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the `learn()` command, we provided our prepared datasets, `df_x` and `jpm_prices`,
    and specified the prediction for the year of 2018\. For this example, we assumed
    there are 20 trading days in a month. Using a `lookback_period` value of `20`,
    we are using a past month's prices to fit our model for prediction daily.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在`learn()`命令中，我们提供了我们准备好的数据集`df_x`和`jpm_prices`，并指定了2018年的预测。在这个例子中，我们假设一个月有20个交易日。使用`lookback_period`值为`20`，我们使用过去一个月的价格来拟合我们的模型以进行每日预测。
- en: 'Let''s retrieve the resulting `df_result` DataFrame from the model and plot
    both the actual and predicted values:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从模型中检索结果的`df_result` DataFrame，并绘制实际值和预测值：
- en: '[PRE7]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the `style` parameter, we specified that actual values are to be drawn as
    a solid line, and predicted values drawn as dotted lines. This gives us the following
    graph:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在`style`参数中，我们指定实际值绘制为实线，预测值绘制为虚线。这给我们以下图表：
- en: '![](Images/13a145be-ebca-4b73-90da-a02f4b8fd62c.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/13a145be-ebca-4b73-90da-a02f4b8fd62c.png)'
- en: The chart shows our predicted results trailing closely behind the actual values
    up to a certain extent. How well does our model actually perform? In the next
    section, we will discuss several common risk metrics for measuring regression-based
    models.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示我们的预测结果在一定程度上紧随实际值。我们的模型实际上表现如何？在下一节中，我们将讨论用于衡量基于回归的模型的几种常见风险指标。
- en: Risk metrics for measuring prediction performance
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于衡量预测性能的风险指标
- en: The `sklearn.metrics` module implements several regression metrics for measuring
    prediction performance. We will discuss the mean absolute error, the mean squared
    error, the explained variance score, and the R² score in subsequent sections.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.metrics`模块实现了几种用于衡量预测性能的回归指标。我们将在接下来的部分讨论平均绝对误差、均方误差、解释方差得分和R²得分。'
- en: Mean absolute error as a risk metric
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作为风险指标的平均绝对误差
- en: 'The **mean absolute error** (**MAE**) is a risk metric that measures the average
    absolute prediction error and can be written as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**平均绝对误差**（**MAE**）是一种风险度量，衡量了平均绝对预测误差，可以表示如下：'
- en: '![](Images/9ba0fced-2749-4951-93ce-76bea007fb68.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9ba0fced-2749-4951-93ce-76bea007fb68.png)'
- en: Here, *y* and ![](Images/0b48f0bb-7913-4104-a460-d7f2da9a005c.png) are the actual
    and predicted lists of values, respectively, with the same length, *n*. ![](Images/9f3fb134-6d08-4e20-b86e-90a5de21fdf5.png) and *y[i]* are
    the predicted and actual values, respectively, at the index *i**.* Taking the
    absolute values of errors means that our output results in a positive decimal
    value. Low values of MAE are highly desired. A perfect score of 0 implies that
    our prediction powers are exactly aligned with actual values, since there are
    no differences between the two.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*y*和![](Images/0b48f0bb-7913-4104-a460-d7f2da9a005c.png)分别是实际值和预测值的列表，长度相同，为*n*。![](Images/9f3fb134-6d08-4e20-b86e-90a5de21fdf5.png)和*y[i]*分别是索引*i*处的预测值和实际值。取绝对值意味着我们的输出结果为正小数。希望MAE的值尽可能低。完美的分数为0表示我们的预测能力与实际值完全一致，因为两者之间没有差异。
- en: 'Obtain the MAE value of our predictions using the `mean_abolute_error` function
    of the `sklearn.metrics `module with the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`sklearn.metrics`模块的`mean_abolute_error`函数获得我们预测的MAE值，以下是代码：
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The MAE of our linear regression model is 2.458.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的线性回归模型的MAE为2.458。
- en: Mean squared error as a risk metric
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 均方误差作为风险度量
- en: 'Like the MAE, the **mean squared error** (**MSE**) is a risk metric that measures
    the average of the squares of the prediction errors and can be written as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 与MAE类似，**均方误差**（**MSE**）也是一种风险度量，衡量了预测误差的平方的平均值，可以表示如下：
- en: '![](Images/e43040d0-6942-4890-be73-193e3ac3b317.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/e43040d0-6942-4890-be73-193e3ac3b317.png)'
- en: Squaring the errors means that values of MSE are always positive, and low values
    of MSE are highly desired. A perfect MSE score of 0 implies that our prediction
    powers are exactly aligned with actual values, and that the squares of such differences
    are negligible. While the application of both the MSE and MAE helps determine
    the strength of our model's predictive powers, MSE triumphs over MAE by penalizing
    errors that are farther away from the mean. Squaring the errors places a heavier
    bias on the risk metrics.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 平方误差意味着MSE的值始终为正，并且希望MSE的值尽可能低。完美的MSE分数为0表示我们的预测能力与实际值完全一致，这些差异的平方可以忽略不计。虽然MSE和MAE的应用有助于确定模型预测能力的强度，但MSE通过对偏离均值较远的错误进行惩罚而胜过MAE。平方误差对风险度量施加了更重的偏见。
- en: 'Obtain the MSE value of our predictions using the `mean_squared_error` function
    of the `sklearn.metrics` module with the following code:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码通过`sklearn.metrics`模块的`mean_squared_error`函数获得我们预测的MSE值：
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The MSE of our linear regression model is 12.156.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的线性回归模型的MSE为12.156。
- en: Explained variance score as a risk metric
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释方差分数作为风险度量
- en: 'The explained variance score explains the dispersion of errors of a given dataset,
    and the formula is written as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 解释方差分数解释了给定数据集的误差分散，公式如下：
- en: '![](Images/24beb2c6-1765-419a-b919-cdf3608a9789.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/24beb2c6-1765-419a-b919-cdf3608a9789.png)'
- en: Here, *![](Images/186aff43-e401-4808-b8d8-8b6adc1bd9b0.png)* and *Var*(*y*) is
    the variance of prediction errors and actual values respectively. Scores close
    to 1.0 are highly desired, indicating better squares of standard deviations of
    errors.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*![](Images/186aff43-e401-4808-b8d8-8b6adc1bd9b0.png)*和*Var*(*y*)分别是预测误差和实际值的方差。接近1.0的分数是非常理想的，表示误差标准差的平方更好。
- en: 'Obtain the explained variance score of our predictions using the `explained_variance_score`
    function of the `sklearn.metrics` module with the following code:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`sklearn.metrics`模块的`explained_variance_score`函数获得我们预测的解释方差分数的值，以下是代码：
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The explained variance score of our linear regression model is 0.533.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们线性回归模型的解释方差分数为0.533。
- en: R2 as a risk metric
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R²作为风险度量
- en: 'The R² score is also known as the **coefficient of determination**, and it
    measures how well future samples are likely to be predicted by the model. It is
    written as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: R²分数也被称为**确定系数**，它衡量了模型对未来样本的预测能力。它的表示如下：
- en: '![](Images/9c360c02-0496-4e6f-a56b-5c31879971cb.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9c360c02-0496-4e6f-a56b-5c31879971cb.png)'
- en: 'Here, ![](Images/40eec259-3732-44f6-ba5e-f5edf10bd6a2.png) is the mean of actual
    values and can be written as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](Images/40eec259-3732-44f6-ba5e-f5edf10bd6a2.png)是实际值的均值，可以表示如下：
- en: '![](Images/bdb47b9a-bf50-47c2-a325-2f1cd33d08b8.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/bdb47b9a-bf50-47c2-a325-2f1cd33d08b8.png)'
- en: R² scores ranges from negative values to 1.0\. A perfect R² score of 1 implies
    that there is no error in the regression analysis, while a score of 0 indicates
    that the model always predicts the mean of target values. A negative R² score
    indicates that the prediction performs below average.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: R²分数的范围从负值到1.0。R²分数为1表示回归分析没有误差，而分数为0表示模型总是预测目标值的平均值。负的R²分数表示预测表现低于平均水平。
- en: 'Obtain the R² score of our predictions using the `r2_score` function of the
    `sklearn.metrics` module with the following code:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`sklearn.metrics`模块的`r2_score`函数获得我们预测的R²分数，以下是代码：
- en: '[PRE11]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The R² of our linear regression model is 0.4167\. This implies that 41.67% of
    the variability of the target variables have been accounted for.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的线性回归模型的R²为0.4167。这意味着41.67%的目标变量的可变性已经被解释。
- en: Ridge regression
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 岭回归
- en: 'The ridge regression, or L2 regularization, addresses some of the problems
    of OLS regression by penalizing the sum of squares of the model coefficients.
    The cost function for the ridge regression can be written as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归，或L2正则化，通过惩罚模型系数的平方和来解决OLS回归的一些问题。岭回归的代价函数可以表示如下：
- en: '![](Images/7918e635-6bd5-4727-b68b-81d215aaa5f3.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/7918e635-6bd5-4727-b68b-81d215aaa5f3.png)'
- en: Here, the α parameter is expected to be a positive value that controls the amount
    of shrinkage. Larger values of alpha give greater shrinkage, making the coefficients
    more robust to collinearity.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，α参数预期是一个控制收缩量的正值。较大的alpha值会产生更大的收缩，使得系数对共线性更加稳健。
- en: 'The `Ridge` class of the `sklearn.linear_model` module implements ridge regression.
    To implement this model, create a class named `RidgeRegressionModel` that extends
    the `LinearRegressionModel` class, and run the following code:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.linear_model`模块的`Ridge`类实现了岭回归。要实现这个模型，创建一个名为`RidgeRegressionModel`的类，扩展`LinearRegressionModel`类，并运行以下代码：'
- en: '[PRE12]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the new class, the `get_model()` method is overridden to return the ridge regression
    model of scikit-learn while reusing the other methods in the parent class. The
    `alpha` value is set to 0.5, and the rest of the model parameters are left as
    defaults. The `ridge_reg_model` variable represents an instance of our ridge regression
    model, and the `learn()` command is run with the usual parameters values.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在新类中，重写`get_model()`方法以返回scikit-learn的岭回归模型，同时重用父类中的其他方法。将`alpha`值设为0.5，其余模型参数保持默认。`ridge_reg_model`变量表示我们的岭回归模型的一个实例，并使用通常的参数值运行`learn()`命令。
- en: 'Create a function called `print_regression_metrics()` to print the various
    risk metrics covered earlier:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`print_regression_metrics()`的函数，以打印之前介绍的各种风险指标：
- en: '[PRE13]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Pass the `df_result` variable to this function and display the risk metrics
    to the console:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 将`df_result`变量传递给此函数，并在控制台显示风险指标：
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Both mean error scores of the ridge regression model are lower than the linear
    regression model and are closer to zero. The explained variance score and the
    R² score are higher than the linear regression model and are closer to 1\. This
    indicates that our ridge regression model is doing a better job of prediction
    than the linear regression model. Besides having better performance, ridge regression
    computations are less costly than the original linear regression model.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归模型的平均误差得分都低于线性回归模型，并且更接近于零。解释方差得分和R²得分都高于线性回归模型，并且更接近于1。这表明我们的岭回归模型在预测方面比线性回归模型做得更好。除了性能更好外，岭回归计算成本也比原始线性回归模型低。
- en: Other regression models
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他回归模型
- en: The `sklearn.linear_model` module contains various regression models that we
    can consider implementing in our model. The remaining sections briefly describe
    them. A full list of linear models is available at [https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.linear_model`模块包含了我们可以考虑在模型中实现的各种回归模型。其余部分简要描述了它们。线性模型的完整列表可在[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model)找到。'
- en: Lasso regression
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lasso回归
- en: 'Similar to ridge regression, **Least Absolute Shrinkage and Selection Operator** (**LASSO**)
    regression is also another form of regularization that involves penalizing the
    sum of absolute values of regression coefficients. It uses the L1 regularization
    technique. The cost function for the LASSO regression can be written as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 与岭回归类似，**最小绝对值收缩和选择算子**（**LASSO**）回归也是正则化的另一种形式，涉及对回归系数的绝对值之和进行惩罚。它使用L1正则化技术。LASSO回归的成本函数可以写成如下形式：
- en: '![](Images/fd0a41c4-b24d-43b6-bcfa-7e8970f31cae.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/fd0a41c4-b24d-43b6-bcfa-7e8970f31cae.png)'
- en: Like ridge regression, the alpha parameter α controls the strength of the penalty.
    However, for geometric reasons, LASSO regression produces different results than
    ridge regression since it forces a majority of the coefficients to be set to zero.
    It is better suited for estimating sparse coefficients and models with fewer parameter
    values.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 与岭回归类似，alpha参数α控制惩罚的强度。然而，由于几何原因，LASSO回归产生的结果与岭回归不同，因为它强制大多数系数被设为零。它更适合估计稀疏系数和具有较少参数值的模型。
- en: The `Lasso` class of `sklearn.linear_model` implements LASSO regression.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.linear_model`的`Lasso`类实现了LASSO回归。'
- en: Elastic net
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弹性网络
- en: 'Elastic net is another regularized regression method that combines the L1 and
    L2 penalties of the LASSO and ridge regression methods. The cost function for
    elastic net can be written as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 弹性网络是另一种正则化回归方法，结合了LASSO和岭回归方法的L1和L2惩罚。弹性网络的成本函数可以写成如下形式：
- en: '![](Images/310632bc-d7e6-4ea2-b5a5-df69bc56c116.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/310632bc-d7e6-4ea2-b5a5-df69bc56c116.png)'
- en: 'The alpha values are explained here:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这里解释了alpha值：
- en: '![](Images/689be77f-a002-41e5-97fa-b52f59a26e5b.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/689be77f-a002-41e5-97fa-b52f59a26e5b.png)'
- en: '![](Images/4b0169a9-8d38-4ad6-8371-c4cb9a12fe28.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/4b0169a9-8d38-4ad6-8371-c4cb9a12fe28.png)'
- en: Here, `alpha` and `l1_ratio` are parameters of the `ElasticNet` function. When
    `alpha` is zero, the cost function is equivalent to an OLS. When `l1_ratio` is
    zero, the penalty is a ridge or L2 penalty. When `l1_ratio` is 1, the penalty
    is a LASSO or L1 penalty. When `l1_ratio` is between 0 and 1, the penalty is a
    combination of L1 and L2.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`alpha`和`l1_ratio`是`ElasticNet`函数的参数。当`alpha`为零时，成本函数等同于OLS。当`l1_ratio`为零时，惩罚是岭或L2惩罚。当`l1_ratio`为1时，惩罚是LASSO或L1惩罚。当`l1_ratio`在0和1之间时，惩罚是L1和L2的组合。
- en: The `ElasticNet` class of `sklearn.linear_model` implements elastic net regression.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.linear_model`的`ElasticNet`类实现了弹性网络回归。'
- en: Conclusion
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We used a single-asset, trend-following momentum strategy by regression to predict
    the prices of JPM using GS, with the assumption that the pair is cointegrated
    and highly correlated. We can also consider cross-asset momentum to obtain better
    results from diversification. The next section explores multi-asset regression
    for predicting security returns.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了单资产的趋势跟随动量策略通过回归来预测使用GS的JPM价格，假设这对是协整的并且高度相关。我们也可以考虑跨资产动量来从多样化中获得更好的结果。下一节将探讨用于预测证券回报的多资产回归。
- en: Predicting returns with a cross-asset momentum model
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用跨资产动量模型预测回报
- en: In this section, we will create a cross-asset momentum model by having the prices
    of four diversified assets predict the returns of JPM on a daily basis for the
    year of 2018\. The prior 1-month, 3-month, 6-month, and 1-year of lagged returns
    of the S&P 500 stock index, 10-year treasury bond index, US dollar index, and
    gold prices will be used for fitting our model. This gives us a total of 16 features. Let's
    begin by preparing our datasets for developing our models.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过拥有四种多样化资产的价格来预测2018年JPM的每日回报，创建一个跨资产动量模型。我们将使用S&P 500股票指数、10年期国库券指数、美元指数和黄金价格的先前1个月、3个月、6个月和1年的滞后回报来拟合我们的模型。这给我们总共16个特征。让我们开始准备我们的数据集来开发我们的模型。
- en: Preparing the independent variables
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备独立变量
- en: 'We will use Alpha Vantage again as our data provider. As this free service
    does not provide all of the dataset required for our investigation, we shall consider
    other close assets as a proxy. The ticker symbol for the S&P 500 stock index is
    SPX. We will use the SPDR Gold Trust (ticker symbol: GLD) to denote a share of
    the gold bullion as a proxy for gold prices. The Invesco DB US Dollar Index Bullish
    Fund (ticker symbol: UUP) will proxy the US dollar index. The iShares 7-10 Year
    Treasury Bond ETF (ticker symbol: IEF) will proxy the 10-year Treasury Bond Index. Run
    the following code to download our datasets:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次使用Alpha Vantage作为我们的数据提供者。由于这项免费服务没有提供我们调查所需的所有数据集，我们将考虑其他相关资产作为代理。标准普尔500股票指数的股票代码是SPX。我们将使用SPDR
    Gold Trust（股票代码：GLD）来表示黄金价格的代理。Invesco DB美元指数看涨基金（股票代码：UUP）将代表美元指数。iShares 7-10年期国库券ETF（股票代码：IEF）将代表10年期国库券指数。运行以下代码来下载我们的数据集：
- en: '[PRE15]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `ts` variable is the `TimeSeries` object of Alpha Vantage created in the
    previous section. Combine the adjusted closing prices into a single `pandas` DataFrame
    named `df_assets` with the following codes and remove empty values with the `dropna()`
    command:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '`ts`变量是在上一节中创建的Alpha Vantage的`TimeSeries`对象。使用以下代码将调整后的收盘价合并到一个名为`df_assets`的`pandas`
    DataFrame中，并使用`dropna()`命令删除空值：'
- en: '[PRE16]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Calculate the lagged percentage returns of our `df_assets` dataset with the
    following code:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码计算我们的`df_assets`数据集的滞后百分比回报：
- en: '[PRE17]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In the `pct_change()` command, the `periods` parameter specifies the number
    of periods to shift. We assumed 20 trading days in a month when calculating the
    lagged returns. Combine the four `pandas` DataFrame objects into a single DataFrame
    with the `join()` command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在`pct_change()`命令中，`periods`参数指定要移动的周期数。在计算滞后回报时，我们假设一个月有20个交易日。使用`join()`命令将四个`pandas`
    DataFrame对象合并成一个DataFrame：
- en: '[PRE18]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Use the `info()` command to view its properties:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`info()`命令查看其属性：
- en: '[PRE19]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The output is truncated, but you can see 16 features as our independent variables
    spanning the years 2008 to 2019\. Let's continue to obtain the dataset for our
    target variables.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 输出被截断，但您可以看到16个特征作为我们的独立变量，跨越2008年至2019年。让我们继续获取我们目标变量的数据集。
- en: Preparing the target variables
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备目标变量
- en: 'The closing prices of JPM having been downloaded to the `pandas` Series object
    `jpm_prices` earlier, simply calculate the actual percentage returns with the
    following code:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: JPM的收盘价早些时候已经下载到`pandas` Series对象`jpm_prices`中，只需使用以下代码计算实际百分比收益：
- en: '[PRE20]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We obtain a `pandas` Series object as our target variable `y`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得一个`pandas` Series对象作为我们的目标变量`y`。
- en: A multi-asset linear regression model
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多资产线性回归模型
- en: 'In the previous section, we used a single asset with the prices of GS for fitting
    our linear regression model. This same model, `LinearRegressionModel`, accommodates
    multiple assets. Run the following commands to create an instance of this model
    and use our new datasets:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用了单一资产GS的价格来拟合我们的线性回归模型。这个相同的模型`LinearRegressionModel`可以容纳多个资产。运行以下命令来创建这个模型的实例并使用我们的新数据集：
- en: '[PRE21]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the linear regression model instance, `multi_linear_model`, the `learn()`
    command is supplied with the `df_lagged` dataset with 16 features and `y` as the
    percentage changes of JPM. The `lookback_period` value is reduced in consideration
    of the limited lagged returns data available. Let''s plot the actual versus predicted
    percentage changes of JPM:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归模型实例`multi_linear_model`中，`learn()`命令使用具有16个特征的`df_lagged`数据集和`y`作为JPM的百分比变化。考虑到有限的滞后回报数据，`lookback_period`值被减少。让我们绘制JPM的实际与预测百分比变化：
- en: '[PRE22]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This would give us the following graph in which the solid lines show the actual
    percentage returns of JPM, while the dotted lines show the predicted percentage
    returns:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们以下图表，其中实线显示了JPM的实际百分比回报，而虚线显示了预测的百分比回报：
- en: '![](Images/c417dd6d-9ece-4f2a-b9bd-964481cb61ab.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/c417dd6d-9ece-4f2a-b9bd-964481cb61ab.png)'
- en: 'How well did our model perform? Let''s run the same performance metrics in
    the `print_regression_metrics()` function defined in the previous section:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型表现如何？让我们在前一节中定义的`print_regression_metrics()`函数中运行相同的性能指标：
- en: '[PRE23]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The explained variance score and R² scores are in the negative range, suggesting
    that the model performs below average. Can we perform better? Let's explore more
    complex tree models used in regression.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 解释的方差分数和R²分数都在负数范围内，表明模型表现低于平均水平。我们能做得更好吗？让我们探索更复杂的用于回归的树模型。
- en: An ensemble of decision trees
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树的集成
- en: Decision trees are widely used models for classification and regression tasks,
    much like a binary tree, where each node represents a question leading to a yes-no
    answer for traversing the respective left and right nodes. The goal is to get
    to the right answer by asking as few questions as possible.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树是用于分类和回归任务的广泛使用的模型，就像二叉树一样，其中每个节点代表一个问题，导致对相应左右节点的是或否答案。目标是通过尽可能少的问题得到正确答案。
- en: A paper describing deep neural decision trees can be found at [https://arxiv.org/pdf/1806.06988.pdf](https://arxiv.org/pdf/1806.06988.pdf).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在[https://arxiv.org/pdf/1806.06988.pdf](https://arxiv.org/pdf/1806.06988.pdf)找到描述深度神经决策树的论文。
- en: Traversing deep down decision trees can quickly lead to overfitting of the given
    data, rather than inferring the overall properties of the distributions from which they
    are drawn. To address this issue of overfitting, the data can be split into subsets
    and train on different trees, each on a subset. This way, we end up with an ensemble
    of different decision tree models. When random subsets of the samples are drawn
    with replacements for prediction, this method is called **bagging** or **bootstrap
    aggregation**. We may or may not get consistent results across these models, but
    the final model obtained by averaging the bootstrapped models yields better results
    than using a single decision tree. Using an ensemble of randomized decision trees
    is known as **random forests**.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 深入决策树很快会导致给定数据的过拟合，而不是从中抽取的分布的整体特性。为了解决这个过拟合问题，数据可以分成子集，并在不同的树上进行训练，每个子集上进行训练。这样，我们最终得到了不同决策树模型的集成。当用替换抽取预测的随机样本子集时，这种方法称为**装袋**或**自举聚合**。我们可能会或可能不会在这些模型中获得一致的结果，但通过对自举模型进行平均得到的最终模型比使用单个决策树产生更好的结果。使用随机化决策树的集成被称为**随机森林**。
- en: Let's visit some decision tree models in scikit-learn that we may consider implementing
    in our multi-asset regression model.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在scikit-learn中访问一些决策树模型，我们可能考虑在我们的多资产回归模型中实施。
- en: Bagging regressor
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 装袋回归器
- en: 'The `BaggingRegressor` class of `sklearn.ensemble` implements the bagging regressor.
    We can see how a bagging regressor works for multi-asset predictions of the percentage
    returns of JPM. The following code illustrates this:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.ensemble`的`BaggingRegressor`类实现了装袋回归器。我们可以看看装袋回归器如何对JPM的百分比收益进行多资产预测。以下代码说明了这一点：'
- en: '[PRE24]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We created a class named `BaggingRegressorModel` that extends `LinearRegressionModel`,
    and the `get_model()` method is overridden to return the bagging regressor. The
    `n_estimators` parameter specifies `20` base estimators or decision trees in the
    ensemble, with the `random_state` parameter as a seed of `0` used by the random
    number generator. The rest of the parameters are default values. We run this model
    with the same dataset.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个名为`BaggingRegressorModel`的类，它扩展了`LinearRegressionModel`，并且`get_model()`方法被重写以返回装袋回归器。`n_estimators`参数指定了集成中的`20`个基本估计器或决策树，`random_state`参数作为随机数生成器使用的种子为`0`。其余参数为默认值。我们使用相同的数据集运行这个模型。
- en: 'Run the same performance metrics and see how our model performs:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 运行相同的性能指标，看看我们的模型表现如何：
- en: '[PRE25]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The MAE and MSE values indicate that an ensemble of decision trees produces
    fewer prediction errors than the simple linear regression model. Also, though
    the explained variance score and the R² scores are negative, it indicates a better
    variance of data towards the mean than is offered by the simple linear regression
    model.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: MAE和MSE值表明，决策树的集成产生的预测误差比简单线性回归模型少。此外，尽管解释方差分数和R²分数为负值，但它表明数据的方差向均值的方向比简单线性回归模型提供的更好。
- en: Gradient tree boosting regression model
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度树提升回归模型
- en: Gradient tree boosting, or simply gradient boosting, is a technique of improving
    or boosting the performance of weak learners using a gradient descent procedure
    to minimize the loss function. Tree models, usually decision trees, are added
    one at a time and build the model in a stage-wise fashion, while leaving the existing
    trees in the model unchanged. Since gradient boosting is a greedy algorithm, it
    can overfit a training dataset quickly. However, it can benefit from regularization
    methods that penalize various parts of the algorithm and reduce overfitting to
    improve its performance.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度树提升，或简单地说梯度提升，是一种利用梯度下降过程来最小化损失函数，从而改善或提升弱学习器性能的技术。树模型，通常是决策树，一次添加一个，并以分阶段的方式构建模型，同时保持模型中现有的树不变。由于梯度提升是一种贪婪算法，它可以很快地过拟合训练数据集。然而，它可以受益于对各个部分进行惩罚的正则化方法，并减少过拟合以改善其性能。
- en: The `sklearn.ensemble` module provides a gradient-boosting regressor called
    `GradientBoostingRegressor`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.ensemble`模块提供了一个梯度提升回归器，称为`GradientBoostingRegressor`。'
- en: Random forests regression
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林回归
- en: Random forests consist of multiple decision trees each based on a random sub-sample
    of the training data and uses averaging to improve the predictive accuracy and
    to control overfitting. Selection by random inadvertently introduces some form
    of bias. However, due to averaging, it variance also decreases, helping to compensate
    for the increase in bias, and is considered to yield an overall better model.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林由多个决策树组成，每个决策树都基于训练数据的随机子样本，并使用平均化来提高预测准确性和控制过拟合。随机选择无意中引入了某种形式的偏差。然而，由于平均化，它的方差也减小，有助于补偿偏差的增加，并被认为产生了一个整体更好的模型。
- en: The `sklearn.ensemble` module provides a random forest regressor called `RandomForestRegressor`.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.ensemble`模块提供了一个随机森林回归器，称为`RandomForestRegressor`。'
- en: More ensemble models
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多集成模型
- en: The `sklearn.ensemble` module contains various other ensemble regressors, as
    well as classifier models. More information can be found at [https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.ensemble`模块包含各种其他集成回归器，以及分类器模型。更多信息可以在[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)找到。'
- en: Predicting trends with classification-based machine learning
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用基于分类的机器学习预测趋势
- en: Classification-based machine learning is a supervised machine learning approach
    in which a model learns from given input data and classifies it according to new
    observations. Classification may be bi-class, such as identifying whether an option
    should be exercised or not, or multi-class, such as the direction of a price change,
    which can be either up, down, or unchanging.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分类的机器学习是一种监督机器学习方法，模型从给定的输入数据中学习，并根据新的观察结果进行分类。分类可以是双类别的，比如识别一个期权是否应该行使，也可以是多类别的，比如价格变化的方向，可以是上升、下降或不变。
- en: In this section, we will look again at creating cross-asset momentum models
    by having the prices of four diversified assets predict the daily trend of JPM on
    a daily basis for the year of 2018\. The prior 1-month and 3-month lagged returns of
    the S&P 500 stock index, the 10-year treasury bond index, the US dollar index,
    and gold prices will be used to fit the model for prediction. Our target variables
    consist of Boolean indicators, where a `True` value indicates an increase or no-change
    from the previous trading day's closing price, and a `False` value indicates a
    decrease.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将再次看一下通过四种多元资产的价格来预测2018年JPM每日趋势的动量模型。我们将使用S&P 500股票指数、10年期国债指数、美元指数和黄金价格的前1个月和3个月滞后收益来拟合预测模型。我们的目标变量包括布尔指示器，其中“True”值表示与前一个交易日收盘价相比的增加或不变，而“False”值表示减少。
- en: Let's begin by preparing the dataset for our models.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始准备我们模型的数据集。
- en: Preparing the target variables
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备目标变量
- en: 'We have already downloaded the JPM dataset to the `pandas` DataFrame, `df_jpm`,
    in a previous section, and the `y` variable contains the daily percentage change
    of JPM. Convert these values to labels with the following code:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在之前的部分将JPM数据集下载到了`pandas` DataFrame `df_jpm`中，而`y`变量包含了JPM的每日百分比变化。使用以下代码将这些值转换为标签：
- en: '[PRE26]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Using the `head()` command, we can see that the `y_direction` variable becomes
    a `pandas` Series object of Boolean values. A percentage change of zero or more
    classifies the value with a `True` label, and `False` otherwise. Let''s extract
    unique values with the `unique()` command as column names for use later on:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`head()`命令，我们可以看到`y_direction`变量成为了一个`pandas` Series对象，其中包含布尔值。百分比变化为零或更多的值被分类为`True`标签，否则为`False`。让我们使用`unique()`命令提取唯一值作为以后使用的列名：
- en: '[PRE27]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The column names are extracted to a variable called `flags`. With our target
    variables ready, let's continue to obtain our independent multi-asset variables.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 列名被提取到一个名为`flags`的变量中。有了我们的目标变量，让我们继续获取我们的独立多资产变量。
- en: Preparing the dataset of multiple assets as input variables
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备多个资产作为输入变量的数据集
- en: 'We will be reusing the `pandas` DataFrame variables, `df_assets_1m` and `df_assets_3m`,
    from the previous section containing the lagged 1-month and 3-month percentage
    returns of the four assets and combine them into a single variable, `df_input`,
    with the following code:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重用前一部分中包含四种资产的滞后1个月和3个月百分比收益的`pandas` DataFrame变量`df_assets_1m`和`df_assets_3m`，并将它们合并为一个名为`df_input`的单个变量，使用以下代码：
- en: '[PRE28]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Use the `info()` command to view its properties:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`info()`命令查看其属性：
- en: '[PRE29]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The output is truncated, but you can see we have eight features as our independent
    variables spanning the years 2007 to 2019. With our input and target variables
    created, let's explore the various classifiers available in scikit-learn for modeling.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 输出被截断了，但是你可以看到我们有八个特征作为我们的独立变量，跨越了2007年到2019年。有了我们的输入和目标变量，让我们探索scikit-learn中可用的各种分类器模型。
- en: Logistic regression
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: 'Despite its name, logistic regression is actually a linear model used for classification.
    It uses a logistic function, also known as a **sigmoid** function, to model the
    probabilities describing the possible outcomes of a single trial. A logistic function
    helps to map any real-valued number to a value between 0 and 1\. A standard logistic
    function is written as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其名称是逻辑回归，但实际上它是用于分类的线性模型。它使用逻辑函数，也称为**S形**函数，来模拟描述单次试验可能结果的概率。逻辑函数有助于将任何实值映射到0和1之间的值。标准的逻辑函数如下所示：
- en: '![](Images/c47c9d05-fbda-41d4-85d1-563d19452828.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/c47c9d05-fbda-41d4-85d1-563d19452828.png)'
- en: '*e* is the base of the natural logarithm, and *x* is the *X*-value of the sigmoid''s
    midpoint. ![](Images/3da6b246-a810-490a-ae25-c0bb3259dafd.png) is the predicted
    real value between 0 and 1, to be converted to a binary equivalent of 0 or 1 either
    by rounding or a cut-off value.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '*e*是自然对数的底，*x*是S形函数中点的*X*值。![](Images/3da6b246-a810-490a-ae25-c0bb3259dafd.png)是预测的实际值，介于0和1之间，可以通过四舍五入或截断值转换为0或1的二进制等价值。'
- en: 'The `LogisticRegression` class of the `sklean.linear_model` module implements
    logistic regression. Let''s implement this classifier model by writing a new class
    named `LogisticRegressionModel` that extends `LinearRegressionModel` with the
    following code:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklean.linear_model`模块的`LogisticRegression`类实现了逻辑回归。让我们通过编写一个名为`LogisticRegressionModel`的新类来实现这个分类器模型，该类扩展了`LinearRegressionModel`，使用以下代码：'
- en: '[PRE30]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The same underlying linear regression logic is used in our new classifier model.
    The `get_model()` method is overridden to return an instance of the `LogisticRegression`
    classifier model, using the LBFGS solver algorithm in the optimization problem.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新分类器模型使用了相同的基本线性回归逻辑。`get_model()`方法被重写以返回一个使用LBFGS求解器算法的`LogisticRegression`分类器模型的实例。
- en: A paper on the **limited-memory** **Broyden**–**Fletcher**–**Goldfarb**–**Shanno**
    (**LBFGS**) algorithm for machine learning can be read at [https://arxiv.org/pdf/1802.05374.pdf](https://arxiv.org/pdf/1802.05374.pdf)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 有关用于机器学习的**有限内存** **Broyden**–**Fletcher**–**Goldfarb**–**Shanno** (**LBFGS**)算法的论文可以在[https://arxiv.org/pdf/1802.05374.pdf](https://arxiv.org/pdf/1802.05374.pdf)上阅读。
- en: 'Create an instance of this model and provide our data:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 创建这个模型的实例并提供我们的数据：
- en: '[PRE31]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Again, the parameter values indicate that we are interested in performing predictions
    for the year of 2018, and we will be using a `lookback_period` value of `100`
    as the number of daily historical data points when fitting our model. Let''s inspect
    the results stored in `df_result` with the `head()` command:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，参数值表明我们有兴趣对2018年进行预测，并且在拟合模型时将使用`lookback_period`值为`100`作为每日历史数据点的数量。让我们使用`head()`命令检查存储在`df_result`中的结果：
- en: '[PRE32]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This produces the following table:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下表格：
- en: '| **Date** | **Actual** | **Predicted** |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| **日期** | **实际** | **预测** |'
- en: '| --- | --- | --- |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **2018-01-02** | True | True |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| **2018-01-02** | True | True |'
- en: '| **2018-01-03** | True | True |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| **2018-01-03** | True | True |'
- en: '| **2018-01-04** | True | True |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| **2018-01-04** | True | True |'
- en: '| **2018-01-05** | False | True |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| **2018-01-05** | False | True |'
- en: '| **2018-01-08** | True | True |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| **2018-01-08** | True | True |'
- en: Since our target variables are Boolean values, the model outputs predict Boolean
    values as well. But how well does our model perform? In the following sections,
    we will explore risk metrics for measuring our predictions. These metrics are
    different from those used for regression-based predictions in earlier sections.
    Classification-based machine learning takes another approach for measuring output
    labels.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的目标变量是布尔值，模型输出也预测布尔值。但我们的模型表现如何？在接下来的部分中，我们将探讨用于测量我们预测的风险指标。这些指标与前面部分用于基于回归的预测的指标不同。基于分类的机器学习采用另一种方法来测量输出标签。
- en: Risk metrics for measuring classification-based predictions
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于测量基于分类的预测的风险指标
- en: In this section, we will explore common risk metrics for measuring classification-based
    machine learning predictions, namely the confusion matrix, accuracy score, precision
    score, recall score, and F1 score.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨用于测量基于分类的机器学习预测的常见风险指标，即混淆矩阵、准确度分数、精度分数、召回率分数和F1分数。
- en: Confusion matrix
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'A confusion matrix, or error matrix, is a square matrix that helps to visualize
    and describe the performance of a classification model for which the true values
    are known. The `confusion_matrix` function of the `sklearn.metrics` module helps
    to calculate this matrix for us, as shown in the following code:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵，或错误矩阵，是一个帮助可视化和描述分类模型性能的方阵，其中真实值是已知的。`sklearn.metrics`模块的`confusion_matrix`函数帮助我们计算这个矩阵，如下面的代码所示：
- en: '[PRE33]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We obtain the actual and predicted values as separate lists. Since we have two
    types of class labels, we obtain a two-by-two matrix. The `heatmap` module of
    the `seaborn` library helps us understand this matrix.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实际值和预测值作为单独的列表获取。由于我们有两种类标签，我们获得一个二乘二的矩阵。`seaborn`库的`heatmap`模块帮助我们理解这个矩阵。
- en: 'Seaborn is a data visualization library based on Matplotlib. It provides a
    high-level interface for drawing attractive and informative statistical graphics,
    and is a popular tool for data scientists. If you do not have Seaborn installed,
    simply run the command: `pip install seaborn`'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: Seaborn是一个基于Matplotlib的数据可视化库。它提供了一个高级接口，用于绘制引人注目和信息丰富的统计图形，是数据科学家的流行工具。如果您没有安装Seaborn，只需运行命令：`pip
    install seaborn`
- en: 'Run the following Python codes to generate the confusion matrix:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下Python代码生成混淆矩阵：
- en: '[PRE34]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This produces the following output:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](Images/e8dcd93d-44a8-4d51-aaaf-28b98491978a.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/e8dcd93d-44a8-4d51-aaaf-28b98491978a.png)'
- en: Don't let the confusion matrix confuse you. Let's break down the numbers in
    a logical manner and see how easily a confusion matrix works. Starting from the
    left column, we have a total of 126 samples classified as False, of which the
    classifier predicted correctly 60 times, and these are known as **true negatives**
    (**TNs**). However, the classifier predicted it wrongly 66 times, and these are
    known as **false negatives** (**FNs**). In the right column, we have a total of
    125 samples belonging to the True class. The classifier predicted wrongly 55 times,
    and these are known as **false positives** (**FPs**). The classifier did predict
    correctly 70 times though, and these are known as **true positives** (**TPs**).
    These computed rates are used in other risk metrics, as we shall discover in the
    following sections.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让混淆矩阵让你困惑。让我们以一种逻辑的方式分解数字，看看混淆矩阵是如何工作的。从左列开始，我们有126个样本被分类为False，分类器正确预测了60次，这些被称为真负例（TNs）。然而，分类器错误预测了66次，这些被称为假负例（FNs）。在右列，我们有125个属于True类的样本。分类器错误预测了55次，这些被称为假正例（FPs）。分类器虽然有70次预测正确，这些被称为真正例（TPs）。这些计算出的比率在其他风险指标中使用，我们将在接下来的部分中发现。
- en: Accuracy score
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确度分数
- en: 'An accuracy score is the ratio of correct predictions to the total number of
    observations. By default, it is expressed as a fractional value between 0 and
    1\. When the accuracy score is 1.0, it means that the entire set of predicted
    labels in the sample matches with the true set of labels. The accuracy score can
    be written as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度分数是正确预测的观测值与总观测值的比率。默认情况下，它表示为0到1之间的分数。当准确度分数为1.0时，意味着样本中的整个预测标签集与真实标签集匹配。准确度分数可以写成如下形式：
- en: '![](Images/3a76457f-d1b9-4343-963b-e13f2919c63a.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/3a76457f-d1b9-4343-963b-e13f2919c63a.png)'
- en: 'Here, *I(x)* is the indicator function that returns 1 for a correct prediction,
    and 0 otherwise. The `accuracy_score` function of the `sklearn.metrics` module
    calculates this score for us with the following code:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*I(x)*是指示函数，对于正确的预测返回1，否则返回0。`sklearn.metrics`模块的`accuracy_score`函数使用以下代码为我们计算这个分数：
- en: '[PRE35]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The accuracy score suggests that our model is correct 52% of the time. Accuracy
    scores are great at measuring symmetrical datasets where values of false positives
    and false negatives are almost the same. To evaluate the performance of our model fully,
    we need to look at other risk metrics.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度分数表明我们的模型有52%的正确率。准确度分数非常适合测量对称数据集的性能，其中假正例和假负例的值几乎相同。为了充分评估我们模型的性能，我们需要查看其他风险指标。
- en: Precision score
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精度分数
- en: 'A precision score is the ratio of correctly predicted positive observations
    to the total number of predicted positive observations, and can be written as
    follows:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 精度分数是正确预测的正例观测值与总预测的正例观测值的比率，可以写成如下形式：
- en: '![](Images/c729d639-a8bb-4c08-a8c6-6877e0fc1b97.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/c729d639-a8bb-4c08-a8c6-6877e0fc1b97.png)'
- en: 'This gives a precision score between 0 and 1, with 1 as the best value indicating
    that the model classifies correctly all the time. The `precision_score` function
    of the `sklearn.metrics` module calculates this score for us with the following
    code:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了一个介于0和1之间的精度分数，1表示模型一直正确分类。`sklearn.metrics`模块的`precision_score`函数使用以下代码为我们计算这个分数：
- en: '[PRE36]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The precision score suggests that our model is able to predict a classification
    correctly 52% of the time.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 精度分数表明我们的模型能够正确预测分类的52%的时间。
- en: Recall score
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 召回分数
- en: 'The recall score is the ratio of correctly predicted positive observations
    to all the observations in the actual class, and can be written as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 召回分数是正确预测的正样本占实际类别中所有样本的比率，可以写成如下形式：
- en: '![](Images/5a9ad0ce-d532-48ba-9666-4151d3f5e5cd.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/5a9ad0ce-d532-48ba-9666-4151d3f5e5cd.png)'
- en: 'This gives a recall score of between 0 and 1, with 1 as the best value. The
    `recall_score` function of the `sklearn.metrics` module calculates this score
    for us with the following code:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了一个介于0和1之间的召回分数，1是最佳值。`sklearn.metrics`模块的`recall_score`函数使用以下代码为我们计算这个分数：
- en: '[PRE37]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The recall score suggests that our logistic regression model correctly identifies
    positive samples 56% of the time.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 召回分数表明我们的逻辑回归模型正确识别正样本的时间为56%。
- en: F1 score
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: F1分数
- en: 'The F1 score, or F-measure, is the weighted average of the precision score
    and the recall score, and can be written as follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数，或F-度量，是精度分数和召回分数的加权平均值，可以写成如下形式：
- en: '![](Images/e1661497-9810-45da-b138-0665a041a5c4.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/e1661497-9810-45da-b138-0665a041a5c4.png)'
- en: This gives an F1 score between 0 and 1\. When either the precision score or
    the recall score is 0, the F1 score will be 0\. However, when both the precision
    score and recall score are positive, the F1 score gives equal weights to both
    measures. Maximizing the F1 score creates a balanced classification model with
    optimal balance of recall and precision.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了介于0和1之间的F1分数。当精度分数或召回分数为0时，F1分数将为0。但是，当精度分数和召回分数都为正时，F1分数对两个度量给予相等的权重。最大化F1分数可以创建一个具有最佳召回和精度平衡的平衡分类模型。
- en: 'The `f1_score` function of the `sklearn.metrics` module calculates this score
    for us with the following code:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.metrics`模块的`f1_score`函数使用以下代码为我们计算这个分数：'
- en: '[PRE38]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The F1 score of our logistic regression model is 0.536.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的逻辑回归模型的F1分数为0.536。
- en: Support vector classifier
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量分类器
- en: A **support vector classifier** (**SVC**) is a concept of a **support vector
    machine** (**SVM**) that uses support vectors for classifying datasets.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量分类器**（**SVC**）是使用支持向量对数据集进行分类的**支持向量机**（**SVM**）的概念。'
- en: More information on SVMs can be found at [http://www.statsoft.com/textbook/support-vector-machines](http://www.statsoft.com/textbook/support-vector-machines).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 有关SVM的更多信息可以在[http://www.statsoft.com/textbook/support-vector-machines](http://www.statsoft.com/textbook/support-vector-machines)找到。
- en: 'The `SVC` class of the `sklean.svm` module implements the SVM classifier. Write
    a class named `SVCModel` and extend `LogisticRegressionModel` with the following
    code:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '`SVC`类的`sklean.svm`模块实现了SVM分类器。编写一个名为`SVCModel`的类，并使用以下代码扩展`LogisticRegressionModel`：'
- en: '[PRE39]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Here, we are overriding the `get_model()` method to return the `SVC` class
    of scikit-learn. A high-penalty `C` value of `1000` is specified. The `gamma`
    parameter is the kernel coefficient with a default value of `auto`. The `learn()`
    command is executed with our usual model parameters. With that, let''s run the
    risk metrics on this model:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们重写`get_model()`方法以返回scikit-learn的`SVC`类。指定了高惩罚`C`值为`1000`。`gamma`参数是具有默认值`auto`的核系数。使用我们通常的模型参数执行`learn()`命令。有了这些，让我们在这个模型上运行风险指标：
- en: '[PRE40]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We obtain better scores than from the logistic regression classifier model.
    By default, the `C` value of the linear SVM is 1.0, which would in practice give
    us generally comparable performance with the logistic regression model. There
    is absolutely no rule of thumb for choosing a `C` value, as it depends entirely on
    the training dataset. A nonlinear SVM kernel can be considered by supplying a `kernel` parameter
    to the `SVC()` model. More information on SVM kernels is available at [https://scikit-learn.org/stable/modules/svm.html#svm-kernels](https://scikit-learn.org/stable/modules/svm.html#svm-kernels).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得的分数比逻辑回归分类器模型更好。默认情况下，线性SVM的`C`值为1.0，这在实践中通常会给我们与逻辑回归模型相当的性能。选择`C`值没有固定的规则，因为它完全取决于训练数据集。可以通过向`SVC()`模型提供`kernel`参数来考虑非线性SVM核。有关SVM核的更多信息，请访问[https://scikit-learn.org/stable/modules/svm.html#svm-kernels](https://scikit-learn.org/stable/modules/svm.html#svm-kernels)。
- en: Other types of classifiers
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他类型的分类器
- en: Besides logistic regression and SVC, scikit-learn contains many other types
    of classifiers for machine learning. The following sections discuss some classifiers
    that we can also consider implementing in our classification-based model.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 除了逻辑回归和SVC，scikit-learn还包含许多其他类型的分类器用于机器学习。以下部分讨论了一些我们也可以考虑在我们的基于分类的模型中实现的分类器。
- en: Stochastic gradient descent
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机梯度下降
- en: '**Stochastic gradient descent** (**SGD**) is a form of **gradient descent**
    that works by using an iterative process to estimate the gradient towards minimizing
    an objective loss function, such as a linear support vector machine or logistic
    regression. The stochastic term comes about as samples are chosen at random. When
    lesser iterations are used, bigger steps are taken to reach the solution, and
    the model is said to have a **high learning rate**. Likewise, with more iterations,
    smaller steps are taken, resulting in a model with a **small learning rate**.
    SGD is a popular choice of machine learning algorithm among practitioners as it
    has been effectively used in large-scale text classification and natural language
    processing models.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机梯度下降**（**SGD**）是一种使用迭代过程来估计梯度以最小化目标损失函数的**梯度下降**形式，例如线性支持向量机或逻辑回归。随机项是因为样本是随机选择的。当使用较少的迭代时，会采取更大的步骤来达到解决方案，模型被认为具有**高学习率**。同样，使用更多的迭代，会采取更小的步骤，导致具有**小学习率**的模型。SGD是从业者中机器学习算法的流行选择，因为它已经在大规模文本分类和自然语言处理模型中得到有效使用。'
- en: The `SGDClassifier` class of the `sklearn.linear_model` module implements the
    SGD classifier.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.linear_model`模块的`SGDClassifier`类实现了SGD分类器。'
- en: Linear discriminant analysis
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性判别分析
- en: '**Linear discriminant analysis** (**LDA**) is a classic classifier that uses
    a linear decision surface, where the mean and variance for every class of the
    data is estimated. It assumes that the data is Gaussian, and that each attribute
    has the same variance, and values of each variable are around the mean. LDA computes
    *discriminant scores* by using Bayes'' theorem for each observation to determine
    to which class it belongs.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '**线性判别分析**（**LDA**）是一种经典的分类器，它使用线性决策面，其中估计了数据每个类的均值和方差。它假设数据是高斯分布的，每个属性具有相同的方差，并且每个变量的值都在均值附近。LDA通过使用贝叶斯定理为每个观测计算*判别分数*，以确定它属于哪个类。'
- en: The `LinearDiscriminantAnalysis` class of the `sklearn.discriminant_analysis`
    module implements the LDA classifier.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.discriminant_analysis`模块的`LinearDiscriminantAnalysis`类实现了LDA分类器。'
- en: Quadratic discriminant analysis
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二次判别分析
- en: '**Quadratic discriminant analysis** (**QDA**) is very similar to LDA, but uses
    a quadratic decision boundary and each class uses its own estimate of variance.
    Running the risk metrics shows that the QDA model does not necessarily give better
    performance than the LDA model. The type of decision boundary has to be taken
    into consideration for the model required. QDA is better suited for large datasets,
    as it tends to have a lower bias and higher variance. On the other hand, LDA is
    suitable for smaller datasets that have a lower bias and a higher variance.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '**二次判别分析**（**QDA**）与LDA非常相似，但使用二次决策边界，每个类使用自己的方差估计。运行风险指标显示，QDA模型不一定比LDA模型表现更好。必须考虑所需模型的决策边界类型。QDA更适用于具有较低偏差和较高方差的大型数据集。另一方面，LDA适用于具有较低偏差和较高方差的较小数据集。'
- en: The `QuadraticDiscriminantAnalysis` class of the `sklearn.discriminant_analysis`
    module implements the QDA model.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.discriminant_analysis`模块的`QuadraticDiscriminantAnalysis`类实现了QDA模型。'
- en: KNN classifier
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KNN分类器
- en: The **k-nearest neighbors** (**k-NN**) classifier is a simple algorithm that
    conducts a simple majority vote of the nearest neighbors of each point, and that
    point is assigned to a class that has the most representatives within the nearest
    neighbors of the point. While there is not a need to train a model for generalization,
    the predicting phase is slower and costlier in terms of time and memory.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '**k-最近邻**（**k-NN**）分类器是一种简单的算法，它对每个点的最近邻进行简单的多数投票，并将该点分配给在该点的最近邻中具有最多代表的类。虽然不需要为泛化训练模型，但预测阶段在时间和内存方面较慢且成本较高。'
- en: The `KNeighborsClassifier` class of the `sklearn.neighbors` module implements
    the KNN classifier.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn.neighbors`模块的`KNeighborsClassifier`类实现了KNN分类器。'
- en: Conclusion on the use of machine learning algorithms
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对机器学习算法的使用结论
- en: You may have observed that predicted values from our models are far off from
    actual values. This chapter aims to demonstrate the best of the machine learning
    features that scikit-learn offers, which may possibly be used to predict time
    series data. No studies to date have shown that machine learning algorithms can
    predict prices even close to 100% of the time. A lot more effort goes into building
    and running machine learning systems effectively.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，我们模型的预测值与实际值相差甚远。本章旨在展示scikit-learn提供的机器学习功能的最佳特性，这可能用于预测时间序列数据。迄今为止，没有研究表明机器学习算法可以预测价格接近100%的时间。构建和有效运行机器学习系统需要付出更多的努力。
- en: Summary
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have been introduced to machine learning in the context
    of finance. We discussed how AI and machine learning is transforming the financial
    sector. Machine learning can be supervised or unsupervised, and supervised algorithms
    can be regression-based and classification-based. The scikit-learn Python library
    provides various machine learning algorithms and risk metrics.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了金融领域的机器学习。我们讨论了人工智能和机器学习如何改变金融行业。机器学习可以是监督的或无监督的，监督算法可以是基于回归或基于分类的。Python的scikit-learn库提供了各种机器学习算法和风险指标。
- en: We discussed the use of regression-based machine learning models such as OLS
    regression, ridge regression, LASSO regression, and elastic net regularization
    in predicting continuous values such as security prices. An ensemble of decision
    trees was also discussed, such as the bagging regressor, gradient tree boosting,
    and random forests. To measure the performance of regression models, we visited
    the MSE, MAE, explained variance score, and R² score.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了基于回归的机器学习模型的使用，如OLS回归、岭回归、LASSO回归和弹性网络正则化，用于预测证券价格等连续值。还讨论了决策树的集成，如装袋回归器、梯度树提升和随机森林。为了衡量回归模型的性能，我们讨论了均方误差、平均绝对误差、解释方差分数和R²分数。
- en: Classification-based machine learning classifies input values as classes or
    labels. Such classes may be bi-class or multi-class. We discussed the use of logistic
    regression, SVC, LDA and QDA, and k-NN classifiers for predicting price trends.
    To measure the performance of classification models, we visited the confusion
    matrix, accuracy score, precision and recall scores, as well as the F1 score.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分类的机器学习将输入值分类为类别或标签。这些类别可以是二元或多元的。我们讨论了逻辑回归、支持向量机、LDA和QDA以及k-NN分类器用于预测价格趋势。为了衡量分类模型的性能，我们讨论了混淆矩阵、准确率、精确度和召回率，以及F1分数。
- en: In the next chapter, we will explore the use of deep learning in finance.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨在金融领域中使用深度学习。
