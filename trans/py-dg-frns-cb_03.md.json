["```py\npip install biplist==1.0.2\n```", "```py\nfrom __future__ import print_function\nimport argparse\nimport biplist\nimport os\nimport sys\n```", "```py\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument(\"PLIST_FILE\", help=\"Input PList File\")\n    args = parser.parse_args()\n```", "```py\n    if not os.path.exists(args.PLIST_FILE) or \\\n            not os.path.isfile(args.PLIST_FILE):\n        print(\"[-] {} does not exist or is not a file\".format(\n            args.PLIST_FILE))\n        sys.exit(1)\n\n    main(args.PLIST_FILE)\n```", "```py\ndef main(plist):\n    print(\"[+] Opening {} file\".format(plist))\n    try:\n        plist_data = biplist.readPlist(plist)\n    except (biplist.InvalidPlistException,\n            biplist.NotBinaryPlistException) as e:\n        print(\"[-] Invalid PLIST file - unable to be opened by biplist\")\n        sys.exit(2)\n```", "```py\n    print(\"[+] Printing Info.plist Device \"\n          \"and User Information to Console\\n\")\n    for k in plist_data:\n        if k != 'Applications' and k != 'iTunes Files':\n            print(\"{:<25s} - {}\".format(k, plist_data[k]))\n```", "```py\nfrom __future__ import print_function\nimport argparse\nimport csv\nimport os\nimport sqlite3\nimport sys\n```", "```py\nif __name__ == '__main__':\n    # Command-line Argument Parser\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument(\"SQLITE_DATABASE\", help=\"Input SQLite database\")\n    parser.add_argument(\"OUTPUT_CSV\", help=\"Output CSV File\")\n    args = parser.parse_args()\n```", "```py\n    directory = os.path.dirname(args.OUTPUT_CSV)\n    if directory != '' and not os.path.exists(directory):\n        os.makedirs(directory)\n```", "```py\n    main(args.SQLITE_DATABASE, args.OUTPUT_CSV)\n```", "```py\ndef main(database, out_csv):\n    print(\"[+] Attempting connection to {} database\".format(database))\n    if not os.path.exists(database) or not os.path.isfile(database):\n        print(\"[-] Database does not exist or is not a file\")\n        sys.exit(1)\n```", "```py\n    # Connect to SQLite Database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n```", "```py\n    # Query DB for Column Names and Data of Message Table\n    c.execute(\"pragma table_info(message)\")\n    table_data = c.fetchall()\n    columns = [x[1] for x in table_data]\n```", "```py\n    c.execute(\"select * from message\")\n    message_data = c.fetchall()\n```", "```py\n    print(\"[+] Writing Message Content to {}\".format(out_csv))\n    write_csv(out_csv, columns, message_data)\n```", "```py\ndef write_csv(output, cols, msgs):\n    with open(output, \"w\", newline=\"\") as csvfile:\n        csv_writer = csv.writer(csvfile)\n        csv_writer.writerow(cols)\n        csv_writer.writerows(msgs)\n```", "```py\nfrom __future__ import print_function\nimport argparse\nimport os\nimport sqlite3\nimport sys\n```", "```py\nif __name__ == \"__main__\":\n    # Command-line Argument Parser\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument(\"SQLITE_DATABASE\", help=\"Input SQLite database\")\n    parser.add_argument(\"TABLE\", help=\"Table to query from\")\n    parser.add_argument(\"--column\", help=\"Optional column argument\")\n    args = parser.parse_args()\n```", "```py\n    if args.column is not None:\n        main(args.SQLITE_DATABASE, args.TABLE, col=args.column)\n    else:\n        main(args.SQLITE_DATABASE, args.TABLE)\n```", "```py\ndef main(database, table, **kwargs):\n    print(\"[+] Attempting connection to {} database\".format(database))\n    if not os.path.exists(database) or not os.path.isfile(database):\n        print(\"[-] Database does not exist or is not a file\")\n        sys.exit(1)\n```", "```py\n    # Connect to SQLite Database\n    conn = sqlite3.connect(database)\n    c = conn.cursor()\n```", "```py\n    # Query Table for Primary Key\n    c.execute(\"pragma table_info({})\".format(table))\n    table_data = c.fetchall()\n    if table_data == []:\n        print(\"[-] Check spelling of table name - '{}' did not return \"\n              \"any results\".format(table))\n        sys.exit(2)\n```", "```py\n    if \"col\" in kwargs:\n        find_gaps(c, table, kwargs[\"col\"])\n\n    else:\n        # Add Primary Keys to List\n        potential_pks = []\n        for row in table_data:\n            if row[-1] == 1:\n                potential_pks.append(row[1])\n```", "```py\n        if len(potential_pks) != 1:\n            print(\"[-] None or multiple primary keys found -- please \"\n                  \"check if there is a primary key or specify a specific \"\n                  \"key using the --column argument\")\n            sys.exit(3)\n\n        find_gaps(c, table, potential_pks[0])\n```", "```py\ndef find_gaps(db_conn, table, pk):\n    print(\"[+] Identifying missing ROWIDs for {} column\".format(pk))\n    try:\n        db_conn.execute(\"select {} from {}\".format(pk, table))\n    except sqlite3.OperationalError:\n        print(\"[-] '{}' column does not exist -- \"\n              \"please check spelling\".format(pk))\n        sys.exit(4)\n    results = db_conn.fetchall()\n```", "```py\n    rowids = sorted([x[0] for x in results])\n    total_missing = rowids[-1] - len(rowids)\n```", "```py\n    if total_missing == 0:\n        print(\"[*] No missing ROWIDs from {} column\".format(pk))\n        sys.exit(0)\n    else:\n        print(\"[+] {} missing ROWID(s) from {} column\".format(\n            total_missing, pk))\n```", "```py\n    # Find Missing ROWIDs\n    gaps = set(range(rowids[0], rowids[-1] + 1)).difference(rowids)\n    print(\"[*] Missing ROWIDS: {}\".format(gaps))\n```", "```py\nfrom __future__ import print_function\nimport argparse\nimport logging\nimport os\nfrom shutil import copyfile\nimport sqlite3\nimport sys\n\nlogger = logging.getLogger(__name__)\n```", "```py\nif __name__ == \"__main__\":\n    # Command-line Argument Parser\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument(\n        \"INPUT_DIR\",\n        help=\"Location of folder containing iOS backups, \"\n        \"e.g. ~\\Library\\Application Support\\MobileSync\\Backup folder\"\n    )\n    parser.add_argument(\"OUTPUT_DIR\", help=\"Output Directory\")\n    parser.add_argument(\"-l\", help=\"Log file path\",\n                        default=__file__[:-2] + \"log\")\n    parser.add_argument(\"-v\", help=\"Increase verbosity\",\n                        action=\"store_true\")\n    args = parser.parse_args()\n```", "```py\n    if args.v:\n        logger.setLevel(logging.DEBUG)\n    else:\n        logger.setLevel(logging.INFO)\n```", "```py\n    msg_fmt = logging.Formatter(\"%(asctime)-15s %(funcName)-13s\"\n                                \"%(levelname)-8s %(message)s\")\n    strhndl = logging.StreamHandler(sys.stderr)\n    strhndl.setFormatter(fmt=msg_fmt)\n    fhndl = logging.FileHandler(args.l, mode='a')\n    fhndl.setFormatter(fmt=msg_fmt)\n\n    logger.addHandler(strhndl)\n    logger.addHandler(fhndl)\n```", "```py\n    logger.info(\"Starting iBackup Visualizer\")\n    logger.debug(\"Supplied arguments: {}\".format(\" \".join(sys.argv[1:])))\n    logger.debug(\"System: \" + sys.platform)\n    logger.debug(\"Python Version: \" + sys.version)\n```", "```py\n    if not os.path.exists(args.OUTPUT_DIR):\n        os.makedirs(args.OUTPUT_DIR)\n```", "```py\n    if os.path.exists(args.INPUT_DIR) and os.path.isdir(args.INPUT_DIR):\n        main(args.INPUT_DIR, args.OUTPUT_DIR)\n    else:\n        logger.error(\"Supplied input directory does not exist or is not \"\n                     \"a directory\")\n        sys.exit(1)\n```", "```py\ndef main(in_dir, out_dir):\n    backups = backup_summary(in_dir)\n```", "```py\ndef backup_summary(in_dir):\n    logger.info(\"Identifying all iOS backups in {}\".format(in_dir))\n    root = os.listdir(in_dir)\n    backups = {}\n```", "```py\n    for x in root:\n        temp_dir = os.path.join(in_dir, x)\n        if os.path.isdir(temp_dir) and len(x) == 40:\n            num_files = 0\n            size = 0\n```", "```py\n            for root, subdir, files in os.walk(temp_dir):\n                num_files += len(files)\n                size += sum(os.path.getsize(os.path.join(root, name))\n                            for name in files)\n```", "```py\n            backups[x] = [temp_dir, num_files, size]\n\n    return backups\n```", "```py\n    print(\"Backup Summary\")\n    print(\"=\" * 20)\n    if len(backups) > 0:\n        for i, b in enumerate(backups):\n            print(\"Backup No.: {} \\n\"\n                  \"Backup Dev. Name: {} \\n\"\n                  \"# Files: {} \\n\"\n                  \"Backup Size (Bytes): {}\\n\".format(\n                      i, b, backups[b][1], backups[b][2])\n                  )\n```", "```py\n            try:\n                db_items = process_manifest(backups[b][0])\n            except IOError:\n                logger.warn(\"Non-iOS 10 backup encountered or \"\n                            \"invalid backup. Continuing to next backup.\")\n                continue\n```", "```py\ndef process_manifest(backup):\n    manifest = os.path.join(backup, \"Manifest.db\")\n\n    if not os.path.exists(manifest):\n        logger.error(\"Manifest DB not found in {}\".format(manifest))\n        raise IOError\n```", "```py\n    conn = sqlite3.connect(manifest)\n    c = conn.cursor()\n    items = {}\n    for row in c.execute(\"SELECT * from Files;\"):\n        items[row[0]] = [row[2], row[1], row[3]]\n\n    return items\n```", "```py\n            create_files(in_dir, out_dir, b, db_items)\n        print(\"=\" * 20)\n\n    else:\n        logger.warning(\n            \"No valid backups found. The input directory should be \"\n            \"the parent-directory immediately above the SHA-1 hash \"\n            \"iOS device backups\")\n        sys.exit(2)\n```", "```py\ndef create_files(in_dir, out_dir, b, db_items):\n    msg = \"Copying Files for backup {} to {}\".format(\n        b, os.path.join(out_dir, b))\n    logger.info(msg)\n```", "```py\n    files_not_found = 0\n    for x, key in enumerate(db_items):\n        if db_items[key][0] is None or db_items[key][0] == \"\":\n            continue\n```", "```py\n        else:\n            dirpath = os.path.join(\n                out_dir, b, os.path.dirname(db_items[key][0]))\n            filepath = os.path.join(out_dir, b, db_items[key][0])\n            if not os.path.exists(dirpath):\n                os.makedirs(dirpath)\n```", "```py\n            original_dir = b + \"/\" + key[0:2] + \"/\" + key\n            path = os.path.join(in_dir, original_dir)\n```", "```py\n            if os.path.exists(filepath):\n                filepath = filepath + \"_{}\".format(x)\n```", "```py\n            try:\n                copyfile(path, filepath)\n            except IOError:\n                logger.debug(\"File not found in backup: {}\".format(path))\n                files_not_found += 1\n```", "```py\n    if files_not_found > 0:\n        logger.warning(\"{} files listed in the Manifest.db not\"\n                       \"found in backup\".format(files_not_found))\n\n    copyfile(os.path.join(in_dir, b, \"Info.plist\"),\n             os.path.join(out_dir, b, \"Info.plist\"))\n    copyfile(os.path.join(in_dir, b, \"Manifest.db\"),\n             os.path.join(out_dir, b, \"Manifest.db\"))\n    copyfile(os.path.join(in_dir, b, \"Manifest.plist\"),\n             os.path.join(out_dir, b, \"Manifest.plist\"))\n    copyfile(os.path.join(in_dir, b, \"Status.plist\"),\n             os.path.join(out_dir, b, \"Status.plist\"))\n```", "```py\npip install requests==2.18.4\n```", "```py\nfrom __future__ import print_function\nimport argparse\nimport csv\nimport os\nimport sys\nimport xml.etree.ElementTree as ET\nimport requests\n```", "```py\nif __name__ == \"__main__\":\n    # Command-line Argument Parser\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__),\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\"INPUT_FILE\", help=\"INPUT FILE with MAC Addresses\")\n    parser.add_argument(\"OUTPUT_CSV\", help=\"Output CSV File\")\n    parser.add_argument(\n        \"-t\", help=\"Input type: Cellebrite XML report or TXT file\",\n        choices=('xml', 'txt'), default=\"xml\")\n    parser.add_argument('--api', help=\"Path to API key file\",\n                        default=os.path.expanduser(\"~/.wigle_api\"),\n                        type=argparse.FileType('r'))\n    args = parser.parse_args()\n```", "```py\n    if not os.path.exists(args.INPUT_FILE) or \\\n            not os.path.isfile(args.INPUT_FILE):\n        print(\"[-] {} does not exist or is not a file\".format(\n            args.INPUT_FILE))\n        sys.exit(1)\n\n    directory = os.path.dirname(args.OUTPUT_CSV)\n    if directory != '' and not os.path.exists(directory):\n        os.makedirs(directory)\n\n    api_key = args.api.readline().strip().split(\":\")\n```", "```py\n    main(args.INPUT_FILE, args.OUTPUT_CSV, args.t, api_key)\n```", "```py\ndef main(in_file, out_csv, type, api_key):\n    if type == 'xml':\n        wifi = parse_xml(in_file)\n    else:\n        wifi = parse_txt(in_file)\n\n    query_wigle(wifi, out_csv, api_key)\n```", "```py\ndef parse_xml(xml_file):\n    wifi = {}\n    xmlns = \"{http://pa.cellebrite.com/report/2.0}\"\n    print(\"[+] Opening {} report\".format(xml_file))\n    xml_tree = ET.parse(xml_file)\n    print(\"[+] Parsing report for all connected WiFi addresses\")\n    root = xml_tree.getroot()\n```", "```py\n    for child in root.iter():\n        if child.tag == xmlns + \"model\":\n            if child.get(\"type\") == \"Location\":\n```", "```py\n                for field in child.findall(xmlns + \"field\"):\n                    if field.get(\"name\") == \"TimeStamp\":\n                        ts_value = field.find(xmlns + \"value\")\n                        try:\n                            ts = ts_value.text\n                        except AttributeError:\n                            continue\n```", "```py\n                    if field.get(\"name\") == \"Description\":\n                        value = field.find(xmlns + \"value\")\n                        try:\n                            value_text = value.text\n                        except AttributeError:\n                            continue\n```", "```py\n                        if \"SSID\" in value.text:\n                            bssid, ssid = value.text.split(\"\\t\")\n                            bssid = bssid[7:]\n                            ssid = ssid[6:]\n```", "```py\n                            if bssid in wifi.keys():\n                                wifi[bssid][\"Timestamps\"].append(ts)\n                                wifi[bssid][\"SSID\"].append(ssid)\n                            else:\n                                wifi[bssid] = {\n                                    \"Timestamps\": [ts], \"SSID\": [ssid],\n                                    \"Wigle\": {}}\n    return wifi\n```", "```py\ndef parse_txt(txt_file):\n    wifi = {}\n    print(\"[+] Extracting MAC addresses from {}\".format(txt_file))\n    with open(txt_file) as mac_file:\n        for line in mac_file:\n            wifi[line.strip()] = {\"Timestamps\": [\"N/A\"], \"SSID\": [\"N/A\"],\n                                  \"Wigle\": {}}\n    return wifi\n```", "```py\ndef query_wigle(wifi_dictionary, out_csv, api_key):\n    print(\"[+] Querying Wigle.net through Python API for {} \"\n          \"APs\".format(len(wifi_dictionary)))\n    for mac in wifi_dictionary:\n        wigle_results = query_mac_addr(mac, api_key)\n```", "```py\ndef query_mac_addr(mac_addr, api_key):\n    query_url = \"https://api.wigle.net/api/v2/network/search?\" \\\n        \"onlymine=false&freenet=false&paynet=false\" \\\n        \"&netid={}\".format(mac_addr)\n    req = requests.get(query_url, auth=(api_key[0], api_key[1]))\n    return req.json()\n```", "```py\n        try:\n            if wigle_results[\"resultCount\"] == 0:\n                wifi_dictionary[mac][\"Wigle\"][\"results\"] = []\n                continue\n            else:\n                wifi_dictionary[mac][\"Wigle\"] = wigle_results\n        except KeyError:\n            if wigle_results[\"error\"] == \"too many queries today\":\n                print(\"[-] Wigle daily query limit exceeded\")\n                wifi_dictionary[mac][\"Wigle\"][\"results\"] = []\n                continue\n            else:\n                print(\"[-] Other error encountered for \"\n                      \"address {}: {}\".format(mac, wigle_results['error']))\n                wifi_dictionary[mac][\"Wigle\"][\"results\"] = []\n                continue\n    prep_output(out_csv, wifi_dictionary)\n```", "```py\ndef prep_output(output, data):\n    csv_data = {}\n    google_map = \"https://www.google.com/maps/search/\"\n```", "```py\n    for x, mac in enumerate(data):\n        for y, ts in enumerate(data[mac][\"Timestamps\"]):\n            for z, result in enumerate(data[mac][\"Wigle\"][\"results\"]):\n                shortres = data[mac][\"Wigle\"][\"results\"][z]\n                g_map_url = \"{}{},{}\".format(\n                    google_map, shortres[\"trilat\"], shortres[\"trilong\"])\n```", "```py\n                csv_data[\"{}-{}-{}\".format(x, y, z)] = {\n                    **{\n                        \"BSSID\": mac, \"SSID\": data[mac][\"SSID\"][y],\n                        \"Cellebrite Connection Time\": ts,\n                        \"Google Map URL\": g_map_url},\n                    **shortres\n                }\n\n    write_csv(output, csv_data)\n```", "```py\ndef write_csv(output, data):\n    print(\"[+] Writing data to {}\".format(output))\n    field_list = set()\n    for row in data:\n        for field in data[row]:\n            field_list.add(field)\n```", "```py\n    with open(output, \"w\", newline=\"\") as csvfile:\n        csv_writer = csv.DictWriter(csvfile, fieldnames=sorted(\n            field_list), extrasaction='ignore')\n```", "```py\n        csv_writer.writeheader()\n        for csv_row in data:\n            csv_writer.writerow(data[csv_row])\n```", "```py\nfrom __future__ import print_function\nimport argparse\nimport binascii\nimport csv\nfrom itertools import product\nimport os\nimport re\nimport sqlite3\nimport sys\n```", "```py\nif __name__ == \"__main__\":\n    # Command-line Argument Parser\n    parser = argparse.ArgumentParser(\n        description=__description__,\n        epilog=\"Developed by {} on {}\".format(\n            \", \".join(__authors__), __date__)\n    )\n    parser.add_argument(\"SQLITE_DATABASE\", help=\"Input SQLite database\")\n    parser.add_argument(\"TABLE\", help=\"Table to query from\")\n    parser.add_argument(\"OUTPUT_CSV\", help=\"Output CSV File\")\n    parser.add_argument(\"--column\", help=\"Optional column argument\")\n    args = parser.parse_args()\n```", "```py\n    if args.column is not None:\n        main(args.SQLITE_DATABASE, args.TABLE,\n             args.OUTPUT_CSV, col=args.column)\n    else:\n        main(args.SQLITE_DATABASE, args.TABLE, args.OUTPUT_CSV)\n```", "```py\n    print(\"[+] Carving for missing ROWIDs\")\n    varints = varint_converter(list(gaps))\n```", "```py\ndef varint_converter(rows):\n    varints = {}\n    varint_combos = []\n    for i, row in enumerate(rows):\n        if row <= 127:\n            varints[hex(row)[2:]] = row\n```", "```py\n        else:\n            combos = [x for x in range(0, 256)]\n            counter = 1\n            while True:\n                counter += 1\n                print(\"[+] Generating and finding all {} byte \"\n                      \"varints..\".format(counter))\n                varint_combos = list(product(combos, repeat=counter))\n                varint_combos = [x for x in varint_combos if x[0] >= 128]\n```", "```py\n                for varint_combo in varint_combos:\n                    varint = integer_converter(varint_combo)\n                    if varint == row:\n                        varints[\"\".join([hex(v)[2:].zfill(2) for v in\n                                         varint_combo])] = row\n                        i += 1\n                        try:\n                            row = rows[i]\n                        except IndexError:\n                            return varints\n```", "```py\ndef integer_converter(numbs):\n    binary = \"\"\n    for numb in numbs:\n        binary += bin(numb)[2:].zfill(8)[1:]\n    binvar = binary.lstrip(\"0\")\n    if binvar != '':\n        return int(binvar, 2)\n    else:\n        return 0\n```", "```py\n    search_results = find_candidates(database, varints)\n```", "```py\ndef find_candidates(database, varints):\n    results = []\n    candidate_a = \"350055\"\n    candidate_b = \"360055\"\n```", "```py\n    with open(database, \"rb\") as infile:\n        hex_data = str(binascii.hexlify(infile.read()))\n    for varint in varints:\n        search_a = varint + candidate_a\n        search_b = varint + candidate_b\n```", "```py\n        for result in re.finditer(search_a, hex_data):\n            results.append([varints[varint], search_a, result.start() / 2])\n\n        for result in re.finditer(search_b, hex_data):\n            results.append([varints[varint], search_b, result.start() / 2])\n\n    return results\n```", "```py\n    if search_results != []:\n        print(\"[+] Writing {} potential candidates to {}\".format(\n            len(search_results), out_csv))\n        write_csv(out_csv, [\"ROWID\", \"Search Term\", \"Offset\"],\n                  search_results)\n    else:\n        print(\"[-] No search results found for missing ROWIDs\")\n```", "```py\ndef write_csv(output, cols, msgs):\n    with open(output, \"w\", newline=\"\") as csvfile:\n        csv_writer = csv.writer(csvfile)\n        csv_writer.writerow(cols)\n        csv_writer.writerows(msgs)\n```"]