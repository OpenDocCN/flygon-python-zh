# 开始并行计算和 Python

*并行*和*分布式计算*模型基于同时使用不同处理单元进行程序执行。尽管并行和分布式计算之间的区别非常微弱，但可能的定义之一将并行计算模型与共享内存计算模型相关联，将分布式计算模型与消息传递模型相关联。

从这一点开始，我们将使用术语*并行计算*来指代并行和分布式计算模型。

接下来的部分将概述并行编程体系结构和编程模型。这些概念对于初学者来说是有用的，他们第一次接触并行编程技术。此外，它也可以成为有经验的程序员的基本参考。还介绍了并行系统的双重特征。第一种特征基于系统架构，而第二种特征基于并行编程范式。

本章以对 Python 编程语言的简要介绍结束。语言的特点、易用性和学习性，以及软件库和应用程序的可扩展性和丰富性，使 Python 成为任何应用的有价值工具，也适用于并行计算。介绍了线程和进程的概念，以及它们在语言中的使用。

在本章中，我们将涵盖以下内容：

+   为什么我们需要并行计算？

+   弗林的分类

+   内存组织

+   并行编程模型

+   性能评估

+   介绍 Python

+   Python 和并行编程

+   介绍进程和线程

# 为什么我们需要并行计算？

现代计算机提供的计算能力增长导致我们在相对较短的时间内面临着日益复杂的计算问题。直到 21 世纪初，复杂性是通过增加晶体管数量以及单处理器系统的时钟频率来处理的，达到了 3.5-4 GHz 的峰值。然而，晶体管数量的增加导致了处理器本身耗散功率的指数增长。实质上，因此存在着一个物理限制，阻止了单处理器系统性能的进一步提高。

因此，近年来，微处理器制造商已经将注意力集中在*多核*系统上。这些系统基于多个物理处理器的核心，它们共享相同的内存，从而绕过了之前描述的功耗问题。近年来，*四核*和*八核*系统也已成为普通台式机和笔记本配置的标准。

另一方面，硬件上的如此重大变化也导致了软件结构的演变，这些软件一直被设计为在单个处理器上顺序执行。为了利用通过增加处理器数量提供的更多计算资源，现有软件必须以适合 CPU 并行结构的形式进行重新设计，以便通过同时执行同一程序的多个部分的单元来获得更高的效率。

# 弗林的分类

弗林的分类是一种用于分类计算机体系结构的系统。它基于两个主要概念：

+   指令流：具有*n*个 CPU 的系统具有*n*个程序计数器，因此有*n*个指令流。这对应于一个程序计数器。

+   **数据流**：计算数据列表上的函数的程序具有数据流。计算相同函数在几个不同数据列表上的程序具有更多的数据流。这由一组操作数组成。

由于指令和数据流是独立的，存在四类并行机器：**单指令单数据**（**SISD**）、**单指令多数据**（**SIMD**）、**多指令单数据**（**MISD**）和**多指令多数据**（**MIMD**）：

![](img/315c390f-4c31-4a69-811e-5696dff064d1.png)

弗林分类法

# 单指令单数据（SISD）

SISD 计算系统类似于冯·诺伊曼机，即单处理器机器。如*弗林分类法*图所示，它执行单个指令，作用于单个数据流。在 SISD 中，机器指令是按顺序处理的。

在一个时钟周期内，CPU 执行以下操作：

+   **取指**：CPU 从内存区域获取数据和指令，称为*寄存器*。

+   **解码**：CPU 解码指令。

+   **执行**：指令在数据上执行。操作的结果存储在另一个寄存器中。

执行阶段完成后，CPU 开始另一个 CPU 周期：

![](img/8d131bb3-cd52-4f51-969c-8c836a394f89.png)

取指、解码和执行周期

在这种类型的计算机上运行的算法是顺序的，因为它们不包含任何并行性。SISD 计算机的一个例子是具有单个 CPU 的硬件系统。

这些架构的主要元素（即冯·诺伊曼架构）如下：

+   **中央存储器单元**：用于存储指令和程序数据。

+   **CPU**：用于从存储器单元获取指令和/或数据，解码指令并按顺序执行。

+   **I/O 系统**：这指的是程序的输入和输出数据。

传统的单处理器计算机被归类为 SISD 系统：

![](img/1a6b6929-c4c4-41bb-96ae-2ec6b2aea55d.png)

SISD 架构图

以下图表具体显示了 CPU 在取指、解码和执行阶段中使用的区域：

![](img/9ceec645-0aa1-4c90-97a7-cba9f8eb5031.png)

CPU 在取指-解码-执行阶段的组件

# 多指令单数据（MISD）

在这种模型中，*n*个处理器，每个都有自己的控制单元，共享一个单一的存储单元。在每个时钟周期中，从存储器接收的数据由所有处理器同时处理，每个处理器根据从其控制单元接收的指令进行处理。

在这种情况下，通过对同一数据执行多个操作来获得并行性（指令级并行性）。这些架构可以有效解决的问题类型相当特殊，例如数据加密。因此，MISD 计算机在商业领域没有找到位置。MISD 计算机更多地是一种智力锻炼，而不是一种实际的配置。

# 单指令多数据（SIMD）

SIMD 计算机由*n*个相同的处理器组成，每个处理器都有自己的本地存储器，可以在其中存储数据。所有处理器都在单一指令流的控制下工作。此外，还有*n*个数据流，每个处理器对应一个数据流。处理器同时在每个步骤上执行并执行相同的指令，但对不同的数据元素进行操作。这是数据级并行性的一个例子。

SIMD 架构比 MISD 架构更加灵活。并行算法可以解决涵盖广泛应用领域的许多问题。另一个有趣的特点是，这些计算机的算法相对容易设计、分析和实现。限制在于只有能够分解为多个子问题（这些子问题都是相同的，然后通过相同的指令集同时解决）的问题才能用 SIMD 计算机解决。

根据这一范式开发的超级计算机，我们必须提到*Connection Machine*（Thinking Machine,1985）和*MPP*（NASA, 1983）。

正如我们将在第六章中看到的，*分布式 Python*，以及第七章中看到的，*云计算*，现代图形卡（GPU）的出现，内置了许多 SIMD 嵌入单元，导致了这种计算范式的更广泛使用。

# 多指令多数据（MIMD）

根据弗林的分类，这类并行计算机是最一般和最强大的类。这包括*n*个处理器，*n*个指令流和*n*个数据流。每个处理器都有自己的控制单元和本地内存，这使得 MIMD 架构比 SIMD 架构更具计算能力。

每个处理器都在其自己的控制单元发出的指令流的控制下运行。因此，处理器可以潜在地运行不同的程序和不同的数据，这使它们能够解决不同的子问题，并且可以成为单个更大问题的一部分。在 MIMD 中，架构是通过线程和/或进程的并行级别实现的。这也意味着处理器通常是异步操作的。

如今，这种架构应用于许多个人电脑、超级计算机和计算机网络。然而，您需要考虑的一个反面是：异步算法难以设计、分析和实现：

![](img/f3fa5a98-1a89-4d76-a8af-c25a376c1ac8.png)

SIMD 架构（A）和 MIMD 架构（B）

通过考虑 SIMD 机器可以分为两个子组：

+   数值超级计算机

+   矢量机器

另一方面，MIMD 可以分为具有共享内存和具有分布式内存的机器。

事实上，下一节着重讨论 MIMD 机器内存组织的最后一个方面。

# 内存组织

我们需要考虑的另一个方面是评估并行架构的内存组织，或者说，数据访问的方式。无论处理单元有多快，如果内存不能以足够的速度维护和提供指令和数据，那么性能就不会有所改善。

我们需要克服的主要问题是使内存的响应时间与处理器的速度兼容，这是内存周期时间，即两次连续操作之间经过的时间。处理器的周期时间通常比内存的周期时间短得多。

当处理器启动对内存的传输时，处理器的资源将在整个内存周期内保持占用；此外，在此期间，由于正在进行传输，没有其他设备（例如 I/O 控制器、处理器，甚至发出请求的处理器）能够使用内存：

![](img/d56ae362-cff1-4d47-97aa-78419437b2b7.png)

MIMD 架构中的内存组织

解决内存访问问题导致了 MIMD 架构的二分法。第一种系统称为*共享内存*系统，具有高虚拟内存，并且所有处理器都可以平等访问该内存中的数据和指令。另一种系统是***分布式内存***模型，其中每个处理器都有本地内存，其他处理器无法访问。

分布式内存共享的区别在于内存访问的管理，由处理单元执行；这一区别对程序员来说非常重要，因为它决定了并行程序的不同部分如何进行通信。

特别是，分布式内存机器必须在每个本地内存中制作共享数据的副本。这些副本是通过将包含要共享的数据的消息从一个处理器发送到另一个处理器来创建的。这种内存组织的一个缺点是，有时这些消息可能非常大并且需要相对长的时间来传输，而在共享内存系统中，没有消息交换，主要问题在于同步对共享资源的访问。

# 共享内存

共享内存多处理器系统的架构如下图所示。这里的物理连接非常简单。

![](img/0f53e868-04c0-4493-9b33-f9be28089ca2.png)

共享内存架构图

在这里，总线结构允许任意数量的设备（CPU +缓存在前面的图中）共享相同的通道（主内存，如前面的图所示）。总线协议最初是设计用于允许单个处理器和一个或多个磁盘或磁带控制器通过共享内存进行通信。

每个处理器都与缓存内存相关联，因为假定处理器需要在本地内存中具有数据或指令的概率非常高。

当一个处理器修改同时被其他处理器使用的存储在内存系统中的数据时，问题就会发生。新值将从已更改的处理器缓存传递到共享内存。然而，它还必须传递到所有其他处理器，以便它们不使用过时的值。这个问题被称为“缓存一致性”问题，是内存一致性问题的特例，需要硬件实现来处理并发问题和同步，类似于线程编程。

共享内存系统的主要特点如下：

+   所有处理器的内存都是相同的。例如，与相同数据结构相关联的所有处理器将使用相同的逻辑内存地址，从而访问相同的内存位置。

+   通过读取各个处理器的任务并允许共享内存来实现同步。实际上，处理器一次只能访问一个内存。

+   共享内存位置在另一个任务访问时不得被另一个任务更改。

+   任务之间共享数据很快。通信所需的时间是它们中的一个读取单个位置所需的时间（取决于内存访问速度）。

在共享内存系统中，内存访问如下：

+   统一内存访问（UMA）：该系统的基本特征是对内存的访问时间对于每个处理器和任何内存区域都是恒定的。因此，这些系统也被称为对称多处理器（SMP）。它们相对简单实现，但扩展性不强。编码人员负责通过在管理资源的程序中插入适当的控制、信号量、锁等来管理同步。

+   非统一内存访问（NUMA）：这些架构将内存分为分配给每个处理器的高速访问区域，以及用于数据交换的通用区域，访问速度较慢。这些系统也被称为分布式共享内存（DSM）系统。它们具有很强的可扩展性，但开发起来比较复杂。

+   无远程内存访问（NoRMA）：内存在处理器之间物理分布（本地内存）。所有本地内存都是私有的，只能访问本地处理器。处理器之间的通信是通过用于交换消息的通信协议进行的，这被称为消息传递协议。

+   **仅缓存内存架构**（**COMA**）：这些系统只配备了缓存内存。在分析 NUMA 架构时，注意到这种架构在缓存中保留了数据的本地副本，并且这些数据在主内存中存储为重复。这种架构去除了重复，并且只保留了缓存内存；内存在处理器之间物理分布（本地内存）。所有本地内存都是私有的，只能访问本地处理器。处理器之间的通信也是通过消息传递协议进行的。

# 分布式内存

在分布式内存系统中，每个处理器都与内存相关联，处理器只能访问自己的内存。一些作者将这种类型的系统称为多处理机，反映了系统的元素本身是处理器和内存的小而完整的系统，如下图所示：

![](img/edbcb72a-7807-4dba-97da-a1e69af3c29d.png)

分布式内存架构模式

这种组织方式有几个优点：

+   在通信总线或交换机的级别没有冲突。每个处理器可以使用自己本地内存的全部带宽，而不受其他处理器的干扰。

+   没有共享总线意味着处理器数量没有固有限制。系统的大小仅受连接处理器的网络的限制。

+   缓存一致性没有问题。每个处理器负责自己的数据，不必担心升级任何副本。

主要的缺点是处理器之间的通信更难实现。如果一个处理器需要另一个处理器的内存中的数据，那么这两个处理器不一定需要通过消息传递协议交换消息。这引入了两种减速的来源：从一个处理器向另一个处理器构建和发送消息需要时间，而且任何处理器都必须停止以管理从其他处理器接收到的消息。设计为在分布式内存机器上运行的程序必须组织为一组通过消息进行通信的独立任务：

![](img/6174b7b7-c606-48e1-a585-3412e6d542c7.png)

基本消息传递

分布式内存系统的主要特点如下：

+   内存在处理器之间物理分布；每个本地内存只能被其处理器直接访问。

+   通过在处理器之间移动数据（即使只是消息本身）来实现同步（通信）。

+   本地内存中数据的细分会影响机器的性能——必须准确地进行细分，以最小化 CPU 之间的通信。除此之外，协调这些分解和组合操作的处理器必须有效地与操作数据结构各个部分的处理器进行通信。

+   使用消息传递协议，以便 CPU 可以通过交换数据包进行通信。消息是信息的离散单元，从这个意义上说，它们具有明确定义的身份，因此总是可以将它们与其他消息区分开来。

# 大规模并行处理（MPP）

MPP 机器由数百个处理器组成（在某些机器中可以达到数十万个处理器），它们通过通信网络连接。世界上最快的计算机基于这些架构；这些架构系统的一些例子是 Earth Simulator、Blue Gene、ASCI White、ASCI Red、ASCI Purple 和 Red Storm。

# 工作站集群

这些处理系统是基于通过通信网络连接的经典计算机。计算集群属于这一分类。

在集群架构中，我们将节点定义为参与集群的单个计算单元。对于用户来说，集群是完全透明的 - 所有的硬件和软件复杂性都被掩盖，数据和应用程序都可以像来自单个节点一样访问。

在这里，我们确定了三种类型的集群：

+   **故障转移集群**：在这种情况下，节点的活动会持续监控，当一个节点停止工作时，另一台机器会接管这些活动。其目的是通过架构的冗余性来确保连续的服务。

+   **负载平衡集群**：在这个系统中，作业请求被发送到活动较少的节点。这确保了处理作业所需的时间较短。

+   **高性能计算集群**：在这种情况下，每个节点都配置为提供极高的性能。该过程也被分成多个作业，并行化并分布到不同的机器上。

# 异构架构

在超级计算的同质世界中引入 GPU 加速器已经改变了超级计算机的使用和编程方式。尽管 GPU 提供了高性能，但它们不能被视为自主的处理单元，因为它们总是需要与 CPU 的组合一起使用。因此，编程范式非常简单：CPU 控制并以串行方式计算，将计算量非常大且具有高度并行性的任务分配给图形加速器。

CPU 和 GPU 之间的通信不仅可以通过高速总线进行，还可以通过共享单个内存区域进行，无论是物理内存还是虚拟内存。事实上，在两个设备都没有自己的内存区域的情况下，可以使用各种编程模型提供的软件库，如*CUDA*和*OpenCL*，来引用一个共同的内存区域。

这些架构被称为*异构架构*，应用程序可以在单个地址空间中创建数据结构，并将作业发送到适合解决任务的设备硬件。多个处理任务可以安全地在相同的区域内运行，以避免数据一致性问题，这要归功于原子操作。

因此，尽管 CPU 和 GPU 似乎不能有效地共同工作，但通过使用这种新架构，我们可以优化它们与并行应用程序的交互和性能：

![](img/46dac58e-d70e-4177-bc35-1018279093a9.png)

异构架构模式

在接下来的部分中，我们将介绍主要的并行编程模型。

# 并行编程模型

并行编程模型存在作为硬件和内存架构的抽象。事实上，这些模型并不具体，也不指代任何特定类型的机器或内存架构。它们可以（至少在理论上）在任何类型的机器上实现。与以前的细分相比，这些编程模型是在更高的层次上制定的，并代表了软件执行并行计算的方式。每个模型都有自己的方式与其他处理器共享信息，以便访问内存和分配工作。

绝对来说，没有一个模型比其他模型更好。因此，应用的最佳解决方案将在很大程度上取决于程序员需要解决和解决的问题。最广泛使用的并行编程模型如下：

+   共享内存模型

+   多线程模型

+   分布式内存/消息传递模型

+   数据并行模型

在这个配方中，我们将为您概述这些模型。

# 共享内存模型

在这个模型中，任务共享一个内存区域，我们可以异步读写。有一些机制允许编码人员控制对共享内存的访问；例如，锁或信号量。这个模型的优点是编码人员不必澄清任务之间的通信。在性能方面的一个重要缺点是，更难理解和管理数据局部性。这指的是保持数据局部于处理器上，以保留内存访问、缓存刷新和总线流量，当多个处理器使用相同数据时发生。

# 多线程模型

在这个模型中，一个进程可以有多个执行流。例如，首先创建一个顺序部分，然后创建一系列可以并行执行的任务。通常，这种类型的模型用于共享内存架构。因此，对我们来说，管理线程之间的同步将非常重要，因为它们在共享内存上运行，并且程序员必须防止多个线程同时更新相同的位置。

当前一代的 CPU 在软件和硬件上都是多线程的。**POSIX**（代表**可移植操作系统接口**）线程是软件上多线程实现的经典例子。英特尔的超线程技术通过在一个线程停滞或等待 I/O 时在两个线程之间切换来在硬件上实现多线程。即使数据对齐是非线性的，也可以从这个模型中实现并行性。

# 消息传递模型

消息传递模型通常应用于每个处理器都有自己的内存（分布式内存系统）的情况。更多的任务可以驻留在同一台物理机器上或任意数量的机器上。编码人员负责确定通过消息进行的并行性和数据交换，并且需要在代码中请求和调用函数库。

一些例子自 20 世纪 80 年代以来就存在，但直到 20 世纪 90 年代中期才创建了一个标准化的模型，导致了一种事实上的标准，称为**消息传递接口**（**MPI**）。

MPI 模型显然是设计用于分布式内存的，但作为并行编程模型，多平台模型也可以在共享内存机器上使用：

![](img/bd5deb5a-ea45-42d8-ba4e-b7852b6e0fcd.png)

消息传递范式模型

# 数据并行模型

在这个模型中，我们有更多的任务操作相同的数据结构，但每个任务操作不同部分的数据。在共享内存架构中，所有任务都可以通过共享内存访问数据，而在分布式内存架构中，数据结构被划分并驻留在每个任务的本地内存中。

为了实现这个模型，编码人员必须开发一个指定数据分布和对齐的程序；例如，当前一代的 GPU 只有在数据（**任务** **1**，**任务** **2**，**任务** **3**）对齐时才能高效运行，如下图所示：

![](img/93cf041f-f65b-46e5-b36d-59d4ed537910.png)

数据并行范式模型

# 设计并行程序

利用并行性设计算法是基于一系列操作，必须执行这些操作才能使程序正确执行工作而不产生部分或错误的结果。必须执行的宏操作包括：

+   任务分解

+   任务分配

+   聚集

+   映射

# 任务分解

在这个第一阶段，软件程序被分割成任务或一组指令，然后可以在不同的处理器上执行以实现并行性。为了执行这种细分，使用了两种方法：

+   **域分解**：在这里，问题的数据被分解。应用程序对处理不同数据部分的所有处理器都是通用的。当我们有大量必须处理的数据时，使用这种方法。

+   **功能分解**：在这种情况下，问题被分解成任务，每个任务将对所有可用数据执行特定操作。

# 任务分配

在这一步中，指定了任务将在各个进程之间分配的机制。这个阶段非常重要，因为它确定了各个处理器之间的工作负载分配。在这里负载平衡至关重要；事实上，所有处理器必须连续工作，避免长时间处于空闲状态。

为了执行这一点，编码人员考虑了系统的可能异质性，试图将更多的任务分配给性能更好的处理器。最后，为了更有效地进行并行化，有必要尽量限制处理器之间的通信，因为它们通常是减速和资源消耗的来源。

# 聚合

聚合是将较小的任务与较大的任务组合以提高性能的过程。如果设计过程的前两个阶段将问题分割成远远超过可用处理器数量的任务，并且计算机没有专门设计来处理大量小任务（一些架构，如 GPU，可以很好地处理这一点，并且确实受益于运行数百万甚至数十亿的任务），那么设计可能会变得非常低效。

通常，这是因为任务必须被传输到处理器或线程，以便它们计算所述任务。大多数通信的成本与传输的数据量不成比例，但也会为每个通信操作产生固定成本（例如延迟，在建立 TCP 连接时固有的）。如果任务太小，那么这个固定成本很容易使设计变得低效。

# 映射

在并行算法设计过程的映射阶段，我们指定每个任务应在哪里执行。目标是最小化总执行时间。在这里，你经常需要做出权衡，因为两种主要策略经常相互冲突：

+   频繁通信的任务应放置在同一处理器上以增加局部性。

+   可以同时执行的任务应放置在不同的处理器中以增强并发性。

这被称为*映射问题*，已知为**NP 完全**。因此，在一般情况下，该问题没有多项式时间的解决方案。对于相同大小的任务和具有易于识别的通信模式的任务，映射是直接的（我们也可以在这里执行聚合，将映射到相同处理器的任务组合在一起）。然而，如果任务具有难以预测的通信模式或任务的工作量因任务而异，那么设计有效的映射和聚合方案就很困难。

对于这些类型的问题，可以使用负载平衡算法来识别运行时的聚合和映射策略。最困难的问题是在程序执行过程中通信量或任务数量发生变化的问题。对于这类问题，可以使用动态负载平衡算法，它们在执行过程中定期运行。

# 动态映射

存在许多负载平衡算法，适用于各种问题：

+   **全局算法**：这些需要对正在执行的计算进行全局了解，这通常会增加很多开销。

+   **局部算法**：这些仅依赖于与所讨论的任务相关的本地信息，与全局算法相比减少了开销，但通常在寻找最佳聚合和映射方面效果较差。

然而，减少的开销可能会减少执行时间，即使映射本身更糟。如果任务除了在执行开始和结束时很少通信，那么通常会使用任务调度算法，该算法简单地将任务映射到处理器，使它们变为空闲。在任务调度算法中，维护一个任务池。任务被放入此池中，并由工作者从中取出。

在这个模型中有三种常见的方法：

+   **管理者/工作者：**这是基本的动态映射方案，所有工作者都连接到一个集中的管理者。管理者反复向工作者发送任务并收集结果。这种策略可能是相对较少处理器的最佳选择。通过提前获取任务，可以改进基本策略，使通信和计算重叠。

+   **分层管理者/工作者：**这是管理者/工作者的变体，具有半分布式布局。工作者被分成组，每个组都有自己的管理者。这些组管理者与中央管理者通信（可能也相互通信），而工作者从组管理者请求任务。这样可以将负载分散到几个管理者中，并且如果所有工作者都从同一个管理者请求任务，则可以处理更多的处理器。

+   **去中心化：**在这种方案中，一切都是去中心化的。每个处理器维护自己的任务池，并与其他处理器通信以请求任务。处理器如何选择其他处理器来请求任务是不同的，并且是根据问题的基础确定的。

# 评估并行程序的性能

并行编程的发展产生了性能指标的需求，以便决定其使用是否方便。事实上，并行计算的重点是在相对较短的时间内解决大问题。为此目标做出贡献的因素包括所使用的硬件类型、问题的并行度以及采用的并行编程模型。为了方便起见，引入了基本概念的分析，比较了从原始序列获得的并行算法。

通过分析和量化使用的线程数量和/或进程数量来实现性能。为了分析这一点，让我们引入一些性能指标：

+   **加速**

+   **效率**

+   **扩展**

并行计算的限制由**阿姆达尔**定律引入。为了评估顺序算法并行化的效率程度，我们有**古斯塔夫森**定律。

# 加速

**加速**是显示以并行方式解决问题的好处的度量。它定义为在单个处理元素上解决问题所需的时间（*Ts*）与在*p*个相同处理元素上解决相同问题所需的时间（*Tp*）的比率。

我们将加速定义如下：

![](img/d06f79cc-0130-4c88-9669-be45342198b8.png)

我们有线性加速，如果 *S=p*，那么这意味着执行速度随处理器数量的增加而增加。当然，这是一个理想情况。虽然当*Ts*是最佳顺序算法的执行时间时，加速是绝对的，但当*Ts*是单处理器上并行算法的执行时间时，加速是相对的。

让我们总结一下这些条件：

+   *S = p* 是线性或理想加速。

+   *S < p* 是真实加速。

+   *S > p* 是超线性加速。

# 效率

在理想世界中，具有*p*个处理元素的并行系统可以给我们一个等于*p*的加速。然而，这很少实现。通常会在空闲或通信中浪费一些时间。效率是度量处理元素将多少执行时间用于执行有用工作的指标，以执行时间的一部分表示。

我们用 *E* 表示，并可以定义如下：

![](img/a51cb8a0-063e-4177-a8e3-caa123753d53.png)

具有线性加速的算法的值为*E = 1*。在其他情况下，它们的值小于*1*。这三种情况分别标识为：

+   当*E = 1*时，这是一个线性案例。

+   当*E < 1*时，这是一个真实案例。

+   当*E << 1*时，这是一个效率低下的可并行化问题。

# 扩展

扩展被定义为在并行机器上高效的能力。它确定了计算能力（执行速度）与处理器数量成比例。通过增加问题的规模和同时增加处理器的数量，性能不会有损失。

可扩展的系统，根据不同因素的增量，可以保持相同的效率或改善效率。

# Amdahl 定律

Amdahl 定律是一条广泛使用的定律，用于设计处理器和并行算法。它规定了可以实现的最大加速比受程序的串行部分限制：

![](img/d0ef21cb-ef7a-401d-990a-5a3b45325d05.png)

*1 - P*表示程序的串行部分（不并行化）。

这意味着，例如，如果一个程序中有 90%的代码可以并行执行，但 10%必须保持串行，则最大可实现的加速比为 9，即使有无限数量的处理器也是如此。

# Gustafson 定律

Gustafson 定律陈述如下：

![](img/5b33302b-8561-4073-a6df-09072923e8f5.png)

在这里，正如我们在方程中指出的那样：

+   *P*是*处理器数量*。

+   *S*是*加速*因子。

+   *α*是任何并行过程的*不可并行化部分*。

Gustafson 定律与 Amdahl 定律形成对比，后者假设程序的整体工作量不随处理器数量的变化而改变。

事实上，Gustafson 定律建议程序员首先设置解决问题的并行*时间*，然后基于（即时间）*调整*问题的大小。因此，*并行系统*越*快*，在相同时间内可以解决的*问题*就*越大*。

Gustafson 定律的影响是将计算机研究的目标引向以某种方式选择或重新制定问题，以便在相同的时间内仍然可以解决更大的问题。此外，该定律重新定义了*效率*的概念，即需要*至少减少程序的顺序部分*，尽管*工作量增加*。

# 介绍 Python

Python 是一种强大、动态和解释性的编程语言，广泛应用于各种应用程序。它的一些特点如下：

+   清晰易读的语法。

+   非常广泛的标准库，通过额外的软件模块，我们可以添加数据类型、函数和对象。

+   易学易用的快速开发和调试。使用 Python，在 Python 中开发代码可以比在 C/C++代码中快 10 倍。代码也可以作为原型工作，然后转换为 C/C++。

+   基于异常的错误处理。

+   强大的内省功能。

+   丰富的文档和软件社区。

Python 可以被视为一种粘合语言。使用 Python，可以开发更好的应用程序，因为不同类型的编码人员可以共同在一个项目上工作。例如，在构建科学应用程序时，C/C++程序员可以实现高效的数值算法，而在同一项目上的科学家可以编写测试和使用这些算法的 Python 程序。科学家不必学习低级编程语言，C/C++程序员也不需要理解所涉及的科学。

您可以从[`www.python.org/doc/essays/omg-darpa-mcc-position`](https://www.python.org/doc/essays/omg-darpa-mcc-position)了解更多信息。

让我们看一些非常基本的代码示例，以了解 Python 的特点。

以下部分对大多数人来说可能是复习内容。我们将在第二章 *基于线程的并行性*和第三章 *基于进程的并行性*中实际使用这些技术。

# 帮助函数

Python 解释器已经提供了有效的帮助系统。如果要了解如何使用对象，只需键入`help(object)`。

例如，让我们看看如何在整数`0`上使用`help`函数：

```py
>>> help(0)
Help on int object:

class int(object)
 | int(x=0) -> integer
 | int(x, base=10) -> integer
 | 
 | Convert a number or string to an integer, or return 0 if no 
 | arguments are given. If x is a number, return x.__int__(). For 
 | floating point numbers, this truncates towards zero.
 | 
 | If x is not a number or if base is given, then x must be a string,
 | bytes, or bytearray instance representing an integer literal in the
 | given base. The literal can be preceded by '+' or '-' and be
 | surrounded by whitespace. The base defaults to 10\. Valid bases are 0 
 | and 2-36.
 | Base 0 means to interpret the base from the string as an integer 
 | literal.
>>> int('0b100', base=0)
```

`int`对象的描述后面是适用于它的方法列表。前五个方法如下：

```py
 | Methods defined here:
 | 
 | __abs__(self, /)
 | abs(self)
 | 
 | __add__(self, value, /)
 | Return self+value.
 | 
 | __and__(self, value, /)
 | Return self&value.
 | 
 | __bool__(self, /)
 | self != 0
 | 
 | __ceil__(...)
 | Ceiling of an Integral returns itself.
```

`dir(object)`也很有用，它列出了对象可用的方法：

```py
>>> dir(float)
['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', '__floor__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__index__', '__init__', '__int__', '__invert__', '__le__', '__lshift__', '__lt__', '__mod__', '__mul__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__pow__', '__radd__', '__rand__', '__rdivmod__', '__reduce__', '__reduce_ex__', '__repr__', '__rfloordiv__', '__rlshift__', '__rmod__', '__rmul__', '__ror__', '__round__', '__rpow__', '__rrshift__', '__rshift__', '__rsub__', '__rtruediv__', '__rxor__', '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes']
```

最后，对象的相关文档由`.__doc__`函数提供，如下例所示：

```py
>>> abs.__doc__
'Return the absolute value of the argument.'
```

# 语法

Python 不采用语句终止符，并且代码块通过缩进指定。期望缩进级别的语句必须以冒号（`:`）结尾。这导致以下结果：

+   Python 代码更清晰、更易读。

+   程序结构始终与缩进的结构相一致。

+   缩进风格在任何列表中都是统一的。

错误的缩进可能导致错误。

以下示例显示如何使用`if`结构：

```py
print("first print")
if condition:
 print(“second print”)
print(“third print”)
```

在这个例子中，我们可以看到以下内容：

+   以下语句：`print("first print")`，`if condition:`，`print("third print")`具有相同的缩进级别，并且始终被执行。

+   在`if`语句之后，有一个缩进级别更高的代码块，其中包括`print ("second print")`语句。

+   如果`if`的条件为真，则执行`print ("second print")`语句。

+   如果`if`的条件为假，则不执行`print ("second print")`语句。

因此，非常重要的是要注意缩进，因为它始终在程序解析过程中进行评估。

# 注释

注释以井号（`#`）开头，位于单独一行上：

```py
# single line comment
```

多行字符串用于多行注释：

```py
""" first line of a multi-line comment
second line of a multi-line comment."""
```

# 赋值

赋值使用等号（`=`）进行。对于相等性测试，使用相同数量的（`==`）。您可以使用`+=`和`-=`运算符增加和减少值，后跟一个附录。这适用于许多类型的数据，包括字符串。您可以在同一行上分配和使用多个变量。

一些示例如下：

```py
>>> variable = 3
>>> variable += 2
>>> variable
5
>>> variable -= 1
>>> variable
4

>>> _string_ = "Hello"
>>> _string_ += " Parallel Programming CookBook Second Edition!"
>>> print (_string_) 
Hello Parallel Programming CookBook Second Edition!
```

# 数据类型

Python 中最重要的结构是*列表*、*元组*和*字典*。自 Python 2.5 版本以来，集合已经集成到 Python 中（之前的版本可在`sets`库中找到）：

+   **列表**：这些类似于一维数组，但您可以创建包含其他列表的列表。

+   **字典**：这些是包含键对和值（哈希表）的数组。

+   **元组**：这些是不可变的单维对象。

数组可以是任何类型，因此可以将诸如整数和字符串之类的变量混合到列表、字典和元组中。

任何类型的数组中第一个对象的索引始终为零。允许负索引，并且从数组末尾计数；`-1`表示数组的最后一个元素：

```py
#let's play with lists
list_1 = [1, ["item_1", "item_1"], ("a", "tuple")]
list_2 = ["item_1", -10000, 5.01]

>>> list_1
[1, ['item_1', 'item_1'], ('a', 'tuple')]

>>> list_2
['item_1', -10000, 5.01]

>>> list_1[2]
('a', 'tuple')

>>>list_1[1][0]
['item_1', 'item_1']

>>> list_2[0]
item_1

>>> list_2[-1]
5.01

#build a dictionary 
dictionary = {"Key 1": "item A", "Key 2": "item B", 3: 1000}
>>> dictionary 
{'Key 1': 'item A', 'Key 2': 'item B', 3: 1000} 

>>> dictionary["Key 1"] 
item A

>>> dictionary["Key 2"]
-1

>>> dictionary[3]
1000
```

您可以使用冒号（`:`）获取数组范围：

```py
list_3 = ["Hello", "Ruvika", "how" , "are" , "you?"] 
>>> list_3[0:6] 
['Hello', 'Ruvika', 'how', 'are', 'you?'] 

>>> list_3[0:1]
['Hello']

>>> list_3[2:6]
['how', 'are', 'you?']
```

# 字符串

Python 字符串使用单引号（`'`）或双引号（`"`）标示，并且允许在字符串中使用另一种标示：

```py
>>> example = "she loves ' giancarlo"
>>> example
"she loves ' giancarlo"
```

在多行上，它们用三个（或三个单）引号括起来（`'''`多行字符串`'''`）：

```py
>>> _string_='''I am a 
multi-line 
string'''
>>> _string_
'I am a \nmulti-line\nstring'
```

Python 还支持 Unicode；只需使用`u "This is a unicode string"`语法：

```py
>>> ustring = u"I am unicode string"
>>> ustring
'I am unicode string'
```

要在字符串中输入值，请键入`%`运算符和一个元组。然后，每个`%`运算符将从左到右替换为元组元素*：*

```py
>>> print ("My name is %s !" % ('Mr. Wolf'))
My name is Mr. Wolf!
```

# 流程控制

流程控制指令是`if`、`for`和`while`。

在下一个示例中，我们检查数字是正数、负数还是零，并显示结果：

```py
num = 1

if num > 0:
 print("Positive number")
elif num == 0:
 print("Zero")
else:
 print("Negative number")
```

以下代码块使用`for`循环找到存储在列表中的所有数字的总和：

```py
numbers = [6, 6, 3, 8, -3, 2, 5, 44, 12]
sum = 0
for val in numbers:
 sum = sum+val
print("The sum is", sum)
```

我们将执行`while`循环来迭代代码，直到条件结果为真。我们将使用这个循环来代替`for`循环，因为我们不知道会导致代码的迭代次数。在这个例子中，我们使用`while`来添加自然数，直到*sum = 1+2+3+...+n*：

```py
n = 10
# initialize sum and counter
sum = 0
i = 1
while i <= n:
 sum = sum + i
 i = i+1 # update counter

# print the sum
print("The sum is", sum)
```

前三个示例的输出如下：

```py
Positive number
The sum is 83
The sum is 55
>>>
```

# 函数

Python 函数使用`def`关键字声明：

```py
def my_function():
 print("this is a function")
```

要运行一个函数，使用函数名，后跟括号，如下所示：

```py
>>> my_function()
this is a function
```

参数必须在函数名后面的括号内指定：

```py
def my_function(x):
 print(x * 1234)

>>> my_function(7)
8638
```

多个参数必须用逗号分隔：

```py
def my_function(x,y):
 print(x*5+ 2*y)

>>> my_function(7,9)
53
```

使用等号来定义默认参数。如果没有参数调用函数，则将使用默认值：

```py
def my_function(x,y=10):
 print(x*5+ 2*y)

>>> my_function(1)
25

>>> my_function(1,100)
205
```

函数的参数可以是任何类型的数据（如字符串、数字、列表和字典）。在这里，以下列表`lcities`被用作`my_function`的参数：

```py
def my_function(cities):
 for x in cities:
 print(x)

>>> lcities=["Napoli","Mumbai","Amsterdam"]
>>> my_function(lcities)
Napoli
Mumbai
Amsterdam
```

使用`return`语句从函数中返回一个值：

```py
def my_function(x,y):
 return x*y >>> my_function(6,29)  174 
```

Python 支持一种有趣的语法，允许您在需要定义小型单行函数的地方定义它们。这些 lambda 函数源自 Lisp 编程语言。

lambda 函数的一个示例，`functionvar`，如下所示：

```py
# lambda definition equivalent to def f(x): return x + 1

functionvar = lambda x: x * 5
>>> print(functionvar(10))
50
```

# 类

Python 支持类的多重继承。按照惯例（而不是语言规则），私有变量和方法以两个下划线（`__`）开头声明。我们可以给类的实例分配任意属性（属性），如下例所示：

```py
class FirstClass:
 common_value = 10
 def __init__ (self):
 self.my_value = 100
 def my_func (self, arg1, arg2):
 return self.my_value*arg1*arg2

# Build a first instance
>>> first_instance = FirstClass()
>>> first_instance.my_func(1, 2)
200

# Build a second instance of FirstClass
>>> second_instance = FirstClass()

#check the common values for both the instances
>>> first_instance.common_value
10

>>> second_instance.common_value
10

#Change common_value for the first_instance
>>> first_instance.common_value = 1500
>>> first_instance.common_value
1500

#As you can note the common_value for second_instance is not changed
>>> second_instance.common_value
10

# SecondClass inherits from FirstClass. 
# multiple inheritance is declared as follows:
# class SecondClass (FirstClass1, FirstClass2, FirstClassN)

class SecondClass (FirstClass):
 # The "self" argument is passed automatically
 # and refers to the class's instance
 def __init__ (self, arg1):
 self.my_value = 764
 print (arg1)

>>> first_instance = SecondClass ("hello PACKT!!!!")
hello PACKT!!!!

>>> first_instance.my_func (1, 2)
1528
```

# 异常

Python 中的异常使用`try-except`块（`exception_name`）进行管理：

```py
def one_function():
 try:
 # Division by zero causes one exception
 10/0
 except ZeroDivisionError:
 print("Oops, error.")
 else:
 # There was no exception, we can continue.
 pass
 finally:
 # This code is executed when the block
 # try..except is already executed and all exceptions
 # have been managed, even if a new one occurs
 # exception directly in the block.
 print("We finished.")

>>> one_function()
Oops, error.
We finished
```

# 导入库

外部库使用`import [library name]`导入。或者，您可以使用`from [library name] import [function name]`语法导入特定函数。这是一个例子：

```py
import random
randomint = random.randint(1, 101)

>>> print(randomint)
65

from random import randint
randomint = random.randint(1, 102)

>>> print(randomint)
46
```

# 管理文件

为了让我们能够与文件系统交互，Python 提供了内置的`open`函数。可以调用此函数来打开文件并返回一个文件对象。后者允许我们对文件执行各种操作，如读取和写入。当我们完成与文件的交互时，最后必须记得使用`file.close`方法关闭它：

```py
>>> f = open ('test.txt', 'w') # open the file for writing
>>> f.write ('first line of file \ n') # write a line in file
>>> f.write ('second line of file \ n') # write another line in file
>>> f.close () # we close the file
>>> f = open ('test.txt') # reopen the file for reading
>>> content = f.read () # read all the contents of the file
>>> print (content)
first line of the file
second line of the file
>>> f.close () # close the file
```

# 列表推导

列表推导是创建和操作列表的强大工具。它们由一个表达式后跟一个`for`子句，然后后跟零个或多个`if`子句。列表推导的语法非常简单：

```py
[expression for item in list]
```

然后，执行以下操作：

```py
#list comprehensions using strings
>>> list_comprehension_1 = [ x for x in 'python parallel programming cookbook!' ]
>>> print( list_comprehension_1)

['p', 'y', 't', 'h', 'o', 'n', ' ', 'p', 'a', 'r', 'a', 'l', 'l', 'e', 'l', ' ', 'p', 'r', 'o', 'g', 'r', 'a', 'm', 'm', 'i', 'n', 'g', ' ', 'c', 'o', 'o', 'k', 'b', 'o', 'o', 'k', '!']

#list comprehensions using numbers
>>> l1 = [1,2,3,4,5,6,7,8,9,10]
>>> list_comprehension_2 = [ x*10 for x in l1 ]
>>> print( list_comprehension_2)

[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
```

# 运行 Python 脚本

要执行 Python 脚本，只需调用 Python 解释器，然后是脚本名称，即`my_pythonscript.py`。或者，如果我们在不同的工作目录中，则使用其完整地址：

```py
> python my_pythonscript.py 
```

从现在开始，对于每次调用 Python 脚本，我们将使用前面的表示法；即`python`，后跟`script_name.py`，假设启动 Python 解释器的目录是脚本所在的目录。

# 使用 pip 安装 Python 包

`pip`是一个工具，允许我们搜索、下载和安装 Python 包，这些包可以在 Python 包索引中找到，该索引是一个包含数以万计用 Python 编写的包的存储库。这也允许我们管理已经下载的包，允许我们更新或删除它们。

# 安装 pip

`pip`已经包含在 Python 版本≥3.4 和≥2.7.9 中。要检查是否已经安装了这个工具，我们可以运行以下命令：

```py
C:\>pip
```

如果`pip`已经安装，则此命令将显示已安装的版本。

# 更新 pip

还建议检查您使用的`pip`版本是否始终保持最新。要更新它，我们可以使用以下命令：

```py
 C:\>pip install -U pip
```

# 使用 pip

`pip`支持一系列命令，允许我们*搜索、下载、安装、更新*和*删除*软件包，等等。

要安装`PACKAGE`，只需运行以下命令：

```py
C:\>pip install PACKAGE 
```

# 介绍 Python 并行编程

Python 提供了许多库和框架，可以促进高性能计算。但是由于**全局解释器锁**（**GIL**），使用 Python 进行并行编程可能会非常隐匿。

事实上，最广泛和广泛使用的 Python 解释器**CPython**是用 C 编程语言开发的。 CPython 解释器需要 GIL 来进行线程安全操作。使用 GIL 意味着当您尝试访问线程中包含的任何 Python 对象时，您将遇到全局锁。一次只有一个线程可以获取 Python 对象或 C API 的锁。

幸运的是，情况并不那么严重，因为在 GIL 的领域之外，我们可以自由地使用并行性。这包括我们将在接下来的章节中讨论的所有主题，包括多进程、分布式计算和 GPU 计算。

因此，Python 实际上并不是多线程的。但是什么是线程？什么是进程？在接下来的章节中，我们将介绍这两个基本概念以及 Python 编程语言如何处理它们。

# 进程和线程

*线程*可以与轻量级进程进行比较，因为它们提供了类似进程的优势，但是不需要进程的典型通信技术。线程允许将程序的主控制流分成多个并发运行的控制流。相比之下，进程有它们自己的*地址空间*和自己的资源。这意味着在不同进程上运行的代码部分之间的通信只能通过适当的管理机制进行，包括管道、代码 FIFO、邮箱、共享内存区域和消息传递。另一方面，线程允许创建程序的并发部分，其中每个部分都可以访问相同的地址空间、变量和常量。

以下表格总结了线程和进程之间的主要区别：

| **线程** | **进程** |
| --- | --- |
| 共享内存。 | 不共享内存。 |
| 启动/更改 计算成本较低。 | 启动/更改 计算成本较高。 |
| 需要更少的资源（轻量级进程）。 | 需要更多的计算资源。 |
| 需要同步机制来正确处理数据。 | 不需要内存同步。 |

在这个简短的介绍之后，我们终于可以展示进程和线程是如何运行的。

特别是，我们想比较以下函数`do_something`的串行、多线程和多进程执行时间，该函数执行一些基本计算，包括随机选择整数的列表（一个`do_something.py`文件）：

```py
import random

def do_something(count, out_list):
 for i in range(count):
 out_list.append(random.random())
```

接下来是串行（`serial_test.py`）实现。让我们从相关的导入开始：

```py
from do_something import *
import time 
```

请注意导入时间模块，该模块将用于评估执行时间，在本例中，以及`do_something`函数的串行实现。要构建的列表的`size`等于`10000000`，而`do_something`函数将执行`10`次：

```py
if __name__ == "__main__":
 start_time = time.time()
 size = 10000000 
 n_exec = 10
 for i in range(0, exec):
 out_list = list()
 do_something(size, out_list)

 print ("List processing complete.")
 end_time = time.time()
 print("serial time=", end_time - start_time) 
```

接下来，我们有多线程实现（`multithreading_test.py`）。

导入相关库：

```py
from do_something import *
import time
import threading
```

请注意导入`threading`模块，以便使用 Python 的多线程功能。

在这里，有`do_something`函数的多线程执行。我们不会对以下代码中的指令进行深入评论，因为它们将在第二章中更详细地讨论，*基于线程的并行性*。

然而，在这种情况下，也应该注意到，列表的长度显然与串行情况下的长度相同，`size = 10000000`，而定义的线程数为 10，`threads = 10`，这也是必须执行`do_something`函数的次数：

```py
if __name__ == "__main__":
 start_time = time.time()
 size = 10000000
 threads = 10 
 jobs = []
 for i in range(0, threads):
```

还要注意通过`threading.Thread`方法构建单个线程：

```py
out_list = list()
thread = threading.Thread(target=list_append(size,out_list))
jobs.append(thread)
```

我们开始执行线程然后立即停止它们的循环顺序如下：

```py
 for j in jobs:
 j.start()
 for j in jobs:
 j.join()

 print ("List processing complete.")
 end_time = time.time()
 print("multithreading time=", end_time - start_time)
```

最后，有多进程实现（`multiprocessing_test.py`）。

我们首先导入必要的模块，特别是`multiprocessing`库，其特性将在第三章中深入解释，*基于进程的并行*：

```py
from do_something import *
import time
import multiprocessing
```

与先前情况一样，要构建的列表长度，大小和`do_something`函数的执行次数保持不变（`procs = 10`）：

```py
if __name__ == "__main__":
 start_time = time.time()
 size = 10000000 
 procs = 10 
 jobs = []
 for i in range(0, procs):
 out_list = list()
```

在这里，通过`multiprocessing.Process`方法调用单个进程的实现受到如下影响：

```py
 process = multiprocessing.Process\
 (target=do_something,args=(size,out_list))
 jobs.append(process)
```

接下来，我们开始执行进程然后立即停止它们的循环顺序如下执行：

```py
 for j in jobs:
 j.start()

 for j in jobs:
 j.join()

 print ("List processing complete.")
 end_time = time.time()
 print("multiprocesses time=", end_time - start_time)
```

然后，我们打开命令行并运行先前描述的三个函数。

转到已复制函数的文件夹，然后输入以下内容：

```py
> python serial_test.py
```

结果是在具有以下特征的机器上获得的 - CPU Intel i7 / 8 GB RAM，如下所示：

```py
List processing complete.
serial time= 25.428767204284668
```

在`multithreading`实现的情况下，我们有以下情况：

```py
> python multithreading_test.py
```

输出如下：

```py
List processing complete.
multithreading time= 26.168917179107666
```

最后，有**多进程**实现：

```py
> python multiprocessing_test.py
```

其结果如下：

```py
List processing complete.
multiprocesses time= 18.929869890213013
```

可以看到，串行实现的结果（即使用`serial_test.py`）与使用多线程实现的结果类似（使用`multithreading_test.py`），在这种情况下，线程基本上是一个接一个地启动，优先考虑一个而不是另一个，直到结束，而使用 Python 多进程能力在执行时间方面有益（使用`multiprocessing_test.py`）。
