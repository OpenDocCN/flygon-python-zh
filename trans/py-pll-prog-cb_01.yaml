- en: Getting Started with Parallel Computing and Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始并行计算和Python
- en: The *parallel* and *distributed computing* models are based on the simultaneous
    use of different processing units for program execution. Although the distinction
    between parallel and distributed computing is very thin, one of the possible definitions
    associates the parallel calculation model with the shared memory calculation model,
    and the distributed calculation model with the message passing model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*并行*和*分布式计算*模型基于同时使用不同处理单元进行程序执行。尽管并行和分布式计算之间的区别非常微弱，但可能的定义之一将并行计算模型与共享内存计算模型相关联，将分布式计算模型与消息传递模型相关联。'
- en: From this point onward, we will use the term *parallel computing* to refer to
    both parallel and distributed calculation models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点开始，我们将使用术语*并行计算*来指代并行和分布式计算模型。
- en: The next sections provide an overview of parallel programming architectures
    and programming models. These concepts are useful for inexperienced programmers
    who are approaching parallel programming techniques for the first time. Moreover,
    it can be a basic reference for experienced programmers. The dual characterization
    of parallel systems is also presented. The first characterization is based on
    the system architecture, while the second characterization is based on parallel
    programming paradigms.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将概述并行编程体系结构和编程模型。这些概念对于初学者来说是有用的，他们第一次接触并行编程技术。此外，它也可以成为有经验的程序员的基本参考。还介绍了并行系统的双重特征。第一种特征基于系统架构，而第二种特征基于并行编程范式。
- en: The chapter ends with a brief introduction to the Pythonprogramming language.
    The characteristics of the language, ease of use and learning, and the extensibility
    and richness of software libraries and applications make Python a valuable tool
    for any application, and also for parallel computing. The concepts of threads
    and processes are introduced in relation to their use in the language.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以对Python编程语言的简要介绍结束。语言的特点、易用性和学习性，以及软件库和应用程序的可扩展性和丰富性，使Python成为任何应用的有价值工具，也适用于并行计算。介绍了线程和进程的概念，以及它们在语言中的使用。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Why do we need parallel computing?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么我们需要并行计算？
- en: Flynn's taxonomy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弗林的分类
- en: Memory organization
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存组织
- en: Parallel programming models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行编程模型
- en: Evaluating performance
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能评估
- en: Introducing Python
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Python
- en: Python and parallel programming
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python和并行编程
- en: Introducing processes and threads
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍进程和线程
- en: Why do we need parallel computing?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们需要并行计算？
- en: The growth in computing power made available by modern computers has resulted
    in us facing computational problems of increasing complexity in relatively short
    time frames. Until the early 2000s, complexity was dealt with by increasing the
    number of transistors as well as the clock frequency of single-processor systems,
    which reached peaks of 3.5-4 GHz. However, the increase in the number of transistors
    causes the exponential increase of the power dissipated by the processors themselves.
    In essence, there is, therefore, a physical limitation that prevents further improvement
    in the performance of single-processor systems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现代计算机提供的计算能力增长导致我们在相对较短的时间内面临着日益复杂的计算问题。直到21世纪初，复杂性是通过增加晶体管数量以及单处理器系统的时钟频率来处理的，达到了3.5-4
    GHz的峰值。然而，晶体管数量的增加导致了处理器本身耗散功率的指数增长。实质上，因此存在着一个物理限制，阻止了单处理器系统性能的进一步提高。
- en: For this reason, in recent years, microprocessor manufacturers have focused
    their attention on *multi-core* systems. These are based on a core of several
    physical processors that share the same memory, thus bypassing the problem of
    dissipated power described earlier. In recent years, *quad-core* and *octa-core*
    systems have also become standard on normal desktop and laptop configurations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，近年来，微处理器制造商已经将注意力集中在*多核*系统上。这些系统基于多个物理处理器的核心，它们共享相同的内存，从而绕过了之前描述的功耗问题。近年来，*四核*和*八核*系统也已成为普通台式机和笔记本配置的标准。
- en: On the other hand, such a significant change in hardware has also resulted in
    an evolution of software structure, which has always been designed to be executed
    sequentially on a single processor. To take advantage of the greater computational
    resources made available by increasing the number of processors, the existing
    software must be redesigned in a form appropriate to the parallel structure of
    the CPU, so as to obtain greater efficiency through the simultaneous execution
    of the single units of several parts of the same program.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，硬件上的如此重大变化也导致了软件结构的演变，这些软件一直被设计为在单个处理器上顺序执行。为了利用通过增加处理器数量提供的更多计算资源，现有软件必须以适合CPU并行结构的形式进行重新设计，以便通过同时执行同一程序的多个部分的单元来获得更高的效率。
- en: Flynn's taxonomy
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弗林的分类
- en: 'Flynn''s taxonomy is a system for classifying computer architectures. It is
    based on two main concepts:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 弗林的分类是一种用于分类计算机体系结构的系统。它基于两个主要概念：
- en: '**Instruction flow**: A system with *n* CPU has *n* program counters and, therefore, *n *instructions
    flows. This corresponds to a program counter.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指令流：具有*n*个CPU的系统具有*n*个程序计数器，因此有*n*个指令流。这对应于一个程序计数器。
- en: '**Data flow**: A program that calculates a function on a list of data has a
    data flow. The program that calculates the same function on several different
    lists of data has more data flows. This is made up of a set of operands.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据流**：计算数据列表上的函数的程序具有数据流。计算相同函数在几个不同数据列表上的程序具有更多的数据流。这由一组操作数组成。'
- en: 'As the instruction and data flows are independent, there are four categories
    of parallel machines: **Single Instruction Single Data** (**SISD**), **Single
    Instruction Multiple Data** (**SIMD**), **Multiple Instruction Single Data** (**MISD**),
    and **Multiple Instruction Multiple Data** (**MIMD**):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于指令和数据流是独立的，存在四类并行机器：**单指令单数据**（**SISD**）、**单指令多数据**（**SIMD**）、**多指令单数据**（**MISD**）和**多指令多数据**（**MIMD**）：
- en: '![](assets/315c390f-4c31-4a69-811e-5696dff064d1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/315c390f-4c31-4a69-811e-5696dff064d1.png)'
- en: Flynn's taxonomy
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 弗林分类法
- en: Single Instruction Single Data (SISD)
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单指令单数据（SISD）
- en: The SISD computing system is like the von Neumann machine, which is a uniprocessor
    machine. As you can see in *Flynn's taxonomy* diagram, it executes a single instruction
    that operates on a single data stream. In SISD, machine instructions are processed
    sequentially.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SISD计算系统类似于冯·诺伊曼机，即单处理器机器。如*弗林分类法*图所示，它执行单个指令，作用于单个数据流。在SISD中，机器指令是按顺序处理的。
- en: 'In a clock cycle, the CPU executes the following operations:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个时钟周期内，CPU执行以下操作：
- en: '**Fetch**: The CPU fetches the data and instructions from a memory area, which
    is called a *register*.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**取指**：CPU从内存区域获取数据和指令，称为*寄存器*。'
- en: '**Decode**: The CPU decodes the instructions.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码**：CPU解码指令。'
- en: '**Execute**: The instruction is carried out on the data. The result of the
    operation is stored in another register.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行**：指令在数据上执行。操作的结果存储在另一个寄存器中。'
- en: 'Once the execution stage is complete, the CPU sets itself to begin another
    CPU cycle:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 执行阶段完成后，CPU开始另一个CPU周期：
- en: '![](assets/8d131bb3-cd52-4f51-969c-8c836a394f89.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/8d131bb3-cd52-4f51-969c-8c836a394f89.png)'
- en: The fetch, decode, and execute cycle
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 取指、解码和执行周期
- en: The algorithms that run on this type of computer are sequential (or serial)
    since they do not contain any parallelism. An example of a SISD computer is a
    hardware system with a single CPU.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种类型的计算机上运行的算法是顺序的，因为它们不包含任何并行性。SISD计算机的一个例子是具有单个CPU的硬件系统。
- en: 'The main elements of these architectures (namely, von Neumann architectures)
    are as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构的主要元素（即冯·诺伊曼架构）如下：
- en: '**Central memory unit**: This is used to store both instructions and program
    data.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中央存储器单元**：用于存储指令和程序数据。'
- en: '**CPU**: This is used to get the instruction and/or data from the memory unit,
    which decodes the instructions and sequentially implements them.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPU**：用于从存储器单元获取指令和/或数据，解码指令并按顺序执行。'
- en: '**The I/O system**: This refers to the input and output data of the program.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**I/O系统**：这指的是程序的输入和输出数据。'
- en: 'Conventional single-processor computers are classified as SISD systems:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的单处理器计算机被归类为SISD系统：
- en: '![](assets/1a6b6929-c4c4-41bb-96ae-2ec6b2aea55d.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/1a6b6929-c4c4-41bb-96ae-2ec6b2aea55d.png)'
- en: The SISD architecture schema
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: SISD架构图
- en: 'The following diagram specifically shows which areas of a CPU are used in the
    stages of fetch, decode, and execute:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表具体显示了CPU在取指、解码和执行阶段中使用的区域：
- en: '![](assets/9ceec645-0aa1-4c90-97a7-cba9f8eb5031.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/9ceec645-0aa1-4c90-97a7-cba9f8eb5031.png)'
- en: CPU components in the fetch-decode-execute phase
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: CPU在取指-解码-执行阶段的组件
- en: Multiple Instruction Single Data (MISD)
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多指令单数据（MISD）
- en: In this model, *n* processors, each with their own control unit, share a single
    memory unit. In each clock cycle, the data received from the memory is processed
    by all processors simultaneously, each in accordance with the instructions received
    from its control unit.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种模型中，*n*个处理器，每个都有自己的控制单元，共享一个单一的存储单元。在每个时钟周期中，从存储器接收的数据由所有处理器同时处理，每个处理器根据从其控制单元接收的指令进行处理。
- en: In this case, the parallelism (instruction-level parallelism) is obtained by
    performing several operations on the same piece of data. The types of problems
    that can be solved efficiently in these architectures are rather special, such
    as data encryption. For this reason, the MISD computer has not foundspace in the
    commercial sector. MISD computers are more of an intellectual exercise than a
    practical configuration.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，通过对同一数据执行多个操作来获得并行性（指令级并行性）。这些架构可以有效解决的问题类型相当特殊，例如数据加密。因此，MISD计算机在商业领域没有找到位置。MISD计算机更多地是一种智力锻炼，而不是一种实际的配置。
- en: Single Instruction Multiple Data (SIMD)
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单指令多数据（SIMD）
- en: A SIMD computer consists of *n* identical processors, each with their own local
    memory, where it is possible to store data. All processors work under the control
    of a single instruction stream. In addition to this, there are *n* data streams,
    one for each processor. The processors work simultaneously on each step and execute
    the same instructions, but on different data elements. This is an example of data-level
    parallelism.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: SIMD计算机由*n*个相同的处理器组成，每个处理器都有自己的本地存储器，可以在其中存储数据。所有处理器都在单一指令流的控制下工作。此外，还有*n*个数据流，每个处理器对应一个数据流。处理器同时在每个步骤上执行并执行相同的指令，但对不同的数据元素进行操作。这是数据级并行性的一个例子。
- en: The SIMD architectures are much more versatile than MISD architectures. Numerous
    problems covering a wide range of applications can be solved by parallel algorithms
    on SIMD computers. Another interesting feature is that the algorithms for these
    computers are relatively easy to design, analyze, and implement. The limitation
    is that only the problems that can be divided into a number of subproblems (which
    are all identical, each of which will then be solved simultaneously through the
    same set of instructions) can be addressed with the SIMD computer.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: SIMD架构比MISD架构更加灵活。并行算法可以解决涵盖广泛应用领域的许多问题。另一个有趣的特点是，这些计算机的算法相对容易设计、分析和实现。限制在于只有能够分解为多个子问题（这些子问题都是相同的，然后通过相同的指令集同时解决）的问题才能用SIMD计算机解决。
- en: With the supercomputer developed according to this paradigm, we must mention
    the *Connection Machine* (Thinking Machine,1985) and *MPP* (NASA, 1983).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这一范式开发的超级计算机，我们必须提到*Connection Machine*（Thinking Machine,1985）和*MPP*（NASA,
    1983）。
- en: As we will see in [Chapter 6](1ea5f8e3-bc1e-4d48-8ffe-d96ed8d56259.xhtml), *Distributed
    Python*, and [Chapter 7](c043f263-c2f1-40ce-a390-c0999635225c.xhtml), *Cloud Computing*,
    the advent of modern graphics cards (GPUs), built with many SIMD-embedded units,
    has led to the more widespread use of this computational paradigm.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在[第6章](1ea5f8e3-bc1e-4d48-8ffe-d96ed8d56259.xhtml)中看到的，*分布式Python*，以及[第7章](c043f263-c2f1-40ce-a390-c0999635225c.xhtml)中看到的，*云计算*，现代图形卡（GPU）的出现，内置了许多SIMD嵌入单元，导致了这种计算范式的更广泛使用。
- en: Multiple Instruction Multiple Data (MIMD)
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多指令多数据（MIMD）
- en: This class of parallel computers is the most general and most powerful class,
    according to Flynn's classification. This contains *n* processors, *n* instruction
    streams, and *n* data streams. Each processor has its own control unit and local
    memory, which makes MIMD architectures more computationally powerful than SIMD
    architectures.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 根据弗林的分类，这类并行计算机是最一般和最强大的类。这包括*n*个处理器，*n*个指令流和*n*个数据流。每个处理器都有自己的控制单元和本地内存，这使得MIMD架构比SIMD架构更具计算能力。
- en: Each processor operates under the control of a flow of instructions issued by
    its own control unit. Therefore, the processors can potentially run different
    programs with different data, which allows them to solve subproblems that are
    different and can be a part of a single larger problem. In MIMD, the architecture
    is achieved with the help of the parallelism level with threads and/or processes.
    This also means that the processors usually operate asynchronously.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个处理器都在其自己的控制单元发出的指令流的控制下运行。因此，处理器可以潜在地运行不同的程序和不同的数据，这使它们能够解决不同的子问题，并且可以成为单个更大问题的一部分。在MIMD中，架构是通过线程和/或进程的并行级别实现的。这也意味着处理器通常是异步操作的。
- en: 'Nowadays, this architecture is applied to many PCs, supercomputers, and computer
    networks. However, there is a counter that you need to consider: asynchronous
    algorithms are difficult to design, analyze, and implement:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，这种架构应用于许多个人电脑、超级计算机和计算机网络。然而，您需要考虑的一个反面是：异步算法难以设计、分析和实现：
- en: '![](assets/f3fa5a98-1a89-4d76-a8af-c25a376c1ac8.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f3fa5a98-1a89-4d76-a8af-c25a376c1ac8.png)'
- en: The SIMD architecture (A) and the MIMD architecture (B)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: SIMD架构（A）和MIMD架构（B）
- en: 'Flynn''s taxonomy can be extended by considering that SIMD machines can be
    divided into two subgroups:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑SIMD机器可以分为两个子组：
- en: Numerical supercomputers
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值超级计算机
- en: Vectorial machines
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矢量机器
- en: On the other hand, MIMD can be divided into machines that have a shared memoryand
    those that have a distributed memory.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，MIMD可以分为具有共享内存和具有分布式内存的机器。
- en: Indeed the next section focuses on this last aspect of the organization of the
    memory of MIMD machines.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，下一节着重讨论MIMD机器内存组织的最后一个方面。
- en: Memory organization
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存组织
- en: Another aspect that we need to consider in order to evaluate parallel architectures
    is memory organization, or rather, the way in which data is accessed. No matter
    how fast the processing unit is, if memory cannot maintain and provide instructions
    and data at a sufficient speed, then there will be no improvement in performance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要考虑的另一个方面是评估并行架构的内存组织，或者说，数据访问的方式。无论处理单元有多快，如果内存不能以足够的速度维护和提供指令和数据，那么性能就不会有所改善。
- en: The main problem that we need to overcome to make the response time of memory
    compatible with the speed of the processor is the memory cycle time, which is
    defined as the time that has elapsed between two successive operations. The cycle
    time of the processor is typically much shorter than the cycle time of memory.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要克服的主要问题是使内存的响应时间与处理器的速度兼容，这是内存周期时间，即两次连续操作之间经过的时间。处理器的周期时间通常比内存的周期时间短得多。
- en: 'When a processor initiates a transfer to or from memory, the processor''s resources
    will remain occupied for the entire duration of the memory cycle; furthermore,
    during this period, no other device (for example, I/O controller, processor, or
    even the processor that made the request) will be able to use the memory due to
    the transfer in progress:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理器启动对内存的传输时，处理器的资源将在整个内存周期内保持占用；此外，在此期间，由于正在进行传输，没有其他设备（例如I/O控制器、处理器，甚至发出请求的处理器）能够使用内存：
- en: '![](assets/d56ae362-cff1-4d47-97aa-78419437b2b7.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d56ae362-cff1-4d47-97aa-78419437b2b7.png)'
- en: Memory organization in the MIMD architecture
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: MIMD架构中的内存组织
- en: Solutions to the problem of memory access have resulted in a dichotomy of MIMD
    architectures. The first type of system, known as the *shared memory* system,
    has high virtual memory and all processors have equal access to data and instructions
    in this memory. The other type of system is the ***distributed memory*** model,
    wherein each processor has local memory that is not accessible to other processors.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 解决内存访问问题导致了MIMD架构的二分法。第一种系统称为*共享内存*系统，具有高虚拟内存，并且所有处理器都可以平等访问该内存中的数据和指令。另一种系统是***分布式内存***模型，其中每个处理器都有本地内存，其他处理器无法访问。
- en: What distinguishes memory shared by distributed memory is the management of
    memory access, which is performed by the processing unit; this distinction is
    very important for programmers because it determines how different parts of a
    parallel program must communicate.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存共享的区别在于内存访问的管理，由处理单元执行；这一区别对程序员来说非常重要，因为它决定了并行程序的不同部分如何进行通信。
- en: In particular, a distributed memory machine must make copies of shared data
    in each local memory. These copies are created by sending a message containing
    the data to be shared from one processor to another. A drawback of this memory
    organization is that, sometimes, these messages can be very large and take a relatively
    long time to transfer, while in a shared memory system, there is no exchange of
    messages, and the main problem lies in synchronizing access to shared resources.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，分布式内存机器必须在每个本地内存中制作共享数据的副本。这些副本是通过将包含要共享的数据的消息从一个处理器发送到另一个处理器来创建的。这种内存组织的一个缺点是，有时这些消息可能非常大并且需要相对长的时间来传输，而在共享内存系统中，没有消息交换，主要问题在于同步对共享资源的访问。
- en: Shared memory
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享内存
- en: 'The schema of a shared memory multiprocessor system is shown in the following
    diagram. The physical connections here are quite simple:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 共享内存多处理器系统的架构如下图所示。这里的物理连接非常简单。
- en: '![](assets/0f53e868-04c0-4493-9b33-f9be28089ca2.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/0f53e868-04c0-4493-9b33-f9be28089ca2.png)'
- en: Shared memory architecture schema
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 共享内存架构图
- en: Here, the bus structure allows an arbitrary number of devices (**CPU** + **C****ache**
    in the preceding diagram) that share the same channel (**Main Memory**, as shown
    in the preceding diagram). The bus protocols were originally designed to allow
    a single processor and one or more disks or tape controllers to communicate through
    the shared memory here.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，总线结构允许任意数量的设备（CPU +缓存在前面的图中）共享相同的通道（主内存，如前面的图所示）。总线协议最初是设计用于允许单个处理器和一个或多个磁盘或磁带控制器通过共享内存进行通信。
- en: Each processor has been associated with cache memory, as it is assumed that
    the probability that a processor needs to have data or instructions present in
    the local memory is very high.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 每个处理器都与缓存内存相关联，因为假定处理器需要在本地内存中具有数据或指令的概率非常高。
- en: The problem occurs when a processor modifies data stored in the memory system
    that is simultaneously used by other processors. The new value will pass from
    the processor cache that has been changed to the shared memory. Later, however,
    it must also be passed to all the other processors, so that they do not work with
    the obsolete value. This problem is known as the problem of *cache coherency*—a
    special case of the problem of memory consistency, which requires hardware implementations
    that can handle concurrency issues and synchronization, similar to that of thread
    programming.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个处理器修改同时被其他处理器使用的存储在内存系统中的数据时，问题就会发生。新值将从已更改的处理器缓存传递到共享内存。然而，它还必须传递到所有其他处理器，以便它们不使用过时的值。这个问题被称为“缓存一致性”问题，是内存一致性问题的特例，需要硬件实现来处理并发问题和同步，类似于线程编程。
- en: 'The main features of shared memory systems are as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 共享内存系统的主要特点如下：
- en: The memory is the same for all processors. For example, all the processors associated
    with the same data structure will work with the same logical memory addresses,
    thus accessing the same memory locations.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有处理器的内存都是相同的。例如，与相同数据结构相关联的所有处理器将使用相同的逻辑内存地址，从而访问相同的内存位置。
- en: The synchronization is obtained by reading the tasks of various processors and
    allowing the shared memory. In fact, the processors can only access one memory
    at a time.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过读取各个处理器的任务并允许共享内存来实现同步。实际上，处理器一次只能访问一个内存。
- en: A shared memory location must not be changed from a task while another task
    accesses it.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享内存位置在另一个任务访问时不得被另一个任务更改。
- en: Sharing data between tasks is fast. The time required to communicate is the
    time that one of them takes to read a single location (depending on the speed
    of memory access).
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务之间共享数据很快。通信所需的时间是它们中的一个读取单个位置所需的时间（取决于内存访问速度）。
- en: 'The memory access in shared memory systems is as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在共享内存系统中，内存访问如下：
- en: '**Uniform Memory Access** (**UMA**): The fundamental characteristic of this
    system is the access time to the memory that is constant for each processor and
    for any area of memory. For this reason, these systems are also called **Symmetric
    Multiprocessors** (**SMPs**). They are relatively simple to implement, but not
    very scalable. The coder is responsible for the management of the synchronization
    by inserting appropriate controls, semaphores, locks, and more in the program
    that manages resources.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统一内存访问（UMA）：该系统的基本特征是对内存的访问时间对于每个处理器和任何内存区域都是恒定的。因此，这些系统也被称为对称多处理器（SMP）。它们相对简单实现，但扩展性不强。编码人员负责通过在管理资源的程序中插入适当的控制、信号量、锁等来管理同步。
- en: '**Non-Uniform Memory Access** (**NUMA**): These architectures divide the memory
    into high-speed access area that is assigned to each processor, and also, a common
    area for the data exchange, with slower access. These systems are also called
    **Distributed Shared Memory** (**DSM**) systems. They are very scalable, but complex
    to develop.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非统一内存访问（NUMA）：这些架构将内存分为分配给每个处理器的高速访问区域，以及用于数据交换的通用区域，访问速度较慢。这些系统也被称为分布式共享内存（DSM）系统。它们具有很强的可扩展性，但开发起来比较复杂。
- en: '**No Remote Memory Access** (**NoRMA**): The memory is physically distributed
    among the processors (local memory). All local memories are private and can only
    access the local processor. The communication between the processors is through
    a communication protocol used for exchanging messages, which is known as the *message-passing
    protocol*.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无远程内存访问（NoRMA）：内存在处理器之间物理分布（本地内存）。所有本地内存都是私有的，只能访问本地处理器。处理器之间的通信是通过用于交换消息的通信协议进行的，这被称为消息传递协议。
- en: '**Cache-Only Memory Architecture** (**COMA**): These systems are equipped with
    only cached memories. While analyzing NUMA architectures, it was noticed that
    this architecture kept the local copies of the data in the cache and that this
    data was stored as duplicates in the main memory. This architecture removes duplicates
    and keeps only the cached memories; the memory is physically distributed among
    the processors (local memory). All local memories are private and can only access
    the local processor. The communication between the processors is also through
    the message-passing protocol.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅缓存内存架构**（**COMA**）：这些系统只配备了缓存内存。在分析NUMA架构时，注意到这种架构在缓存中保留了数据的本地副本，并且这些数据在主内存中存储为重复。这种架构去除了重复，并且只保留了缓存内存；内存在处理器之间物理分布（本地内存）。所有本地内存都是私有的，只能访问本地处理器。处理器之间的通信也是通过消息传递协议进行的。'
- en: Distributed memory
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式内存
- en: 'In a system with distributed memory, the memory is associated with each processor
    and a processor is only able to address its own memory. Some authors refer to
    this type of system as a multicomputer, reflecting the fact that the elements
    of the system are, themselves, small and complete systems of a processor and memory,
    as you can see in the following diagram:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式内存系统中，每个处理器都与内存相关联，处理器只能访问自己的内存。一些作者将这种类型的系统称为多处理机，反映了系统的元素本身是处理器和内存的小而完整的系统，如下图所示：
- en: '![](assets/edbcb72a-7807-4dba-97da-a1e69af3c29d.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/edbcb72a-7807-4dba-97da-a1e69af3c29d.png)'
- en: The distributed memory architecture schema
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存架构模式
- en: 'This kind of organization has several advantages:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这种组织方式有几个优点：
- en: There are no conflicts at the level of the communication bus or switch. Each
    processor can use the full bandwidth of their own local memory without any interference
    from other processors.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在通信总线或交换机的级别没有冲突。每个处理器可以使用自己本地内存的全部带宽，而不受其他处理器的干扰。
- en: The lack of a common bus means that there is no intrinsic limit to the number
    of processors. The size of the system is only limited by the network used to connect
    the processors.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有共享总线意味着处理器数量没有固有限制。系统的大小仅受连接处理器的网络的限制。
- en: There are no problems with cache coherency. Each processor is responsible for
    its own data and does not have to worry about upgrading any copies.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存一致性没有问题。每个处理器负责自己的数据，不必担心升级任何副本。
- en: 'The main disadvantage is that communication between processors is more difficult
    to implement. If a processor requires data in the memory of another processor,
    then the two processors should not necessarily exchange messages via the message-passing
    protocol. This introduces two sources of slowdown: to build and send a message
    from one processor to another takes time, and also, any processor should be stopped
    in order to manage the messages received from other processors. A program designed
    to work on a distributed memory machine must be organized as a set of independent
    tasks that communicate via messages:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的缺点是处理器之间的通信更难实现。如果一个处理器需要另一个处理器的内存中的数据，那么这两个处理器不一定需要通过消息传递协议交换消息。这引入了两种减速的来源：从一个处理器向另一个处理器构建和发送消息需要时间，而且任何处理器都必须停止以管理从其他处理器接收到的消息。设计为在分布式内存机器上运行的程序必须组织为一组通过消息进行通信的独立任务：
- en: '![](assets/6174b7b7-c606-48e1-a585-3412e6d542c7.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/6174b7b7-c606-48e1-a585-3412e6d542c7.png)'
- en: Basic message passing
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基本消息传递
- en: 'The main features of distributed memory systems are as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式内存系统的主要特点如下：
- en: Memory is physically distributed between processors; each local memory is directly
    accessible only by its processor.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存在处理器之间物理分布；每个本地内存只能被其处理器直接访问。
- en: Synchronization is achieved by moving data (even if it's just the message itself)
    between processors (communication).
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在处理器之间移动数据（即使只是消息本身）来实现同步（通信）。
- en: The subdivision of data in the local memories affects the performance of the
    machine—it is essential to make subdivisions accurate, so as to minimize the communication
    between the CPUs. In addition to this, the processor that coordinates these operations
    of decomposition and composition must effectively communicate with the processors
    that operate on the individual parts of data structures.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地内存中数据的细分会影响机器的性能——必须准确地进行细分，以最小化CPU之间的通信。除此之外，协调这些分解和组合操作的处理器必须有效地与操作数据结构各个部分的处理器进行通信。
- en: The message-passing protocol is used so that the CPUs can communicate with each
    other through the exchange of data packets. The messages are discrete units of
    information, in the sense that they have a well-defined identity, so it is always
    possible to distinguish them from each other.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用消息传递协议，以便CPU可以通过交换数据包进行通信。消息是信息的离散单元，从这个意义上说，它们具有明确定义的身份，因此总是可以将它们与其他消息区分开来。
- en: Massively Parallel Processing (MPP)
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模并行处理（MPP）
- en: MPP machines are composed of hundreds of processors (which can be as large as
    hundreds of thousands of processors in some machines) that are connected by a
    communication network. The fastest computers in the world are based on these architectures;
    some examples of these architecture systems are Earth Simulator, Blue Gene, ASCI
    White, ASCI Red, and ASCI Purple and Red Storm.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: MPP机器由数百个处理器组成（在某些机器中可以达到数十万个处理器），它们通过通信网络连接。世界上最快的计算机基于这些架构；这些架构系统的一些例子是Earth
    Simulator、Blue Gene、ASCI White、ASCI Red、ASCI Purple和Red Storm。
- en: Clusters of workstations
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作站集群
- en: These processing systems are based on classical computers that are connected
    by communication networks. Computational clusters fall into this classification.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些处理系统是基于通过通信网络连接的经典计算机。计算集群属于这一分类。
- en: In a cluster architecture, we define a node as a single computing unit that
    takes part in the cluster. For the user, the cluster is fully transparent—all
    the hardware and software complexity is masked and data and applications are made
    accessible as if they were all from a single node.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群架构中，我们将节点定义为参与集群的单个计算单元。对于用户来说，集群是完全透明的 - 所有的硬件和软件复杂性都被掩盖，数据和应用程序都可以像来自单个节点一样访问。
- en: 'Here, we''ve identified three types of clusters:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们确定了三种类型的集群：
- en: '**Fail-over cluster**: In this, the node''s activity is continuously monitored,
    and when one stops working, another machine takes over the charge of those activities.
    The aim is to ensure a continuous service due to the redundancy of the architecture.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故障转移集群**：在这种情况下，节点的活动会持续监控，当一个节点停止工作时，另一台机器会接管这些活动。其目的是通过架构的冗余性来确保连续的服务。'
- en: '**Load balancing cluster**: In this system, a job request is sent to the node
    that has less activity. This ensures that less time is taken to process the job.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载平衡集群**：在这个系统中，作业请求被发送到活动较少的节点。这确保了处理作业所需的时间较短。'
- en: '**High-performance computing cluster**: In this, each node is configured to
    provide extremely high performance. The process is also divided into multiple
    jobs on multiple nodes. The jobs are parallelized and will be distributed to different
    machines.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高性能计算集群**：在这种情况下，每个节点都配置为提供极高的性能。该过程也被分成多个作业，并行化并分布到不同的机器上。'
- en: Heterogeneous architectures
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异构架构
- en: 'The introduction of GPU accelerators in the homogeneous world of supercomputing
    has changed the nature of how supercomputers are both used and programmed now.
    Despite the high performance offered by GPUs, they cannot be considered as an
    autonomous processing unit as they should always be accompanied by a combination
    of CPUs. The programming paradigm, therefore, is very simple: the CPU takes control
    and computes in a serial manner, assigning tasks to the graphics accelerator that
    are, computationally, very expensive and have a high degree of parallelism.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在超级计算的同质世界中引入GPU加速器已经改变了超级计算机的使用和编程方式。尽管GPU提供了高性能，但它们不能被视为自主的处理单元，因为它们总是需要与CPU的组合一起使用。因此，编程范式非常简单：CPU控制并以串行方式计算，将计算量非常大且具有高度并行性的任务分配给图形加速器。
- en: The communication between a CPU and a GPU can take place, not only through the
    use of a high-speed bus but also through the sharing of a single area of memory
    for both physical or virtual memory. In fact, in the case where both the devices
    are not equipped with their own memory areas, it is possible to refer to a common
    memory area using the software libraries provided by the various programming models,
    such as *CUDA* and *OpenCL*.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: CPU和GPU之间的通信不仅可以通过高速总线进行，还可以通过共享单个内存区域进行，无论是物理内存还是虚拟内存。事实上，在两个设备都没有自己的内存区域的情况下，可以使用各种编程模型提供的软件库，如*CUDA*和*OpenCL*，来引用一个共同的内存区域。
- en: These architectures are called *heterogeneous architectures*, wherein applications
    can create data structures in a single address space and send a job to the device
    hardware, which is appropriate for the resolution of the task. Several processing
    tasks can operate safely in the same regions to avoid data consistency problems,
    thanks to the atomic operations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构被称为*异构架构*，应用程序可以在单个地址空间中创建数据结构，并将作业发送到适合解决任务的设备硬件。多个处理任务可以安全地在相同的区域内运行，以避免数据一致性问题，这要归功于原子操作。
- en: 'So, despite the fact that the CPU and GPU do not seem to work efficiently together,
    with the use of this new architecture, we can optimize their interaction with,
    and the performance of, parallel applications:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，尽管CPU和GPU似乎不能有效地共同工作，但通过使用这种新架构，我们可以优化它们与并行应用程序的交互和性能：
- en: '![](assets/46dac58e-d70e-4177-bc35-1018279093a9.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/46dac58e-d70e-4177-bc35-1018279093a9.png)'
- en: The heterogeneous architecture schema
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 异构架构模式
- en: In the following section, we introduce the main parallel programming models.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将介绍主要的并行编程模型。
- en: Parallel programming models
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行编程模型
- en: Parallel programming models exist as an abstraction of hardware and memory architectures.
    In fact, these models are not specific and do not refer to any particular types
    of machines or memory architectures. They can be implemented (at least theoretically)
    on any kind of machines. Compared to the previous subdivisions, these programming
    models are made at a higher level and represent the way in which the software
    must be implemented to perform parallel computation. Each model has its own way
    of sharing information with other processors in order to access memory and divide
    the work.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 并行编程模型存在作为硬件和内存架构的抽象。事实上，这些模型并不具体，也不指代任何特定类型的机器或内存架构。它们可以（至少在理论上）在任何类型的机器上实现。与以前的细分相比，这些编程模型是在更高的层次上制定的，并代表了软件执行并行计算的方式。每个模型都有自己的方式与其他处理器共享信息，以便访问内存和分配工作。
- en: 'In absolute terms, no one model is better than the other. Therefore, the best
    solution to be applied will depend very much on the problem that a programmer
    should address and resolve. The most widely used models for parallel programming
    are as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 绝对来说，没有一个模型比其他模型更好。因此，应用的最佳解决方案将在很大程度上取决于程序员需要解决和解决的问题。最广泛使用的并行编程模型如下：
- en: Shared memory model
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享内存模型
- en: Multithread model
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程模型
- en: Distributed memory/message passing model
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式内存/消息传递模型
- en: Data-parallel model
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据并行模型
- en: In this recipe, we will give you an overview of these models.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将为您概述这些模型。
- en: Shared memory model
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享内存模型
- en: In this model, tasks share a single memory area in which we can read and write
    asynchronously. There are mechanisms that allow the coder to control the access
    to the shared memory; for example, locks or semaphores. This model offers the
    advantage that the coder does not have to clarify the communication between tasks.
    An important disadvantage, in terms of performance, is that it becomes more difficult
    to understand and manage data locality. This refers to keeping data local to the
    processor that works on conserving memory access, cache refreshes, and bus traffic
    that occurs when multiple processors use the same data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，任务共享一个内存区域，我们可以异步读写。有一些机制允许编码人员控制对共享内存的访问；例如，锁或信号量。这个模型的优点是编码人员不必澄清任务之间的通信。在性能方面的一个重要缺点是，更难理解和管理数据局部性。这指的是保持数据局部于处理器上，以保留内存访问、缓存刷新和总线流量，当多个处理器使用相同数据时发生。
- en: Multithread model
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程模型
- en: In this model, a process can have multiple flows of execution. For example,
    a sequential part is created and, subsequently, a series of tasks are created
    that can be executed in parallel. Usually, this type of model is used on shared
    memory architectures. So, it will be very important for us to manage the synchronization
    between threads, as they operate on shared memory, and the programmer must prevent
    multiple threads from updating the same locations at the same time.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，一个进程可以有多个执行流。例如，首先创建一个顺序部分，然后创建一系列可以并行执行的任务。通常，这种类型的模型用于共享内存架构。因此，对我们来说，管理线程之间的同步将非常重要，因为它们在共享内存上运行，并且程序员必须防止多个线程同时更新相同的位置。
- en: The current-generation CPUs are multithreaded in software and hardware. **POSIX**
    (short for **Portable Operating System Interface**) threads are classic examples
    of the implementation of multithreading on software. Intel's Hyper-Threading technology
    implements multithreading on hardware by switching between two threads when one
    is stalled or waiting on I/O. Parallelism can be achieved from this model, even
    if the data alignment is nonlinear.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当前一代的CPU在软件和硬件上都是多线程的。**POSIX**（代表**可移植操作系统接口**）线程是软件上多线程实现的经典例子。英特尔的超线程技术通过在一个线程停滞或等待I/O时在两个线程之间切换来在硬件上实现多线程。即使数据对齐是非线性的，也可以从这个模型中实现并行性。
- en: Message passing model
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息传递模型
- en: The message passing model is usually applied in cases where each processor has
    its own memory (distributed memory system). More tasks can reside on the same
    physical machine or on an arbitrary number of machines. The coder is responsible
    for determining the parallelism and data exchange that occurs through the messages,
    and it is necessary to request and call a library of functions within the code.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递模型通常应用于每个处理器都有自己的内存（分布式内存系统）的情况。更多的任务可以驻留在同一台物理机器上或任意数量的机器上。编码人员负责确定通过消息进行的并行性和数据交换，并且需要在代码中请求和调用函数库。
- en: Some of the examples have been around since the 1980s, but only in the mid-1990s
    was a standardized model created, leading to a de facto standard called a **Message
    Passing Interface **(**MPI**).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一些例子自20世纪80年代以来就存在，但直到20世纪90年代中期才创建了一个标准化的模型，导致了一种事实上的标准，称为**消息传递接口**（**MPI**）。
- en: 'The MPI model is clearly designed with distributed memory, but being models
    of parallel programming, a multiplatform model can also be used with a shared
    memory machine:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: MPI模型显然是设计用于分布式内存的，但作为并行编程模型，多平台模型也可以在共享内存机器上使用：
- en: '![](assets/bd5deb5a-ea45-42d8-ba4e-b7852b6e0fcd.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bd5deb5a-ea45-42d8-ba4e-b7852b6e0fcd.png)'
- en: Message passing paradigm model
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递范式模型
- en: Data-parallel model
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据并行模型
- en: In this model, we have more tasks that operate on the same data structure, but
    each task operates on a different portion of data. In the shared memory architecture,
    all tasks have access to data through shared memory and distributed memory architectures,
    where the data structure is divided and resides in the local memory of each task.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，我们有更多的任务操作相同的数据结构，但每个任务操作不同部分的数据。在共享内存架构中，所有任务都可以通过共享内存访问数据，而在分布式内存架构中，数据结构被划分并驻留在每个任务的本地内存中。
- en: 'To implement this model, a coder must develop a program that specifies the
    distribution and alignment of data; for example, the current-generation GPUs are
    highly operational only if data (**Task** **1**, **Task** **2**, **Task** **3**)
    is aligned, as shown in the following diagram:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这个模型，编码人员必须开发一个指定数据分布和对齐的程序；例如，当前一代的GPU只有在数据（**任务** **1**，**任务** **2**，**任务**
    **3**）对齐时才能高效运行，如下图所示：
- en: '![](assets/93cf041f-f65b-46e5-b36d-59d4ed537910.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/93cf041f-f65b-46e5-b36d-59d4ed537910.png)'
- en: The data-parallel paradigm model
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行范式模型
- en: Designing a parallel program
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计并行程序
- en: 'The design of algorithms that exploit parallelism is based on a series of operations,
    which must be carried out for the program to perform the job correctly without
    producing partial or erroneous results. The macro operations that must be carried
    out for a correct parallelization of an algorithm are as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 利用并行性设计算法是基于一系列操作，必须执行这些操作才能使程序正确执行工作而不产生部分或错误的结果。必须执行的宏操作包括：
- en: Task decomposition
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务分解
- en: Task assignment
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务分配
- en: Agglomeration
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚集
- en: Mapping
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 映射
- en: Task decomposition
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务分解
- en: 'In this first phase, the software program is split into tasks or a set of instructions
    that can then be executed on different processors to implement parallelism. To
    perform this subdivision, two methods are used:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第一阶段，软件程序被分割成任务或一组指令，然后可以在不同的处理器上执行以实现并行性。为了执行这种细分，使用了两种方法：
- en: '**Domain decomposition**: Here, the data of the problems is decomposed. The
    application is common to all the processors that work on different portions of
    data. This methodology is used when we have a large amount of data that must be
    processed.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**域分解**：在这里，问题的数据被分解。应用程序对处理不同数据部分的所有处理器都是通用的。当我们有大量必须处理的数据时，使用这种方法。'
- en: '**Functional decomposition**: In this case, the problem is split into tasks,
    where each task will perform a particular operation on all the available data.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能分解**：在这种情况下，问题被分解成任务，每个任务将对所有可用数据执行特定操作。'
- en: Task assignment
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务分配
- en: In this step, the mechanism by which the tasks will be distributed among the
    various processes is specified. This phase is very important because it establishes
    the distribution of workload among the various processors. Load balancing is crucial
    here; in fact, all processors must work with continuity, avoiding being in an
    idle state for a long time.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，指定了任务将在各个进程之间分配的机制。这个阶段非常重要，因为它确定了各个处理器之间的工作负载分配。在这里负载平衡至关重要；事实上，所有处理器必须连续工作，避免长时间处于空闲状态。
- en: To perform this, the coder takes into account the possible heterogeneity of
    the system that tries to assign more tasks to better-performing processors. Finally,
    for greater efficiency of parallelization, it is necessary to limit communication
    as much as possible between processors, as they are often the source of slowdowns
    and consumption of resources.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行这一点，编码人员考虑了系统的可能异质性，试图将更多的任务分配给性能更好的处理器。最后，为了更有效地进行并行化，有必要尽量限制处理器之间的通信，因为它们通常是减速和资源消耗的来源。
- en: Agglomeration
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聚合
- en: Agglomeration is the process of combining smaller tasks with larger ones in
    order to improve performance. If the previous two stages of the design process
    partitioned the problem into a number of tasks that greatly exceed the number
    of processors available, and if the computer is not specifically designed to handle
    a huge number of small tasks (some architectures, such as GPUs, handle this fine
    and indeed benefit from running millions, or even billions, of tasks), then the
    design can turn out to be highly inefficient.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合是将较小的任务与较大的任务组合以提高性能的过程。如果设计过程的前两个阶段将问题分割成远远超过可用处理器数量的任务，并且计算机没有专门设计来处理大量小任务（一些架构，如GPU，可以很好地处理这一点，并且确实受益于运行数百万甚至数十亿的任务），那么设计可能会变得非常低效。
- en: Commonly, this is because tasks have to be communicated to the processor or
    thread so that they compute the said task. Most communications have costs that
    are disproportionate to the amount of data transferred, but also incur a fixed
    cost for every communication operation (such as the latency, which is inherent
    in setting up a TCP connection). If the tasks are too small, then this fixed cost
    can easily make the design inefficient.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这是因为任务必须被传输到处理器或线程，以便它们计算所述任务。大多数通信的成本与传输的数据量不成比例，但也会为每个通信操作产生固定成本（例如延迟，在建立TCP连接时固有的）。如果任务太小，那么这个固定成本很容易使设计变得低效。
- en: Mapping
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 映射
- en: 'In the mapping stage of the parallel algorithm design process, we specify where
    each task is to be executed. The goal is to minimize the total execution time.
    Here, you must often make trade-offs, as the two main strategies often conflict
    with each other:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在并行算法设计过程的映射阶段，我们指定每个任务应在哪里执行。目标是最小化总执行时间。在这里，你经常需要做出权衡，因为两种主要策略经常相互冲突：
- en: The tasks that communicate frequently should be placed in the same processor
    to increase locality.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频繁通信的任务应放置在同一处理器上以增加局部性。
- en: The tasks that can be executed concurrently should be placed in different processors
    to enhance concurrency.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以同时执行的任务应放置在不同的处理器中以增强并发性。
- en: This is known as the *mapping problem*, and it is known to be **NP-complete**.
    As such, no polynomial-time solutions to the problem in the general case exist.
    For tasks of equal size and tasks with easily identified communication patterns,
    the mapping is straightforward (we can also perform agglomeration here to combine
    tasks that map to the same processor). However, if the tasks have communication
    patterns that are hard to predict or the amount of work varies per task, then
    it is hard to design an efficient mapping and agglomeration scheme.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为*映射问题*，已知为**NP完全**。因此，在一般情况下，该问题没有多项式时间的解决方案。对于相同大小的任务和具有易于识别的通信模式的任务，映射是直接的（我们也可以在这里执行聚合，将映射到相同处理器的任务组合在一起）。然而，如果任务具有难以预测的通信模式或任务的工作量因任务而异，那么设计有效的映射和聚合方案就很困难。
- en: For these types of problems, load balancing algorithms can be used to identify
    agglomeration and mapping strategies during runtime. The hardest problems are
    those in which the amount of communication or the number of tasks changes during
    the execution of the program. For these kinds of problems, dynamic load balancing
    algorithms can be used, which run periodically during the execution.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些类型的问题，可以使用负载平衡算法来识别运行时的聚合和映射策略。最困难的问题是在程序执行过程中通信量或任务数量发生变化的问题。对于这类问题，可以使用动态负载平衡算法，它们在执行过程中定期运行。
- en: Dynamic mapping
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态映射
- en: 'Numerous load balancing algorithms exist for a variety of problems:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多负载平衡算法，适用于各种问题：
- en: '**Global algorithms**: These require global knowledge of the computation being
    performed, which often adds a lot of overhead.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全局算法**：这些需要对正在执行的计算进行全局了解，这通常会增加很多开销。'
- en: '**Local algorithms**: These rely only on information that is local to the task
    in question, which reduces overhead compared to global algorithms, but they are
    usually worse at finding optimal agglomeration and mapping.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局部算法**：这些仅依赖于与所讨论的任务相关的本地信息，与全局算法相比减少了开销，但通常在寻找最佳聚合和映射方面效果较差。'
- en: However, the reduced overhead may reduce the execution time, even though the
    mapping is worse by itself. If the tasks rarely communicate other than at the
    start and end of the execution, then a task-scheduling algorithm is often used,
    which simply maps tasks to processors as they become idle. In a task-scheduling
    algorithm, a task pool is maintained. Tasks are placed in this pool and are taken
    from it by workers.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，减少的开销可能会减少执行时间，即使映射本身更糟。如果任务除了在执行开始和结束时很少通信，那么通常会使用任务调度算法，该算法简单地将任务映射到处理器，使它们变为空闲。在任务调度算法中，维护一个任务池。任务被放入此池中，并由工作者从中取出。
- en: 'There are three common approaches in this model:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中有三种常见的方法：
- en: '**Manager/worker: **This is the basic dynamic mapping scheme in which all the
    workers connect to a centralized manager. The manager repeatedly sends tasks to
    the workers and collects the results. This strategy is probably the best for a
    relatively small number of processors. The basic strategy can be improved by fetching
    tasks in advance so that communication and computation overlap each other.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理者/工作者：**这是基本的动态映射方案，所有工作者都连接到一个集中的管理者。管理者反复向工作者发送任务并收集结果。这种策略可能是相对较少处理器的最佳选择。通过提前获取任务，可以改进基本策略，使通信和计算重叠。'
- en: '**Hierarchical manager/worker**: This is the variant of a manager/worker that
    has a semi-distributed layout. Workers are split into groups, each with their
    own manager. These group managers communicate with the central manager (and possibly
    among themselves as well), while workers request tasks from the group managers.
    This spreads the load among several managers and can, as such, handle a larger
    number of processors if all workers request tasks from the same manager.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分层管理者/工作者：**这是管理者/工作者的变体，具有半分布式布局。工作者被分成组，每个组都有自己的管理者。这些组管理者与中央管理者通信（可能也相互通信），而工作者从组管理者请求任务。这样可以将负载分散到几个管理者中，并且如果所有工作者都从同一个管理者请求任务，则可以处理更多的处理器。'
- en: '**Decentralize**: In this scheme, everything is decentralized. Each processor
    maintains its own task pool and communicates with the other processors in order
    to request tasks. How the processors choose other processors to request tasks
    varies and is determined on the basis of the problem.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**去中心化：**在这种方案中，一切都是去中心化的。每个处理器维护自己的任务池，并与其他处理器通信以请求任务。处理器如何选择其他处理器来请求任务是不同的，并且是根据问题的基础确定的。'
- en: Evaluating the performance of a parallel program
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估并行程序的性能
- en: The development of parallel programming created the need for performance metrics
    in order to decide whether its use is convenient or not. Indeed, the focus of
    parallel computing is to solve large problems in a relatively short period of
    time. The factors contributing to this objective are, for example, the type of
    hardware used, the degree of parallelism of the problem, and the parallel programming
    model adopted. To facilitate this, the analysis of basic concepts was introduced,
    which compares the parallel algorithm obtained from the original sequence.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 并行编程的发展产生了性能指标的需求，以便决定其使用是否方便。事实上，并行计算的重点是在相对较短的时间内解决大问题。为此目标做出贡献的因素包括所使用的硬件类型、问题的并行度以及采用的并行编程模型。为了方便起见，引入了基本概念的分析，比较了从原始序列获得的并行算法。
- en: 'The performance is achieved by analyzing and quantifying the number of threads
    and/or the number of processes used. To analyze this, let''s introduce a few performance
    indexes:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析和量化使用的线程数量和/或进程数量来实现性能。为了分析这一点，让我们引入一些性能指标：
- en: '**Speedup**'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加速**'
- en: '**Efficiency**'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**'
- en: '**Scaling**'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展**'
- en: The limitations of parallel computation are introduced by **Amdahl**'s law.
    To evaluate the *degree of efficiency* of the parallelization of a sequential
    algorithm, we have**Gustafson**'s law.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 并行计算的限制由**阿姆达尔**定律引入。为了评估顺序算法并行化的效率程度，我们有**古斯塔夫森**定律。
- en: Speedup
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加速
- en: The **speedup** is the measure that displays the benefit of solving a problem
    in parallel. It is defined as the ratio of the time taken to solve a problem on
    a single processing element (*Ts*) to the time required to solve the same problem
    on *p* identical processing elements (*Tp*).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**加速**是显示以并行方式解决问题的好处的度量。它定义为在单个处理元素上解决问题所需的时间（*Ts*）与在*p*个相同处理元素上解决相同问题所需的时间（*Tp*）的比率。'
- en: 'We denote speedup as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将加速定义如下：
- en: '![](assets/d06f79cc-0130-4c88-9669-be45342198b8.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d06f79cc-0130-4c88-9669-be45342198b8.png)'
- en: We have a linear speedup, where if *S=p*, then it means that the speed of execution
    increases with the number of processors. Of course, this is an ideal case. While
    the speedup is absolute when *Ts* is the execution time of the best sequential
    algorithm, the speedup is relative when *Ts* is the execution time of the parallel
    algorithm for a single processor.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有线性加速，如果 *S=p*，那么这意味着执行速度随处理器数量的增加而增加。当然，这是一个理想情况。虽然当*Ts*是最佳顺序算法的执行时间时，加速是绝对的，但当*Ts*是单处理器上并行算法的执行时间时，加速是相对的。
- en: 'Let''s recap these conditions:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下这些条件：
- en: '*S = p* is a linear or ideal speedup.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S = p* 是线性或理想加速。'
- en: '*S < p* is a real speedup.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S < p* 是真实加速。'
- en: '*S > p* is a superlinear speedup.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S > p* 是超线性加速。'
- en: Efficiency
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 效率
- en: In an ideal world, a parallel system with *p* processing elements can give us
    a speedup that is equal to *p*. However, this is very rarely achieved. Usually,
    some time is wasted in either idling or communicating. Efficiency is a measure
    of how much of the execution time a processing element puts toward doing useful
    work, given as a fraction of the time spent.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想世界中，具有*p*个处理元素的并行系统可以给我们一个等于*p*的加速。然而，这很少实现。通常会在空闲或通信中浪费一些时间。效率是度量处理元素将多少执行时间用于执行有用工作的指标，以执行时间的一部分表示。
- en: 'We denote it by *E* and can define it as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用 *E* 表示，并可以定义如下：
- en: '![](assets/a51cb8a0-063e-4177-a8e3-caa123753d53.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a51cb8a0-063e-4177-a8e3-caa123753d53.png)'
- en: 'The algorithms with linear speedup have a value of *E = 1*. In other cases,
    they have the value of *E* is less than *1*. The three cases are identified as
    follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 具有线性加速的算法的值为*E = 1*。在其他情况下，它们的值小于*1*。这三种情况分别标识为：
- en: When *E = 1*, it is a linear case.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*E = 1*时，这是一个线性案例。
- en: When *E < 1*, it is a real case.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*E < 1*时，这是一个真实案例。
- en: When *E << 1*, it is a problem that is parallelizable with low efficiency.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*E << 1*时，这是一个效率低下的可并行化问题。
- en: Scaling
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展
- en: Scaling is defined as the ability to be efficient on a parallel machine. It
    identifies the computing power (speed of execution) in proportion to the number
    of processors. By increasing the size of the problem and, at the same time, the
    number of processors, there will be no loss in terms of performance.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展被定义为在并行机器上高效的能力。它确定了计算能力（执行速度）与处理器数量成比例。通过增加问题的规模和同时增加处理器的数量，性能不会有损失。
- en: The scalable system, depending on the increments of the different factors, may
    maintain the same efficiency or improve it.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展的系统，根据不同因素的增量，可以保持相同的效率或改善效率。
- en: Amdahl's law
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Amdahl定律
- en: 'Amdahl''s law is a widely used law that is used to design processors and parallel
    algorithms. It states that the maximum speedup that can be achieved is limited
    by the serial component of the program:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Amdahl定律是一条广泛使用的定律，用于设计处理器和并行算法。它规定了可以实现的最大加速比受程序的串行部分限制：
- en: '![](assets/d0ef21cb-ef7a-401d-990a-5a3b45325d05.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d0ef21cb-ef7a-401d-990a-5a3b45325d05.png)'
- en: '*1 – P* denotes the serial component (not parallelized) of a program.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '*1 - P*表示程序的串行部分（不并行化）。'
- en: This means that, for example, if a program in which 90% of the code can be made
    parallel, but 10% must remain serial, then the maximum achievable speedup is 9,
    even for an infinite number of processors.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，例如，如果一个程序中有90%的代码可以并行执行，但10%必须保持串行，则最大可实现的加速比为9，即使有无限数量的处理器也是如此。
- en: Gustafson's law
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Gustafson定律
- en: 'Gustafson''s law states the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Gustafson定律陈述如下：
- en: '![](assets/5b33302b-8561-4073-a6df-09072923e8f5.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5b33302b-8561-4073-a6df-09072923e8f5.png)'
- en: 'Here, as we indicated in the equation the following applies:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，正如我们在方程中指出的那样：
- en: '*P* is the *number of processors.*'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*是*处理器数量*。'
- en: '*S* is the *speedup* factor.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*S*是*加速*因子。'
- en: '*α* is the *non-parallelizable fraction* of any parallel process.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*α*是任何并行过程的*不可并行化部分*。'
- en: Gustafson's law is in cont*rast* to Amdahl's law, which, as we described, assumes
    that the overall workload of a program does not change with respect to the number
    of processors.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Gustafson定律与Amdahl定律形成对比，后者假设程序的整体工作量不随处理器数量的变化而改变。
- en: In fact, Gustafson's law suggests that programmers first set the *time* allowed
    for solving a problem in parallel and then based on that (that is time) *to size*
    the problem. Therefore, the *faster*the parallel system is, the *greater* the
    problems that can be solved over the same period of time.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，Gustafson定律建议程序员首先设置解决问题的并行*时间*，然后基于（即时间）*调整*问题的大小。因此，*并行系统*越*快*，在相同时间内可以解决的*问题*就*越大*。
- en: The effect of Gustafson's law was to direct the objectives of computer research
    towards the selection or reformulation of problems in such a way that the solution
    of a larger problem would still be possible in the same amount of time. Furthermore,
    this law redefines the concept of *efficiency* as a need *to reduce at least the
    sequential part* of a program, despite the *increase in workload*.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Gustafson定律的影响是将计算机研究的目标引向以某种方式选择或重新制定问题，以便在相同的时间内仍然可以解决更大的问题。此外，该定律重新定义了*效率*的概念，即需要*至少减少程序的顺序部分*，尽管*工作量增加*。
- en: Introducing Python
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Python
- en: 'Python is a powerful, dynamic, and interpreted programming language that is
    used in a wide variety of applications. Some of its features are as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Python是一种强大、动态和解释性的编程语言，广泛应用于各种应用程序。它的一些特点如下：
- en: A clear and readable syntax.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清晰易读的语法。
- en: A very extensive standard library, where, through additional software modules,
    we can add data types, functions, and objects.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常广泛的标准库，通过额外的软件模块，我们可以添加数据类型、函数和对象。
- en: Easy-to-learn rapid development and debugging. Developing Python code in Python
    can be up to 10 times faster than in C/C++ code. The code can also work as a prototype
    and then translated into C/C ++.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易学易用的快速开发和调试。使用Python，在Python中开发代码可以比在C/C++代码中快10倍。代码也可以作为原型工作，然后转换为C/C++。
- en: Exception-based error handling.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于异常的错误处理。
- en: A strong introspection functionality.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强大的内省功能。
- en: The richness of documentation and a software community.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的文档和软件社区。
- en: Python can be seen as a glue language. Using Python, better applications can
    be developed because different kinds of coders can work together on a project.
    For example, when building a scientific application, C/C++ programmers can implement
    efficient numerical algorithms, while scientists on the same project can write
    Python programs that test and use those algorithms. Scientists don't have to learn
    a low-level programming language and C/C++ programmers don't need to understand
    the science involved.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Python可以被视为一种粘合语言。使用Python，可以开发更好的应用程序，因为不同类型的编码人员可以共同在一个项目上工作。例如，在构建科学应用程序时，C/C++程序员可以实现高效的数值算法，而在同一项目上的科学家可以编写测试和使用这些算法的Python程序。科学家不必学习低级编程语言，C/C++程序员也不需要理解所涉及的科学。
- en: You can read more about this from [https://www.python.org/doc/essays/omg-darpa-mcc-position](https://www.python.org/doc/essays/omg-darpa-mcc-position).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[https://www.python.org/doc/essays/omg-darpa-mcc-position](https://www.python.org/doc/essays/omg-darpa-mcc-position)了解更多信息。
- en: Let's take a look at some examples of very basic code to get an idea of the
    features of Python.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些非常基本的代码示例，以了解Python的特点。
- en: The following section can be a refresher for most of you. We will use these
    techniques practically in [Chapter 2](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml), *Thread-Based
    Parallelism*, and [Chapter 3](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml), *Process-Based
    Parallelism*.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分对大多数人来说可能是复习内容。我们将在[第2章](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml) *基于线程的并行性*和[第3章](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml)
    *基于进程的并行性*中实际使用这些技术。
- en: Help functions
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 帮助函数
- en: The Python interpreter already provides a valid help system. If you want to
    know how to use an object, then just type `help(object)`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Python解释器已经提供了有效的帮助系统。如果要了解如何使用对象，只需键入`help(object)`。
- en: 'Let''s see, for example, how to use the `help` function on integer `0`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们看看如何在整数`0`上使用`help`函数：
- en: '[PRE0]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The description of the `int` object is followed by a list of methods that are
    applicable to it. The first five methods are as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`int`对象的描述后面是适用于它的方法列表。前五个方法如下：'
- en: '[PRE1]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Also useful is `dir(object)`, which lists the methods available for an object:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '`dir(object)`也很有用，它列出了对象可用的方法：'
- en: '[PRE2]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, the relevant documentation for an object is provided by the `.__doc__`
    function, as shown in the following example:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对象的相关文档由`.__doc__`函数提供，如下例所示：
- en: '[PRE3]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Syntax
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语法
- en: 'Python doesn''t adopt statement terminators, and code blocks are specified
    through indentation. Statements that expect an indentation level must end in a
    colon (`:`). This leads to the following:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Python不采用语句终止符，并且代码块通过缩进指定。期望缩进级别的语句必须以冒号（`:`）结尾。这导致以下结果：
- en: The Python code is clearer and more readable.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python代码更清晰、更易读。
- en: The program structure always coincides with that of the indentation.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序结构始终与缩进的结构相一致。
- en: The style of indentation is uniform in any listing.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩进风格在任何列表中都是统一的。
- en: Bad indentation can lead to errors.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的缩进可能导致错误。
- en: 'The following example shows how to use the `if` construct:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例显示如何使用`if`结构：
- en: '[PRE4]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this example, we can see the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以看到以下内容：
- en: 'The following statements: `print("first print")`, `if condition:`, `print("third
    print")` have the same indentation level and are always executed.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下语句：`print("first print")`，`if condition:`，`print("third print")`具有相同的缩进级别，并且始终被执行。
- en: After the `if` statement, there is a block of code with a higher indentation
    level, which includes the `print ("second print")` statement.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`if`语句之后，有一个缩进级别更高的代码块，其中包括`print ("second print")`语句。
- en: If the condition of `if` is true, then the `print ("second print")` statement
    is executed.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`if`的条件为真，则执行`print ("second print")`语句。
- en: If the condition of `if` is false, then the `print ("second print")` statement
    is not executed.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`if`的条件为假，则不执行`print ("second print")`语句。
- en: It is, therefore, very important to pay attention to indentation because it
    is always evaluated in the program parsing process.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，非常重要的是要注意缩进，因为它始终在程序解析过程中进行评估。
- en: Comments
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注释
- en: 'Comments start with the hash sign (`#`) and are on a single line:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 注释以井号（`#`）开头，位于单独一行上：
- en: '[PRE5]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Multi-line strings are used for multi-line comments:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 多行字符串用于多行注释：
- en: '[PRE6]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Assignments
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 赋值
- en: Assignments are made with the equals symbol (`=`). For equality tests, the same
    amount (`==`) is used. You can increase and decrease a value using the `+=` and
    `-=` operators, followed by an addendum. This works with many types of data, including
    strings. You can assign and use multiple variables on the same line.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 赋值使用等号（`=`）进行。对于相等性测试，使用相同数量的（`==`）。您可以使用`+=`和`-=`运算符增加和减少值，后跟一个附录。这适用于许多类型的数据，包括字符串。您可以在同一行上分配和使用多个变量。
- en: 'Some examples are as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 一些示例如下：
- en: '[PRE7]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Data types
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据类型
- en: 'The most significant structures in Python are *lists*, *tuples*,and *dictionaries*.
    Sets have been integrated into Python since version 2.5 (the previous versions
    are available in the `sets` library):'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: Python中最重要的结构是*列表*、*元组*和*字典*。自Python 2.5版本以来，集合已经集成到Python中（之前的版本可在`sets`库中找到）：
- en: '**Lists**: These are similar to one-dimensional arrays, but you can create
    lists that contain other lists.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列表**：这些类似于一维数组，但您可以创建包含其他列表的列表。'
- en: '**Dictionaries**: These are arrays that contain key pairs and values (hash
    tables).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**字典**：这些是包含键对和值（哈希表）的数组。'
- en: '**Tuples**: These are immutable mono-dimensional objects.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元组**：这些是不可变的单维对象。'
- en: Arrays can be of any type, so you can mix variables such as integers and strings
    into your lists, dictionaries and tuples.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 数组可以是任何类型，因此可以将诸如整数和字符串之类的变量混合到列表、字典和元组中。
- en: 'The index of the first object in any type of array is always zero. Negative
    indexes are allowed and count from the end of the array; `-1` indicates the last
    element of the array:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 任何类型的数组中第一个对象的索引始终为零。允许负索引，并且从数组末尾计数；`-1`表示数组的最后一个元素：
- en: '[PRE8]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can get an array range using the colon (`:`):'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用冒号（`:`）获取数组范围：
- en: '[PRE9]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Strings
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 字符串
- en: 'Python strings are indicated using either the single (`''`) or double (`"`)
    quotation mark and they are allowed to use one notation within a string delimited
    by the other:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Python字符串使用单引号（`'`）或双引号（`"`）标示，并且允许在字符串中使用另一种标示：
- en: '[PRE10]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'On multiple lines, they are enclosed in triple (or three single) quotation
    marks (`''''''` multi-line string `''''''`):'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在多行上，它们用三个（或三个单）引号括起来（`'''`多行字符串`'''`）：
- en: '[PRE11]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Python also supports Unicode; just use the `u "This is a unicode string"` syntax
    :'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Python还支持Unicode；只需使用`u "This is a unicode string"`语法：
- en: '[PRE12]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To enter values in a string, type the `%` operator and a tuple. Then, each `%`
    operator is replaced by a tuple element, from left to right*:*
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 要在字符串中输入值，请键入`%`运算符和一个元组。然后，每个`%`运算符将从左到右替换为元组元素*：*
- en: '[PRE13]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Flow control
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流程控制
- en: Flow control instructions are `if`, `for`, and `while`.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 流程控制指令是`if`、`for`和`while`。
- en: 'In the next example, we check whether the number is positive, negative, or
    zero and display the result:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个示例中，我们检查数字是正数、负数还是零，并显示结果：
- en: '[PRE14]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following code block finds the sum of all the numbers stored in a list,
    using a `for` loop:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块使用`for`循环找到存储在列表中的所有数字的总和：
- en: '[PRE15]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will execute the `while` loop to iterate the code until the condition result
    is true. We will use this loop over the `for`loop since we are unaware of the
    number of iterations that will result in the code. In this example, we use `while`
    to add natural numbers up to *sum = 1+2+3+...+n*:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将执行`while`循环来迭代代码，直到条件结果为真。我们将使用这个循环来代替`for`循环，因为我们不知道会导致代码的迭代次数。在这个例子中，我们使用`while`来添加自然数，直到*sum
    = 1+2+3+...+n*：
- en: '[PRE16]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The outputs for the preceding three examples are as follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 前三个示例的输出如下：
- en: '[PRE17]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Functions
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数
- en: 'Python functions are declared with the `def` keyword:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: Python函数使用`def`关键字声明：
- en: '[PRE18]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To run a function, use the function name, followed by parentheses, as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行一个函数，使用函数名，后跟括号，如下所示：
- en: '[PRE19]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Parameters must be specified after the function name, inside the parentheses:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 参数必须在函数名后面的括号内指定：
- en: '[PRE20]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Multiple parameters must be separated with a comma:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 多个参数必须用逗号分隔：
- en: '[PRE21]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Use the equals sign to define a default parameter. If you call the function
    without the parameter, then the default value will be used:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 使用等号来定义默认参数。如果没有参数调用函数，则将使用默认值：
- en: '[PRE22]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The parameters of a function can be of any type of data (such as string, number,
    list, and dictionary). Here, the following list, `lcities`, is used as a parameter
    for `my_function`:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的参数可以是任何类型的数据（如字符串、数字、列表和字典）。在这里，以下列表`lcities`被用作`my_function`的参数：
- en: '[PRE23]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Use the `return` statement to return a value from a function:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`return`语句从函数中返回一个值：
- en: '[PRE24]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Python supports an interesting syntax that allows you to define small, single-line
    functions on the fly. Derived from the Lisp programming language, these lambda
    functions can be used wherever a function is required.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: Python支持一种有趣的语法，允许您在需要定义小型单行函数的地方定义它们。这些lambda函数源自Lisp编程语言。
- en: 'An example of a lambda function, `functionvar`, is shown as follows:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: lambda函数的一个示例，`functionvar`，如下所示：
- en: '[PRE25]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Classes
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类
- en: 'Python supports multiple inheritances of classes. Conventionally (not a language
    rule), private variables and methods are declared by being preceded with two underscores
    (`__`). We can assign arbitrary attributes (properties) to the instances of a
    class, as shown in the following example:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: Python支持类的多重继承。按照惯例（而不是语言规则），私有变量和方法以两个下划线（`__`）开头声明。我们可以给类的实例分配任意属性（属性），如下例所示：
- en: '[PRE26]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Exceptions
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异常
- en: 'Exceptions in Python are managed with `try-except` blocks (`exception_name`):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: Python中的异常使用`try-except`块（`exception_name`）进行管理：
- en: '[PRE27]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Importing libraries
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入库
- en: 'External libraries are imported with `import [library name]`. Alternatively,
    you can use the `from [library name] import [function name]` syntax to import
    a specific function. Here is an example:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 外部库使用`import [library name]`导入。或者，您可以使用`from [library name] import [function
    name]`语法导入特定函数。这是一个例子：
- en: '[PRE28]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Managing files
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理文件
- en: 'To allow us to interact with the filesystem, Python provides us with the built-in `open` function.This
    function can be invoked to open a file and return an object file. The latter allows
    us to perform various operations on the file, such as reading and writing. When
    we have finished interacting with the file, we must finally remember to close
    it by using the `file.close` method:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们能够与文件系统交互，Python提供了内置的`open`函数。可以调用此函数来打开文件并返回一个文件对象。后者允许我们对文件执行各种操作，如读取和写入。当我们完成与文件的交互时，最后必须记得使用`file.close`方法关闭它：
- en: '[PRE29]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: List comprehensions
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列表推导
- en: 'List comprehensions are a powerful tool for creating and manipulating lists.
    They consist of an expression that is followed by a `for` clause and then followed
    by zero, or more,`if` clauses. The syntax for list comprehensions is simply the
    following:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 列表推导是创建和操作列表的强大工具。它们由一个表达式后跟一个`for`子句，然后后跟零个或多个`if`子句。列表推导的语法非常简单：
- en: '[PRE30]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, perform the following:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行以下操作：
- en: '[PRE31]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Running Python scripts
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Python脚本
- en: 'To execute a Python script, simply invoke the Python interpreter followed by
    the script name, in this case, `my_pythonscript.py`. Or, if we are in a different
    working directory, then use its full address:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行Python脚本，只需调用Python解释器，然后是脚本名称，即`my_pythonscript.py`。或者，如果我们在不同的工作目录中，则使用其完整地址：
- en: '[PRE32]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: From now on, for every invocation of a Python script, we will use the preceding
    notation; that is, `python`, followed by `script_name.py`, assuming that the directory
    from which the Python interpreter is launched is the one where the script to be
    execu*ted* resides.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，对于每次调用Python脚本，我们将使用前面的表示法；即`python`，后跟`script_name.py`，假设启动Python解释器的目录是脚本所在的目录。
- en: Installing Python packages using pip
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pip安装Python包
- en: '`pip` is a tool that allows us to search, download, and install Python packages
    found on the Python Package Index, which is a repository that contains tens of
    thousands of packages written in Python. This also allows us to manage the packages
    we have already downloaded, allowing us to update or remove them.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip`是一个工具，允许我们搜索、下载和安装Python包，这些包可以在Python包索引中找到，该索引是一个包含数以万计用Python编写的包的存储库。这也允许我们管理已经下载的包，允许我们更新或删除它们。'
- en: Installing pip
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装pip
- en: '`pip` is already included in Python versions ≥ 3.4 and ≥ 2.7.9\. To check whether
    this tool is already installed, we can run the following command:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip`已经包含在Python版本≥3.4和≥2.7.9中。要检查是否已经安装了这个工具，我们可以运行以下命令：'
- en: '[PRE33]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: If `pip` is already installed, then this command will show us the installed
    version.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`pip`已经安装，则此命令将显示已安装的版本。
- en: Updating pip
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新pip
- en: 'It is also recommended to check that the `pip` version you are using is always
    up to date. To update it, we can use the following command:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 还建议检查您使用的`pip`版本是否始终保持最新。要更新它，我们可以使用以下命令：
- en: '[PRE34]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Using pip
  id: totrans-342
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pip
- en: '`pip` supports a series of commands that allow us,among other things, to *search,
    download, install, update,* and *remove* packages.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip`支持一系列命令，允许我们*搜索、下载、安装、更新*和*删除*软件包，等等。'
- en: 'To install `PACKAGE`, just run the following command:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`PACKAGE`，只需运行以下命令：
- en: '[PRE35]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Introducing Python parallel programming
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Python并行编程
- en: Python provides many libraries and frameworks that facilitate high-performance
    computations. However, doing parallel programming with Python can be quite insidious
    due to the **Global Interpreter Lock** (**GIL**).
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: Python提供了许多库和框架，可以促进高性能计算。但是由于**全局解释器锁**（**GIL**），使用Python进行并行编程可能会非常隐匿。
- en: In fact, the most widespread and widely used Python interpreter, **CPython**,
    is developed in the C programming language. The CPython interpreter needs GIL
    for thread-safe operations. The use of GIL implies that you will encounter a global
    lock when you attempt to access any Python objects contained within threads. And
    only one thread at a time can acquire the lock for a Python object or C API.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，最广泛和广泛使用的Python解释器**CPython**是用C编程语言开发的。 CPython解释器需要GIL来进行线程安全操作。使用GIL意味着当您尝试访问线程中包含的任何Python对象时，您将遇到全局锁。一次只有一个线程可以获取Python对象或C
    API的锁。
- en: Fortunately, things are not so serious, because, outside the realm of GIL, we
    can freely use parallelism. This category includes all the topics that we will
    discuss in the next chapters, including multiprocessing, distributed computing,
    and GPU computing.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，情况并不那么严重，因为在GIL的领域之外，我们可以自由地使用并行性。这包括我们将在接下来的章节中讨论的所有主题，包括多进程、分布式计算和GPU计算。
- en: So, Python is not really multithreaded. But what is a thread? What is a process?
    In the following sections, we will introduce these two fundamental concepts and
    how they are addressed by the Python programming language.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Python实际上并不是多线程的。但是什么是线程？什么是进程？在接下来的章节中，我们将介绍这两个基本概念以及Python编程语言如何处理它们。
- en: Processes and threads
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程和线程
- en: '*Threads* can be compared to light processes, in the sense that they offer
    advantages similar to those of processes, without, however, requiring the typical
    communication techniques of processes. Threads allow you to divide the main control
    flow of a program into multiple concurrently running control streams. Processes,
    by contrast, have their *own* *addressing space* and their own resources*.*It
    follows that communication between parts of code running on different processes
    can only take place through appropriate management mechanisms, including pipes,
    code FIFO, mailboxes, shared memory areas, and message passing. Threads, on the
    other hand, allow the creation of concurrent parts of the program, in which each
    part can access the same address space, variables, and constants.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '*线程*可以与轻量级进程进行比较，因为它们提供了类似进程的优势，但是不需要进程的典型通信技术。线程允许将程序的主控制流分成多个并发运行的控制流。相比之下，进程有它们自己的*地址空间*和自己的资源。这意味着在不同进程上运行的代码部分之间的通信只能通过适当的管理机制进行，包括管道、代码FIFO、邮箱、共享内存区域和消息传递。另一方面，线程允许创建程序的并发部分，其中每个部分都可以访问相同的地址空间、变量和常量。'
- en: 'The following table summarizes the main differences between threads and processes:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了线程和进程之间的主要区别：
- en: '| **Threads** | **Processes** |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| **线程** | **进程** |'
- en: '| --- | --- |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Share memory. | Do not share memory. |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 共享内存。 | 不共享内存。 |'
- en: '| Start/change are computationally less expensive. | Start/change are computationally
    expensive. |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 启动/更改 计算成本较低。 | 启动/更改 计算成本较高。 |'
- en: '| Require fewer resources (light processes). | Require more computational resources.
    |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 需要更少的资源（轻量级进程）。 | 需要更多的计算资源。 |'
- en: '| Need synchronization mechanisms to handle data correctly. | No memory synchronization
    is required. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 需要同步机制来正确处理数据。 | 不需要内存同步。 |'
- en: After this brief introduction, we can finally show how processes and threads
    operate.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简短的介绍之后，我们终于可以展示进程和线程是如何运行的。
- en: 'In particular, we want to compare the serial, multithread, and multiprocess
    execution times of the following function, `do_something`, which performs some
    basic calculations, including building a list of integers selected randomly (a `do_something.py` file):'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们想比较以下函数`do_something`的串行、多线程和多进程执行时间，该函数执行一些基本计算，包括随机选择整数的列表（一个`do_something.py`文件）：
- en: '[PRE36]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next, there is the serial (`serial_test.py`) implementation. Let''s start with
    the relevant imports:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是串行（`serial_test.py`）实现。让我们从相关的导入开始：
- en: '[PRE37]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Note the importing of the module time, which will be used to evaluate the execution
    time, in this instance, and the serial implementation of the `do_something` function. `size`
    of the list to build is equal to `10000000`, while the `do_something` function
    will be executed `10` times:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意导入时间模块，该模块将用于评估执行时间，在本例中，以及`do_something`函数的串行实现。要构建的列表的`size`等于`10000000`，而`do_something`函数将执行`10`次：
- en: '[PRE38]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Next, we have the multithreaded implementation (`multithreading_test.py`).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有多线程实现（`multithreading_test.py`）。
- en: 'Import the relevant libraries:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 导入相关库：
- en: '[PRE39]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Note the import of the `threading` module in order to operate with the multithreading
    capabilities of Python.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意导入`threading`模块，以便使用Python的多线程功能。
- en: Here, there is the multithreading execution of the `do_something` function.
    We will not comment in-depth on the instructions in the following code, as they
    will be discussed in more detail in [Chapter 2](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml), *Thread-Based
    Parallelism*.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，有`do_something`函数的多线程执行。我们不会对以下代码中的指令进行深入评论，因为它们将在[第2章](c95be391-9558-4d2d-867e-96f61fbc5bbf.xhtml)中更详细地讨论，*基于线程的并行性*。
- en: 'However, it should be noted in this case, too, that the length of the list
    is obviously the same as in the serial case, `size = 10000000`, while the number
    of threads defined is 10, `threads = 10`, which is also the number of times the
    `do_something` function must be executed:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这种情况下，也应该注意到，列表的长度显然与串行情况下的长度相同，`size = 10000000`，而定义的线程数为10，`threads =
    10`，这也是必须执行`do_something`函数的次数：
- en: '[PRE40]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Note also the construction of the single thread, through the `threading.Thread`
    method:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意通过`threading.Thread`方法构建单个线程：
- en: '[PRE41]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The sequence of cycles in which we start executing threads and then stop them
    immediately afterwards is as follows:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始执行线程然后立即停止它们的循环顺序如下：
- en: '[PRE42]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Finally, there is the multiprocessing implementation (`multiprocessing_test.py`).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有多进程实现（`multiprocessing_test.py`）。
- en: 'We start by importing the necessary modules and, in particular, the `multiprocessing`
    library, whose features will be explained in-depth in [Chapter 3](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml),
    *Process-Based Parallelism*:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入必要的模块，特别是`multiprocessing`库，其特性将在[第3章](5d4a1d39-061e-4c7c-937c-4ce3c9c6ea93.xhtml)中深入解释，*基于进程的并行*：
- en: '[PRE43]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'As in the previous cases, the length of the list to build, the size, and the
    execution number of the `do_something` function remain the same (`procs = 10`):'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 与先前情况一样，要构建的列表长度，大小和`do_something`函数的执行次数保持不变（`procs = 10`）：
- en: '[PRE44]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Here, the implementation of a single process through the `multiprocessing.Process`
    method call is affected as follows:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，通过`multiprocessing.Process`方法调用单个进程的实现受到如下影响：
- en: '[PRE45]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Next, the sequence of cycles in which we start executing processes and then
    stop them immediately afterwards is executed as follows:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们开始执行进程然后立即停止它们的循环顺序如下执行：
- en: '[PRE46]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Then, we open the command shell and run the three functions described previously.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们打开命令行并运行先前描述的三个函数。
- en: 'Go to the folder where the functions have been copied and then type the following:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 转到已复制函数的文件夹，然后输入以下内容：
- en: '[PRE47]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The result, obtained on a machine with the following features—CPU Intel i7/8
    GB of RAM, is as follows:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是在具有以下特征的机器上获得的 - CPU Intel i7 / 8 GB RAM，如下所示：
- en: '[PRE48]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'In the case of the `multithreading` implementation, we have the following:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在`multithreading`实现的情况下，我们有以下情况：
- en: '[PRE49]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output is as follows:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE50]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Finally, there is the **multiprocessing** implementation:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有**多进程**实现：
- en: '[PRE51]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Its result is as follows:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 其结果如下：
- en: '[PRE52]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: As can be seen, the results of the serial implementation (that is, using `serial_test.py`)
    are similar to those obtained with the implementation of multithreading (using
    `multithreading_test.py`) where the threads are essentially launched one after
    the other, giving precedence to the one over the other until the end, while we
    have benefits in terms of execution times using the Python multiprocessing capability
    (using `multiprocessing_test.py`).
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 可以看到，串行实现的结果（即使用`serial_test.py`）与使用多线程实现的结果类似（使用`multithreading_test.py`），在这种情况下，线程基本上是一个接一个地启动，优先考虑一个而不是另一个，直到结束，而使用Python多进程能力在执行时间方面有益（使用`multiprocessing_test.py`）。
